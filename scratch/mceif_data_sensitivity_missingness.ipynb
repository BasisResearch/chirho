{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-05T22:39:34.511003Z",
     "start_time": "2024-08-05T22:39:33.801850Z"
    }
   },
   "outputs": [],
   "source": [
    "import chirho.observational.handlers\n",
    "import pyro\n",
    "import torch\n",
    "import pyro.distributions as dist\n",
    "from chirho.interventional.handlers import Interventions, do\n",
    "from chirho.counterfactual.handlers.counterfactual import TwinWorldCounterfactual\n",
    "from chirho.counterfactual.handlers.counterfactual import MultiWorldCounterfactual\n",
    "from chirho.indexed.ops import gather, IndexSet\n",
    "from functools import singledispatch\n",
    "from pyro.infer.autoguide import AutoDelta, AutoMultivariateNormal, AutoNormal\n",
    "from functools import partial\n",
    "from chirho.indexed.ops import gather, IndexSet\n",
    "from chirho.observational.handlers import condition\n",
    "from chirho.observational.handlers.condition import Observations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import ceil, sqrt\n",
    "from itertools import product\n",
    "from random import randint\n",
    "from contextlib import nullcontext\n",
    "import matplotlib\n",
    "from utils.build_svi_iter import build_svi_iter\n",
    "from chirho.observational.handlers.predictive import PredictiveModel\n",
    "import seaborn as sns\n",
    "pyro.settings.set(module_local_params=True)\n",
    "\n",
    "# seed = randint(0, int(1e6))\n",
    "# print(seed)\n",
    "seed = 715440\n",
    "\n",
    "pyro.set_rng_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Partial Missingness and Informative Data\n",
    "In this notebook, we'll establish a simple causal model where some of the data is missing. We expect that the data-sensitivity should be larger for data with no missingness, and smaller — but still non-zero — for data with missingness. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c8f0ddadde2915e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "VEC_DIM = -1\n",
    "MAT_DIM = -2\n",
    "DATA_DIM = -3\n",
    "MC_DIM = -4\n",
    "NUM_CONFOUNDERS = 100\n",
    "NUM_OUTCOME = 1\n",
    "NUM_TREATMENT = 30\n",
    "\n",
    "\n",
    "def missingness_likelihood_model(\n",
    "        treatment_coefficients,  # (..., NUM_CONFOUNDERS, NUM_TREATMENT)\n",
    "        confounder_coefficients,  # (..., NUM_CONFOUNDERS, 1)\n",
    "        missingness_coefficients,  # (..., NUM_CONFOUNDERS + NUM_TREATMENT, 1)\n",
    "        outcome_coefficients  # (..., NUM_CONFOUNDERS + NUM_TREATMENT, NUM_OUTCOME)\n",
    "):\n",
    "    \n",
    "    assert treatment_coefficients.shape[-2:] == (NUM_CONFOUNDERS, NUM_TREATMENT),\\\n",
    "        f\"Treatment coefficients shape: {treatment_coefficients.shape}\"\n",
    "    assert confounder_coefficients.shape[-2:] == (NUM_CONFOUNDERS, 1),\\\n",
    "        f\"Confounder coefficients shape: {confounder_coefficients.shape}\"\n",
    "    assert missingness_coefficients.shape[-2:] == (NUM_CONFOUNDERS + NUM_TREATMENT, 1),\\\n",
    "        f\"Missingness coefficients shape: {missingness_coefficients.shape}\"\n",
    "    assert outcome_coefficients.shape[-2:] == (NUM_CONFOUNDERS + NUM_TREATMENT, NUM_OUTCOME),\\\n",
    "        f\"Outcome coefficients shape: {outcome_coefficients.shape}\"\n",
    "    \n",
    "    confounders = pyro.sample(\"conf\", dist.Normal(confounder_coefficients, 1))\n",
    "    assert confounders.shape[-2:] == (NUM_CONFOUNDERS, 1), f\"Confounders shape: {confounders.shape}\"\n",
    "    \n",
    "    treatment_means = treatment_coefficients.transpose(-2, -1) @ confounders\n",
    "    assert treatment_means.shape[-2:] == (NUM_TREATMENT, 1), f\"Treatment means shape: {treatment_means.shape}\"\n",
    "    \n",
    "    treatment = pyro.sample(\"treat\", dist.Normal(treatment_means, 1))\n",
    "    assert treatment.shape[-2:] == (NUM_TREATMENT, 1), f\"Treatment shape: {treatment.shape}\"\n",
    "    \n",
    "    # HACK treatment may have been intervened on and have had dimensions added on the left. This breaks the cats below.\n",
    "    # To resolve, expand the left dimensions of the confounders to match the treatment dimensions.\n",
    "    if len(treatment.shape) > len(confounders.shape):\n",
    "        # HACK hardcoding a single left split dimension.\n",
    "        confounders = confounders[None, ...].expand((treatment.shape[0],) + (-1,) * (len(treatment.shape) - 1))\n",
    "    \n",
    "    missingness_logit = missingness_coefficients.transpose(-2, -1) @ torch.cat([confounders, treatment], dim=-2)\n",
    "    assert missingness_logit.shape[-2:] == (1, 1), f\"Missingness logit shape: {missingness_logit.shape}\"\n",
    "    \n",
    "    missingness = pyro.sample(\"miss\", dist.Bernoulli(logits=missingness_logit))\n",
    "    assert missingness.shape[-2:] == (1, 1), f\"Missingness shape: {missingness.shape}\"\n",
    "    \n",
    "    outcome_means = outcome_coefficients.transpose(-2, -1) @ torch.cat([confounders, treatment], dim=-2)\n",
    "    assert outcome_means.shape[-2:] == (NUM_OUTCOME, 1), f\"Outcome means shape: {outcome_means.shape}\"\n",
    "    \n",
    "    # HACK to make outcome still be computationally non-deterministic (so we can condition on it) when missingness is zero.\n",
    "    outcome = pyro.sample(\"out\", dist.Normal(outcome_means * missingness, 1. * missingness + 1e-3))\n",
    "    assert outcome.shape[-2:] == (NUM_OUTCOME, 1), f\"Outcome shape: {outcome.shape}\"\n",
    "    \n",
    "    return dict(\n",
    "        conf=confounders,\n",
    "        treat=treatment,\n",
    "        miss=missingness,\n",
    "        out=outcome\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T22:39:34.526808Z",
     "start_time": "2024-08-05T22:39:34.514586Z"
    }
   },
   "id": "4d1517a308497729",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def coefficient_prior():\n",
    "    with pyro.plate(\"conf_plate\", NUM_CONFOUNDERS, dim=MAT_DIM):\n",
    "        confounder_coefficients = pyro.sample(\"confounder_coefficients\", dist.Normal(0, 1.))\n",
    "    \n",
    "        with pyro.plate(\"treat_plate\", NUM_TREATMENT, dim=VEC_DIM):\n",
    "            treatment_coefficients = pyro.sample(\"treatment_coefficients\", dist.Normal(0., 1))\n",
    "    \n",
    "    with pyro.plate(\"conf_treat_plate\", NUM_CONFOUNDERS + NUM_TREATMENT, dim=MAT_DIM):\n",
    "        missingness_coefficients = pyro.sample(\"missingness_coefficients\", dist.Normal(0., 1.))\n",
    "        \n",
    "        with pyro.plate(\"out_plate\", NUM_OUTCOME, dim=VEC_DIM):\n",
    "            outcome_coefficients = pyro.sample(\"outcome_coefficients\", dist.Normal(0., 1.))\n",
    "    \n",
    "    return dict(\n",
    "        confounder_coefficients=confounder_coefficients,\n",
    "        treatment_coefficients=treatment_coefficients,\n",
    "        missingness_coefficients=missingness_coefficients,\n",
    "        outcome_coefficients=outcome_coefficients\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T22:39:34.527148Z",
     "start_time": "2024-08-05T22:39:34.517602Z"
    }
   },
   "id": "9947e218ede35328",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def full_missingness_model(num_data=1):\n",
    "    coefficients = coefficient_prior()\n",
    "    \n",
    "    with pyro.plate(\"data\", num_data, dim=DATA_DIM):\n",
    "        return missingness_likelihood_model(**coefficients), coefficients"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T22:39:34.527423Z",
     "start_time": "2024-08-05T22:39:34.519626Z"
    }
   },
   "id": "b3d1c6155e226777",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed data shapes:\n",
      "('conf', torch.Size([200, 100, 1]))\n",
      "('treat', torch.Size([200, 30, 1]))\n",
      "('miss', torch.Size([200, 1, 1]))\n",
      "('out', torch.Size([200, 1, 1]))\n",
      "True coefficients shapes:\n",
      "('confounder_coefficients', torch.Size([100, 1]))\n",
      "('treatment_coefficients', torch.Size([100, 30]))\n",
      "('missingness_coefficients', torch.Size([130, 1]))\n",
      "('outcome_coefficients', torch.Size([130, 1]))\n"
     ]
    }
   ],
   "source": [
    "NOBSERVED = 200\n",
    "observed_data, true_coefficients = full_missingness_model(NOBSERVED)\n",
    "print(\"Observed data shapes:\")\n",
    "print('\\n'.join([str((k, v.shape)) for k, v in observed_data.items()]))\n",
    "print(\"True coefficients shapes:\")\n",
    "print('\\n'.join([str((k, v.shape)) for k, v in true_coefficients.items()]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T22:39:34.527733Z",
     "start_time": "2024-08-05T22:39:34.521937Z"
    }
   },
   "id": "1e9c558a51bd60a4",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missingness rate: 87.50%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missingness rate: {1. - observed_data['miss'].mean().item():.2%}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T22:39:34.529438Z",
     "start_time": "2024-08-05T22:39:34.526407Z"
    }
   },
   "id": "fc1f102e56d733e",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for treatment_idx in range(NUM_TREATMENT):\n",
    "#     plt.scatter(observed_data[\"treat\"].detach()[..., treatment_idx, 0], observed_data[\"out\"].detach()[..., 0, 0], c=observed_data[\"miss\"].detach()[..., 0, 0])\n",
    "#     plt.xlabel(\"Treatment\")\n",
    "#     plt.ylabel(\"Outcome\")\n",
    "#     plt.title(f\"Treatment {treatment_idx}\")\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T22:39:34.544027Z",
     "start_time": "2024-08-05T22:39:34.529744Z"
    }
   },
   "id": "6bb866cf6183804f",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stochastic Variational Inference"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a269a37b7be2fc4f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "conditioned_missingness_model = condition(partial(full_missingness_model, NOBSERVED), data=observed_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T22:39:34.558841Z",
     "start_time": "2024-08-05T22:39:34.531435Z"
    }
   },
   "id": "db74138e00137419",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.0.0 (20240704.0754)\n -->\n<!-- Pages: 1 -->\n<svg width=\"687pt\" height=\"479pt\"\n viewBox=\"0.00 0.00 687.00 478.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 474.5)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-474.5 683,-474.5 683,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_conf_plate</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"8,-345.5 8,-462.5 438,-462.5 438,-345.5 8,-345.5\"/>\n<text text-anchor=\"middle\" x=\"401.5\" y=\"-352.7\" font-family=\"Times,serif\" font-size=\"14.00\">conf_plate</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_treat_plate</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"226,-378 226,-454.5 430,-454.5 430,-378 226,-378\"/>\n<text text-anchor=\"middle\" x=\"393.5\" y=\"-385.2\" font-family=\"Times,serif\" font-size=\"14.00\">treat_plate</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_conf_treat_plate</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"240,-156.5 240,-273.5 671,-273.5 671,-156.5 240,-156.5\"/>\n<text text-anchor=\"middle\" x=\"619.12\" y=\"-163.7\" font-family=\"Times,serif\" font-size=\"14.00\">conf_treat_plate</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_out_plate</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"465,-189 465,-265.5 663,-265.5 663,-189 465,-189\"/>\n<text text-anchor=\"middle\" x=\"629.88\" y=\"-196.2\" font-family=\"Times,serif\" font-size=\"14.00\">out_plate</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_data</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"120,-8 120,-337.5 232,-337.5 232,-8 120,-8\"/>\n<text text-anchor=\"middle\" x=\"212.75\" y=\"-15.2\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n</g>\n<!-- confounder_coefficients -->\n<g id=\"node1\" class=\"node\">\n<title>confounder_coefficients</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"116\" cy=\"-428.5\" rx=\"100.48\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"116\" y=\"-423.45\" font-family=\"Times,serif\" font-size=\"14.00\">confounder_coefficients</text>\n</g>\n<!-- conf -->\n<g id=\"node5\" class=\"node\">\n<title>conf</title>\n<ellipse fill=\"gray\" stroke=\"black\" cx=\"155\" cy=\"-311.5\" rx=\"27.3\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"155\" y=\"-306.45\" font-family=\"Times,serif\" font-size=\"14.00\">conf</text>\n</g>\n<!-- confounder_coefficients&#45;&gt;conf -->\n<g id=\"edge1\" class=\"edge\">\n<title>confounder_coefficients&#45;&gt;conf</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.92,-410.03C128.21,-391.5 138.23,-361.95 145.6,-340.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"148.89,-341.41 148.79,-330.81 142.26,-339.16 148.89,-341.41\"/>\n</g>\n<!-- treatment_coefficients -->\n<g id=\"node2\" class=\"node\">\n<title>treatment_coefficients</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"328\" cy=\"-428.5\" rx=\"93.83\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"328\" y=\"-423.45\" font-family=\"Times,serif\" font-size=\"14.00\">treatment_coefficients</text>\n</g>\n<!-- treat -->\n<g id=\"node6\" class=\"node\">\n<title>treat</title>\n<ellipse fill=\"gray\" stroke=\"black\" cx=\"196\" cy=\"-239.5\" rx=\"27.3\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"196\" y=\"-234.45\" font-family=\"Times,serif\" font-size=\"14.00\">treat</text>\n</g>\n<!-- treatment_coefficients&#45;&gt;treat -->\n<g id=\"edge2\" class=\"edge\">\n<title>treatment_coefficients&#45;&gt;treat</title>\n<path fill=\"none\" stroke=\"black\" d=\"M315.82,-410.24C292.34,-376.98 240.76,-303.91 213.57,-265.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"216.71,-263.77 208.08,-257.62 210.99,-267.81 216.71,-263.77\"/>\n</g>\n<!-- missingness_coefficients -->\n<g id=\"node3\" class=\"node\">\n<title>missingness_coefficients</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"352\" cy=\"-239.5\" rx=\"103.56\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"352\" y=\"-234.45\" font-family=\"Times,serif\" font-size=\"14.00\">missingness_coefficients</text>\n</g>\n<!-- miss -->\n<g id=\"node7\" class=\"node\">\n<title>miss</title>\n<ellipse fill=\"gray\" stroke=\"black\" cx=\"196\" cy=\"-130.5\" rx=\"28.32\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"196\" y=\"-125.45\" font-family=\"Times,serif\" font-size=\"14.00\">miss</text>\n</g>\n<!-- missingness_coefficients&#45;&gt;miss -->\n<g id=\"edge4\" class=\"edge\">\n<title>missingness_coefficients&#45;&gt;miss</title>\n<path fill=\"none\" stroke=\"black\" d=\"M329.16,-221.77C305.95,-204.92 268.86,-178.35 236,-156.5 232.7,-154.3 229.21,-152.04 225.73,-149.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"227.69,-146.92 217.36,-144.55 223.96,-152.84 227.69,-146.92\"/>\n</g>\n<!-- outcome_coefficients -->\n<g id=\"node4\" class=\"node\">\n<title>outcome_coefficients</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"564\" cy=\"-239.5\" rx=\"90.76\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"564\" y=\"-234.45\" font-family=\"Times,serif\" font-size=\"14.00\">outcome_coefficients</text>\n</g>\n<!-- out -->\n<g id=\"node8\" class=\"node\">\n<title>out</title>\n<ellipse fill=\"gray\" stroke=\"black\" cx=\"175\" cy=\"-58.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"175\" y=\"-53.45\" font-family=\"Times,serif\" font-size=\"14.00\">out</text>\n</g>\n<!-- outcome_coefficients&#45;&gt;out -->\n<g id=\"edge9\" class=\"edge\">\n<title>outcome_coefficients&#45;&gt;out</title>\n<path fill=\"none\" stroke=\"black\" d=\"M548.38,-221.5C530.7,-203.16 500.28,-174.22 469,-156.5 383.25,-107.92 269.5,-79.17 211.86,-66.76\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"212.76,-63.38 202.26,-64.74 211.32,-70.23 212.76,-63.38\"/>\n</g>\n<!-- conf&#45;&gt;treat -->\n<g id=\"edge3\" class=\"edge\">\n<title>conf&#45;&gt;treat</title>\n<path fill=\"none\" stroke=\"black\" d=\"M164.51,-294.26C169.37,-285.96 175.41,-275.65 180.89,-266.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"183.74,-268.35 185.78,-257.95 177.7,-264.81 183.74,-268.35\"/>\n</g>\n<!-- conf&#45;&gt;miss -->\n<g id=\"edge5\" class=\"edge\">\n<title>conf&#45;&gt;miss</title>\n<path fill=\"none\" stroke=\"black\" d=\"M150.88,-293.5C144.63,-263.69 135.84,-200.91 160,-156.5 161.4,-153.93 163.19,-151.56 165.23,-149.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167.4,-152.15 172.81,-143.04 162.9,-146.79 167.4,-152.15\"/>\n</g>\n<!-- conf&#45;&gt;out -->\n<g id=\"edge7\" class=\"edge\">\n<title>conf&#45;&gt;out</title>\n<path fill=\"none\" stroke=\"black\" d=\"M146.72,-293.97C144.01,-287.72 141.35,-280.44 140,-273.5 130.05,-222.46 132.56,-207.96 140,-156.5 143.58,-131.76 153.66,-105.16 162.09,-86.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"165.19,-87.72 166.17,-77.17 158.83,-84.8 165.19,-87.72\"/>\n</g>\n<!-- treat&#45;&gt;miss -->\n<g id=\"edge6\" class=\"edge\">\n<title>treat&#45;&gt;miss</title>\n<path fill=\"none\" stroke=\"black\" d=\"M196,-221.31C196,-204.77 196,-179.48 196,-159.94\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"199.5,-160.16 196,-150.16 192.5,-160.16 199.5,-160.16\"/>\n</g>\n<!-- treat&#45;&gt;out -->\n<g id=\"edge10\" class=\"edge\">\n<title>treat&#45;&gt;out</title>\n<path fill=\"none\" stroke=\"black\" d=\"M187.01,-222.19C177.88,-204.62 164.34,-175.52 159,-148.5 154.95,-128 159.44,-104.77 164.68,-87.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167.99,-88.29 167.77,-77.7 161.34,-86.12 167.99,-88.29\"/>\n</g>\n<!-- miss&#45;&gt;out -->\n<g id=\"edge8\" class=\"edge\">\n<title>miss&#45;&gt;out</title>\n<path fill=\"none\" stroke=\"black\" d=\"M190.92,-112.55C188.62,-104.9 185.85,-95.66 183.27,-87.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"186.7,-86.31 180.47,-77.74 179.99,-88.32 186.7,-86.31\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.graphs.Digraph at 0x28404af90>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.render_model(conditioned_missingness_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T22:39:34.676432Z",
     "start_time": "2024-08-05T22:39:34.533673Z"
    }
   },
   "id": "627012d7a3ec5f2a",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 9.60%\r"
     ]
    }
   ],
   "source": [
    "svi = build_svi_iter(\n",
    "    conditioned_missingness_model,\n",
    "    AutoMultivariateNormal,\n",
    "    lr=2e-3\n",
    ")\n",
    "NITER = 4000\n",
    "for i in range(NITER):\n",
    "    svi.svi_iter()\n",
    "    print(f\"Progress {(i+1)/NITER:.2%}\", end=\"\\r\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-08-05T22:39:34.678042Z"
    }
   },
   "id": "c02e7fe6bb0a2943",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.plot(svi.losses)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b52893ceac951690",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check Performance of Plug-In Estimator\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5022343924d9cce0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MultivariateTreatmentGrid(torch.nn.Module):\n",
    "    def __init__(self, model, values, num_monte_carlo: int = 100, results_shaper=None, constant_idices=None, generate_product_values=False):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.num_monte_carlo = num_monte_carlo\n",
    "        self.results_shaper = results_shaper or (lambda x: x)\n",
    "        self.constant_idices = constant_idices or {}\n",
    "        \n",
    "        if generate_product_values:\n",
    "            # Expand values over the grid of treatments.\n",
    "            product_values = []\n",
    "            for value in product(values, repeat=NUM_TREATMENT):\n",
    "                # HACK manually specifying the broadcast shape...\n",
    "                product_values.append(torch.tensor(value)[None, None, :, None])\n",
    "            assert len(product_values) == 2 ** NUM_TREATMENT\n",
    "            \n",
    "            self.product_values = tuple(product_values)\n",
    "        else:\n",
    "            # HACK manually specifying the broadcast shape...\n",
    "            self.product_values = tuple(v[None, None, :, None] for v in values)\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        with MultiWorldCounterfactual():\n",
    "            with pyro.plate(\"monte_carlo_functional\", size=self.num_monte_carlo, dim=MC_DIM):\n",
    "                with do(actions=dict(treat=self.product_values)):\n",
    "                    predictive_samples, coefficient_samples = self.model(*args, **kwargs)\n",
    "                    Ys = predictive_samples[\"out\"]\n",
    "                \n",
    "                outs = []\n",
    "                for i, _ in enumerate(self.product_values):\n",
    "                    idx_set = IndexSet(treat={i+1}, **self.constant_idices)\n",
    "                    outs.append(gather(Ys, idx_set))\n",
    "                    \n",
    "        return self.results_shaper(outs)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d4fcb3bf1aa26638",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def reshape_results_to_mean(results):\n",
    "    results = torch.cat(results, dim=0)  # (len(product_values), num_monte_carlo, num_data, NUM_OUTCOME, 1)\n",
    "    return results.squeeze(-1).mean(-2).mean(-2)  # (len(product_values), NUM_OUTCOME)\n",
    "\n",
    "def reshape_results_to_estimates(results):\n",
    "    results = torch.cat(results, dim=0)  # (len(product_values), num_monte_carlo, num_data, NUM_OUTCOME, 1)\n",
    "    results = results.squeeze(-1).transpose(-1, 1)  # (len(product_values), NUM_OUTCOME, num_monte_carlo, num_data)\n",
    "    return results.reshape(results.shape[:2] + (-1,))\n",
    "\n",
    "NMC = 1e2\n",
    "NBD = 1\n",
    "# intervention_values = (-10., 10.)\n",
    "intervention_values = (torch.ones(NUM_TREATMENT) * -10., torch.ones(NUM_TREATMENT) * 10.)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "38da77302d4148ad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "full_missingness_model_wo_missingness = do(full_missingness_model, {\"miss\": torch.tensor(1.)})"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5118609ac4e19304",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "true_model = condition(full_missingness_model_wo_missingness, data=true_coefficients)\n",
    "true_results = MultivariateTreatmentGrid(\n",
    "    true_model,\n",
    "    intervention_values,\n",
    "    num_monte_carlo=NMC,\n",
    "    constant_idices=dict(miss={1})\n",
    ")(num_data=NBD)\n",
    "true_result_estimates = reshape_results_to_estimates(true_results)\n",
    "print(true_result_estimates.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "97b75ecbeb2c17d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "posterior_predictive_model = PredictiveModel(full_missingness_model_wo_missingness, svi.guide)\n",
    "posterior_results = MultivariateTreatmentGrid(\n",
    "    posterior_predictive_model,\n",
    "    intervention_values,\n",
    "    num_monte_carlo=NMC,\n",
    "    constant_idices=dict(miss={1})\n",
    ")(num_data=NBD)\n",
    "posterior_result_estimates = reshape_results_to_estimates(posterior_results)\n",
    "print(posterior_result_estimates.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6afef017b6899f67",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prior_predictive_model = full_missingness_model\n",
    "prior_results = MultivariateTreatmentGrid(\n",
    "    full_missingness_model_wo_missingness,\n",
    "    intervention_values,\n",
    "    num_monte_carlo=NMC,\n",
    "    constant_idices=dict(miss={1})\n",
    ")(num_data=NBD)\n",
    "prior_result_estimates = reshape_results_to_estimates(prior_results)\n",
    "print(prior_result_estimates.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b59baf8bb0a46e46",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_intervention_outcome_grid(*results):\n",
    "    num_interventions = results[0].shape[0]\n",
    "    num_outcomes = results[0].shape[1]\n",
    "    fig, axs = plt.subplots(num_outcomes, num_interventions, figsize=(num_interventions * 5, num_outcomes * 5), sharey=True, sharex=True)\n",
    "    \n",
    "    if not isinstance(axs, np.ndarray):\n",
    "        axs = np.array([axs])\n",
    "    if axs.ndim == 1:\n",
    "        axs = axs[None, :]\n",
    "    \n",
    "    for i, j in product(range(num_interventions), range(num_outcomes)):\n",
    "        mean = results[0][i, j].mean().item()\n",
    "        axs[j, i].axvline(mean, color=\"black\", linestyle=\"--\")\n",
    "        \n",
    "        for result in results:\n",
    "            sns.kdeplot(result[i, j].detach().numpy(), ax=axs[j, i], fill=False)\n",
    "        \n",
    "        \n",
    "    return fig, axs"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "21688317d58bb662",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_, axs = plot_intervention_outcome_grid(true_result_estimates, posterior_result_estimates, prior_result_estimates)\n",
    "# Add legend to the first plot.\n",
    "axs[0, 0].legend([\"True Effect\", \"True\", \"Post Pred\", \"Prior Pred\"])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d032e67fcd5dbc4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TODO Add Robust Estimator to Above"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c7aaf9db5dd5bea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
