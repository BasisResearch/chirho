{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=-1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=-1\n",
    "\n",
    "import os\n",
    "\n",
    "import contextlib\n",
    "from typing import Callable, Mapping, TypeVar, Union\n",
    "\n",
    "import pyro.distributions.constraints as constraints\n",
    "import torch\n",
    "\n",
    "from chirho.explainable.handlers.components import (\n",
    "    consequent_neq,\n",
    "    random_intervention,\n",
    "    sufficiency_intervention,\n",
    "    undo_split,\n",
    ")\n",
    "from chirho.explainable.handlers.preemptions import Preemptions\n",
    "from chirho.interventional.handlers import do\n",
    "from chirho.interventional.ops import Intervention\n",
    "from chirho.observational.handlers.condition import Factors\n",
    "\n",
    "S = TypeVar(\"S\")\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Callable, Mapping, TypeVar, Union\n",
    "\n",
    "\n",
    "from chirho.observational.handlers import condition\n",
    "from chirho.counterfactual.handlers.counterfactual import MultiWorldCounterfactual\n",
    "from chirho.explainable.handlers import SplitSubsets, SearchForExplanation #, SearchForNS\n",
    "\n",
    "\n",
    "from chirho.indexed.ops import (IndexSet, gather, indices_of) \n",
    "from chirho.interventional.handlers import do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_disjunctive():\n",
    "        match_dropped = pyro.sample(\"match_dropped\", dist.Bernoulli(0.7)) # notice uneven probs here\n",
    "        lightning = pyro.sample(\"lightning\", dist.Bernoulli(0.4))\n",
    "\n",
    "        forest_fire = pyro.deterministic(\"forest_fire\", torch.max(match_dropped, lightning), event_dim=0)\n",
    "\n",
    "        return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n",
    "\n",
    "observations = {\"match_dropped\": torch.tensor(1.), \n",
    "                \"lightning\": torch.tensor(0.),\n",
    "                \"forest_fire\": torch.tensor(1.)}\n",
    "\n",
    "antecedents = {\"match_dropped\": torch.tensor(0.0)} \n",
    "\n",
    "witnesses = {} # ignore witnesses for now\n",
    "\n",
    "consequents = {\"forest_fire\": constraints.boolean}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[8.]]]]])\n",
      "IndexSet({'match_dropped': {0, 1, 2}})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with MultiWorldCounterfactual() as mwc:\n",
    "    with do(actions = {\"match_dropped\": (torch.tensor(0.0), torch.tensor(8.0))}):\n",
    "        with condition(data = observations):\n",
    "            with pyro.poutine.trace() as int_trace:\n",
    "                            ff_disjunctive()\n",
    "\n",
    "print(int_trace.trace.nodes['match_dropped']['value'])  \n",
    "\n",
    "with mwc:\n",
    "    print(indices_of(int_trace.trace.nodes['match_dropped']['value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-inf, -inf, 0., 0., 0., 0., 0., 0., 0., 0.]]]]])\n"
     ]
    }
   ],
   "source": [
    "with MultiWorldCounterfactual() as ffd_mwc:  # needed to keep track of multiple scenarios\n",
    "    with SearchForExplanation(antecedents = antecedents, \n",
    "                              witnesses = witnesses,\n",
    "                              consequents = consequents,\n",
    "                              consequent_scale= 1e-8):\n",
    "        with condition(data = observations):\n",
    "            with pyro.plate(\"sample\", 10): # run a few times\n",
    "                with pyro.poutine.trace() as ffd_tr:\n",
    "                    ff_disjunctive()\n",
    "\n",
    "ffd_tr.trace.compute_log_prob() \n",
    "ffd_nd = ffd_tr.trace.nodes\n",
    "\n",
    "with ffd_mwc: \n",
    "    original_intervened = gather(ffd_nd['__consequent_forest_fire']['log_prob'], \n",
    "                IndexSet(**{'match_dropped': {1}}))\n",
    "    print(original_intervened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def SearchForNS(\n",
    "    antecedents: Union[\n",
    "        Mapping[str, Intervention[T]],\n",
    "        Mapping[str, constraints.Constraint],\n",
    "    ],\n",
    "    witnesses: Union[\n",
    "        Mapping[str, Intervention[T]], Mapping[str, constraints.Constraint]\n",
    "    ],\n",
    "    consequents: Union[\n",
    "        Mapping[str, Callable[[T], Union[float, torch.Tensor]]],\n",
    "        Mapping[str, constraints.Constraint],\n",
    "    ],\n",
    "    *,\n",
    "    antecedent_bias: float = 0.0,\n",
    "    witness_bias: float = 0.0,\n",
    "    consequent_scale: float = 1e-2,\n",
    "    antecedent_prefix: str = \"__antecedent_\",\n",
    "    witness_prefix: str = \"__witness_\",\n",
    "    consequent_prefix: str = \"__consequent_\",\n",
    "):\n",
    "    \"\"\"\n",
    "    # TODO revise this docstring\n",
    "    Effect handler used for causal explanation search. On each run:\n",
    "\n",
    "      1. The antecedent nodes are intervened on with the values in ``antecedents`` \\\n",
    "        using :func:`~chirho.counterfactual.ops.split` . \\\n",
    "        Unless alternative interventions are provided, \\\n",
    "        counterfactual values are uniformly sampled for each antecedent node \\\n",
    "        using :func:`~chirho.explainable.internals.uniform_proposal` \\\n",
    "        given its support as a :class:`~pyro.distributions.constraints.Constraint`.\n",
    "\n",
    "      2. These interventions are randomly :func:`~chirho.explainable.ops.preempt`-ed \\\n",
    "        using :func:`~chirho.explainable.handlers.undo_split` \\\n",
    "        by a :func:`~chirho.explainable.handlers.SplitSubsets` handler.\n",
    "\n",
    "      3. The witness nodes are randomly :func:`~chirho.explainable.ops.preempt`-ed \\\n",
    "        to be kept at the values given in ``witnesses``.\n",
    "\n",
    "      4. A :func:`~pyro.factor` node is added tracking whether the consequent nodes differ \\\n",
    "        between the factual and counterfactual worlds.\n",
    "\n",
    "    :param antecedents: A mapping from antecedent names to interventions or to constraints.\n",
    "    :param witnesses: A mapping from witness names to interventions or to constraints.\n",
    "    :param consequents: A mapping from consequent names to factor functions or to constraints.\n",
    "    \"\"\"\n",
    "    if antecedents and isinstance(\n",
    "        next(iter(antecedents.values())),\n",
    "        constraints.Constraint,\n",
    "    ):\n",
    "        \n",
    "        antecedents_supports = {a: s for a, s in antecedents.items()}\n",
    "\n",
    "        antecedents = {\n",
    "            a: (\n",
    "                random_intervention(s, name=f\"{antecedent_prefix}_proposal_{a}\"),\n",
    "                sufficiency_intervention(s, antecedents.keys()),\n",
    "            )\n",
    "            for a, s in antecedents_supports.items()\n",
    "        }\n",
    "    else:\n",
    "        \n",
    "        antecedents_supports = {a: constraints.boolean for a in antecedents.keys()}\n",
    "        # TODO generalize to non-scalar antecedents\n",
    " \n",
    "        \n",
    "        antecedents = {\n",
    "            a: (\n",
    "                antecedents[a], \n",
    "                sufficiency_intervention(s, antecedents.keys())\n",
    "                )\n",
    "             \n",
    "            for a, s in antecedents_supports.items()\n",
    "        }\n",
    "\n",
    "\n",
    "    if witnesses and isinstance(\n",
    "        next(iter(witnesses.values())),\n",
    "        constraints.Constraint,\n",
    "    ):\n",
    "        witnesses = {\n",
    "            w: undo_split(s, antecedents=list(antecedents.keys()))\n",
    "            for w, s in witnesses.items()\n",
    "        }\n",
    "\n",
    "    if consequents and isinstance(\n",
    "        next(iter(consequents.values())),\n",
    "        constraints.Constraint,\n",
    "    ):\n",
    "        consequents_neq = {\n",
    "            c: consequent_neq(\n",
    "                support=s,\n",
    "                antecedents=list(antecedents.keys()),\n",
    "                scale=consequent_scale, #TODO allow for different scales for neq and eq\n",
    "            )\n",
    "            for c, s in consequents.items()\n",
    "        }\n",
    "\n",
    "    if len(consequents_neq) == 0:\n",
    "        raise ValueError(\"must have at least one consequent\")\n",
    "\n",
    "    if len(antecedents) == 0:\n",
    "        raise ValueError(\"must have at least one antecedent\")\n",
    "\n",
    "    if set(consequents_neq.keys()) & set(antecedents.keys()):\n",
    "        raise ValueError(\"consequents and possible antecedents must be disjoint\")\n",
    "\n",
    "    if set(consequents_neq.keys()) & set(witnesses.keys()):\n",
    "        raise ValueError(\"consequents and possible witnesses must be disjoint\")\n",
    "\n",
    "    antecedent_handler = SplitSubsets(\n",
    "        supports=antecedents_supports,\n",
    "        actions=antecedents,\n",
    "        bias=antecedent_bias,\n",
    "        prefix=antecedent_prefix,\n",
    "    )\n",
    "\n",
    "    witness_handler: Preemptions = Preemptions(\n",
    "        actions=witnesses, bias=witness_bias, prefix=witness_prefix\n",
    "    )\n",
    "\n",
    "    consequent_neq_handler = Factors(factors=consequents_neq, prefix=f\"{consequent_prefix}_neq\")\n",
    "\n",
    "    with antecedent_handler, witness_handler, consequent_neq_handler:\n",
    "        yield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'consequent_handler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m MultiWorldCounterfactual() \u001b[38;5;28;01mas\u001b[39;00m ffd_ns_mwc:  \u001b[38;5;66;03m# needed to keep track of multiple scenarios\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m SearchForNS(antecedents \u001b[38;5;241m=\u001b[39m antecedents,\n\u001b[1;32m      3\u001b[0m     antecedent_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \n\u001b[1;32m      4\u001b[0m                               witnesses \u001b[38;5;241m=\u001b[39m witnesses,\n\u001b[1;32m      5\u001b[0m                               consequents \u001b[38;5;241m=\u001b[39m consequents,\n\u001b[1;32m      6\u001b[0m                               consequent_scale\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-8\u001b[39m):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m condition(data \u001b[38;5;241m=\u001b[39m observations):\n\u001b[1;32m      8\u001b[0m                 \u001b[38;5;28;01mwith\u001b[39;00m pyro\u001b[38;5;241m.\u001b[39mpoutine\u001b[38;5;241m.\u001b[39mtrace() \u001b[38;5;28;01mas\u001b[39;00m ffd_ns_tr:\n",
      "File \u001b[0;32m~/miniconda3/envs/chirho/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 124\u001b[0m, in \u001b[0;36mSearchForNS\u001b[0;34m(antecedents, witnesses, consequents, antecedent_bias, witness_bias, consequent_scale, antecedent_prefix, witness_prefix, consequent_prefix)\u001b[0m\n\u001b[1;32m    118\u001b[0m witness_handler: Preemptions \u001b[38;5;241m=\u001b[39m Preemptions(\n\u001b[1;32m    119\u001b[0m     actions\u001b[38;5;241m=\u001b[39mwitnesses, bias\u001b[38;5;241m=\u001b[39mwitness_bias, prefix\u001b[38;5;241m=\u001b[39mwitness_prefix\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m consequent_neq_handler \u001b[38;5;241m=\u001b[39m Factors(factors\u001b[38;5;241m=\u001b[39mconsequents_neq, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconsequent_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_neq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m antecedent_handler, witness_handler, \u001b[43mconsequent_handler\u001b[49m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'consequent_handler' is not defined"
     ]
    }
   ],
   "source": [
    "with MultiWorldCounterfactual() as ffd_ns_mwc:  # needed to keep track of multiple scenarios\n",
    "    with SearchForNS(antecedents = antecedents,\n",
    "    antecedent_bias = -0.5, \n",
    "                              witnesses = witnesses,\n",
    "                              consequents = consequents,\n",
    "                              consequent_scale= 1e-8):\n",
    "        with condition(data = observations):\n",
    "                with pyro.poutine.trace() as ffd_ns_tr:\n",
    "                    ff_disjunctive()\n",
    "\n",
    "ffd_ns_tr.trace.compute_log_prob() \n",
    "ffd_ns_nd = ffd_ns_tr.trace.nodes\n",
    "\n",
    "\n",
    "with mwc:\n",
    "    print(\"sufficiency_interv\", sufficiency_intervention(\n",
    "        constraints.boolean, [\"match_dropped\"])(\n",
    "        ffd_ns_nd['match_dropped']['value'])\n",
    "    )\n",
    "    print(indices_of(ffd_ns_nd['forest_fire']['value']))\n",
    "\n",
    "\n",
    "print(ffd_ns_nd['match_dropped']['value'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chirho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
