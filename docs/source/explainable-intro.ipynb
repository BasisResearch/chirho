{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable reasoning with ChiRho (categorical variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The **Explainable Reasoning with ChiRho** package aims to provide a systematic, unified approach to causal explanation computations in terms of different probabilistic queries over expanded causal models that are constructed from a single generic program transformation applied to an arbitrary causal model represented as a ChiRho program. The approach of reducing causal queries to probabilistic computations on transformed causal models is the foundational idea behind all of ChiRho. The key strategy underlying \"causal explanation\" queries is their use of auxiliary variables representing uncertainty over which interventions or preemptions to apply, implicitly inducing a search space over counterfactuals.\n",
    "\n",
    "The goal of this notebook is to illustrate how the package can be used to provide approximate method of answering a range of causal explanation queries with respect to models in which the key role is played by categorical variables. Continuous variables are in the focus of another notebook.\n",
    "\n",
    "In [another notebook](https://basisresearch.github.io/chirho/actual_causality.html) we illustrate how the module allows for a faithful reconstration of a specific notion of local explanation that inspired some of the conceptual moves underlying the current implementation  (the so-called Halpern-Pearl modified definition of actual causality [(J. Halpern, MIT Press, 2016)](https://mitpress.mit.edu/9780262537131/actual-causality/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "[Introduction and motivations](#intuitions-and-motivations)\n",
    "    \n",
    "- [The but-for condition](#the-but-for-condtition)\n",
    "\n",
    "- [Witness nodes and context-sensitivity](#witness-nodes-and-context-sensitivity)\n",
    "\n",
    "[Simplified actual causality](#simplified-actual-causality)\n",
    "\n",
    "[Probability of causation](#probability-of-causation)\n",
    "\n",
    "[Causal explanation](#causal-explanation)\n",
    "\n",
    "[Responsibility attribution](#responsibility-attribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "\n",
    "from chirho.observational.handlers import condition\n",
    "from chirho.counterfactual.handlers.counterfactual import MultiWorldCounterfactual\n",
    "from chirho.explainable.handlers import SearchForExplanation\n",
    "                                            \n",
    "from chirho.indexed.ops import (IndexSet, gather, indices_of) \n",
    "from chirho.interventional.handlers import do\n",
    "\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "runs_n = 5 if smoke_test else 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and motivations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a model of a very simplistic situation, in which a forest fire can be cause by exactly one of two causes: a match being dropped (`match_dropped`), or a lightning (`lightning`), and either of these factors on its own is already deterministcally sufficient for the `forest_fire` to occur. In general, you think a match being dropped is more likely than a lightning (we use fairly large probabilities for the same of example transparency). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'match_dropped': tensor(1.),\n",
       " 'lightning': tensor(0.),\n",
       " 'forest_fire': tensor(1.)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ff_disjunctive():\n",
    "        match_dropped = pyro.sample(\"match_dropped\", dist.Bernoulli(0.7)) # notice uneven probs here\n",
    "        lightning = pyro.sample(\"lightning\", dist.Bernoulli(0.4))\n",
    "\n",
    "        forest_fire = pyro.deterministic(\"forest_fire\", torch.max(match_dropped, lightning), event_dim=0)\n",
    "\n",
    "        return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n",
    "\n",
    "# each run is stochastic\n",
    "ff_disjunctive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose in this particular case you know a forest fire has occured, a match has been dropped, but no lightning occured. This further assumption can be introduced by conditioning on these observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'match_dropped': tensor(1.), 'lightning': tensor(0.), 'forest_fire': tensor(1.)}\n"
     ]
    }
   ],
   "source": [
    "observations = {\"match_dropped\": torch.tensor(1.), \n",
    "                \"lightning\": torch.tensor(0.),\n",
    "                \"forest_fire\": torch.tensor(1.)}\n",
    "\n",
    "with condition(data = observations):\n",
    "    with pyro.poutine.trace() as tr:\n",
    "        ff_disjunctive()\n",
    "\n",
    "# now it is determined how things play out\n",
    "print({key: tr.trace.nodes[key][\"value\"] for key in tr.trace.nodes.keys()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a particular context like this, when you know what happened, or at least know the values of some of the variables at play, you might be interested in using the model to answer a range of causal-explanation related questions.\n",
    "\n",
    "- Did the match being dropped actually cause the fire?\n",
    "- Suppose you only know that the forest fire occured, what are the likely explanations? How likely are they?\n",
    "- Suppose you know both factors occured, to what extent should they be deemed responsible for this outcome?\n",
    "\n",
    "Let's see how these can be addressed using ChiRho. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The but-for condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Witness nodes and context-sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified actual causality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of causation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responsibility attribution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chirho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
