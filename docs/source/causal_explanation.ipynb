{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import contextlib\n",
    "import collections\n",
    "from typing import Callable, Iterable, TypeVar, Mapping, List, Dict\n",
    "\n",
    "\n",
    "from itertools import chain, combinations\n",
    "\n",
    "import random\n",
    "\n",
    "import pyro\n",
    "import torch  \n",
    "\n",
    "from chirho.counterfactual.handlers.selection import get_factual_indices\n",
    "from chirho.indexed.ops import IndexSet, cond, gather, indices_of, scatter\n",
    "\n",
    "S = TypeVar(\"S\")\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "import pyro\n",
    "import chirho\n",
    "import pyro.distributions as dist\n",
    "import pyro.infer\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from chirho.counterfactual.handlers.counterfactual import (MultiWorldCounterfactual,\n",
    "        Preemptions)\n",
    "from chirho.counterfactual.handlers.explanation import (\n",
    "    SearchForCause,\n",
    "    consequent_differs,\n",
    "    random_intervention,\n",
    "    undo_split,\n",
    "    uniform_proposal,\n",
    "    ExplainCauses\n",
    ")\n",
    "from chirho.counterfactual.ops import preempt, split\n",
    "from chirho.indexed.ops import IndexSet, gather, indices_of\n",
    "from chirho.observational.handlers.condition import Factors, condition\n",
    "from chirho.interventional.ops import Intervention, intervene\n",
    "from chirho.interventional.handlers import do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorize_dictionary(dictionary):\n",
    "    return {k: torch.as_tensor(v) for k, v in dictionary.items()}\n",
    "\n",
    "def boolean_constraints_from_list(list):\n",
    "    return {k: pyro.distributions.constraints.boolean for k in list}\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def Explanation_Evaluation( \n",
    "        consequents_observed: Dict[str, torch.Tensor],\n",
    "        causal_candidates: List[str],\n",
    "        condition_on_consequent = True,\n",
    "        runs_n: int = 100,):\n",
    "\n",
    "        consequents = list(consequents_observed.keys())\n",
    "        consequents_observed = tensorize_dictionary(consequents_observed)\n",
    "        # this needs to be replaced if nodes are not boolean\n",
    "        causal_candidate_constraints = boolean_constraints_from_list(causal_candidates)\n",
    "\n",
    "        # needed in order to check if always a part of the antecedent set is a part of an actual cause\n",
    "        with MultiWorldCounterfactual() as mwc:\n",
    "            with ExplainCauses(antecedents = causal_candidate_constraints, \n",
    "                      witnesses = causal_candidates, consequents = consequents,\n",
    "                      antecedent_bias = .1,):\n",
    "                if condition_on_consequent:\n",
    "                    with condition(data = consequents_observed):\n",
    "                        with pyro.plate(\"sample\", runs_n):\n",
    "                            with pyro.poutine.trace() as tr:\n",
    "                                yield {\"mwc\": mwc, \"tr\" : tr}\n",
    "                else:\n",
    "                    with pyro.plate(\"sample\", runs_n):\n",
    "                        with pyro.poutine.trace() as tr:\n",
    "                            yield {\"mwc\": mwc, \"tr\" : tr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the original definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace obtained using the above handler already contains information that can be used to implement the original definition. Such a query can be answered with only two core concepts: subset inclusion and log prob sum comparison. First, let's implement this definition. Later on, we'll move beyond some of the idiosyncracies involved here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a table from the trace\n",
    "# post sampling conditioning on observations or interventions\n",
    "\n",
    "def gather_observed(value, causal_candidates):\n",
    "            \n",
    "    _indices = [i for i in causal_candidates if i in indices_of(value, event_dim=0)]\n",
    "    _int_can = gather(value, IndexSet(**{i: {0} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "def gather_intervened(value, causal_candidates):\n",
    "        \n",
    "    _indices = [i for i in causal_candidates if i in indices_of(value, event_dim=0)]\n",
    "    _int_can = gather(value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "def get_explanation_table(trace, mwc, causal_candidates, consequents):\n",
    "\n",
    "    trace.trace.compute_log_prob()\n",
    "    \n",
    "    table_dict = {}\n",
    "    nodes = trace.trace.nodes\n",
    "\n",
    "    for candidate in causal_candidates:\n",
    "        with mwc:\n",
    "            table_dict[f\"obs_{candidate}\"] = gather_observed(nodes[candidate]['value'],\n",
    "                                                             causal_candidates).squeeze().tolist()\n",
    "    \n",
    "            \n",
    "        table_dict[f\"pint_{candidate}\"] = nodes[f'__antecedent__proposal_{candidate}']['value'].squeeze().tolist()\n",
    "        table_dict[f\"apre_{candidate}\"] = nodes[f'__antecedent_{candidate}']['value'].squeeze().tolist()\n",
    "        table_dict[f\"lp_apre_{candidate}\"] = nodes[f\"__antecedent_{candidate}\"]['log_prob']\n",
    "\n",
    "        table_dict[f\"wpre_{candidate}\"] = nodes[f'__witness_{candidate}']['value'].squeeze().tolist()\n",
    "\n",
    "        # context used twice to make the table more legible (meaningful column ordering)\n",
    "        with mwc:\n",
    "            table_dict[f\"int_{candidate}\"] = gather_intervened(nodes[candidate]['value'],\n",
    "                                                             causal_candidates).squeeze().tolist()\n",
    "            \n",
    "\n",
    "    for consequent in consequents:\n",
    "        with mwc:\n",
    "            table_dict[f\"obs_{consequent}\"] = gather_observed(nodes[consequent][\"value\"], causal_candidates).squeeze().tolist()\n",
    "            table_dict[f\"int_{consequent}\"] = gather_intervened(nodes[consequent][\"value\"], causal_candidates).squeeze().tolist()\n",
    "            table_dict[f\"lp_{consequent}\"] = gather_intervened(nodes[f\"__consequent_{consequent}\"][\"log_prob\"], causal_candidates).squeeze().tolist()\n",
    "        \n",
    "\n",
    "    table_pd = pd.DataFrame(table_dict).drop_duplicates()\n",
    "\n",
    "    # remove rows where proposed interventions are the same as the observed values\n",
    "    for candidate in causal_candidates:\n",
    "        mask = table_pd[f'obs_{candidate}'] != table_pd[f'pint_{candidate}']\n",
    "        table_pd = table_pd[mask]\n",
    "      \n",
    "    \n",
    "    summands = [col for col in table_pd.columns if col.startswith('lp')]\n",
    "    table_pd[\"sum_lp\"] =  table_pd[summands].sum(axis = 1)\n",
    "    table_pd.sort_values(by = \"sum_lp\", ascending = False, inplace = True)\n",
    "\n",
    "    # some sanity checks\n",
    "    for candidate in causal_candidates:\n",
    "        \n",
    "        # witness preempted nodes have the same observed and intervened values\n",
    "        assert all(table_pd.loc[table_pd[f'wpre_{candidate}'] == 1, \n",
    "        f'obs_{candidate}'] == table_pd.loc[table_pd[f'wpre_{candidate}'] == 1,\n",
    "                                            f'int_{candidate}'])\n",
    "\n",
    "        # antecedent preemptions leave obs and int values unchanged\n",
    "        # this might fail generally if a node is downstream from some \n",
    "        # other intervention, but let's keep this sanity check for the simple models \n",
    "        # for now        \n",
    "        assert all(table_pd.loc[table_pd[f'apre_{candidate}'] == 1,\n",
    "                                f'obs_{candidate}'] == \n",
    "                   table_pd.loc[table_pd[f'apre_{candidate}'] == 1,\n",
    "                                f'int_{candidate}'])\n",
    "\n",
    "    return table_pd\n",
    "\n",
    "\n",
    "# brute force conditioning on the observed causal candidates\n",
    "# needed as adding them to condition statements leads to shape errors\n",
    "# needed to implement the original def, not needed later on\n",
    "\n",
    "# post-sampling conditioning on observations\n",
    "def get_conditioned_table(table, dict_of_nodes):\n",
    "    conditioned_table = table.copy()\n",
    "    for candidate in dict_of_nodes.keys():\n",
    "        obs_column = f'obs_{candidate}'\n",
    "        mask = (conditioned_table[obs_column] == dict_of_nodes[candidate])\n",
    "        conditioned_table = conditioned_table[mask]\n",
    "        conditioned_table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return conditioned_table\n",
    "\n",
    "# post-sampling conditioning on selected variables being intervened\n",
    "def get_intervened_table(table, dict_of_nodes):\n",
    "    intervened_table = table.copy()\n",
    "    for candidate in dict_of_nodes.keys():\n",
    "        condition_string = f\"`apre_{candidate}` == 0 and `wpre_{candidate}` == 0 and int_{candidate} == {dict_of_nodes[candidate]}\"        \n",
    "        intervened_table = intervened_table.query(condition_string)\n",
    "        intervened_table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return intervened_table\n",
    "    \n",
    "\n",
    "# a few other utility functions\n",
    "def powerset(dct):\n",
    "    keys = list(dct.keys())\n",
    "    key_tuples = list(chain.from_iterable(combinations(keys, r) for r in range(len(keys) + 1)))[:-1]\n",
    "    subdicts = [{k: dct[k] for k in tpl} for tpl in key_tuples]\n",
    "    return subdicts\n",
    "\n",
    "def active(node, row):\n",
    "    return row[f\"apre_{node}\"] == 0 and row[f\"wpre_{node}\"] == 0 and row[f\"obs_{node}\"] != row[f\"pint_{node}\"]\n",
    "\n",
    "def minimal_sets(set_list):\n",
    "    inclusion_minimal = []\n",
    "    for s1 in set_list:\n",
    "        is_minimal = True\n",
    "        for s2 in set_list:\n",
    "            if s1 != s2 and s2.issubset(s1):\n",
    "                is_minimal = False\n",
    "        if is_minimal:\n",
    "            inclusion_minimal.append(s1)\n",
    "    return inclusion_minimal\n",
    "\n",
    "\n",
    "def minimal_cause_sets(table, causal_candidates_dict):\n",
    "    \n",
    "    subset_minimal_causes = []\n",
    "    # TODO remove if really redundant\n",
    "    subset_logprobs = []\n",
    "    changers = table[table['sum_lp']  > -1e7].copy()\n",
    "    \n",
    "    for _, row in changers.iterrows():\n",
    "        active_set = {node for node in causal_candidates_dict.keys() if active(node, row)}\n",
    "        if active_set not in subset_minimal_causes:\n",
    "            subset_minimal_causes.append(active_set)\n",
    "    # TODO remove if really redudnant\n",
    "    #        subset_logprobs.append(row['sum_lp'])\n",
    "        subset_minimal_causes = minimal_sets(subset_minimal_causes)\n",
    "        \n",
    "    return subset_minimal_causes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explanation_Halpern():\n",
    "\n",
    "    def __init__(self, table, consequent_dict, causal_candidates_dict):\n",
    "        self.table = table\n",
    "        self.consequent_dict = consequent_dict\n",
    "        self.causal_candidates_dict = causal_candidates_dict\n",
    "\n",
    "        self.ex1A = self.ex1A_check(self.table, consequent_dict= self.consequent_dict, causal_candidates_dict= self.causal_candidates_dict)\n",
    "        self.ex1B = self.ex1B_check(self.table, consequent_dict=self.consequent_dict, causal_candidates_dict= self.causal_candidates_dict)\n",
    "        self.ex2 = self.ex2_check(self.table, consequent_dict= self.consequent_dict, causal_candidates_dict= self.causal_candidates_dict)\n",
    "        self.ex3_4 = self.ex3_4_check(self.table, consequent_dict=self.consequent_dict, causal_candidates_dict=self.causal_candidates_dict)\n",
    "\n",
    "    \n",
    "    def ex1A_check(self, table, consequent_dict, causal_candidates_dict):\n",
    "\n",
    "        # suppose not only consequent but also the causal candidates are observed    \n",
    "        merged_dict = {**consequent_dict, **causal_candidates_dict}\n",
    "        \n",
    "        table_conditioned = get_conditioned_table(table, merged_dict)\n",
    "\n",
    "        # check if causal candidates coincide with a minimal cause set\n",
    "        minimal_conditioned = minimal_cause_sets(table_conditioned, causal_candidates_dict)\n",
    "        parthood_flag = any(any(candidate in s for candidate in causal_candidates_dict.keys()) for s in minimal_conditioned)   \n",
    "        return parthood_flag, minimal_conditioned\n",
    "    \n",
    "   \n",
    "    def ex1B_check(self, table, causal_candidates_dict, consequent_dict):\n",
    "        table_intervened = get_intervened_table(table, causal_candidates_dict)\n",
    "        return all((table_intervened[f\"int_{key}\"] == consequent_dict[key]).all() for key in consequent_dict.keys()) \n",
    "\n",
    "    \n",
    "    def ex2_check(self, table,  consequent_dict, causal_candidates_dict,):\n",
    "        sub_candidates = powerset(causal_candidates_dict)\n",
    "        minimality_flag = True\n",
    "        for sub_candidate in sub_candidates:\n",
    "            ex1A_flag = self.ex1A_check(table, consequent_dict= consequent_dict, causal_candidates_dict= sub_candidate)[0]\n",
    "            ex1B_flag = self.ex1B_check(table, consequent_dict = consequent_dict, causal_candidates_dict= sub_candidate)\n",
    "            \n",
    "            if ex1A_flag and ex1B_flag:\n",
    "                minimality_flag = False\n",
    "                break\n",
    "        return minimality_flag\n",
    "    \n",
    "    \n",
    "    def ex3_4_check(self, table, consequent_dict, causal_candidates_dict):\n",
    "\n",
    "        merged_dict = {**consequent_dict, **causal_candidates_dict}\n",
    "        table_conditioned = get_conditioned_table(table, merged_dict)\n",
    "        ex3 = table_conditioned.shape[0] > 0\n",
    "        ex4 = any(any(table[f\"obs_{key}\"] != causal_candidates_dict[key]) for key in causal_candidates_dict.keys())\n",
    "\n",
    "        return ex3, ex4\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyro.infer.config_enumerate\n",
    "def ff_conjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() & lightning.bool()),\n",
    "                                      event_dim=0)\n",
    "\n",
    "@pyro.infer.config_enumerate\n",
    "def ff_disjunctive():\n",
    "        u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "        u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "        match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "        lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "        forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() | lightning.bool()).bool(), event_dim=0)\n",
    "\n",
    "        return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "consequents_observed={\"forest_fire\": torch.tensor(True)}\n",
    "causal_candidates=[\"match_dropped\", \"lightning\"]\n",
    "causal_candidates_dict = {\"match_dropped\": 1., \"lightning\": 1.}\n",
    "antecedent_prefix = \"__antecedent\"\n",
    "\n",
    "exp_ff_con_handler =  Explanation_Evaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= 1000,\n",
    ")\n",
    "\n",
    "exp_ff_dis_handler =  Explanation_Evaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= 1000,\n",
    ")\n",
    "\n",
    "with exp_ff_con_handler as con_ff:\n",
    "        ff_conjunctive()\n",
    "\n",
    "with exp_ff_dis_handler as dis_ff:\n",
    "        ff_disjunctive()\n",
    "\n",
    "table_con_ff = get_explanation_table(con_ff[\"tr\"], con_ff[\"mwc\"], causal_candidates, consequents=[\"forest_fire\"])\n",
    "table_dis_ff = get_explanation_table(dis_ff[\"tr\"], dis_ff[\"mwc\"], causal_candidates, consequents=[\"forest_fire\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TraceENUM_ELBO works with bare model, doesn't seem to work \n",
    "# with Explanation_Evaluation\n",
    "\n",
    "# def exp_ff_conjunctive():\n",
    "#     exp_ff_con_handler =  Explanation_Evaluation(\n",
    "#     consequents_observed=consequents_observed,\n",
    "#     causal_candidates= causal_candidates,\n",
    "#     runs_n= 1000,\n",
    "#     )\n",
    "#     with exp_ff_con_handler as con_ff:\n",
    "#         ff_conjunctive()\n",
    "\n",
    "# def guide():\n",
    "#     pass\n",
    "\n",
    "# works with bare model\n",
    "#ff_conjunctive_conditioned = pyro.condition(ff_conjunctive, data={\"forest_fire\": torch.tensor(True)})\n",
    "#pyro.infer.TraceEnum_ELBO().compute_marginals(ff_conjunctive_conditioned, guide)\n",
    "\n",
    "#doesn't work here\n",
    "#pyro.infer.TraceEnum_ELBO().compute_marginals(exp_ff_conjunctive,guide)\n",
    "\n",
    "# will proceed with sampling from the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, [{'match_dropped'}, {'lightning'}])\n",
      "True\n",
      "True\n",
      "(True, True)\n"
     ]
    }
   ],
   "source": [
    "con_ff_explanation = Explanation_Halpern(table_con_ff, {\"forest_fire\": True}, causal_candidates_dict)\n",
    "\n",
    "print(con_ff_explanation.ex1A)\n",
    "print(con_ff_explanation.ex1B)\n",
    "print(con_ff_explanation.ex2)\n",
    "print(con_ff_explanation.ex3_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, [{'lightning', 'match_dropped'}])\n",
      "True\n",
      "False\n",
      "(True, True)\n"
     ]
    }
   ],
   "source": [
    "dis_ff_explanation = Explanation_Halpern(table_dis_ff, {\"forest_fire\": True}, causal_candidates_dict)\n",
    "\n",
    "print(dis_ff_explanation.ex1A)\n",
    "print(dis_ff_explanation.ex1B)\n",
    "print(dis_ff_explanation.ex2)\n",
    "print(dis_ff_explanation.ex3_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condition 1 requires that (A) in all contexts in which the causal candidates have the postulated values and the consequent is changed, there is at least one member of the causal candidates that is a member of a minimal actual cause of that change to the consequent. Moreover, it requires that (B) for any context under consideration, intervening on all causal candidates to have the postulated value leads to the change in the consequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex1A (True, [{'match_dropped'}, {'lightning'}])\n",
      "ex1A sub (True, [{'match_dropped'}, {'lightning'}])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# intervening on all candidates without conditioning on the outcome\n",
    "#table_causal_candidates = get_intervened_table(table, causal_candidates_hypothetical)\n",
    "# conditioning on outcome\n",
    "\n",
    "\n",
    "def ex1A_check(table, consequent_dict, causal_candidates_dict):\n",
    "\n",
    "    # suppose not only consequent but also the causal candidates are observed    \n",
    "    merged_dict = {**consequent_dict, **causal_candidates_dict}\n",
    "    table_conditioned = get_conditioned_table(table, merged_dict)\n",
    "    \n",
    "    # check if causal candidates coincide with a minimal cause set\n",
    "    minimal_conditioned = minimal_cause_sets(table_conditioned)\n",
    "    parthood_flag = any(any(candidate in s for candidate in causal_candidates_dict.keys()) for s in minimal_conditioned)   \n",
    "    return parthood_flag, minimal_conditioned\n",
    "\n",
    "print(\"ex1A\",\n",
    "ex1A_check(table, {\"forest_fire\": True}, causal_candidates_dict)\n",
    ")\n",
    "\n",
    "\n",
    "print(\"ex1A sub\",\n",
    "ex1A_check(table, {\"forest_fire\": True}, {\"match_dropped\": 1.})\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex1B True\n",
      "ex1B_sub_md False\n",
      "ex1B_sub_l False\n"
     ]
    }
   ],
   "source": [
    "# in the intervened model, is the consequent always as specified in `consequent_dict`\n",
    "def ex1B_check(table, consequent_dict, causal_candidates_dict):\n",
    "    table_intervened = get_intervened_table(table, causal_candidates_dict)\n",
    "    return all((table_intervened[f\"int_{key}\"] == consequent_dict[key]).all() for key in consequent_dict.keys()) \n",
    "\n",
    "# the conjunction is sufficient\n",
    "print(\"ex1B\",\n",
    "ex1B_check(table,{'forest_fire': True}, causal_candidates_dict)\n",
    ")\n",
    "\n",
    "# but single conjuncts are not\n",
    "print(\"ex1B_sub_md\",\n",
    "ex1B_check(table,{'forest_fire': True}, {\"match_dropped\": 1.})  \n",
    ")\n",
    "\n",
    "print(\"ex1B_sub_l\",\n",
    "ex1B_check(table,{'forest_fire': True}, {\"lightning\": 1.})  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second condition of Halpern's definition is that the causal candidate set be a subset-minimal one satisfying both `ex1A` and `ex1B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def powerset(dct):\n",
    "    keys = list(dct.keys())\n",
    "    key_tuples = list(chain.from_iterable(combinations(keys, r) for r in range(len(keys) + 1)))[:-1]\n",
    "    subdicts = [{k: dct[k] for k in tpl} for tpl in key_tuples]\n",
    "    return subdicts\n",
    "\n",
    "\n",
    "consequent_dict =  {'forest_fire': True}\n",
    "\n",
    "\n",
    "\n",
    "def ex2_check(table, consequent_dict, causal_candidates_dict):\n",
    "    sub_candidates = powerset(causal_candidates_dict)\n",
    "    minimality_flag = True\n",
    "    for sub_candidate in sub_candidates:\n",
    "        ex1A_flag = ex1A_check(table, consequent_dict, sub_candidate)[0]\n",
    "        ex1B_flag = ex1B_check(table, consequent_dict, sub_candidate)\n",
    "        \n",
    "        if ex1A_flag and ex1B_flag:\n",
    "            minimality_flag = False\n",
    "            break\n",
    "    return minimality_flag\n",
    "\n",
    "print(ex2_check(table, consequent_dict, causal_candidates_dict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, True)\n"
     ]
    }
   ],
   "source": [
    "def ex3_4_check(table, consequent_dict, causal_candidates_dict):\n",
    "\n",
    "    merged_dict = {**consequent_dict, **causal_candidates_dict}\n",
    "    table_conditioned = get_conditioned_table(table, merged_dict)\n",
    "    ex3 = table_conditioned.shape[0] > 0\n",
    "    ex4 = any(any(table[f\"obs_{key}\"] != causal_candidates_dict[key]) for key in causal_candidates_dict.keys())\n",
    "\n",
    "    return ex3, ex4\n",
    "\n",
    "print(ex3_4_check(table, consequent_dict, causal_candidates_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this reduces the actual causality check to checking a property of the resulting sums of log probabilities\n",
    "# for the antecedent preemption and the consequent differs nodes\n",
    "\n",
    "def ac_check(trace, mwc, antecedents, witnesses, consequents):\n",
    "\n",
    "     table = get_table(trace, mwc, antecedents, witnesses, consequents)\n",
    "     \n",
    "     if (list(table['sum_log_prob'])[0]<= -1e8):\n",
    "          print(\"No resulting difference to the consequent in the sample.\")\n",
    "          return\n",
    "     \n",
    "     winners = table[table['sum_log_prob'] == table['sum_log_prob'].max()]\n",
    "     \n",
    "\n",
    "     ac_flags = []\n",
    "     for index, row in winners.iterrows():\n",
    "          active_antecedents = []\n",
    "          for antecedent in antecedents:\n",
    "               if row[f\"apr_{antecedent}\"] == 0:\n",
    "                    active_antecedents.append(antecedent)\n",
    "\n",
    "          ac_flags.append(set(active_antecedents) == set(antecedents))\n",
    "\n",
    "     if not any(ac_flags):\n",
    "          print(\"The antecedent set is not minimal.\")\n",
    "     else:\n",
    "          print(\"The antecedent set is an actual cause.\")\n",
    "\n",
    "     return any(ac_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing of traces\n",
    "# to identify potential explanations\n",
    "\n",
    "# Is always a part of the antecedent\n",
    "# a part of an actual cause of the consequent?\n",
    "def sufficient_causality_checkA(output_dict, antecedents = None, witnesses = None, consequents = None):\n",
    "\n",
    "    if antecedents is None:\n",
    "        antecedents = output_dict['antecedents']\n",
    "    if consequents is None:\n",
    "        consequents = list(output_dict['consequents_observed'].keys())\n",
    "    \n",
    "    endogenous_nodes = output_dict['endogenous_nodes']\n",
    "    causal_candidates = output_dict['causal_candidates']\n",
    "\n",
    "    if witnesses is None:\n",
    "        witnesses = [node for node in endogenous_nodes if (\n",
    "                                          node not in antecedents.keys() and \n",
    "                                          node not in consequents)]\n",
    "\n",
    "    table = get_table(output_dict['tr_sufficiency_A'],\n",
    "                      output_dict['mwc_sufficiency_A'],\n",
    "                      antecedents, witnesses, \n",
    "                      consequents)\n",
    "\n",
    "    # a bit hacky, but adding antecedents to conditioning\n",
    "    # within the first batch of handlers\n",
    "    # led to tensor broadcasting issues\n",
    "    for antecedent_str in antecedents.keys():\n",
    "        table = table[table[f\"{antecedent_str}_obs\"] == antecedents[antecedent_str]]\n",
    "    \n",
    "    table = table[table['sum_log_prob'] > -1e8]\n",
    "    \n",
    "    # we need to check set inclusion minimality of cause sets\n",
    "    # as there might be inclusion minimal sets that are not log-prob-sum minimal\n",
    "    # just because they have a higher cardinality\n",
    "    candidate_sets = []\n",
    "    for i, row in table.iterrows():\n",
    "        candidate_set = set()\n",
    "        for node in causal_candidates:\n",
    "            if row[f\"{node}_int\"] != row[f\"{node}_obs\"]:\n",
    "                candidate_set.add(node)\n",
    "        candidate_sets.append(candidate_set)\n",
    "        \n",
    "    actual_cause_sets = minimal_sets(candidate_sets)\n",
    "        \n",
    "    frozensets = [frozenset(s) for s in actual_cause_sets]\n",
    "    unique_actual_cause_sets = [set(f) for f in set(frozensets)]\n",
    "        \n",
    "    sufficiency_flag = any(key in ac_set for key in antecedents.keys() for ac_set in actual_cause_sets)\n",
    "\n",
    "    return  unique_actual_cause_sets, sufficiency_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does fixing the antecedent always lead to a change in the consequent?\n",
    "\n",
    "def sufficient_causality_checkB(output_dict, mwc = None, trace = None, antecedents = None, consequents = None):\n",
    "    \n",
    "    if antecedents is None:\n",
    "        antecedents = output_dict['antecedents']\n",
    "    if consequents is None:\n",
    "        consequents = list(output_dict['consequents_observed'].keys())\n",
    "    \n",
    "    if trace is None:    \n",
    "        trace = output_dict[\"tr_sufficiency_B\"]    \n",
    "    \n",
    "    if mwc is None:\n",
    "        mwc = output_dict[\"mwc_sufficiency_B\"]\n",
    "    \n",
    "    outcome_df = pd.DataFrame()\n",
    "    with mwc:\n",
    "        for consequent in consequents:\n",
    "            value = trace.trace.nodes[consequent][\"value\"]\n",
    "            _indices = [\n",
    "                    i for i in list(antecedents.keys()) if i in indices_of(value, event_dim=0)\n",
    "                ]\n",
    "            _int_con = gather(\n",
    "            value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "            outcome_df[consequent] = _int_con.squeeze().tolist()\n",
    "        \n",
    "    return ((outcome_df) == True).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the antecedent set a minimal set that \n",
    "# satisfies these two conditions?\n",
    "\n",
    "def minimal_sufficiency_check(output_dict):\n",
    "    antecedent_candidates = powerset(output_dict['antecedents'])\n",
    "    \n",
    "    a_checks = []\n",
    "    b_checks = []\n",
    "    for i, antecedent_candidate in enumerate(antecedent_candidates):\n",
    "        a_checks.append(sufficient_causality_checkA(\n",
    "            output_dict,antecedents = antecedent_candidate,            \n",
    "                witnesses = [node for node in output_dict['endogenous_nodes'] if (\n",
    "                            node not in antecedent_candidate.keys() and \n",
    "                            node not in output_dict['consequents_observed'].keys())])[1]\n",
    "        )\n",
    "    \n",
    "        b_checks.append( sufficient_causality_checkB(output_dict, \n",
    "                                                     mwc = output_dict[\"mwc_candidate\"][i],\n",
    "                                                     trace = output_dict[\"tr_candidate\"][i],\n",
    "                                            antecedents = antecedent_candidate)\n",
    "            )\n",
    "        \n",
    "    minimality = not any(a and b for a,b in zip(a_checks, b_checks))       \n",
    "    \n",
    "    return {\"minimality\": minimality, \"a_checks\": a_checks, \"b_checks\": b_checks, \"antecedent_candidates\": antecedent_candidates}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the explanation possible and nontrivial?\n",
    "\n",
    "def possibility_and_nontriviality_check(output_dict):\n",
    "    \n",
    "    trace = output_dict[\"tr_priors\"]\n",
    "    antecedents = output_dict['antecedents']\n",
    "    consequents_observed = output_dict['consequents_observed']\n",
    "    \n",
    "    reqs = {**antecedents, **consequents_observed}\n",
    "\n",
    "    reqs_outcome = pd.DataFrame()\n",
    "\n",
    "    for req in reqs:\n",
    "        reqs_outcome[req] = trace.trace.nodes[req][\"value\"]\n",
    "           \n",
    "    possibility = (reqs_outcome == 1.0).all(axis=1).any()\n",
    "    nontriviality = (reqs_outcome.iloc[:, :2] == 0.0).any(axis=1).any()\n",
    "    \n",
    "    return possibility, nontriviality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explanation_check(output_object):\n",
    "    \n",
    "    sufficiencyA = sufficient_causality_checkA(output_object)[1]\n",
    "    sufficiencyB = sufficient_causality_checkB(output_object)\n",
    "    minimal_sufficiency = minimal_sufficiency_check(output_object)['minimality']\n",
    "    possibility, nontriviality = possibility_and_nontriviality_check(output_object)\n",
    "    \n",
    "    return all([sufficiencyA, sufficiencyB, minimal_sufficiency, possibility, nontriviality])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest fire example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 7.1.2. from Halpern's *Actual Causality*. First, all contexts available, no settings excluded by what the agent knows about the world. In the conjunctive model, the joint nodes are an explanation of forest fire, none of the individual ones is. In the disjunctive model, the reverse is true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_conjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() & lightning.bool()),\n",
    "                                      event_dim=0)\n",
    "\n",
    "def ff_disjunctive():\n",
    "        u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "        u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "        match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "        lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "        forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() | lightning.bool()).bool(), event_dim=0)\n",
    "\n",
    "        return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ff_con_handler =  Explanation_Evaluation(\n",
    "    model = ff_conjunctive,\n",
    "    antecedents={\"match_dropped\": 1.0, \"lightning\": 1.0},\n",
    "    consequents_observed={\"forest_fire\": torch.tensor(True)},\n",
    "    endogenous_nodes=[\"match_dropped\", \"lightning\", \"forest_fire\"],\n",
    ")\n",
    "    \n",
    "with exp_ff_con_handler as con_ff:\n",
    "    ff_conjunctive()\n",
    "    \n",
    "explanation_check(con_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ff_con_separate_handler =  Explanation_Evaluation(\n",
    "    model = ff_conjunctive,\n",
    "    antecedents={\"match_dropped\": 1.0},\n",
    "    consequents_observed={\"forest_fire\": torch.tensor(True)},\n",
    "    endogenous_nodes=[\"match_dropped\", \"lightning\", \"forest_fire\"],\n",
    ")\n",
    "     \n",
    "with exp_ff_con_separate_handler as con_ff_separate:\n",
    "    ff_conjunctive()\n",
    "    \n",
    "explanation_check(con_ff_separate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ff_dis_handler =  Explanation_Evaluation(\n",
    "    model = ff_disjunctive,\n",
    "    antecedents={\"match_dropped\": 1.0, \"lightning\": 1.0},\n",
    "    consequents_observed={\"forest_fire\": torch.tensor(True)},\n",
    "    endogenous_nodes=[\"match_dropped\", \"lightning\", \"forest_fire\"],\n",
    ") \n",
    "    \n",
    "with exp_ff_dis_handler as dis_ff:\n",
    "    ff_disjunctive()\n",
    "\n",
    "explanation_check(dis_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ff_dis_separate_handler =  Explanation_Evaluation(\n",
    "    model = ff_disjunctive,\n",
    "    antecedents={\"match_dropped\": 1.0},\n",
    "    consequents_observed={\"forest_fire\": torch.tensor(True)},\n",
    "    endogenous_nodes=[\"match_dropped\", \"lightning\", \"forest_fire\"],\n",
    ") \n",
    "\n",
    "with exp_ff_dis_separate_handler as dis_ff_separate:\n",
    "    ff_disjunctive()\n",
    "\n",
    "explanation_check(dis_ff_separate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended forest fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In April, given the electrical storm in May, the forest would have caught fire in May (and not in June). However, given the storm, if there had been an electrical storm only in May, the forest\n",
    "would not have caught fire at all; if there had been an electrical storm only in June, it would have caught fire in June. The model has five endogenous variables: `ar` for *April rains*, \n",
    "`esm` for *electric storms in May*, `esj` for *electric storms in June*, `ffm` for *forest fire in May*, `ffj` for *forest fire in June* and `ff` for *forest fire either in May or in June (or both)*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_extended():\n",
    "    u_ar = pyro.sample(\"u_ar\", dist.Bernoulli(0.5))\n",
    "    u_esm = pyro.sample(\"u_esm\", dist.Bernoulli(0.5))\n",
    "    u_esj = pyro.sample(\"u_esj\", dist.Bernoulli(0.5))\n",
    "\n",
    "    ar = pyro.deterministic(\"ar\", u_ar, event_dim=0)\n",
    "    esm = pyro.deterministic(\"esm\", u_esm, event_dim=0)\n",
    "    esj = pyro.deterministic(\"esj\", u_esj, event_dim=0)\n",
    "\n",
    "    ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
    "    ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
    "\n",
    "    ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
    "\n",
    "    return {\"u_ar\": u_ar, \"u_esm\": u_esm, \"u_esj\": u_esj, \n",
    "            \"ar\": ar, \"esm\": esm, \"esj\": esj, \"ffm\": ffm, \"ffj\": ffj, \"ff\": ff}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with no excluded settings\n",
    "# one explanation for ff is esj\n",
    "\n",
    "exp_ff_extended_handler =  Explanation_Evaluation(\n",
    "    model = ff_extended,\n",
    "    antecedents={\"esj\": 1.},\n",
    "    consequents_observed={\"ff\": 1.},\n",
    "    endogenous_nodes=[\"ar\", \"esm\", \"esj\"],\n",
    ") \n",
    "\n",
    "with exp_ff_extended_handler as ext_ff1:\n",
    "    ff_extended()\n",
    "\n",
    "explanation_check(ext_ff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another is esm=1 and ar=0\n",
    "\n",
    "exp_ff_extended_handler2 =  Explanation_Evaluation(\n",
    "    model = ff_extended,\n",
    "    antecedents= {\"esm\": 1., \"ar\": 0.},\n",
    "    consequents_observed={\"ff\": 1.},\n",
    "    endogenous_nodes=[\"ar\", \"esm\", \"esj\"],\n",
    ") \n",
    "\n",
    "with exp_ff_extended_handler2 as ext_ff2:\n",
    "    ff_extended()\n",
    "\n",
    "explanation_check(ext_ff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             candidates  explanatory_status\n",
      "0                                    {}               False\n",
      "1                           {'ar': 0.0}               False\n",
      "2                           {'ar': 1.0}               False\n",
      "3                          {'esm': 1.0}               False\n",
      "4                          {'esm': 0.0}               False\n",
      "5               {'ar': 1.0, 'esm': 1.0}               False\n",
      "6               {'ar': 0.0, 'esm': 1.0}                True\n",
      "7               {'ar': 1.0, 'esm': 0.0}               False\n",
      "8               {'ar': 0.0, 'esm': 0.0}               False\n",
      "9                          {'esj': 1.0}                True\n",
      "10                         {'esj': 0.0}               False\n",
      "11              {'ar': 1.0, 'esj': 1.0}               False\n",
      "12              {'ar': 0.0, 'esj': 0.0}               False\n",
      "13              {'ar': 0.0, 'esj': 1.0}               False\n",
      "14              {'ar': 1.0, 'esj': 0.0}               False\n",
      "15             {'esm': 0.0, 'esj': 1.0}               False\n",
      "16             {'esm': 1.0, 'esj': 0.0}               False\n",
      "17             {'esm': 1.0, 'esj': 1.0}               False\n",
      "18             {'esm': 0.0, 'esj': 0.0}               False\n",
      "19  {'ar': 0.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "20  {'ar': 1.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "21  {'ar': 1.0, 'esm': 1.0, 'esj': 0.0}               False\n",
      "22  {'ar': 0.0, 'esm': 0.0, 'esj': 0.0}               False\n",
      "23  {'ar': 1.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "24  {'ar': 0.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "25  {'ar': 1.0, 'esm': 0.0, 'esj': 0.0}               False\n",
      "26  {'ar': 0.0, 'esm': 1.0, 'esj': 0.0}               False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n"
     ]
    }
   ],
   "source": [
    "# explore all 27 possible explanations\n",
    "# to confirm that these are the only \n",
    "# possible explanations\n",
    "\n",
    "explanatory_status = []\n",
    "candidates = []\n",
    "\n",
    "nodes = [\"ar\", \"esm\", \"esj\"]\n",
    "subsets = [[]]\n",
    "for node in nodes:\n",
    "        subsets.extend([subset + [node] for subset in subsets])\n",
    "\n",
    "\n",
    "for subset in subsets:\n",
    "        for _ in range(50):\n",
    "                random_setting = [random.choice([0., 1.]) \n",
    "                          for _ in range(len(subset))]\n",
    "                candidate = {var: val for var, val in zip(subset, random_setting)}\n",
    "\n",
    "                if candidate in candidates:\n",
    "                        continue\n",
    "\n",
    "                candidates.append(candidate)\n",
    "\n",
    "                _ext_handler =  Explanation_Evaluation(\n",
    "                                model = ff_extended,\n",
    "                                antecedents= candidate,\n",
    "                                consequents_observed={\"ff\": 1.},\n",
    "                                endogenous_nodes=[\"ar\", \"esm\", \"esj\"],\n",
    "                                ) \n",
    "                \n",
    "                with _ext_handler as _ext_obj:\n",
    "                        ff_extended()\n",
    "\n",
    "                explanatory_status.append(explanation_check(_ext_obj))\n",
    "\n",
    "explanation_search = pd.DataFrame({\"candidates\": candidates,\n",
    "                                   \"explanatory_status\": explanatory_status})\n",
    "\n",
    "print(explanation_search)\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chirho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
