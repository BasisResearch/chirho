{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "The **Explainable Reasoning with ChiRho** package aims to provide a systematic, unified approach to actual causality and causal explanation computations in terms of different probabilistic queries over expanded causal models that are constructed from a single generic program transformation applied to an arbitrary causal model represented as a ChiRho program. The approach of reducing causal queries to probabilistic computations on transformed causal models is the foundational idea behind all of ChiRho. Where “actual causality” or \"causal explanation\" queries differ is their use of auxiliary variables representing uncertainty over which interventions or preemptions to apply, implicitly inducing a search space over counterfactuals.\n",
    "\n",
    "\n",
    "The goal of this notebook is to illustrate how the package can be used to provide approximate method of answering causal explanation queries in line with the definition of causal explanation formulated in ch. 7 of *Actual Causality* [(J. Halpern, MIT Press, 2016)](https://mitpress.mit.edu/9780262537131/actual-causality/).\n",
    "\n",
    "In another notebook, we illustrated how the package can be used to answer analogous queries related to actual causality, as defined in the same book.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "[Intuitions and formalization](##intuitions-and-formalization)\n",
    "\n",
    "[Implementation](##implementation)\n",
    "\n",
    "[Examples](##examples)\n",
    "\n",
    "- [Comments on example selection](###comments-on-example-selection)\n",
    "  \n",
    "- [Forest fire](###forest-fire)\n",
    "\n",
    "- [Extended forest fire](###extended-forest-fire)\n",
    "\n",
    "[Going beyond the original definition](##going-beyond-the-original-definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuitions and formalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this approach, an explanation is a claim that, if found to be true, would describe, roughly speaking, an actual cause of the fact to be explained. Moreover, as agents may have different epistemic states, explanations are agent-relative, telling the agents something that they don't already know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this picture, the agent starts with some uncertainty, represented as a set $K$ of causal settings not excluded by what they know (for the sake of simplicity, we consider only causal settings differing in the values of the exogenous variables in the examples).  Relative to $K$, $\\vec{X} = \\vec{x}$ is an explanation of $\\varphi$ iff the following hold:\n",
    "\n",
    "1. $\\vec{X} = \\vec{x}$ is a sufficient cause of $\\varphi$ in all contexts in $K$ that satisfy $\\vec{X} = \\vec{x} \\wedge \\varphi$. That is:\n",
    "\n",
    "    A. For any $\\langle M, \\vec{u}\\rangle \\in K$, if $\\langle M, \\vec{u}\\rangle \\models \\vec{X} = \\vec{x} \\wedge \\varphi$, then there exists a conjunct $X=x$ of $\\vec{X} = \\vec{x}$ and a possibly empty conjunction $\\vec{Y}= \\vec{y}$ such that $X=x \\wedge \\vec{Y} = \\vec{y}$ is an actual cause of $\\varphi$ in $\\langle M, \\vec{u}\\rangle$. We will call this condition **causal overlap**. \n",
    "\n",
    "    B. $\\langle M, \\vec{u}\\rangle\\models[\\vec{X} = \\vec{x}]\\varphi$ for any $\\langle M, \\vec{u}\\rangle \\in K$. We will call this condition **sufficiency**.\n",
    "\n",
    "2. $\\vec{X}$ is a minimal set satisfying 1. This is the **minimality** condition.\n",
    "\n",
    "3. $\\vec{X} = \\vec{x} \\wedge \\varphi$ hold in at least one member of $K$. We'll call this condition **possibility**.\n",
    "\n",
    "Moreover, an explanation is **non-trivial** just in case $\\vec{X} = \\vec{x}$ fails in at least one member of $K$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import contextlib\n",
    "import random\n",
    "from itertools import chain, combinations\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import pandas as pd\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "import pyro.infer\n",
    "import torch\n",
    "from chirho.observational.handlers import condition\n",
    "from chirho.counterfactual.handlers.counterfactual import MultiWorldCounterfactual\n",
    "from chirho.explainable.handlers import SearchForExplanation\n",
    "                                            \n",
    "from chirho.indexed.ops import (IndexSet, gather, indices_of) \n",
    "from chirho.interventional.handlers import do\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "runs_n = 5 if smoke_test else 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key will be played by the `ExplanationEvaluation` effect handler, which takes observations and a list of causal candidate nodes, and:\n",
    "\n",
    "(1) if desired, conditions on the observations\n",
    "\n",
    "(2) converts the list of causal candidate nodes to a list of distribution constraints used in our search through the space of possible interventions (in our applications here, the nodes are boolean, and so are the constraints), and\n",
    "\n",
    "(3) while keeping track of multiple possible worlds using `MultiWorldCounterfactual`, uses `SearchForExplanation` to transform the original model into one in which:\n",
    "\n",
    "(A) some causal candidates are randomly selected for intervention and intervened with a random intervention, with slight preference for non-intervention, resulting in a preference for smaller causal candidate sets,\n",
    "\n",
    "(B) some witness candidates (roughly, a subset of the unintervened causal candidates) are preempted, that is, considered to be part of the actual context and their values are kept as observed even in the counterfactual worlds.\n",
    "\n",
    "The sample trace of the transformed model can then be used to answer causal explanation queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorize_dictionary(dictionary: Dict[str, float]) -> Dict[str, torch.Tensor]:\n",
    "    return {k: torch.as_tensor(v) for k, v in dictionary.items()}\n",
    "\n",
    "def boolean_constraints_from_list(list: List[str]) -> Dict[str, pyro.distributions.constraints.Constraint]:\n",
    "    return {k: pyro.distributions.constraints.boolean for k in list}\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def ExplanationEvaluation( \n",
    "        consequents_observed: Dict[str, torch.Tensor],\n",
    "        causal_candidates: Union[Dict[str, torch.Tensor], Dict[str, constraints.Constraint]],\n",
    "        condition_on_consequent = True,\n",
    "        runs_n: int = runs_n,):\n",
    "\n",
    "        # = list(consequents_observed.keys())\n",
    "        consequents_observed = tensorize_dictionary(consequents_observed)\n",
    "        # this needs to be replaced if nodes are not boolean\n",
    "        causal_candidate_constraints = causal_candidates\n",
    "        if isinstance(causal_candidates, list):\n",
    "            causal_candidate_constraints = boolean_constraints_from_list(causal_candidates)\n",
    "\n",
    "        consequent_constraints = boolean_constraints_from_list(list(consequents_observed.keys()))\n",
    "        # needed in order to check if always a part of the antecedent set is a part of an actual cause\n",
    "        with MultiWorldCounterfactual() as mwc:\n",
    "            with SearchForExplanation(antecedents = causal_candidate_constraints, \n",
    "                      witnesses = causal_candidates, consequents = consequent_constraints,\n",
    "                      antecedent_bias = .1,):\n",
    "                if condition_on_consequent:\n",
    "                    with condition(data = consequents_observed):\n",
    "                        with pyro.plate(\"sample\", runs_n):\n",
    "                            with pyro.poutine.trace() as tr:\n",
    "                                yield {\"mwc\": mwc, \"tr\" : tr}\n",
    "                else:\n",
    "                    with pyro.plate(\"sample\", runs_n):\n",
    "                        with pyro.poutine.trace() as tr:\n",
    "                            yield {\"mwc\": mwc, \"tr\" : tr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace obtained using the above handler already contains information that can be used to implement the original definition. Such a query can be answered with only two core concepts: subset inclusion and log prob sum comparison. First, let's implement this definition. Later on, we'll move beyond some of the idiosyncracies involved here. The reader might skip the cell below as containing some rather unexciting boilerplate; examples of resultinig tables will be given further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a table from the trace\n",
    "# post sampling conditioning on observations or interventions\n",
    "\n",
    "def gather_observed(value, causal_candidates):\n",
    "            \n",
    "    _indices = [i for i in causal_candidates if i in indices_of(value, event_dim=0)]\n",
    "    _int_can = gather(value, IndexSet(**{i: {0} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "def gather_intervened(value, causal_candidates):\n",
    "        \n",
    "    _indices = [i for i in causal_candidates if i in indices_of(value, event_dim=0)]\n",
    "    _int_can = gather(value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "def get_explanation_table(trace, mwc, causal_candidates, consequents, prior_contributions = None):\n",
    "\n",
    "    trace.trace.compute_log_prob()\n",
    "    \n",
    "    table_dict = {}\n",
    "    nodes = trace.trace.nodes\n",
    "\n",
    "    for candidate in causal_candidates:\n",
    "        with mwc:\n",
    "            table_dict[f\"obs_{candidate}\"] = gather_observed(nodes[candidate]['value'],\n",
    "                                                             causal_candidates).squeeze().tolist()\n",
    "    \n",
    "            \n",
    "        table_dict[f\"pint_{candidate}\"] = nodes[f'__antecedent__proposal_{candidate}']['value'].squeeze().tolist()\n",
    "        table_dict[f\"apre_{candidate}\"] = nodes[f'__antecedent_{candidate}']['value'].squeeze().tolist()\n",
    "        table_dict[f\"lp_apre_{candidate}\"] = nodes[f\"__antecedent_{candidate}\"]['log_prob']\n",
    "\n",
    "        table_dict[f\"wpre_{candidate}\"] = nodes[f'__witness_{candidate}']['value'].squeeze().tolist()\n",
    "\n",
    "        # context used twice to make the table more legible (meaningful column ordering)\n",
    "        with mwc:\n",
    "            table_dict[f\"int_{candidate}\"] = gather_intervened(nodes[candidate]['value'],\n",
    "                                                             causal_candidates).squeeze().tolist()\n",
    "            \n",
    "\n",
    "    for consequent in consequents:\n",
    "        with mwc:\n",
    "            table_dict[f\"obs_{consequent}\"] = gather_observed(nodes[consequent][\"value\"], causal_candidates).squeeze().tolist()\n",
    "            table_dict[f\"int_{consequent}\"] = gather_intervened(nodes[consequent][\"value\"], causal_candidates).squeeze().tolist()    \n",
    "            table_dict[f\"lp_{consequent}\"] = gather_intervened(nodes[f\"__consequent_{consequent}\"][\"log_prob\"], causal_candidates).squeeze().tolist()\n",
    "        \n",
    "    if prior_contributions is not None:\n",
    "        for node in prior_contributions:\n",
    "            table_dict[f\"lp_{node}\"] = gather_observed(nodes[node][\"log_prob\"], causal_candidates).squeeze().tolist()\n",
    "            \n",
    "    table_pd = pd.DataFrame(table_dict).drop_duplicates()\n",
    "\n",
    "    # small cleanup:\n",
    "    # remove rows where proposed interventions are the same as the observed values\n",
    "    for candidate in causal_candidates:\n",
    "        mask = table_pd[f'obs_{candidate}'] != table_pd[f'pint_{candidate}']\n",
    "        table_pd = table_pd[mask]\n",
    "      \n",
    "    \n",
    "    summands = [col for col in table_pd.columns if col.startswith('lp')]\n",
    "    table_pd[\"sum_lp\"] =  table_pd[summands].sum(axis = 1)\n",
    "    table_pd.sort_values(by = \"sum_lp\", ascending = False, inplace = True)\n",
    "\n",
    "    # some sanity checks\n",
    "    for candidate in causal_candidates:\n",
    "        \n",
    "        # witness preempted nodes have the same observed and intervened values\n",
    "        assert all(table_pd.loc[table_pd[f'wpre_{candidate}'] == 1, \n",
    "        f'obs_{candidate}'] == table_pd.loc[table_pd[f'wpre_{candidate}'] == 1,\n",
    "                                            f'int_{candidate}'])\n",
    "\n",
    "        # antecedent preemptions leave obs and int values unchanged\n",
    "        # this might fail generally if a node is downstream from some \n",
    "        # other intervention, but let's keep this sanity check for the simple models \n",
    "        # for now        \n",
    "        assert all(table_pd.loc[table_pd[f'apre_{candidate}'] == 1,\n",
    "                                f'obs_{candidate}'] == \n",
    "                   table_pd.loc[table_pd[f'apre_{candidate}'] == 1,\n",
    "                                f'int_{candidate}'])\n",
    "        \n",
    "\n",
    "    return table_pd\n",
    "\n",
    "\n",
    "# brute force conditioning on the observed causal candidates\n",
    "# needed to implement the original def, not needed later on\n",
    "\n",
    "# post-sampling conditioning on observations\n",
    "def get_conditioned_table(table, dict_of_nodes):\n",
    "    conditioned_table = table.copy()\n",
    "    for candidate in dict_of_nodes.keys():\n",
    "        obs_column = f'obs_{candidate}'\n",
    "        mask = (conditioned_table[obs_column] == dict_of_nodes[candidate])\n",
    "        conditioned_table = conditioned_table[mask]\n",
    "        conditioned_table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return conditioned_table\n",
    "\n",
    "# post-sampling conditioning on selected variables being intervened\n",
    "def get_intervened_table(table, dict_of_nodes):\n",
    "    intervened_table = table.copy()\n",
    "    for candidate in dict_of_nodes.keys():\n",
    "        condition_string = f\"`apre_{candidate}` == 0 and `wpre_{candidate}` == 0 and int_{candidate} == {dict_of_nodes[candidate]}\"        \n",
    "        intervened_table = intervened_table.query(condition_string)\n",
    "        intervened_table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return intervened_table\n",
    "    \n",
    "\n",
    "# a few other utility functions\n",
    "\n",
    "# from a dictionary of interventions generate all non-empty subdictionaries\n",
    "# needed as a search space for subset-inclusion\n",
    "def powerset(dct):\n",
    "    keys = list(dct.keys())\n",
    "    key_tuples = list(chain.from_iterable(combinations(keys, r) for r in range(len(keys) + 1)))[:-1]\n",
    "    subdicts = [{k: dct[k] for k in tpl} for tpl in key_tuples]\n",
    "    return subdicts\n",
    "\n",
    "#  in a given row in a sample table, which nodes are active in an intervention considered in that row?\n",
    "def active(node, row):\n",
    "    return row[f\"apre_{node}\"] == 0 and row[f\"wpre_{node}\"] == 0 and row[f\"obs_{node}\"] != row[f\"pint_{node}\"]\n",
    "\n",
    "def minimal_sets(set_list):\n",
    "    inclusion_minimal = []\n",
    "    for s1 in set_list:\n",
    "        is_minimal = True\n",
    "        for s2 in set_list:\n",
    "            if s1 != s2 and s2.issubset(s1):\n",
    "                is_minimal = False\n",
    "        if is_minimal:\n",
    "            inclusion_minimal.append(s1)\n",
    "    return inclusion_minimal\n",
    "\n",
    "\n",
    "# go through those rows where the intervened consequents differ from the observed ones\n",
    "# keep track of subset-minimal interventions and the corresponding row log_probs.\n",
    "# needed as there might be subset-minimal interventions that aren't in a log_prob-maximal row\n",
    "def minimal_cause_sets(table, causal_candidates, get_values = False, return_logprobs = False):\n",
    "\n",
    "    if isinstance(causal_candidates, dict):\n",
    "        causal_candidates = list(causal_candidates.keys())\n",
    "    \n",
    "    subset_minimal_causes = []\n",
    "    subset_minimal_causes_dicts = []\n",
    "    subset_logprobs = []\n",
    "    frozen_sets = set()\n",
    "    changers = table[table['sum_lp']  > -1e8].copy()\n",
    "    \n",
    "    for _, row in changers.iterrows():\n",
    "        active_set = {node for node in  causal_candidates if active(node, row)}\n",
    "        active_set_frozen = frozenset(active_set)\n",
    "        active_dict = {node: row[f\"obs_{node}\"] for node in active_set}\n",
    "        if active_set_frozen not in frozen_sets:\n",
    "            frozen_sets.add(active_set_frozen)\n",
    "            subset_minimal_causes.append(active_set)\n",
    "            subset_minimal_causes_dicts.append(active_dict)\n",
    "            subset_logprobs.append(row['sum_lp'])\n",
    "\n",
    "\n",
    "    # output, depending on what is needed, as specified by the arguments\n",
    "    if not get_values and not return_logprobs:\n",
    "        return subset_minimal_causes\n",
    "    elif get_values and not return_logprobs:\n",
    "        return subset_minimal_causes_dicts\n",
    "    elif not get_values and return_logprobs:\n",
    "        return subset_minimal_causes, subset_logprobs\n",
    "    elif get_values and return_logprobs:\n",
    "        return subset_minimal_causes_dicts, subset_logprobs\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An implementation of (an approximate counterpart of) Halpern's definition of explanation is captured by `ExplanationHalpern`, which basically takes the cleaned-up output of the tansformed model and checks if the conditions corresponding to those listed in the definition occur. Its use will be illustrated further in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplanationHalpern():\n",
    "\n",
    "    def __init__(self, table, consequent_dict, causal_candidates_dict, print_report = True):\n",
    "        self.table = table\n",
    "        self.consequent_dict = consequent_dict\n",
    "        self.causal_candidates_dict = causal_candidates_dict\n",
    "\n",
    "        self.ex1A = self.ex1A_check(self.table, consequent_dict= self.consequent_dict, causal_candidates_dict= self.causal_candidates_dict)\n",
    "        self.ex1B = self.ex1B_check(self.table, consequent_dict=self.consequent_dict, causal_candidates_dict= self.causal_candidates_dict)\n",
    "        self.ex2 = self.ex2_check(self.table, consequent_dict= self.consequent_dict, causal_candidates_dict= self.causal_candidates_dict)\n",
    "        self.ex3_4 = self.ex3_4_check(self.table, consequent_dict=self.consequent_dict, causal_candidates_dict=self.causal_candidates_dict)\n",
    "        self.explanation = self.explanation_check()\n",
    "        if print_report:\n",
    "                print(f\"explanation check: {self.explanation}, \", \n",
    "                f\"causal_overlap: {self.ex1B}, \",\n",
    "                f\"minimality: {self.ex2}, \",\n",
    "                f\"possibility: {self.ex3_4[0]}, \", \n",
    "                f\"non-triviality: {self.ex3_4[1]}\")\n",
    "        \n",
    "    # Condition 1 requires that (A) in all contexts in which the causal candidates have the postulated values \n",
    "    # and the consequent is changed, there is at least one member of the causal candidates \n",
    "    # that is a member of a minimal actual cause of that change to the consequent.\n",
    "    def ex1A_check(self, table, consequent_dict, causal_candidates_dict):\n",
    "\n",
    "        # suppose not only consequent but also the causal candidates are observed    \n",
    "        merged_dict = {**consequent_dict, **causal_candidates_dict}\n",
    "        \n",
    "        table_conditioned = get_conditioned_table(table, merged_dict)\n",
    "\n",
    "        # check if causal candidates coincide with a minimal cause set\n",
    "        minimal_conditioned = minimal_cause_sets(table_conditioned, causal_candidates_dict)\n",
    "        parthood_flag = any(any(candidate in s for candidate in causal_candidates_dict.keys()) for s in minimal_conditioned)   \n",
    "        return parthood_flag, minimal_conditioned\n",
    "    \n",
    "    # Moreover, it requires that (B) for any context under consideration, intervening on all causal candidates \n",
    "    # to have the postulated value leads to the consequent.\n",
    "    def ex1B_check(self, table, causal_candidates_dict, consequent_dict):\n",
    "        table_intervened = get_intervened_table(table, causal_candidates_dict)\n",
    "        return all((table_intervened[f\"int_{key}\"] == consequent_dict[key]).all() for key in consequent_dict.keys()) \n",
    "\n",
    "    # The second condition of Halpern's definition is that the causal candidate set \n",
    "    # be a subset-minimal one satisfying both `ex1A` and `ex1B`.\n",
    "    def ex2_check(self, table,  consequent_dict, causal_candidates_dict,):\n",
    "        sub_candidates = powerset(causal_candidates_dict)\n",
    "        minimality_flag = True\n",
    "        for sub_candidate in sub_candidates:\n",
    "            ex1A_flag = self.ex1A_check(table, consequent_dict= consequent_dict, causal_candidates_dict= sub_candidate)[0]\n",
    "            ex1B_flag = self.ex1B_check(table, consequent_dict = consequent_dict, causal_candidates_dict= sub_candidate)\n",
    "            \n",
    "            if ex1A_flag and ex1B_flag:\n",
    "                minimality_flag = False\n",
    "                break\n",
    "        return minimality_flag\n",
    "    \n",
    "    # The remaining checks are whether the explanation is possible (given the consequent) and non-trivial.\n",
    "    def ex3_4_check(self, table, consequent_dict, causal_candidates_dict):\n",
    "\n",
    "        merged_dict = {**consequent_dict, **causal_candidates_dict}\n",
    "        table_conditioned = get_conditioned_table(table, merged_dict)\n",
    "        ex3 = table_conditioned.shape[0] > 0\n",
    "        ex4 = any(any(table[f\"obs_{key}\"] != causal_candidates_dict[key]) for key in causal_candidates_dict.keys())\n",
    "\n",
    "        return ex3, ex4\n",
    "    \n",
    "    def explanation_check(self):\n",
    "        return self.ex1A[0] and self.ex1B and self.ex2 and self.ex3_4[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on example selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **forest fire:** one of the running examples in the book: we choose it, as it is the simplest model rich enough to illustrate a few interesting properties of explanation\n",
    "\n",
    "- **extended forest fire:** the most complicated example of an explanation discussed in the book, we use it to illustrate how the implementation handles it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 7.1.2. from Halpern's *Actual Causality*. In the conjunctive model if both a lightning occurs and a match is dropped, a forest fire results, but both factors are required. In the disjunctive model, each of these factors individually is sufficient for the forest fire.\n",
    "\n",
    "Suppose all contexts are available and no setting is excluded by what the agent knows about the world. \n",
    "- In the conjunctive model, the joint nodes are an explanation of forest fire, none of the individual ones is. This is in contrast with actual causality claims, as each of the nodes is an actual cause, but the conjunction is not.\n",
    "- In the disjunctive model, the reverse is true. Each node is an explanation of forest fire, but the conjunction is not. This is in contrast with actual causality claims, as none of the individual nodes is an actual cause, but the conjunction is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyro.infer.config_enumerate\n",
    "def ff_conjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() & lightning.bool()),\n",
    "                                      event_dim=0)\n",
    "    \n",
    "    return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n",
    "\n",
    "@pyro.infer.config_enumerate\n",
    "def ff_disjunctive():\n",
    "        u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "        u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "        match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "        lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "        forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() | lightning.bool()).bool(), event_dim=0)\n",
    "\n",
    "        return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we specify the observed consequent, the causal candidates, and run the transformed models multiple times, putting the cleaned up samples in the corresponding tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "consequents_observed={\"forest_fire\": torch.tensor(True)}\n",
    "causal_candidates=boolean_constraints_from_list([\"match_dropped\", \"lightning\"])\n",
    "causal_candidates_dict = {\"match_dropped\": 1., \"lightning\": 1.}\n",
    "antecedent_prefix = \"__antecedent\"\n",
    "\n",
    "exp_ff_con_handler =  ExplanationEvaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= runs_n,\n",
    ")\n",
    "\n",
    "exp_ff_dis_handler =  ExplanationEvaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= runs_n,\n",
    ")\n",
    "\n",
    "with exp_ff_con_handler as con_ff:\n",
    "        ff_conjunctive()\n",
    "\n",
    "with exp_ff_dis_handler as dis_ff:\n",
    "        ff_disjunctive()\n",
    "\n",
    "table_con_ff = get_explanation_table(con_ff[\"tr\"], con_ff[\"mwc\"], causal_candidates, consequents=[\"forest_fire\"])\n",
    "table_dis_ff = get_explanation_table(dis_ff[\"tr\"], dis_ff[\"mwc\"], causal_candidates, consequents=[\"forest_fire\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned up table contains the following columns:\n",
    "\n",
    "- `obs_<node>` storing the observed value of any causal candidate node.\n",
    "- `pint_<node>`, containing the proposed random intervention for that causal candidate.\n",
    "- `apre_<node>`, the value of the auxicilary stochastic node specifying whether the intervention is preempted. It takes value `0` if the intervention is performed, `1` otherwise. \n",
    "- `lp_apre_<node>` records the log probability of the auxiliary node taking that value. As antecedent interventions are performed with a non-trivial bias, this in effect results in preference for non-interventions and smalle causal sets.\n",
    "- `wpre_<node>` contains information on whether a given node has been preempted as a witness, that is, whether it's counterfactual value has been intervened to be the same as the observed one. Witness preemption nullifies causal candidate intervention as well.\n",
    "- `int_<node>` recalls the overal result: the counterfactual value of that node.\n",
    "- `lp_<consequent>` records log probabilities associated with whether the value of a consquent differs between the observed and the counterfactual world. If it doesn't, the value is `-1e8`, effectively dropping cases in which no difference has been made to the consequent from our \"sight\". If it does, the value is `0`, not making a difference to our row ranking. \n",
    "- `sum_lp` contains the sum of log probabilities listed in the table. This sum is the result of both whether a given interventional setting results in a change to the consquent, and of the size (cardinality) of the antecedent set being in fact intervened on.\n",
    "\n",
    "The table is ordered by `sum_lp`, with interventional settings making the smallest interventions that would make a difference to the consequence listed at the top. Repeated rows are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_match_dropped</th>\n",
       "      <th>pint_match_dropped</th>\n",
       "      <th>apre_match_dropped</th>\n",
       "      <th>lp_apre_match_dropped</th>\n",
       "      <th>wpre_match_dropped</th>\n",
       "      <th>int_match_dropped</th>\n",
       "      <th>obs_lightning</th>\n",
       "      <th>pint_lightning</th>\n",
       "      <th>apre_lightning</th>\n",
       "      <th>lp_apre_lightning</th>\n",
       "      <th>wpre_lightning</th>\n",
       "      <th>int_lightning</th>\n",
       "      <th>obs_forest_fire</th>\n",
       "      <th>int_forest_fire</th>\n",
       "      <th>lp_forest_fire</th>\n",
       "      <th>sum_lp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-1.437167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-1.437167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-1.437167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-1.437167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-1.437167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-6.437753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-6.437753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-6.437753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-6.437753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-6.437753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      obs_match_dropped  pint_match_dropped  apre_match_dropped  \\\n",
       "455                 0.0                 1.0                   0   \n",
       "69                  1.0                 0.0                   1   \n",
       "314                 1.0                 0.0                   1   \n",
       "4                   1.0                 0.0                   0   \n",
       "334                 1.0                 0.0                   1   \n",
       "...                 ...                 ...                 ...   \n",
       "84                  0.0                 1.0                   0   \n",
       "456                 1.0                 0.0                   0   \n",
       "381                 0.0                 1.0                   0   \n",
       "225                 0.0                 1.0                   0   \n",
       "1625                0.0                 1.0                   0   \n",
       "\n",
       "      lp_apre_match_dropped  wpre_match_dropped  int_match_dropped  \\\n",
       "455               -0.916291                   0                1.0   \n",
       "69                -0.510826                   1                1.0   \n",
       "314               -0.510826                   0                1.0   \n",
       "4                 -0.916291                   0                0.0   \n",
       "334               -0.510826                   1                1.0   \n",
       "...                     ...                 ...                ...   \n",
       "84                -0.916291                   0                1.0   \n",
       "456               -0.916291                   1                1.0   \n",
       "381               -0.916291                   1                0.0   \n",
       "225               -0.916291                   0                1.0   \n",
       "1625              -0.916291                   1                0.0   \n",
       "\n",
       "      obs_lightning  pint_lightning  apre_lightning  lp_apre_lightning  \\\n",
       "455             1.0             0.0               1          -0.510826   \n",
       "69              0.0             1.0               0          -0.916291   \n",
       "314             0.0             1.0               0          -0.916291   \n",
       "4               1.0             0.0               1          -0.510826   \n",
       "334             1.0             0.0               0          -0.916291   \n",
       "...             ...             ...             ...                ...   \n",
       "84              1.0             0.0               0          -0.916291   \n",
       "456             0.0             1.0               0          -0.916291   \n",
       "381             0.0             1.0               0          -0.916291   \n",
       "225             0.0             1.0               0          -0.916291   \n",
       "1625            1.0             0.0               0          -0.916291   \n",
       "\n",
       "      wpre_lightning  int_lightning  obs_forest_fire  int_forest_fire  \\\n",
       "455                0            1.0            False             True   \n",
       "69                 0            1.0            False             True   \n",
       "314                0            1.0            False             True   \n",
       "4                  1            1.0             True            False   \n",
       "334                0            0.0             True            False   \n",
       "...              ...            ...              ...              ...   \n",
       "84                 0            0.0            False            False   \n",
       "456                1            0.0            False            False   \n",
       "381                0            1.0            False            False   \n",
       "225                1            0.0            False            False   \n",
       "1625               1            1.0            False            False   \n",
       "\n",
       "      lp_forest_fire    sum_lp  \n",
       "455        -0.010050 -1.437167  \n",
       "69         -0.010050 -1.437167  \n",
       "314        -0.010050 -1.437167  \n",
       "4          -0.010050 -1.437167  \n",
       "334        -0.010050 -1.437167  \n",
       "...              ...       ...  \n",
       "84         -4.605171 -6.437753  \n",
       "456        -4.605171 -6.437753  \n",
       "381        -4.605171 -6.437753  \n",
       "225        -4.605171 -6.437753  \n",
       "1625       -4.605171 -6.437753  \n",
       "\n",
       "[64 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(table_con_ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass the table, together with the postulated observed ouotcome and cnadidate event list to `ExplanationHalpern`, and have our causal explanation query answered. `explanation_check` is true if all the conditions are satisfied, whereas the other outputs contain the evaluation results of particular elements of the defintion, as already specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation check: True,  causal_overlap: True,  minimality: True,  possibility: True,  non-triviality: True\n",
      "explanation check: False,  causal_overlap: False,  minimality: True,  possibility: True,  non-triviality: True\n",
      "explanation check: False,  causal_overlap: True,  minimality: False,  possibility: True,  non-triviality: True\n",
      "explanation check: True,  causal_overlap: True,  minimality: True,  possibility: True,  non-triviality: True\n"
     ]
    }
   ],
   "source": [
    "# conjunction in the conjunctive model\n",
    "con_ff_explanation = ExplanationHalpern(table_con_ff, {\"forest_fire\": True}, causal_candidates_dict)\n",
    "# one of the nodes in the conjunctive model\n",
    "con_ff_explanation_match = ExplanationHalpern(table_con_ff, {\"forest_fire\": True}, {\"match_dropped\": 1.})\n",
    "\n",
    "# conjunction in the disjunctive model\n",
    "dis_ff_explanation = ExplanationHalpern(table_dis_ff, {\"forest_fire\": True}, causal_candidates_dict)\n",
    "# one of the nodes in the disjunctive model\n",
    "dis_ff_explanation_match = ExplanationHalpern(table_dis_ff, {\"forest_fire\": True}, {\"match_dropped\": 1.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended forest fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based on example 7.1.4. In April, given the electrical storm in May, the forest would have caught fire in May (and not in June). However, given the storm, if there had been an electrical storm only in May, the forest\n",
    "would not have caught fire at all; if there had been an electrical storm only in June, it would have caught fire in June. The model has five endogenous variables: `ar` for *April rains*, \n",
    "`esm` for *electric storms in May*, `esj` for *electric storms in June*, `ffm` for *forest fire in May*, `ffj` for *forest fire in June* and `ff` for *forest fire either in May or in June (or both)*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_extended():\n",
    "    u_ar = pyro.sample(\"u_ar\", dist.Bernoulli(0.5))\n",
    "    u_esm = pyro.sample(\"u_esm\", dist.Bernoulli(0.5))\n",
    "    u_esj = pyro.sample(\"u_esj\", dist.Bernoulli(0.5))\n",
    "\n",
    "    ar = pyro.deterministic(\"ar\", u_ar, event_dim=0)\n",
    "    esm = pyro.deterministic(\"esm\", u_esm, event_dim=0)\n",
    "    esj = pyro.deterministic(\"esj\", u_esj, event_dim=0)\n",
    "\n",
    "    ffm = pyro.deterministic(\"ffmt\", esm  * (1 - ar), event_dim=0).float()\n",
    "    ffj = pyro.deterministic(\"ffj\", (esj * torch.max(ar, (1 - esm))), event_dim=0).float()\n",
    "    ff = pyro.deterministic(\"ff\", torch.max(ffm, ffj), event_dim=0).float()\n",
    "    \n",
    "    return {\"u_ar\": u_ar, \"u_esm\": u_esm, \"u_esj\": u_esj, \n",
    "            \"ar\": ar, \"esm\": esm, \"esj\": esj, \"ffm\": ffm, \"ffj\": ffj, \"ff\": ff}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, there are only two possible explanations of a forest fire according to this model: `{\"esm\": 1.,  \"ar\": 0.}`, and `{\"esj\": 1.}`. They are correctly identified using our approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation check: True,  causal_overlap: True,  minimality: True,  possibility: True,  non-triviality: True\n",
      "explanation check: True,  causal_overlap: True,  minimality: True,  possibility: True,  non-triviality: True\n",
      "explanation check: False,  causal_overlap: True,  minimality: False,  possibility: True,  non-triviality: True\n",
      "explanation check: False,  causal_overlap: False,  minimality: True,  possibility: True,  non-triviality: True\n"
     ]
    }
   ],
   "source": [
    "consequents_observed={\"ff\": 1.}\n",
    "causal_candidates_dict = {\"esj\": 1., \"esm\": 1.,  \"ar\": 0.}\n",
    "causal_candidates= boolean_constraints_from_list(causal_candidates_dict.keys())\n",
    "\n",
    "exp_ff_ext_handler =  ExplanationEvaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= runs_n,\n",
    ")\n",
    "\n",
    "with exp_ff_ext_handler as ext_ff:\n",
    "    ff_extended()\n",
    "\n",
    "table_ext_ff = get_explanation_table(ext_ff[\"tr\"], ext_ff[\"mwc\"], causal_candidates, consequents=[\"ff\"])\n",
    "\n",
    "\n",
    "ext_ff_1_explanation = ExplanationHalpern(table_ext_ff, {\"ff\": 1.}, {\"esm\": 1.,  \"ar\": 0.})\n",
    "ext_ff_1_explanation = ExplanationHalpern(table_ext_ff, {\"ff\": 1.}, {\"esj\": 1.})\n",
    "ext_ff_1_explanation = ExplanationHalpern(table_ext_ff, {\"ff\": 1.}, {\"esj\": 1, \"esm\": 1.,  \"ar\": 0.})\n",
    "ext_ff_1_explanation = ExplanationHalpern(table_ext_ff, {\"ff\": 1.},{'ar': 1.0, 'esm': 0.0}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, however, we would like to explore the space of possible explanations - in this particular case, confirming that these are the only two explanations. If we approach it from the perspective of the query of the type \"is a given setting of a certain collection of endogenous variables an explanation of a given outcome\" as a primitive, it seems like the way to go is to manually propose candidates and run a separate query every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             candidates  explanatory_status\n",
      "0                                    {}               False\n",
      "1                           {'ar': 1.0}               False\n",
      "2                           {'ar': 0.0}               False\n",
      "3                          {'esm': 1.0}               False\n",
      "4                          {'esm': 0.0}               False\n",
      "5               {'ar': 0.0, 'esm': 1.0}                True\n",
      "6               {'ar': 0.0, 'esm': 0.0}               False\n",
      "7               {'ar': 1.0, 'esm': 1.0}               False\n",
      "8               {'ar': 1.0, 'esm': 0.0}               False\n",
      "9                          {'esj': 1.0}                True\n",
      "10                         {'esj': 0.0}               False\n",
      "11              {'ar': 1.0, 'esj': 1.0}               False\n",
      "12              {'ar': 1.0, 'esj': 0.0}               False\n",
      "13              {'ar': 0.0, 'esj': 1.0}               False\n",
      "14              {'ar': 0.0, 'esj': 0.0}               False\n",
      "15             {'esm': 1.0, 'esj': 1.0}               False\n",
      "16             {'esm': 0.0, 'esj': 1.0}               False\n",
      "17             {'esm': 1.0, 'esj': 0.0}               False\n",
      "18             {'esm': 0.0, 'esj': 0.0}               False\n",
      "19  {'ar': 0.0, 'esm': 1.0, 'esj': 0.0}               False\n",
      "20  {'ar': 0.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "21  {'ar': 1.0, 'esm': 0.0, 'esj': 0.0}               False\n",
      "22  {'ar': 1.0, 'esm': 1.0, 'esj': 0.0}               False\n",
      "23  {'ar': 1.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "24  {'ar': 0.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "25  {'ar': 1.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "26  {'ar': 0.0, 'esm': 0.0, 'esj': 0.0}               False\n"
     ]
    }
   ],
   "source": [
    "# explore all 27 possible explanations\n",
    "# to confirm that these are the only \n",
    "# possible explanations\n",
    "\n",
    "explanatory_status = []\n",
    "candidates = []\n",
    "\n",
    "nodes = [\"ar\", \"esm\", \"esj\"]\n",
    "subsets = [[]]\n",
    "for node in nodes:\n",
    "        subsets.extend([subset + [node] for subset in subsets])\n",
    "\n",
    "\n",
    "for subset in subsets:\n",
    "        for _ in range(50):\n",
    "                random_setting = [random.choice([0., 1.]) \n",
    "                          for _ in range(len(subset))]\n",
    "                candidate = {var: val for var, val in zip(subset, random_setting)}\n",
    "\n",
    "                if candidate in candidates:\n",
    "                        continue\n",
    "\n",
    "                candidates.append(candidate)\n",
    "                \n",
    "                explanatory_status.append(ExplanationHalpern(table_ext_ff, {\"ff\": 1.}, \n",
    "                                                             candidate, \n",
    "                                                             print_report = False).explanation)\n",
    "\n",
    "explanation_search = pd.DataFrame({\"candidates\": candidates,\n",
    "                                   \"explanatory_status\": explanatory_status})\n",
    "\n",
    "print(explanation_search)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going beyond the original definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While actual causes do not have to be explanations in Halpern's sense, one key intuition behind why one needs a notion of an explanation as defined by Halpern is that one is interested in narrowing down the search space to things that would **overlap** with actual causes if they were true and guiding our investigation in the search of actual causes. We propose an explanation, and then investigate the node values to see what the actual causes are. If this is your motivation, the approach we present allows you to focusing on possible actual causes directly and skip this extra step, by finding possible states that would **be** actual causes, if true. In fact, the handler that we have already explores the possible actual causes for us. Moreover, if we still are interested in testing for being an explanation in Halpern sense, instead of running a wider search we can just check the potential actual causes for whether they are explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'esj': 1.0}, {'ar': 0.0}, {'esm': 1.0}, {'ar': 1.0, 'esj': 1.0}, {'esm': 0.0, 'esj': 1.0}, {'esm': 1.0, 'ar': 0.0}, {'esm': 1.0, 'ar': 0.0, 'esj': 1.0}, {}]\n",
      "I would count as Halpern's explanation! {'esj': 1.0}\n",
      "I would count as Halpern's explanation! {'esm': 1.0, 'ar': 0.0}\n"
     ]
    }
   ],
   "source": [
    "table_ext_ff_conditioned = get_conditioned_table(table_ext_ff, {\"ff\": 1.})\n",
    "\n",
    "possible_actual_causes = minimal_cause_sets(table_ext_ff_conditioned, [\"ar\", \"esm\", \"esj\"], get_values=True)\n",
    "print(possible_actual_causes)\n",
    "\n",
    "for pac in possible_actual_causes:\n",
    "    if ExplanationHalpern(table_ext_ff, {\"ff\": 1.}, pac, print_report = False).explanation:\n",
    "        print(\"I would count as Halpern's explanation!\", pac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice also that the bias used in the effect handlers results in smaller sets being ranked higher, which also can be useful in your search. This feature may be used in interaction with our priors about which states of possible causes are more likely, we just need to add the corresponding log probabilities to the log prob sum. For a simple illustration, let us get back to the disjunctive model of forest fire, with the caveat that now we think a lightning is less likely and a match being dropped more likely to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyro.infer.config_enumerate\n",
    "def ff_disjunctive_uneven():\n",
    "        u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.7)) # notice uneven probs here\n",
    "        u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.4)) # and here\n",
    "\n",
    "        match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "        lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "        forest_fire = pyro.deterministic(\"forest_fire\", torch.max(match_dropped, lightning), event_dim=0)\n",
    "\n",
    "        return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pretty much the same analysis as before\n",
    "\n",
    "consequents_observed={\"forest_fire\": 1.}\n",
    "causal_candidates=boolean_constraints_from_list([\"lightning\",\"match_dropped\"])\n",
    "\n",
    "exp_ff_dis__uneven_handler =  ExplanationEvaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= runs_n,\n",
    ")\n",
    "\n",
    "with exp_ff_dis__uneven_handler as dis_ff_uneven:\n",
    "        ff_disjunctive_uneven()\n",
    "\n",
    "dis_ff_uneven[\"tr\"].trace.compute_log_prob()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now however, the difference is that we include `prior_contributions` in the table, effectively recording their corresponding log probabilities and including it in the log prob sum, which has impact on the ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([{'match_dropped': 1.0}, {'match_dropped': 1.0, 'lightning': 1.0}, {'lightning': 1.0}, {}], [-2.3046672642230988, -3.1155974566936493, -3.557430177927017, -6.494323015213013])\n"
     ]
    }
   ],
   "source": [
    "table_dis_ff_uneven = get_explanation_table(dis_ff_uneven[\"tr\"], dis_ff_uneven[\"mwc\"], causal_candidates, consequents=[\"forest_fire\"],\n",
    "                                             prior_contributions=[\"u_match_dropped\", \"u_lightning\"])  # here we add the priors for the two nodes\n",
    "\n",
    "table_dis_ff_uneven_conditioned = get_conditioned_table(table_dis_ff_uneven, {\"forest_fire\": 1.})\n",
    "\n",
    "\n",
    "possible_actual_causes = minimal_cause_sets(table_dis_ff_uneven_conditioned, [\"match_dropped\", \"lightning\"], get_values=True, return_logprobs=True)\n",
    "\n",
    "print(possible_actual_causes)\n",
    "\n",
    "# the proper way to read this: \"just match dropped and no lightning\" are ranked higher than\n",
    "# \"match_dropped and lightning\", which are ranked higher than \"no match dropped and just the lightning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_lightning</th>\n",
       "      <th>pint_lightning</th>\n",
       "      <th>apre_lightning</th>\n",
       "      <th>lp_apre_lightning</th>\n",
       "      <th>wpre_lightning</th>\n",
       "      <th>int_lightning</th>\n",
       "      <th>obs_match_dropped</th>\n",
       "      <th>pint_match_dropped</th>\n",
       "      <th>apre_match_dropped</th>\n",
       "      <th>lp_apre_match_dropped</th>\n",
       "      <th>wpre_match_dropped</th>\n",
       "      <th>int_match_dropped</th>\n",
       "      <th>obs_forest_fire</th>\n",
       "      <th>int_forest_fire</th>\n",
       "      <th>lp_forest_fire</th>\n",
       "      <th>lp_u_match_dropped</th>\n",
       "      <th>lp_u_lightning</th>\n",
       "      <th>sum_lp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>-2.304667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>-2.304667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>-2.710132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-3.115597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-7.305253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-7.305253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>-7.305253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-7.710718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    obs_lightning  pint_lightning  apre_lightning  lp_apre_lightning  \\\n",
       "0             0.0             1.0               1          -0.510826   \n",
       "1             0.0             1.0               1          -0.510826   \n",
       "2             0.0             1.0               0          -0.916291   \n",
       "3             1.0             0.0               0          -0.916291   \n",
       "26            1.0             0.0               1          -0.510826   \n",
       "27            1.0             0.0               1          -0.510826   \n",
       "30            0.0             1.0               0          -0.916291   \n",
       "32            1.0             0.0               0          -0.916291   \n",
       "\n",
       "    wpre_lightning  int_lightning  obs_match_dropped  pint_match_dropped  \\\n",
       "0                1            0.0                1.0                 0.0   \n",
       "1                0            0.0                1.0                 0.0   \n",
       "2                1            0.0                1.0                 0.0   \n",
       "3                0            0.0                1.0                 0.0   \n",
       "26               1            1.0                1.0                 0.0   \n",
       "27               0            1.0                1.0                 0.0   \n",
       "30               0            1.0                1.0                 0.0   \n",
       "32               1            1.0                1.0                 0.0   \n",
       "\n",
       "    apre_match_dropped  lp_apre_match_dropped  wpre_match_dropped  \\\n",
       "0                    0              -0.916291                   0   \n",
       "1                    0              -0.916291                   0   \n",
       "2                    0              -0.916291                   0   \n",
       "3                    0              -0.916291                   0   \n",
       "26                   0              -0.916291                   0   \n",
       "27                   0              -0.916291                   0   \n",
       "30                   0              -0.916291                   0   \n",
       "32                   0              -0.916291                   0   \n",
       "\n",
       "    int_match_dropped  obs_forest_fire  int_forest_fire  lp_forest_fire  \\\n",
       "0                 0.0              1.0              0.0       -0.010050   \n",
       "1                 0.0              1.0              0.0       -0.010050   \n",
       "2                 0.0              1.0              0.0       -0.010050   \n",
       "3                 0.0              1.0              0.0       -0.010050   \n",
       "26                0.0              1.0              1.0       -4.605171   \n",
       "27                0.0              1.0              1.0       -4.605171   \n",
       "30                0.0              1.0              1.0       -4.605171   \n",
       "32                0.0              1.0              1.0       -4.605171   \n",
       "\n",
       "    lp_u_match_dropped  lp_u_lightning    sum_lp  \n",
       "0            -0.356675       -0.510826 -2.304667  \n",
       "1            -0.356675       -0.510826 -2.304667  \n",
       "2            -0.356675       -0.510826 -2.710132  \n",
       "3            -0.356675       -0.916291 -3.115597  \n",
       "26           -0.356675       -0.916291 -7.305253  \n",
       "27           -0.356675       -0.916291 -7.305253  \n",
       "30           -0.356675       -0.510826 -7.305253  \n",
       "32           -0.356675       -0.916291 -7.710718  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_lightning</th>\n",
       "      <th>pint_lightning</th>\n",
       "      <th>apre_lightning</th>\n",
       "      <th>lp_apre_lightning</th>\n",
       "      <th>wpre_lightning</th>\n",
       "      <th>int_lightning</th>\n",
       "      <th>obs_match_dropped</th>\n",
       "      <th>pint_match_dropped</th>\n",
       "      <th>apre_match_dropped</th>\n",
       "      <th>lp_apre_match_dropped</th>\n",
       "      <th>wpre_match_dropped</th>\n",
       "      <th>int_match_dropped</th>\n",
       "      <th>obs_forest_fire</th>\n",
       "      <th>int_forest_fire</th>\n",
       "      <th>lp_forest_fire</th>\n",
       "      <th>lp_u_match_dropped</th>\n",
       "      <th>lp_u_lightning</th>\n",
       "      <th>sum_lp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-3.115597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-7.305253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-7.305253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-7.710718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    obs_lightning  pint_lightning  apre_lightning  lp_apre_lightning  \\\n",
       "3             1.0             0.0               0          -0.916291   \n",
       "26            1.0             0.0               1          -0.510826   \n",
       "27            1.0             0.0               1          -0.510826   \n",
       "32            1.0             0.0               0          -0.916291   \n",
       "\n",
       "    wpre_lightning  int_lightning  obs_match_dropped  pint_match_dropped  \\\n",
       "3                0            0.0                1.0                 0.0   \n",
       "26               1            1.0                1.0                 0.0   \n",
       "27               0            1.0                1.0                 0.0   \n",
       "32               1            1.0                1.0                 0.0   \n",
       "\n",
       "    apre_match_dropped  lp_apre_match_dropped  wpre_match_dropped  \\\n",
       "3                    0              -0.916291                   0   \n",
       "26                   0              -0.916291                   0   \n",
       "27                   0              -0.916291                   0   \n",
       "32                   0              -0.916291                   0   \n",
       "\n",
       "    int_match_dropped  obs_forest_fire  int_forest_fire  lp_forest_fire  \\\n",
       "3                 0.0              1.0              0.0       -0.010050   \n",
       "26                0.0              1.0              1.0       -4.605171   \n",
       "27                0.0              1.0              1.0       -4.605171   \n",
       "32                0.0              1.0              1.0       -4.605171   \n",
       "\n",
       "    lp_u_match_dropped  lp_u_lightning    sum_lp  \n",
       "3            -0.356675       -0.916291 -3.115597  \n",
       "26           -0.356675       -0.916291 -7.305253  \n",
       "27           -0.356675       -0.916291 -7.305253  \n",
       "32           -0.356675       -0.916291 -7.710718  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_lightning</th>\n",
       "      <th>pint_lightning</th>\n",
       "      <th>apre_lightning</th>\n",
       "      <th>lp_apre_lightning</th>\n",
       "      <th>wpre_lightning</th>\n",
       "      <th>int_lightning</th>\n",
       "      <th>obs_match_dropped</th>\n",
       "      <th>pint_match_dropped</th>\n",
       "      <th>apre_match_dropped</th>\n",
       "      <th>lp_apre_match_dropped</th>\n",
       "      <th>wpre_match_dropped</th>\n",
       "      <th>int_match_dropped</th>\n",
       "      <th>obs_forest_fire</th>\n",
       "      <th>int_forest_fire</th>\n",
       "      <th>lp_forest_fire</th>\n",
       "      <th>lp_u_match_dropped</th>\n",
       "      <th>lp_u_lightning</th>\n",
       "      <th>sum_lp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-3.115597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-3.557430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-3.557430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010050</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-3.962895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-7.305253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-7.305253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-0.356675</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-7.710718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.605171</td>\n",
       "      <td>-1.203973</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>-8.558016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    obs_lightning  pint_lightning  apre_lightning  lp_apre_lightning  \\\n",
       "3             1.0             0.0               0          -0.916291   \n",
       "4             1.0             0.0               0          -0.916291   \n",
       "5             1.0             0.0               0          -0.916291   \n",
       "6             1.0             0.0               0          -0.916291   \n",
       "21            1.0             0.0               0          -0.916291   \n",
       "25            1.0             0.0               0          -0.916291   \n",
       "33            1.0             0.0               0          -0.916291   \n",
       "45            1.0             0.0               0          -0.916291   \n",
       "\n",
       "    wpre_lightning  int_lightning  obs_match_dropped  pint_match_dropped  \\\n",
       "3                0            0.0                1.0                 0.0   \n",
       "4                0            0.0                0.0                 1.0   \n",
       "5                0            0.0                0.0                 1.0   \n",
       "6                0            0.0                0.0                 1.0   \n",
       "21               0            0.0                1.0                 0.0   \n",
       "25               0            0.0                1.0                 0.0   \n",
       "33               0            0.0                1.0                 0.0   \n",
       "45               0            0.0                0.0                 1.0   \n",
       "\n",
       "    apre_match_dropped  lp_apre_match_dropped  wpre_match_dropped  \\\n",
       "3                    0              -0.916291                   0   \n",
       "4                    1              -0.510826                   0   \n",
       "5                    1              -0.510826                   1   \n",
       "6                    0              -0.916291                   1   \n",
       "21                   1              -0.510826                   0   \n",
       "25                   1              -0.510826                   1   \n",
       "33                   0              -0.916291                   1   \n",
       "45                   0              -0.916291                   0   \n",
       "\n",
       "    int_match_dropped  obs_forest_fire  int_forest_fire  lp_forest_fire  \\\n",
       "3                 0.0              1.0              0.0       -0.010050   \n",
       "4                 0.0              1.0              0.0       -0.010050   \n",
       "5                 0.0              1.0              0.0       -0.010050   \n",
       "6                 0.0              1.0              0.0       -0.010050   \n",
       "21                1.0              1.0              1.0       -4.605171   \n",
       "25                1.0              1.0              1.0       -4.605171   \n",
       "33                1.0              1.0              1.0       -4.605171   \n",
       "45                1.0              1.0              1.0       -4.605171   \n",
       "\n",
       "    lp_u_match_dropped  lp_u_lightning    sum_lp  \n",
       "3            -0.356675       -0.916291 -3.115597  \n",
       "4            -1.203973       -0.916291 -3.557430  \n",
       "5            -1.203973       -0.916291 -3.557430  \n",
       "6            -1.203973       -0.916291 -3.962895  \n",
       "21           -0.356675       -0.916291 -7.305253  \n",
       "25           -0.356675       -0.916291 -7.305253  \n",
       "33           -0.356675       -0.916291 -7.710718  \n",
       "45           -1.203973       -0.916291 -8.558016  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can also inspect the rows corresponding to the interventional settings involving these explanations\n",
    "\n",
    "lightning_active = [active('lightning',table_dis_ff_uneven_conditioned.iloc[row]) for row in range(table_dis_ff_uneven_conditioned.shape[0])]\n",
    "match_dropped_active = [active('match_dropped',table_dis_ff_uneven_conditioned.iloc[row]) for row in range(table_dis_ff_uneven_conditioned.shape[0])]\n",
    "lightning_and_match_active = lightning_active and match_dropped_active\n",
    "\n",
    "display(table_dis_ff_uneven_conditioned.iloc[match_dropped_active].query('obs_match_dropped == 1'))\n",
    "\n",
    "display(table_dis_ff_uneven_conditioned.iloc[lightning_and_match_active].query('obs_lightning == 1 and obs_match_dropped == 1'))\n",
    "\n",
    "display(table_dis_ff_uneven_conditioned.iloc[lightning_active].query('obs_lightning == 1'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chirho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
