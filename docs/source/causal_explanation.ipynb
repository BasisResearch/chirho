{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import contextlib\n",
    "import collections\n",
    "from typing import Callable, Iterable, TypeVar, Mapping, List, Dict\n",
    "\n",
    "\n",
    "from itertools import chain, combinations\n",
    "\n",
    "import random\n",
    "\n",
    "import pyro\n",
    "import torch  # noqa: F401\n",
    "\n",
    "from chirho.counterfactual.handlers.selection import get_factual_indices\n",
    "from chirho.indexed.ops import IndexSet, cond, gather, indices_of, scatter\n",
    "\n",
    "S = TypeVar(\"S\")\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "import pyro\n",
    "import chirho\n",
    "import pyro.distributions as dist\n",
    "import pyro.infer\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from chirho.counterfactual.handlers.counterfactual import (MultiWorldCounterfactual,\n",
    "        Preemptions)\n",
    "from chirho.counterfactual.handlers.explanation import (\n",
    "    SearchForCause,\n",
    "    consequent_differs,\n",
    "    random_intervention,\n",
    "    undo_split,\n",
    "    uniform_proposal,\n",
    ")\n",
    "from chirho.counterfactual.ops import preempt, split\n",
    "from chirho.indexed.ops import IndexSet, gather, indices_of\n",
    "from chirho.observational.handlers.condition import Factors, condition\n",
    "from chirho.interventional.ops import Intervention, intervene\n",
    "from chirho.interventional.handlers import do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def ExplainCauses(\n",
    "    antecedents: Mapping[str, Intervention[T]]\n",
    "    | Mapping[str, pyro.distributions.constraints.Constraint],\n",
    "    witnesses: Mapping[str, Intervention[T]] | Iterable[str],\n",
    "    consequents: Mapping[str, Callable[[T], float | torch.Tensor]]\n",
    "    | Iterable[str],\n",
    "    *,\n",
    "    antecedent_bias: float = 0.0,\n",
    "    witness_bias: float = 0.0,\n",
    "    consequent_eps: float = -1e8,\n",
    "    antecedent_prefix: str = \"__antecedent_\",\n",
    "    witness_prefix: str = \"__witness_\",\n",
    "    consequent_prefix: str = \"__consequent_\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Effect handler for causal explanation.\n",
    "\n",
    "    :param antecedents: A mapping from antecedent names to interventions.\n",
    "    :param witnesses: A mapping from witness names to interventions.\n",
    "    :param consequents: A mapping from consequent names to factor functions.\n",
    "    \"\"\"\n",
    "    if isinstance(\n",
    "        next(iter(antecedents.values())),\n",
    "        pyro.distributions.constraints.Constraint,\n",
    "    ):\n",
    "        antecedents = {\n",
    "            a: random_intervention(s, name=f\"{antecedent_prefix}_proposal_{a}\")\n",
    "            for a, s in antecedents.items()\n",
    "        }\n",
    "\n",
    "    if not isinstance(witnesses, collections.abc.Mapping):\n",
    "        witnesses = {\n",
    "            w: undo_split(antecedents=list(antecedents.keys()))\n",
    "            for w in witnesses\n",
    "        }\n",
    "\n",
    "    if not isinstance(consequents, collections.abc.Mapping):\n",
    "        consequents = {\n",
    "            c: consequent_differs(\n",
    "                antecedents=list(antecedents.keys()), eps=consequent_eps\n",
    "            )\n",
    "            for c in consequents\n",
    "        }\n",
    "\n",
    "    if len(consequents) == 0:\n",
    "        raise ValueError(\"must have at least one consequent\")\n",
    "\n",
    "    if len(antecedents) == 0:\n",
    "        raise ValueError(\"must have at least one antecedent\")\n",
    "\n",
    "    if set(consequents.keys()) & set(antecedents.keys()):\n",
    "        raise ValueError(\n",
    "            \"consequents and possible antecedents must be disjoint\"\n",
    "        )\n",
    "\n",
    "    if set(consequents.keys()) & set(witnesses.keys()):\n",
    "        raise ValueError(\"consequents and possible witnesses must be disjoint\")\n",
    "\n",
    "    antecedent_handler = SearchForCause(\n",
    "        actions=antecedents, bias=antecedent_bias, prefix=antecedent_prefix\n",
    "    )\n",
    "    witness_handler = Preemptions(\n",
    "        actions=witnesses, bias=witness_bias, prefix=witness_prefix\n",
    "    )\n",
    "    consequent_handler = Factors(factors=consequents, prefix=consequent_prefix)\n",
    "\n",
    "    with antecedent_handler, witness_handler, consequent_handler:\n",
    "            yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tensorize_dictionary(dictionary):\n",
    "    return {k: torch.as_tensor(v) for k, v in dictionary.items()}\n",
    "\n",
    "def boolean_constraints_from_list(list):\n",
    "    return {k: pyro.distributions.constraints.boolean for k in list}\n",
    "\n",
    "# trace-handling helper functions\n",
    "\n",
    "def gather_observed(value, causal_candidates):\n",
    "            \n",
    "    _indices = [\n",
    "            i for i in causal_candidates if i in indices_of(value, event_dim=0)\n",
    "        ]\n",
    "    _int_can = gather(\n",
    "    value, IndexSet(**{i: {0} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "\n",
    "# def gather_observed(value, antecedents, witnesses):\n",
    "    \n",
    "#     if isinstance(antecedents, dict):\n",
    "#         antecedents_list = list(antecedents.keys())\n",
    "#     else:\n",
    "#         antecedents_list = antecedents\n",
    "        \n",
    "#     _indices = [\n",
    "#             i for i in antecedents_list + witnesses if i in indices_of(value, event_dim=0)\n",
    "#         ]\n",
    "#     _int_can = gather(\n",
    "#     value, IndexSet(**{i: {0} for i in _indices}), event_dim=0,)\n",
    "#     return _int_can\n",
    "\n",
    "def gather_intervened(value, antecedents, witnesses):\n",
    "    \n",
    "    if isinstance(antecedents, dict):\n",
    "        antecedents_list = list(antecedents.keys())\n",
    "    else:\n",
    "        antecedents_list = antecedents\n",
    "        \n",
    "        \n",
    "    _indices = [\n",
    "            i for i in antecedents_list + witnesses if i in indices_of(value, event_dim=0)\n",
    "        ]\n",
    "    _int_can = gather(\n",
    "    value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "def get_table(trace, mwc, antecedents, witnesses, consequents):\n",
    "\n",
    "    values_table = {}\n",
    "    nodes = trace.trace.nodes\n",
    "    \n",
    "\n",
    "    if isinstance(antecedents, dict):\n",
    "        antecedents_list = list(antecedents.keys())\n",
    "    else:\n",
    "        antecedents_list = antecedents\n",
    "\n",
    "    with mwc:\n",
    "\n",
    "        for antecedent_str in antecedents_list:\n",
    "                \n",
    "            obs_ant = gather_observed(nodes[antecedent_str][\"value\"], antecedents_list, witnesses)\n",
    "            int_ant = gather_intervened(nodes[antecedent_str][\"value\"], antecedents_list, witnesses)\n",
    "\n",
    "            values_table[f\"{antecedent_str}_obs\"] = obs_ant.squeeze().tolist()\n",
    "            values_table[f\"{antecedent_str}_int\"] = int_ant.squeeze().tolist()\n",
    "            \n",
    "            apr_ant = nodes[f\"__antecedent_{antecedent_str}\"][\"value\"]\n",
    "            values_table[f\"apr_{antecedent_str}\"] = apr_ant.squeeze().tolist()\n",
    "            \n",
    "            values_table[f\"apr_{antecedent_str}_lp\"] = nodes[f\"__antecedent_{antecedent_str}\"][\"fn\"].log_prob(apr_ant)\n",
    "\n",
    "        if witnesses:\n",
    "            for candidate in witnesses:\n",
    "                obs_candidate = gather_observed(nodes[candidate][\"value\"], antecedents_list, witnesses)\n",
    "                int_candidate = gather_intervened(nodes[candidate][\"value\"], antecedents_list, witnesses)\n",
    "                values_table[f\"{candidate}_obs\"] = obs_candidate.squeeze().tolist()\n",
    "                values_table[f\"{candidate}_int\"] = int_candidate.squeeze().tolist()\n",
    "\n",
    "                wpr_con = nodes[f\"__witness_{candidate}\"][\"value\"]\n",
    "                values_table[f\"wpr_{candidate}\"] = wpr_con.squeeze().tolist()\n",
    "            \n",
    "\n",
    "        for consequent in consequents:\n",
    "            \n",
    "            obs_consequent = gather_observed(nodes[consequent][\"value\"], antecedents_list, witnesses)\n",
    "            int_consequent = gather_intervened(nodes[consequent][\"value\"], antecedents_list, witnesses)\n",
    "            con_lp = nodes[f\"__consequent_{consequent}\"]['fn'].log_prob(torch.tensor(1)) #TODO: this feels like a hack\n",
    "            _indices_lp = [\n",
    "            i for i in antecedents_list + witnesses if i in indices_of(con_lp)]\n",
    "            int_con_lp = gather(con_lp, IndexSet(**{i: {1} for i in _indices_lp}), event_dim=0,)      \n",
    "\n",
    "\n",
    "            values_table[f\"{consequent}_obs\"] = obs_consequent.squeeze().tolist()   \n",
    "            values_table[f\"{consequent}_int\"] = int_consequent.squeeze().tolist()\n",
    "            values_table[f\"{consequent}_lp\"] = int_con_lp.squeeze().tolist()   \n",
    "\n",
    "    values_df = pd.DataFrame(values_table)\n",
    "\n",
    "    values_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    summands = [col for col in values_df.columns if col.endswith('lp')]\n",
    "    values_df[\"sum_log_prob\"] =  values_df[summands].sum(axis = 1)\n",
    "    values_df.sort_values(by = \"sum_log_prob\", ascending = False, inplace = True)\n",
    "\n",
    "    return values_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table2(trace, mwc, causal_candidates):\n",
    "\n",
    "    trace.trace.compute_log_prob()\n",
    "    \n",
    "    table_dict = {}\n",
    "    nodes = trace.trace.nodes\n",
    "    \n",
    "    print(nodes.keys())\n",
    "\n",
    "\n",
    "    \n",
    "   #candidate = causal_candidates[0]\n",
    "\n",
    "    for candidate in causal_candidates:\n",
    "        with mwc:\n",
    "            table_dict[f\"obs_{candidate}\"] = gather_observed(nodes[f'__antecedent__proposal_{candidate}']['value'],\n",
    "                                                             causal_candidates).squeeze().tolist()\n",
    "    \n",
    "            \n",
    "        table_dict[f\"pint_{candidate}\"] = nodes[f'__antecedent__proposal_{candidate}']['value'].squeeze().tolist()\n",
    "        table_dict[f\"apre_{candidate}\"] = nodes[f'__antecedent_{candidate}']['value'].squeeze().tolist()\n",
    "        table_dict[f\"wpre_{candidate}\"] = nodes[f'__witness_{candidate}']['value'].squeeze().tolist()\n",
    "        \n",
    "        table_dict[f\"lp_apre_{candidate}\"] = nodes[f\"__antecedent_{candidate}\"]['log_prob']\n",
    "\n",
    "        #values_table[f\"apr_{antecedent_str}_lp\"] = nodes[f\"__antecedent_{antecedent_str}\"][\"fn\"].log_prob(apr_ant)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #with mwc:\n",
    "        \n",
    "\n",
    "    # if isinstance(antecedents, dict):\n",
    "    #     antecedents_list = list(antecedents.keys())\n",
    "    # else:\n",
    "    #     antecedents_list = antecedents\n",
    "\n",
    "    # with mwc:\n",
    "\n",
    "    #     for antecedent_str in antecedents_list:\n",
    "                \n",
    "    #         obs_ant = gather_observed(nodes[antecedent_str][\"value\"], antecedents_list, witnesses)\n",
    "    #         int_ant = gather_intervened(nodes[antecedent_str][\"value\"], antecedents_list, witnesses)\n",
    "\n",
    "    #         values_table[f\"{antecedent_str}_obs\"] = obs_ant.squeeze().tolist()\n",
    "    #         values_table[f\"{antecedent_str}_int\"] = int_ant.squeeze().tolist()\n",
    "            \n",
    "    #         apr_ant = nodes[f\"__antecedent_{antecedent_str}\"][\"value\"]\n",
    "    #         values_table[f\"apr_{antecedent_str}\"] = apr_ant.squeeze().tolist()\n",
    "            \n",
    "    #         values_table[f\"apr_{antecedent_str}_lp\"] = nodes[f\"__antecedent_{antecedent_str}\"][\"fn\"].log_prob(apr_ant)\n",
    "\n",
    "    #     if witnesses:\n",
    "    #         for candidate in witnesses:\n",
    "    #             obs_candidate = gather_observed(nodes[candidate][\"value\"], antecedents_list, witnesses)\n",
    "    #             int_candidate = gather_intervened(nodes[candidate][\"value\"], antecedents_list, witnesses)\n",
    "    #             values_table[f\"{candidate}_obs\"] = obs_candidate.squeeze().tolist()\n",
    "    #             values_table[f\"{candidate}_int\"] = int_candidate.squeeze().tolist()\n",
    "\n",
    "    #             wpr_con = nodes[f\"__witness_{candidate}\"][\"value\"]\n",
    "    #             values_table[f\"wpr_{candidate}\"] = wpr_con.squeeze().tolist()\n",
    "            \n",
    "\n",
    "    #     for consequent in consequents:\n",
    "            \n",
    "    #         obs_consequent = gather_observed(nodes[consequent][\"value\"], antecedents_list, witnesses)\n",
    "    #         int_consequent = gather_intervened(nodes[consequent][\"value\"], antecedents_list, witnesses)\n",
    "    #         con_lp = nodes[f\"__consequent_{consequent}\"]['fn'].log_prob(torch.tensor(1)) #TODO: this feels like a hack\n",
    "    #         _indices_lp = [\n",
    "    #         i for i in antecedents_list + witnesses if i in indices_of(con_lp)]\n",
    "    #         int_con_lp = gather(con_lp, IndexSet(**{i: {1} for i in _indices_lp}), event_dim=0,)      \n",
    "\n",
    "\n",
    "    #         values_table[f\"{consequent}_obs\"] = obs_consequent.squeeze().tolist()   \n",
    "    #         values_table[f\"{consequent}_int\"] = int_consequent.squeeze().tolist()\n",
    "    #         values_table[f\"{consequent}_lp\"] = int_con_lp.squeeze().tolist()   \n",
    "\n",
    "    # values_df = pd.DataFrame(values_table)\n",
    "\n",
    "    # values_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # summands = [col for col in values_df.columns if col.endswith('lp')]\n",
    "    # values_df[\"sum_log_prob\"] =  values_df[summands].sum(axis = 1)\n",
    "    # values_df.sort_values(by = \"sum_log_prob\", ascending = False, inplace = True)\n",
    "\n",
    "    table_pd = pd.DataFrame(table_dict).drop_duplicates()\n",
    "    \n",
    "    summands = [col for col in table_pd.columns if col.startswith('lp')]\n",
    "    table_pd[\"sum_lp\"] =  table_pd[summands].sum(axis = 1)\n",
    "    table_pd.sort_values(by = \"sum_lp\", ascending = False, inplace = True)\n",
    "\n",
    "    \n",
    "    return table_pd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def Explanation_Evaluation( \n",
    "        consequents_observed: Dict[str, torch.Tensor],\n",
    "        causal_candidates: List[str],\n",
    "        runs_n: int = 100,):\n",
    "\n",
    "        consequents = list(consequents_observed.keys())\n",
    "        consequents_observed = tensorize_dictionary(consequents_observed)\n",
    "        # this needs to be replaced if nodes are not boolean\n",
    "        causal_candidate_constraints = boolean_constraints_from_list(causal_candidates)\n",
    "\n",
    "        # needed to check if always a part of the antecedent set is a part of an actual cause\n",
    "        with MultiWorldCounterfactual() as mwc:\n",
    "            with ExplainCauses(antecedents = causal_candidate_constraints, \n",
    "                      witnesses = causal_candidates, consequents = consequents,\n",
    "                      antecedent_bias = .1):\n",
    "                with condition(data = {\"forest_fire\": torch.tensor(True)}):\n",
    "                    with pyro.plate(\"sample\", runs_n):\n",
    "                        with pyro.poutine.trace() as tr:\n",
    "                            yield {\"mwc\": mwc, \"tr\" : tr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_conjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() & lightning.bool()),\n",
    "                                      event_dim=0)\n",
    "\n",
    "def ff_disjunctive():\n",
    "        u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "        u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "        match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "        lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "        forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() | lightning.bool()).bool(), event_dim=0)\n",
    "\n",
    "        return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "antecedents={\"match_dropped\": 1.0, \"lightning\": 1.0}\n",
    "consequents_observed={\"forest_fire\": torch.tensor(True)}\n",
    "causal_candidates=[\"match_dropped\", \"lightning\"]\n",
    "\n",
    "exp_ff_con_handler =  Explanation_Evaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates,\n",
    "    runs_n= 100,\n",
    ")\n",
    "    \n",
    "with exp_ff_con_handler as con_ff:\n",
    "    ff_conjunctive()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['u_match_dropped', 'u_lightning', '__antecedent__proposal_match_dropped', '__antecedent_match_dropped', '__witness_match_dropped', 'match_dropped', '__antecedent__proposal_lightning', '__antecedent_lightning', '__witness_lightning', 'lightning', 'forest_fire_factual', 'forest_fire_counterfactual', '__consequent_forest_fire', 'forest_fire'])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "gather_observed() missing 1 required positional argument: 'witnesses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mwc \u001b[39m=\u001b[39m con_ff[\u001b[39m\"\u001b[39m\u001b[39mmwc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tr \u001b[39m=\u001b[39m con_ff[\u001b[39m\"\u001b[39m\u001b[39mtr\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m table \u001b[39m=\u001b[39m get_table2(tr, mwc, causal_candidates)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m display(table)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(table\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;32m/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m candidate \u001b[39min\u001b[39;00m causal_candidates:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mwith\u001b[39;00m mwc:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         table_dict[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mobs_\u001b[39m\u001b[39m{\u001b[39;00mcandidate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m gather_observed(nodes[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m__antecedent__proposal_\u001b[39;49m\u001b[39m{\u001b[39;49;00mcandidate\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                                                          causal_candidates)\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     table_dict[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpint_\u001b[39m\u001b[39m{\u001b[39;00mcandidate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m nodes[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m__antecedent__proposal_\u001b[39m\u001b[39m{\u001b[39;00mcandidate\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/causal_explanation.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     table_dict[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapre_\u001b[39m\u001b[39m{\u001b[39;00mcandidate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m nodes[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m__antecedent_\u001b[39m\u001b[39m{\u001b[39;00mcandidate\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mtolist()\n",
      "\u001b[0;31mTypeError\u001b[0m: gather_observed() missing 1 required positional argument: 'witnesses'"
     ]
    }
   ],
   "source": [
    "mwc = con_ff[\"mwc\"]\n",
    "tr = con_ff[\"tr\"]\n",
    "\n",
    "table = get_table2(tr, mwc, causal_candidates)\n",
    "\n",
    "display(table)\n",
    "\n",
    "print(table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general helper functions\n",
    "\n",
    "def minimal_sets(set_list):\n",
    "    inclusion_minimal = []\n",
    "    for s1 in set_list:\n",
    "        is_minimal = True\n",
    "        for s2 in set_list:\n",
    "            if s1 != s2 and s2.issubset(s1):\n",
    "                is_minimal = False\n",
    "        if is_minimal:\n",
    "            inclusion_minimal.append(s1)\n",
    "    return inclusion_minimal\n",
    "\n",
    "\n",
    "def tensorize_dictionary(dictionary):\n",
    "    return {k: torch.as_tensor(v) for k, v in dictionary.items()}\n",
    "\n",
    "def boolean_constraints_from_list(list):\n",
    "    return {k: pyro.distributions.constraints.boolean for k in list}\n",
    "\n",
    "# will be used to find non-empty \n",
    "# intervention subdictionaries\n",
    "def powerset(dict):\n",
    "    subdicts = []\n",
    "    keys = list(dict.keys())\n",
    "    key_tuples =  list(chain.from_iterable(combinations(keys, r) for r in range(len(keys)+1)))[1:-1]\n",
    "    for tuple in key_tuples:\n",
    "        subdicts.append({k: dict[k] for k in tuple})\n",
    "    return subdicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace-handling helper functions\n",
    "\n",
    "def gather_observed(value, antecedents, witnesses):\n",
    "    \n",
    "    if isinstance(antecedents, dict):\n",
    "        antecedents_list = list(antecedents.keys())\n",
    "    else:\n",
    "        antecedents_list = antecedents\n",
    "        \n",
    "    _indices = [\n",
    "            i for i in antecedents_list + witnesses if i in indices_of(value, event_dim=0)\n",
    "        ]\n",
    "    _int_can = gather(\n",
    "    value, IndexSet(**{i: {0} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "def gather_intervened(value, antecedents, witnesses):\n",
    "    \n",
    "    if isinstance(antecedents, dict):\n",
    "        antecedents_list = list(antecedents.keys())\n",
    "    else:\n",
    "        antecedents_list = antecedents\n",
    "        \n",
    "        \n",
    "    _indices = [\n",
    "            i for i in antecedents_list + witnesses if i in indices_of(value, event_dim=0)\n",
    "        ]\n",
    "    _int_can = gather(\n",
    "    value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "def get_table(trace, mwc, antecedents, witnesses, consequents):\n",
    "\n",
    "    values_table = {}\n",
    "    nodes = trace.trace.nodes\n",
    "    \n",
    "\n",
    "    if isinstance(antecedents, dict):\n",
    "        antecedents_list = list(antecedents.keys())\n",
    "    else:\n",
    "        antecedents_list = antecedents\n",
    "\n",
    "    with mwc:\n",
    "\n",
    "        for antecedent_str in antecedents_list:\n",
    "                \n",
    "            obs_ant = gather_observed(nodes[antecedent_str][\"value\"], antecedents_list, witnesses)\n",
    "            int_ant = gather_intervened(nodes[antecedent_str][\"value\"], antecedents_list, witnesses)\n",
    "\n",
    "            values_table[f\"{antecedent_str}_obs\"] = obs_ant.squeeze().tolist()\n",
    "            values_table[f\"{antecedent_str}_int\"] = int_ant.squeeze().tolist()\n",
    "            \n",
    "            apr_ant = nodes[f\"__antecedent_{antecedent_str}\"][\"value\"]\n",
    "            values_table[f\"apr_{antecedent_str}\"] = apr_ant.squeeze().tolist()\n",
    "            \n",
    "            values_table[f\"apr_{antecedent_str}_lp\"] = nodes[f\"__antecedent_{antecedent_str}\"][\"fn\"].log_prob(apr_ant)\n",
    "\n",
    "        if witnesses:\n",
    "            for candidate in witnesses:\n",
    "                obs_candidate = gather_observed(nodes[candidate][\"value\"], antecedents_list, witnesses)\n",
    "                int_candidate = gather_intervened(nodes[candidate][\"value\"], antecedents_list, witnesses)\n",
    "                values_table[f\"{candidate}_obs\"] = obs_candidate.squeeze().tolist()\n",
    "                values_table[f\"{candidate}_int\"] = int_candidate.squeeze().tolist()\n",
    "\n",
    "                wpr_con = nodes[f\"__witness_{candidate}\"][\"value\"]\n",
    "                values_table[f\"wpr_{candidate}\"] = wpr_con.squeeze().tolist()\n",
    "            \n",
    "\n",
    "        for consequent in consequents:\n",
    "            \n",
    "            obs_consequent = gather_observed(nodes[consequent][\"value\"], antecedents_list, witnesses)\n",
    "            int_consequent = gather_intervened(nodes[consequent][\"value\"], antecedents_list, witnesses)\n",
    "            con_lp = nodes[f\"__consequent_{consequent}\"]['fn'].log_prob(torch.tensor(1)) #TODO: this feels like a hack\n",
    "            _indices_lp = [\n",
    "            i for i in antecedents_list + witnesses if i in indices_of(con_lp)]\n",
    "            int_con_lp = gather(con_lp, IndexSet(**{i: {1} for i in _indices_lp}), event_dim=0,)      \n",
    "\n",
    "\n",
    "            values_table[f\"{consequent}_obs\"] = obs_consequent.squeeze().tolist()   \n",
    "            values_table[f\"{consequent}_int\"] = int_consequent.squeeze().tolist()\n",
    "            values_table[f\"{consequent}_lp\"] = int_con_lp.squeeze().tolist()   \n",
    "\n",
    "    values_df = pd.DataFrame(values_table)\n",
    "\n",
    "    values_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    summands = [col for col in values_df.columns if col.endswith('lp')]\n",
    "    values_df[\"sum_log_prob\"] =  values_df[summands].sum(axis = 1)\n",
    "    values_df.sort_values(by = \"sum_log_prob\", ascending = False, inplace = True)\n",
    "\n",
    "    return values_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this reduces the actual causality check to checking a property of the resulting sums of log probabilities\n",
    "# for the antecedent preemption and the consequent differs nodes\n",
    "\n",
    "def ac_check(trace, mwc, antecedents, witnesses, consequents):\n",
    "\n",
    "     table = get_table(trace, mwc, antecedents, witnesses, consequents)\n",
    "     \n",
    "     if (list(table['sum_log_prob'])[0]<= -1e8):\n",
    "          print(\"No resulting difference to the consequent in the sample.\")\n",
    "          return\n",
    "     \n",
    "     winners = table[table['sum_log_prob'] == table['sum_log_prob'].max()]\n",
    "     \n",
    "\n",
    "     ac_flags = []\n",
    "     for index, row in winners.iterrows():\n",
    "          active_antecedents = []\n",
    "          for antecedent in antecedents:\n",
    "               if row[f\"apr_{antecedent}\"] == 0:\n",
    "                    active_antecedents.append(antecedent)\n",
    "\n",
    "          ac_flags.append(set(active_antecedents) == set(antecedents))\n",
    "\n",
    "     if not any(ac_flags):\n",
    "          print(\"The antecedent set is not minimal.\")\n",
    "     else:\n",
    "          print(\"The antecedent set is an actual cause.\")\n",
    "\n",
    "     return any(ac_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @contextlib.contextmanager\n",
    "# def Explanation_Evaluation( \n",
    "#         model: Callable,\n",
    "#         antecedents: Dict[str, torch.Tensor],\n",
    "#         consequents_observed: Dict[str, torch.Tensor],\n",
    "#         endogenous_nodes: List[str],\n",
    "#         runs_n: int = 100,):\n",
    "\n",
    "#         consequents = list(consequents_observed.keys())\n",
    "#         consequents_observed = tensorize_dictionary(consequents_observed)\n",
    "#         causal_candidates = [node for node in endogenous_nodes if node not in consequents_observed.keys()]\n",
    "#         # this needs to be replaced if nodes are not boolean\n",
    "#         causal_candidate_constraints = boolean_constraints_from_list(causal_candidates)\n",
    "\n",
    "#         # needed to check if always a part of the antecedent set is a part of an actual cause\n",
    "#         with MultiWorldCounterfactual() as mwc_sufficiency_A:\n",
    "#             with ExplainCauses(antecedents = causal_candidate_constraints, \n",
    "#                       witnesses = causal_candidates, consequents = consequents):\n",
    "#                 with condition(data = {\"forest_fire\": torch.tensor(True)}):\n",
    "#                     with pyro.plate(\"sample\", runs_n):\n",
    "#                         with pyro.poutine.trace() as tr_sufficiency_A:\n",
    "#                             model()\n",
    "                            \n",
    "#         # needed to check P(consequents | do(antecedents)) = 1                    \n",
    "#         with MultiWorldCounterfactual() as mwc_sufficiency_B:\n",
    "#             with do( actions = antecedents):\n",
    "#                 with pyro.plate(\"samples\", runs_n):\n",
    "#                     with pyro.poutine.trace() as tr_sufficiency_B:\n",
    "#                         model()\n",
    "        \n",
    "#         # needed to check minimality:\n",
    "#         antecedent_candidates = powerset(antecedents)\n",
    "#         candidate_mwc = []\n",
    "#         candidate_traces = []\n",
    "#         for antecedent_candidate in antecedent_candidates:\n",
    "#             antecedent_candidate = tensorize_dictionary(antecedent_candidate)\n",
    "#             with MultiWorldCounterfactual() as mwc_candidate:\n",
    "#                 with do( actions = antecedent_candidate):\n",
    "#                     with pyro.plate(\"samples\", runs_n):\n",
    "#                         with pyro.poutine.trace() as candidate_trace:\n",
    "#                             model()\n",
    "#             candidate_mwc.append(mwc_candidate)\n",
    "#             candidate_traces.append(candidate_trace)\n",
    "        \n",
    "                        \n",
    "#         # will be used to check\n",
    "#         # - possibility: P(antecedents & consequent) > 0\n",
    "#         # - nontriviality: P(antecedents < 1) \n",
    "#         with pyro.plate(\"samples\", runs_n):\n",
    "#             with pyro.poutine.trace() as tr_priors:\n",
    "#                 model()\n",
    "          \n",
    "                            \n",
    "#         yield {\"mwc_sufficiency_A\": mwc_sufficiency_A, \"tr_sufficiency_A\": tr_sufficiency_A,\n",
    "#                \"mwc_sufficiency_B\": mwc_sufficiency_B, \"tr_sufficiency_B\": tr_sufficiency_B,\n",
    "#                \"tr_priors\": tr_priors,  \n",
    "#                \"mwc_candidate\": candidate_mwc, \n",
    "#                \"tr_candidate\": candidate_traces,\n",
    "#                \"antecedents\": antecedents, \n",
    "#                \"consequents_observed\": consequents_observed, \"endogenous_nodes\": endogenous_nodes,\n",
    "#                \"causal_candidates\": causal_candidates}\n",
    "        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing of traces\n",
    "# to identify potential explanations\n",
    "\n",
    "# Is always a part of the antecedent\n",
    "# a part of an actual cause of the consequent?\n",
    "def sufficient_causality_checkA(output_dict, antecedents = None, witnesses = None, consequents = None):\n",
    "\n",
    "    if antecedents is None:\n",
    "        antecedents = output_dict['antecedents']\n",
    "    if consequents is None:\n",
    "        consequents = list(output_dict['consequents_observed'].keys())\n",
    "    \n",
    "    endogenous_nodes = output_dict['endogenous_nodes']\n",
    "    causal_candidates = output_dict['causal_candidates']\n",
    "\n",
    "    if witnesses is None:\n",
    "        witnesses = [node for node in endogenous_nodes if (\n",
    "                                          node not in antecedents.keys() and \n",
    "                                          node not in consequents)]\n",
    "\n",
    "    table = get_table(output_dict['tr_sufficiency_A'],\n",
    "                      output_dict['mwc_sufficiency_A'],\n",
    "                      antecedents, witnesses, \n",
    "                      consequents)\n",
    "\n",
    "    # a bit hacky, but adding antecedents to conditioning\n",
    "    # within the first batch of handlers\n",
    "    # led to tensor broadcasting issues\n",
    "    for antecedent_str in antecedents.keys():\n",
    "        table = table[table[f\"{antecedent_str}_obs\"] == antecedents[antecedent_str]]\n",
    "    \n",
    "    table = table[table['sum_log_prob'] > -1e8]\n",
    "    \n",
    "    # we need to check set inclusion minimality of cause sets\n",
    "    # as there might be inclusion minimal sets that are not log-prob-sum minimal\n",
    "    # just because they have a higher cardinality\n",
    "    candidate_sets = []\n",
    "    for i, row in table.iterrows():\n",
    "        candidate_set = set()\n",
    "        for node in causal_candidates:\n",
    "            if row[f\"{node}_int\"] != row[f\"{node}_obs\"]:\n",
    "                candidate_set.add(node)\n",
    "        candidate_sets.append(candidate_set)\n",
    "        \n",
    "    actual_cause_sets = minimal_sets(candidate_sets)\n",
    "        \n",
    "    frozensets = [frozenset(s) for s in actual_cause_sets]\n",
    "    unique_actual_cause_sets = [set(f) for f in set(frozensets)]\n",
    "        \n",
    "    sufficiency_flag = any(key in ac_set for key in antecedents.keys() for ac_set in actual_cause_sets)\n",
    "\n",
    "    return  unique_actual_cause_sets, sufficiency_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does fixing the antecedent always lead to a change in the consequent?\n",
    "\n",
    "def sufficient_causality_checkB(output_dict, mwc = None, trace = None, antecedents = None, consequents = None):\n",
    "    \n",
    "    if antecedents is None:\n",
    "        antecedents = output_dict['antecedents']\n",
    "    if consequents is None:\n",
    "        consequents = list(output_dict['consequents_observed'].keys())\n",
    "    \n",
    "    if trace is None:    \n",
    "        trace = output_dict[\"tr_sufficiency_B\"]    \n",
    "    \n",
    "    if mwc is None:\n",
    "        mwc = output_dict[\"mwc_sufficiency_B\"]\n",
    "    \n",
    "    outcome_df = pd.DataFrame()\n",
    "    with mwc:\n",
    "        for consequent in consequents:\n",
    "            value = trace.trace.nodes[consequent][\"value\"]\n",
    "            _indices = [\n",
    "                    i for i in list(antecedents.keys()) if i in indices_of(value, event_dim=0)\n",
    "                ]\n",
    "            _int_con = gather(\n",
    "            value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "            outcome_df[consequent] = _int_con.squeeze().tolist()\n",
    "        \n",
    "    return ((outcome_df) == True).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the antecedent set a minimal set that \n",
    "# satisfies these two conditions?\n",
    "\n",
    "def minimal_sufficiency_check(output_dict):\n",
    "    antecedent_candidates = powerset(output_dict['antecedents'])\n",
    "    \n",
    "    a_checks = []\n",
    "    b_checks = []\n",
    "    for i, antecedent_candidate in enumerate(antecedent_candidates):\n",
    "        a_checks.append(sufficient_causality_checkA(\n",
    "            output_dict,antecedents = antecedent_candidate,            \n",
    "                witnesses = [node for node in output_dict['endogenous_nodes'] if (\n",
    "                            node not in antecedent_candidate.keys() and \n",
    "                            node not in output_dict['consequents_observed'].keys())])[1]\n",
    "        )\n",
    "    \n",
    "        b_checks.append( sufficient_causality_checkB(output_dict, \n",
    "                                                     mwc = output_dict[\"mwc_candidate\"][i],\n",
    "                                                     trace = output_dict[\"tr_candidate\"][i],\n",
    "                                            antecedents = antecedent_candidate)\n",
    "            )\n",
    "        \n",
    "    minimality = not any(a and b for a,b in zip(a_checks, b_checks))       \n",
    "    \n",
    "    return {\"minimality\": minimality, \"a_checks\": a_checks, \"b_checks\": b_checks, \"antecedent_candidates\": antecedent_candidates}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the explanation possible and nontrivial?\n",
    "\n",
    "def possibility_and_nontriviality_check(output_dict):\n",
    "    \n",
    "    trace = output_dict[\"tr_priors\"]\n",
    "    antecedents = output_dict['antecedents']\n",
    "    consequents_observed = output_dict['consequents_observed']\n",
    "    \n",
    "    reqs = {**antecedents, **consequents_observed}\n",
    "\n",
    "    reqs_outcome = pd.DataFrame()\n",
    "\n",
    "    for req in reqs:\n",
    "        reqs_outcome[req] = trace.trace.nodes[req][\"value\"]\n",
    "           \n",
    "    possibility = (reqs_outcome == 1.0).all(axis=1).any()\n",
    "    nontriviality = (reqs_outcome.iloc[:, :2] == 0.0).any(axis=1).any()\n",
    "    \n",
    "    return possibility, nontriviality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explanation_check(output_object):\n",
    "    \n",
    "    sufficiencyA = sufficient_causality_checkA(output_object)[1]\n",
    "    sufficiencyB = sufficient_causality_checkB(output_object)\n",
    "    minimal_sufficiency = minimal_sufficiency_check(output_object)['minimality']\n",
    "    possibility, nontriviality = possibility_and_nontriviality_check(output_object)\n",
    "    \n",
    "    return all([sufficiencyA, sufficiencyB, minimal_sufficiency, possibility, nontriviality])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest fire example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 7.1.2. from Halpern's *Actual Causality*. First, all contexts available, no settings excluded by what the agent knows about the world. In the conjunctive model, the joint nodes are an explanation of forest fire, none of the individual ones is. In the disjunctive model, the reverse is true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_conjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() & lightning.bool()),\n",
    "                                      event_dim=0)\n",
    "\n",
    "def ff_disjunctive():\n",
    "        u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "        u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "        match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "        lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "        forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() | lightning.bool()).bool(), event_dim=0)\n",
    "\n",
    "        return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ff_con_handler =  Explanation_Evaluation(\n",
    "    model = ff_conjunctive,\n",
    "    antecedents={\"match_dropped\": 1.0, \"lightning\": 1.0},\n",
    "    consequents_observed={\"forest_fire\": torch.tensor(True)},\n",
    "    endogenous_nodes=[\"match_dropped\", \"lightning\", \"forest_fire\"],\n",
    ")\n",
    "    \n",
    "with exp_ff_con_handler as con_ff:\n",
    "    ff_conjunctive()\n",
    "    \n",
    "explanation_check(con_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ff_con_separate_handler =  Explanation_Evaluation(\n",
    "    model = ff_conjunctive,\n",
    "    antecedents={\"match_dropped\": 1.0},\n",
    "    consequents_observed={\"forest_fire\": torch.tensor(True)},\n",
    "    endogenous_nodes=[\"match_dropped\", \"lightning\", \"forest_fire\"],\n",
    ")\n",
    "     \n",
    "with exp_ff_con_separate_handler as con_ff_separate:\n",
    "    ff_conjunctive()\n",
    "    \n",
    "explanation_check(con_ff_separate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ff_dis_handler =  Explanation_Evaluation(\n",
    "    model = ff_disjunctive,\n",
    "    antecedents={\"match_dropped\": 1.0, \"lightning\": 1.0},\n",
    "    consequents_observed={\"forest_fire\": torch.tensor(True)},\n",
    "    endogenous_nodes=[\"match_dropped\", \"lightning\", \"forest_fire\"],\n",
    ") \n",
    "    \n",
    "with exp_ff_dis_handler as dis_ff:\n",
    "    ff_disjunctive()\n",
    "\n",
    "explanation_check(dis_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ff_dis_separate_handler =  Explanation_Evaluation(\n",
    "    model = ff_disjunctive,\n",
    "    antecedents={\"match_dropped\": 1.0},\n",
    "    consequents_observed={\"forest_fire\": torch.tensor(True)},\n",
    "    endogenous_nodes=[\"match_dropped\", \"lightning\", \"forest_fire\"],\n",
    ") \n",
    "\n",
    "with exp_ff_dis_separate_handler as dis_ff_separate:\n",
    "    ff_disjunctive()\n",
    "\n",
    "explanation_check(dis_ff_separate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended forest fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In April, given the electrical storm in May, the forest would have caught fire in May (and not in June). However, given the storm, if there had been an electrical storm only in May, the forest\n",
    "would not have caught fire at all; if there had been an electrical storm only in June, it would have caught fire in June. The model has five endogenous variables: `ar` for *April rains*, \n",
    "`esm` for *electric storms in May*, `esj` for *electric storms in June*, `ffm` for *forest fire in May*, `ffj` for *forest fire in June* and `ff` for *forest fire either in May or in June (or both)*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_extended():\n",
    "    u_ar = pyro.sample(\"u_ar\", dist.Bernoulli(0.5))\n",
    "    u_esm = pyro.sample(\"u_esm\", dist.Bernoulli(0.5))\n",
    "    u_esj = pyro.sample(\"u_esj\", dist.Bernoulli(0.5))\n",
    "\n",
    "    ar = pyro.deterministic(\"ar\", u_ar, event_dim=0)\n",
    "    esm = pyro.deterministic(\"esm\", u_esm, event_dim=0)\n",
    "    esj = pyro.deterministic(\"esj\", u_esj, event_dim=0)\n",
    "\n",
    "    ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
    "    ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
    "\n",
    "    ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
    "\n",
    "    return {\"u_ar\": u_ar, \"u_esm\": u_esm, \"u_esj\": u_esj, \n",
    "            \"ar\": ar, \"esm\": esm, \"esj\": esj, \"ffm\": ffm, \"ffj\": ffj, \"ff\": ff}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with no excluded settings\n",
    "# one explanation for ff is esj\n",
    "\n",
    "exp_ff_extended_handler =  Explanation_Evaluation(\n",
    "    model = ff_extended,\n",
    "    antecedents={\"esj\": 1.},\n",
    "    consequents_observed={\"ff\": 1.},\n",
    "    endogenous_nodes=[\"ar\", \"esm\", \"esj\"],\n",
    ") \n",
    "\n",
    "with exp_ff_extended_handler as ext_ff1:\n",
    "    ff_extended()\n",
    "\n",
    "explanation_check(ext_ff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another is esm=1 and ar=0\n",
    "\n",
    "exp_ff_extended_handler2 =  Explanation_Evaluation(\n",
    "    model = ff_extended,\n",
    "    antecedents= {\"esm\": 1., \"ar\": 0.},\n",
    "    consequents_observed={\"ff\": 1.},\n",
    "    endogenous_nodes=[\"ar\", \"esm\", \"esj\"],\n",
    ") \n",
    "\n",
    "with exp_ff_extended_handler2 as ext_ff2:\n",
    "    ff_extended()\n",
    "\n",
    "explanation_check(ext_ff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             candidates  explanatory_status\n",
      "0                                    {}               False\n",
      "1                           {'ar': 0.0}               False\n",
      "2                           {'ar': 1.0}               False\n",
      "3                          {'esm': 1.0}               False\n",
      "4                          {'esm': 0.0}               False\n",
      "5               {'ar': 1.0, 'esm': 1.0}               False\n",
      "6               {'ar': 0.0, 'esm': 1.0}                True\n",
      "7               {'ar': 1.0, 'esm': 0.0}               False\n",
      "8               {'ar': 0.0, 'esm': 0.0}               False\n",
      "9                          {'esj': 1.0}                True\n",
      "10                         {'esj': 0.0}               False\n",
      "11              {'ar': 1.0, 'esj': 1.0}               False\n",
      "12              {'ar': 0.0, 'esj': 0.0}               False\n",
      "13              {'ar': 0.0, 'esj': 1.0}               False\n",
      "14              {'ar': 1.0, 'esj': 0.0}               False\n",
      "15             {'esm': 0.0, 'esj': 1.0}               False\n",
      "16             {'esm': 1.0, 'esj': 0.0}               False\n",
      "17             {'esm': 1.0, 'esj': 1.0}               False\n",
      "18             {'esm': 0.0, 'esj': 0.0}               False\n",
      "19  {'ar': 0.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "20  {'ar': 1.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "21  {'ar': 1.0, 'esm': 1.0, 'esj': 0.0}               False\n",
      "22  {'ar': 0.0, 'esm': 0.0, 'esj': 0.0}               False\n",
      "23  {'ar': 1.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "24  {'ar': 0.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "25  {'ar': 1.0, 'esm': 0.0, 'esj': 0.0}               False\n",
      "26  {'ar': 0.0, 'esm': 1.0, 'esj': 0.0}               False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n"
     ]
    }
   ],
   "source": [
    "# explore all 27 possible explanations\n",
    "# to confirm that these are the only \n",
    "# possible explanations\n",
    "\n",
    "explanatory_status = []\n",
    "candidates = []\n",
    "\n",
    "nodes = [\"ar\", \"esm\", \"esj\"]\n",
    "subsets = [[]]\n",
    "for node in nodes:\n",
    "        subsets.extend([subset + [node] for subset in subsets])\n",
    "\n",
    "\n",
    "for subset in subsets:\n",
    "        for _ in range(50):\n",
    "                random_setting = [random.choice([0., 1.]) \n",
    "                          for _ in range(len(subset))]\n",
    "                candidate = {var: val for var, val in zip(subset, random_setting)}\n",
    "\n",
    "                if candidate in candidates:\n",
    "                        continue\n",
    "\n",
    "                candidates.append(candidate)\n",
    "\n",
    "                _ext_handler =  Explanation_Evaluation(\n",
    "                                model = ff_extended,\n",
    "                                antecedents= candidate,\n",
    "                                consequents_observed={\"ff\": 1.},\n",
    "                                endogenous_nodes=[\"ar\", \"esm\", \"esj\"],\n",
    "                                ) \n",
    "                \n",
    "                with _ext_handler as _ext_obj:\n",
    "                        ff_extended()\n",
    "\n",
    "                explanatory_status.append(explanation_check(_ext_obj))\n",
    "\n",
    "explanation_search = pd.DataFrame({\"candidates\": candidates,\n",
    "                                   \"explanatory_status\": explanatory_status})\n",
    "\n",
    "print(explanation_search)\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chirho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
