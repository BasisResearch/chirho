{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import contextlib\n",
    "import collections\n",
    "from typing import Callable, Iterable, TypeVar, Mapping, List, Dict\n",
    "\n",
    "\n",
    "from itertools import chain, combinations\n",
    "\n",
    "import random\n",
    "\n",
    "import pyro\n",
    "import torch  \n",
    "\n",
    "from chirho.counterfactual.handlers.selection import get_factual_indices\n",
    "from chirho.indexed.ops import IndexSet, cond, gather, indices_of, scatter\n",
    "\n",
    "S = TypeVar(\"S\")\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "import pyro\n",
    "import chirho\n",
    "import pyro.distributions as dist\n",
    "import pyro.infer\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from chirho.counterfactual.handlers.counterfactual import (MultiWorldCounterfactual,\n",
    "        Preemptions)\n",
    "from chirho.counterfactual.handlers.explanation import (\n",
    "    SearchForCause,\n",
    "    consequent_differs,\n",
    "    random_intervention,\n",
    "    undo_split,\n",
    "    uniform_proposal,\n",
    "    ExplainCauses\n",
    ")\n",
    "from chirho.counterfactual.ops import preempt, split\n",
    "from chirho.indexed.ops import IndexSet, gather, indices_of\n",
    "from chirho.observational.handlers.condition import Factors, condition\n",
    "from chirho.interventional.ops import Intervention, intervene\n",
    "from chirho.interventional.handlers import do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorize_dictionary(dictionary):\n",
    "    return {k: torch.as_tensor(v) for k, v in dictionary.items()}\n",
    "\n",
    "def boolean_constraints_from_list(list):\n",
    "    return {k: pyro.distributions.constraints.boolean for k in list}\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def Explanation_Evaluation( \n",
    "        consequents_observed: Dict[str, torch.Tensor],\n",
    "        causal_candidates: List[str],\n",
    "        condition_on_consequent = True,\n",
    "        runs_n: int = 100,):\n",
    "\n",
    "        consequents = list(consequents_observed.keys())\n",
    "        consequents_observed = tensorize_dictionary(consequents_observed)\n",
    "        # this needs to be replaced if nodes are not boolean\n",
    "        causal_candidate_constraints = boolean_constraints_from_list(causal_candidates)\n",
    "\n",
    "        # needed in order to check if always a part of the antecedent set is a part of an actual cause\n",
    "        with MultiWorldCounterfactual() as mwc:\n",
    "            with ExplainCauses(antecedents = causal_candidate_constraints, \n",
    "                      witnesses = causal_candidates, consequents = consequents,\n",
    "                      antecedent_bias = .1,):\n",
    "                if condition_on_consequent:\n",
    "                    with condition(data = consequents_observed):\n",
    "                        with pyro.plate(\"sample\", runs_n):\n",
    "                            with pyro.poutine.trace() as tr:\n",
    "                                yield {\"mwc\": mwc, \"tr\" : tr}\n",
    "                else:\n",
    "                    with pyro.plate(\"sample\", runs_n):\n",
    "                        with pyro.poutine.trace() as tr:\n",
    "                            yield {\"mwc\": mwc, \"tr\" : tr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the original definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace obtained using the above handler already contains information that can be used to implement the original definition. Such a query can be answered with only two core concepts: subset inclusion and log prob sum comparison. First, let's implement this definition. Later on, we'll move beyond some of the idiosyncracies involved here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a table from the trace\n",
    "# post sampling conditioning on observations or interventions\n",
    "\n",
    "def gather_observed(value, causal_candidates):\n",
    "            \n",
    "    _indices = [i for i in causal_candidates if i in indices_of(value, event_dim=0)]\n",
    "    _int_can = gather(value, IndexSet(**{i: {0} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "def gather_intervened(value, causal_candidates):\n",
    "        \n",
    "    _indices = [i for i in causal_candidates if i in indices_of(value, event_dim=0)]\n",
    "    _int_can = gather(value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "def get_explanation_table(trace, mwc, causal_candidates, consequents):\n",
    "\n",
    "    trace.trace.compute_log_prob()\n",
    "    \n",
    "    table_dict = {}\n",
    "    nodes = trace.trace.nodes\n",
    "\n",
    "    for candidate in causal_candidates:\n",
    "        with mwc:\n",
    "            table_dict[f\"obs_{candidate}\"] = gather_observed(nodes[candidate]['value'],\n",
    "                                                             causal_candidates).squeeze().tolist()\n",
    "    \n",
    "            \n",
    "        table_dict[f\"pint_{candidate}\"] = nodes[f'__antecedent__proposal_{candidate}']['value'].squeeze().tolist()\n",
    "        table_dict[f\"apre_{candidate}\"] = nodes[f'__antecedent_{candidate}']['value'].squeeze().tolist()\n",
    "        table_dict[f\"lp_apre_{candidate}\"] = nodes[f\"__antecedent_{candidate}\"]['log_prob']\n",
    "\n",
    "        table_dict[f\"wpre_{candidate}\"] = nodes[f'__witness_{candidate}']['value'].squeeze().tolist()\n",
    "\n",
    "        # context used twice to make the table more legible (meaningful column ordering)\n",
    "        with mwc:\n",
    "            table_dict[f\"int_{candidate}\"] = gather_intervened(nodes[candidate]['value'],\n",
    "                                                             causal_candidates).squeeze().tolist()\n",
    "            \n",
    "\n",
    "    for consequent in consequents:\n",
    "        with mwc:\n",
    "            table_dict[f\"obs_{consequent}\"] = gather_observed(nodes[consequent][\"value\"], causal_candidates).squeeze().tolist()\n",
    "            table_dict[f\"int_{consequent}\"] = gather_intervened(nodes[consequent][\"value\"], causal_candidates).squeeze().tolist()    \n",
    "            table_dict[f\"lp_{consequent}\"] = gather_intervened(nodes[f\"__consequent_{consequent}\"][\"log_prob\"], causal_candidates).squeeze().tolist()\n",
    "        \n",
    "            # # a slightly hacky way to avoid shape errors in the extended forest fire example\n",
    "            # # where the index of ff is empty\n",
    "            # if len(table_dict[f\"obs_{consequent}\"]) == 2:\n",
    "            #     table_dict[f\"obs_ff\"] = table_dict[f\"obs_{consequent}\"][0]\n",
    "            #     table_dict[f\"int_ff\"] = table_dict[f\"obs_{consequent}\"][1]\n",
    "            #     table_dict[f\"lp_{consequent}\"] = table_dict[f\"lp_{consequent}\"][1]\n",
    "        \n",
    "    table_pd = pd.DataFrame(table_dict).drop_duplicates()\n",
    "\n",
    "    # remove rows where proposed interventions are the same as the observed values\n",
    "    for candidate in causal_candidates:\n",
    "        mask = table_pd[f'obs_{candidate}'] != table_pd[f'pint_{candidate}']\n",
    "        table_pd = table_pd[mask]\n",
    "      \n",
    "    \n",
    "    summands = [col for col in table_pd.columns if col.startswith('lp')]\n",
    "    table_pd[\"sum_lp\"] =  table_pd[summands].sum(axis = 1)\n",
    "    table_pd.sort_values(by = \"sum_lp\", ascending = False, inplace = True)\n",
    "\n",
    "    # some sanity checks\n",
    "    for candidate in causal_candidates:\n",
    "        \n",
    "        # witness preempted nodes have the same observed and intervened values\n",
    "        assert all(table_pd.loc[table_pd[f'wpre_{candidate}'] == 1, \n",
    "        f'obs_{candidate}'] == table_pd.loc[table_pd[f'wpre_{candidate}'] == 1,\n",
    "                                            f'int_{candidate}'])\n",
    "\n",
    "        # antecedent preemptions leave obs and int values unchanged\n",
    "        # this might fail generally if a node is downstream from some \n",
    "        # other intervention, but let's keep this sanity check for the simple models \n",
    "        # for now        \n",
    "        assert all(table_pd.loc[table_pd[f'apre_{candidate}'] == 1,\n",
    "                                f'obs_{candidate}'] == \n",
    "                   table_pd.loc[table_pd[f'apre_{candidate}'] == 1,\n",
    "                                f'int_{candidate}'])\n",
    "\n",
    "    return table_pd\n",
    "\n",
    "\n",
    "# brute force conditioning on the observed causal candidates\n",
    "# needed as adding them to condition statements leads to shape errors\n",
    "# needed to implement the original def, not needed later on\n",
    "\n",
    "# post-sampling conditioning on observations\n",
    "def get_conditioned_table(table, dict_of_nodes):\n",
    "    conditioned_table = table.copy()\n",
    "    for candidate in dict_of_nodes.keys():\n",
    "        obs_column = f'obs_{candidate}'\n",
    "        mask = (conditioned_table[obs_column] == dict_of_nodes[candidate])\n",
    "        conditioned_table = conditioned_table[mask]\n",
    "        conditioned_table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return conditioned_table\n",
    "\n",
    "# post-sampling conditioning on selected variables being intervened\n",
    "def get_intervened_table(table, dict_of_nodes):\n",
    "    intervened_table = table.copy()\n",
    "    for candidate in dict_of_nodes.keys():\n",
    "        condition_string = f\"`apre_{candidate}` == 0 and `wpre_{candidate}` == 0 and int_{candidate} == {dict_of_nodes[candidate]}\"        \n",
    "        intervened_table = intervened_table.query(condition_string)\n",
    "        intervened_table.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return intervened_table\n",
    "    \n",
    "\n",
    "# a few other utility functions\n",
    "def powerset(dct):\n",
    "    keys = list(dct.keys())\n",
    "    key_tuples = list(chain.from_iterable(combinations(keys, r) for r in range(len(keys) + 1)))[:-1]\n",
    "    subdicts = [{k: dct[k] for k in tpl} for tpl in key_tuples]\n",
    "    return subdicts\n",
    "\n",
    "def active(node, row):\n",
    "    return row[f\"apre_{node}\"] == 0 and row[f\"wpre_{node}\"] == 0 and row[f\"obs_{node}\"] != row[f\"pint_{node}\"]\n",
    "\n",
    "def minimal_sets(set_list):\n",
    "    inclusion_minimal = []\n",
    "    for s1 in set_list:\n",
    "        is_minimal = True\n",
    "        for s2 in set_list:\n",
    "            if s1 != s2 and s2.issubset(s1):\n",
    "                is_minimal = False\n",
    "        if is_minimal:\n",
    "            inclusion_minimal.append(s1)\n",
    "    return inclusion_minimal\n",
    "\n",
    "\n",
    "def minimal_cause_sets(table, causal_candidates, get_values = False):\n",
    "\n",
    "    if isinstance(causal_candidates, dict):\n",
    "        causal_candidates = list(causal_candidates.keys())\n",
    "    \n",
    "    subset_minimal_causes = []\n",
    "    subset_minimal_causes_dicts = []\n",
    "    # TODO remove if really redundant\n",
    "    subset_logprobs = []\n",
    "    changers = table[table['sum_lp']  > -1e7].copy()\n",
    "    \n",
    "    for _, row in changers.iterrows():\n",
    "        active_set = {node for node in  causal_candidates if active(node, row)}\n",
    "        active_dict = {node: row[f\"obs_{node}\"] for node in active_set}\n",
    "        if active_set not in subset_minimal_causes:\n",
    "            subset_minimal_causes.append(active_set)\n",
    "            subset_minimal_causes_dicts.append(active_dict)\n",
    "    # TODO remove if really redudnant\n",
    "    #        subset_logprobs.append(row['sum_lp'])\n",
    "        subset_minimal_causes = minimal_sets(subset_minimal_causes)\n",
    "    \n",
    "    if not get_values:\n",
    "        return subset_minimal_causes\n",
    "    else:\n",
    "        return subset_minimal_causes_dicts\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplanationHalpern():\n",
    "\n",
    "    def __init__(self, table, consequent_dict, causal_candidates_dict, print_report = True):\n",
    "        self.table = table\n",
    "        self.consequent_dict = consequent_dict\n",
    "        self.causal_candidates_dict = causal_candidates_dict\n",
    "\n",
    "        self.ex1A = self.ex1A_check(self.table, consequent_dict= self.consequent_dict, causal_candidates_dict= self.causal_candidates_dict)\n",
    "        self.ex1B = self.ex1B_check(self.table, consequent_dict=self.consequent_dict, causal_candidates_dict= self.causal_candidates_dict)\n",
    "        self.ex2 = self.ex2_check(self.table, consequent_dict= self.consequent_dict, causal_candidates_dict= self.causal_candidates_dict)\n",
    "        self.ex3_4 = self.ex3_4_check(self.table, consequent_dict=self.consequent_dict, causal_candidates_dict=self.causal_candidates_dict)\n",
    "        self.explanation = self.explanation_check()\n",
    "        if print_report:\n",
    "                print(f\"explanation check: {self.explanation}, \", \n",
    "                f\"causal_overlap: {self.ex1B}, \",\n",
    "                f\"minimality: {self.ex2}, \",\n",
    "                f\"possibility: {self.ex3_4[0]}, \", \n",
    "                f\"non-triviality: {self.ex3_4[1]}\")\n",
    "        \n",
    "    # Condition 1 requires that (A) in all contexts in which the causal candidates have the postulated values \n",
    "    # and the consequent is changed, there is at least one member of the causal candidates \n",
    "    # that is a member of a minimal actual cause of that change to the consequent.\n",
    "    def ex1A_check(self, table, consequent_dict, causal_candidates_dict):\n",
    "\n",
    "        # suppose not only consequent but also the causal candidates are observed    \n",
    "        merged_dict = {**consequent_dict, **causal_candidates_dict}\n",
    "        \n",
    "        table_conditioned = get_conditioned_table(table, merged_dict)\n",
    "\n",
    "        # check if causal candidates coincide with a minimal cause set\n",
    "        minimal_conditioned = minimal_cause_sets(table_conditioned, causal_candidates_dict)\n",
    "        parthood_flag = any(any(candidate in s for candidate in causal_candidates_dict.keys()) for s in minimal_conditioned)   \n",
    "        return parthood_flag, minimal_conditioned\n",
    "    \n",
    "    # Moreover, it requires that (B) for any context under consideration, intervening on all causal candidates \n",
    "    # to have the postulated value leads to the consequent.\n",
    "    def ex1B_check(self, table, causal_candidates_dict, consequent_dict):\n",
    "        table_intervened = get_intervened_table(table, causal_candidates_dict)\n",
    "        return all((table_intervened[f\"int_{key}\"] == consequent_dict[key]).all() for key in consequent_dict.keys()) \n",
    "\n",
    "    # The second condition of Halpern's definition is that the causal candidate set \n",
    "    # be a subset-minimal one satisfying both `ex1A` and `ex1B`.\n",
    "    def ex2_check(self, table,  consequent_dict, causal_candidates_dict,):\n",
    "        sub_candidates = powerset(causal_candidates_dict)\n",
    "        minimality_flag = True\n",
    "        for sub_candidate in sub_candidates:\n",
    "            ex1A_flag = self.ex1A_check(table, consequent_dict= consequent_dict, causal_candidates_dict= sub_candidate)[0]\n",
    "            ex1B_flag = self.ex1B_check(table, consequent_dict = consequent_dict, causal_candidates_dict= sub_candidate)\n",
    "            \n",
    "            if ex1A_flag and ex1B_flag:\n",
    "                minimality_flag = False\n",
    "                break\n",
    "        return minimality_flag\n",
    "    \n",
    "    # The remaining checks are whether the explanation is possible (given the consequent) and non-trivial.\n",
    "    def ex3_4_check(self, table, consequent_dict, causal_candidates_dict):\n",
    "\n",
    "        merged_dict = {**consequent_dict, **causal_candidates_dict}\n",
    "        table_conditioned = get_conditioned_table(table, merged_dict)\n",
    "        ex3 = table_conditioned.shape[0] > 0\n",
    "        ex4 = any(any(table[f\"obs_{key}\"] != causal_candidates_dict[key]) for key in causal_candidates_dict.keys())\n",
    "\n",
    "        return ex3, ex4\n",
    "    \n",
    "    def explanation_check(self):\n",
    "        return self.ex1A[0] and self.ex1B and self.ex2 and self.ex3_4[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u_ar': tensor(0.), 'u_esm': tensor(1.), 'u_esj': tensor(0.), 'ar': tensor(0.), 'esm': tensor(1.), 'esj': tensor(0.), 'ffm': tensor(1.), 'ffj': tensor(0.), 'ff': tensor(1.)}\n"
     ]
    }
   ],
   "source": [
    "def ff_extended():\n",
    "    u_ar = pyro.sample(\"u_ar\", dist.Bernoulli(0.5))\n",
    "    u_esm = pyro.sample(\"u_esm\", dist.Bernoulli(0.5))\n",
    "    u_esj = pyro.sample(\"u_esj\", dist.Bernoulli(0.5))\n",
    "\n",
    "    ar = pyro.deterministic(\"ar\", u_ar, event_dim=0)\n",
    "    esm = pyro.deterministic(\"esm\", u_esm, event_dim=0)\n",
    "    esj = pyro.deterministic(\"esj\", u_esj, event_dim=0)\n",
    "\n",
    "    ffm = pyro.deterministic(\"ffmt\", esm  * (1 - ar), event_dim=0).float()\n",
    "    \n",
    "    # TODO remove if happy\n",
    "    #ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
    "    \n",
    "\n",
    "    ffj = pyro.deterministic(\"ffj\", (esj * torch.max(ar, (1 - esm))), event_dim=0).float()\n",
    "    \n",
    "     # TODO remove if happy\n",
    "    #ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).squeeze().float()\n",
    "    \n",
    "    ff = pyro.deterministic(\"ff\", torch.max(ffm, ffj), event_dim=0).float()\n",
    "    #ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
    "    \n",
    "    return {\"u_ar\": u_ar, \"u_esm\": u_esm, \"u_esj\": u_esj, \n",
    "            \"ar\": ar, \"esm\": esm, \"esj\": esj, \"ffm\": ffm, \"ffj\": ffj, \"ff\": ff}\n",
    "\n",
    "print(\n",
    "ff_extended()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['u_ar', 'u_esm', 'u_esj', '__antecedent__proposal_ar', '__antecedent_ar', '__witness_ar', 'ar', '__antecedent__proposal_esm', '__antecedent_esm', '__witness_esm', 'esm', '__antecedent__proposal_esj', '__antecedent_esj', '__witness_esj', 'esj', 'ffmt', 'ffj', '__consequent_ff', 'ff'])\n",
      "torch.Size([2, 2, 2, 1, 1, 1, 1000])\n",
      "IndexSet({'ar': {0, 1}, 'esm': {0, 1}, 'esj': {0, 1}})\n",
      "torch.Size([1, 1, 1, 1, 1, 1, 1000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "consequents_observed={\"ff\": 1.}\n",
    "#causal_candidates_1= [\"ar\", \"esm\"]\n",
    "causal_candidates_dict_1 = {\"esj\": 1., \"esm\": 1.,  \"ar\": 0.}\n",
    "causal_candidates_1= list(causal_candidates_dict_1.keys())\n",
    "\n",
    "exp_ff_ext1_handler =  Explanation_Evaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates_1,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= 1000,\n",
    ")\n",
    "\n",
    "with exp_ff_ext1_handler as ext_ff_1:\n",
    "    ff_extended()\n",
    "\n",
    "\n",
    "nodes = ext_ff_1['tr'].trace.nodes\n",
    "mwc = ext_ff_1['mwc']\n",
    "\n",
    "print(nodes.keys())\n",
    "\n",
    "with mwc:\n",
    "    value = nodes['ff']['value']\n",
    "    print(value.shape)\n",
    "    _indices = [i for i in causal_candidates_1 if i in indices_of(value, event_dim=0)]\n",
    "    _int_can = gather(value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "    print(indices_of(value, event_dim=0))\n",
    "    print(_int_can.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['u_ar', 'u_esm', 'u_esj', '__antecedent__proposal_ar', '__antecedent_ar', '__witness_ar', 'ar', '__antecedent__proposal_esm', '__antecedent_esm', '__witness_esm', 'esm', '__antecedent__proposal_esj', '__antecedent_esj', '__witness_esj', 'esj', 'ffmt', 'ffj', '__consequent_ff', 'ff'])\n",
      "torch.Size([2, 2, 2, 1, 1, 1, 1000])\n",
      "IndexSet({'ar': {0, 1}, 'esm': {0, 1}, 'esj': {0, 1}})\n",
      "torch.Size([1, 1, 1, 1, 1, 1, 1000])\n"
     ]
    }
   ],
   "source": [
    "# to potential explanations are proper subsets of these candidates\n",
    "\n",
    "consequents_observed={\"ff\": 1.}\n",
    "#causal_candidates_1= [\"ar\", \"esm\"]\n",
    "causal_candidates_dict_1 = {\"esj\": 1., \"esm\": 1.,  \"ar\": 0.}\n",
    "causal_candidates_1= list(causal_candidates_dict_1.keys())\n",
    "\n",
    "exp_ff_ext1_handler =  Explanation_Evaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates_1,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= 1000,\n",
    ")\n",
    "\n",
    "with exp_ff_ext1_handler as ext_ff_1:\n",
    "    ff_extended()\n",
    "\n",
    "\n",
    "nodes = ext_ff_1['tr'].trace.nodes\n",
    "mwc = ext_ff_1['mwc']\n",
    "\n",
    "print(nodes.keys())\n",
    "\n",
    "with mwc:\n",
    "    value = nodes['ff']['value']\n",
    "    print(value.shape)\n",
    "    _indices = [i for i in causal_candidates_1 if i in indices_of(value, event_dim=0)]\n",
    "    _int_can = gather(value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "    print(indices_of(value, event_dim=0))\n",
    "    print(_int_can.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation check: False,  causal_overlap: True,  minimality: False,  possibility: True,  non-triviality: True\n",
      "explanation check: True,  causal_overlap: True,  minimality: True,  possibility: True,  non-triviality: True\n",
      "explanation check: True,  causal_overlap: True,  minimality: True,  possibility: True,  non-triviality: True\n"
     ]
    }
   ],
   "source": [
    "table_ext_ff_1 = get_explanation_table(ext_ff_1[\"tr\"], ext_ff_1[\"mwc\"], causal_candidates_1, consequents=[\"ff\"])\n",
    "ext_ff_1_explanation = ExplanationHalpern(table_ext_ff_1, {\"ff\": 1.}, {\"esj\": 1, \"esm\": 1.,  \"ar\": 0.})\n",
    "ext_ff_1_explanation = ExplanationHalpern(table_ext_ff_1, {\"ff\": 1.}, {\"esm\": 1.,  \"ar\": 0.})\n",
    "ext_ff_1_explanation = ExplanationHalpern(table_ext_ff_1, {\"ff\": 1.}, {\"esj\": 1.})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, however, we would like to explore the space of possible explanations - in this particular case, confirming that these are the only two explanations. If we approach it from the perspective of the query of the type \"is a given setting of a certain collection of endogenous variables an explanation of a given outcome\", it seems like the way to go is to manually propose candidates and run a separate query every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             candidates  explanatory_status\n",
      "0                                    {}               False\n",
      "1                           {'ar': 0.0}               False\n",
      "2                           {'ar': 1.0}               False\n",
      "3                          {'esm': 1.0}               False\n",
      "4                          {'esm': 0.0}               False\n",
      "5               {'ar': 1.0, 'esm': 0.0}               False\n",
      "6               {'ar': 0.0, 'esm': 1.0}                True\n",
      "7               {'ar': 0.0, 'esm': 0.0}               False\n",
      "8               {'ar': 1.0, 'esm': 1.0}               False\n",
      "9                          {'esj': 0.0}               False\n",
      "10                         {'esj': 1.0}                True\n",
      "11              {'ar': 0.0, 'esj': 1.0}               False\n",
      "12              {'ar': 0.0, 'esj': 0.0}               False\n",
      "13              {'ar': 1.0, 'esj': 1.0}               False\n",
      "14              {'ar': 1.0, 'esj': 0.0}               False\n",
      "15             {'esm': 1.0, 'esj': 0.0}               False\n",
      "16             {'esm': 0.0, 'esj': 0.0}               False\n",
      "17             {'esm': 0.0, 'esj': 1.0}               False\n",
      "18             {'esm': 1.0, 'esj': 1.0}               False\n",
      "19  {'ar': 1.0, 'esm': 0.0, 'esj': 0.0}               False\n",
      "20  {'ar': 1.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "21  {'ar': 1.0, 'esm': 1.0, 'esj': 0.0}               False\n",
      "22  {'ar': 0.0, 'esm': 1.0, 'esj': 0.0}               False\n",
      "23  {'ar': 0.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "24  {'ar': 0.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "25  {'ar': 1.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "26  {'ar': 0.0, 'esm': 0.0, 'esj': 0.0}               False\n"
     ]
    }
   ],
   "source": [
    "# explore all 27 possible explanations\n",
    "# to confirm that these are the only \n",
    "# possible explanations\n",
    "\n",
    "explanatory_status = []\n",
    "candidates = []\n",
    "\n",
    "nodes = [\"ar\", \"esm\", \"esj\"]\n",
    "subsets = [[]]\n",
    "for node in nodes:\n",
    "        subsets.extend([subset + [node] for subset in subsets])\n",
    "\n",
    "\n",
    "for subset in subsets:\n",
    "        for _ in range(50):\n",
    "                random_setting = [random.choice([0., 1.]) \n",
    "                          for _ in range(len(subset))]\n",
    "                candidate = {var: val for var, val in zip(subset, random_setting)}\n",
    "\n",
    "                if candidate in candidates:\n",
    "                        continue\n",
    "\n",
    "                candidates.append(candidate)\n",
    "                \n",
    "\n",
    "                explanatory_status.append(ExplanationHalpern(table_ext_ff_1, {\"ff\": 1.}, \n",
    "                                                             candidate, \n",
    "                                                             print_report = False).explanation)\n",
    "\n",
    "explanation_search = pd.DataFrame({\"candidates\": candidates,\n",
    "                                   \"explanatory_status\": explanatory_status})\n",
    "\n",
    "print(explanation_search)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, however, the handler we have already explores the possible actual causes for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_esj</th>\n",
       "      <th>pint_esj</th>\n",
       "      <th>apre_esj</th>\n",
       "      <th>lp_apre_esj</th>\n",
       "      <th>wpre_esj</th>\n",
       "      <th>int_esj</th>\n",
       "      <th>obs_esm</th>\n",
       "      <th>pint_esm</th>\n",
       "      <th>apre_esm</th>\n",
       "      <th>lp_apre_esm</th>\n",
       "      <th>...</th>\n",
       "      <th>obs_ar</th>\n",
       "      <th>pint_ar</th>\n",
       "      <th>apre_ar</th>\n",
       "      <th>lp_apre_ar</th>\n",
       "      <th>wpre_ar</th>\n",
       "      <th>int_ar</th>\n",
       "      <th>obs_ff</th>\n",
       "      <th>int_ff</th>\n",
       "      <th>lp_ff</th>\n",
       "      <th>sum_lp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.937942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.937942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.937942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.937942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.937942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.343407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.748872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    obs_esj  pint_esj  apre_esj  lp_apre_esj  wpre_esj  int_esj  obs_esm  \\\n",
       "0       0.0       1.0         1    -0.510826         0      0.0      1.0   \n",
       "1       1.0       0.0         0    -0.916291         0      0.0      1.0   \n",
       "2       0.0       1.0         1    -0.510826         1      0.0      1.0   \n",
       "3       0.0       1.0         1    -0.510826         0      0.0      1.0   \n",
       "4       0.0       1.0         1    -0.510826         0      0.0      1.0   \n",
       "5       1.0       0.0         0    -0.916291         0      0.0      0.0   \n",
       "6       1.0       0.0         0    -0.916291         0      0.0      0.0   \n",
       "7       1.0       0.0         0    -0.916291         0      0.0      1.0   \n",
       "8       1.0       0.0         0    -0.916291         0      0.0      1.0   \n",
       "9       1.0       0.0         0    -0.916291         0      0.0      1.0   \n",
       "10      1.0       0.0         0    -0.916291         0      0.0      0.0   \n",
       "11      1.0       0.0         0    -0.916291         0      0.0      0.0   \n",
       "12      1.0       0.0         0    -0.916291         0      0.0      1.0   \n",
       "13      1.0       0.0         0    -0.916291         0      0.0      0.0   \n",
       "14      1.0       0.0         0    -0.916291         0      0.0      0.0   \n",
       "\n",
       "    pint_esm  apre_esm  lp_apre_esm  ...  obs_ar  pint_ar  apre_ar  \\\n",
       "0        0.0         0    -0.916291  ...     0.0      1.0        1   \n",
       "1        0.0         1    -0.510826  ...     1.0      0.0        1   \n",
       "2        0.0         1    -0.510826  ...     0.0      1.0        0   \n",
       "3        0.0         1    -0.510826  ...     0.0      1.0        0   \n",
       "4        0.0         0    -0.916291  ...     0.0      1.0        1   \n",
       "5        1.0         0    -0.916291  ...     1.0      0.0        1   \n",
       "6        1.0         0    -0.916291  ...     1.0      0.0        1   \n",
       "7        0.0         0    -0.916291  ...     1.0      0.0        1   \n",
       "8        0.0         1    -0.510826  ...     1.0      0.0        0   \n",
       "9        0.0         1    -0.510826  ...     0.0      1.0        0   \n",
       "10       1.0         1    -0.510826  ...     0.0      1.0        0   \n",
       "11       1.0         0    -0.916291  ...     0.0      1.0        1   \n",
       "12       0.0         0    -0.916291  ...     0.0      1.0        1   \n",
       "13       1.0         1    -0.510826  ...     0.0      1.0        0   \n",
       "14       1.0         0    -0.916291  ...     0.0      1.0        0   \n",
       "\n",
       "    lp_apre_ar  wpre_ar  int_ar  obs_ff  int_ff  lp_ff    sum_lp  \n",
       "0    -0.510826        0     0.0     1.0     0.0    0.0 -1.937942  \n",
       "1    -0.510826        1     1.0     1.0     0.0    0.0 -1.937942  \n",
       "2    -0.916291        0     1.0     1.0     0.0    0.0 -1.937942  \n",
       "3    -0.916291        0     1.0     1.0     0.0    0.0 -1.937942  \n",
       "4    -0.510826        1     0.0     1.0     0.0    0.0 -1.937942  \n",
       "5    -0.510826        1     1.0     1.0     0.0    0.0 -2.343407  \n",
       "6    -0.510826        0     1.0     1.0     0.0    0.0 -2.343407  \n",
       "7    -0.510826        0     1.0     1.0     0.0    0.0 -2.343407  \n",
       "8    -0.916291        1     1.0     1.0     0.0    0.0 -2.343407  \n",
       "9    -0.916291        0     1.0     1.0     0.0    0.0 -2.343407  \n",
       "10   -0.916291        0     1.0     1.0     0.0    0.0 -2.343407  \n",
       "11   -0.510826        0     0.0     1.0     0.0    0.0 -2.343407  \n",
       "12   -0.510826        1     0.0     1.0     0.0    0.0 -2.343407  \n",
       "13   -0.916291        0     1.0     1.0     0.0    0.0 -2.343407  \n",
       "14   -0.916291        0     1.0     1.0     0.0    0.0 -2.748872  \n",
       "\n",
       "[15 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'esm': 1.0}, {'esj': 1.0}, {'ar': 0.0}, {'esj': 1.0, 'esm': 0.0}, {'esj': 1.0, 'ar': 0.0}, {'esj': 1.0, 'ar': 0.0}, {'esj': 1.0, 'esm': 1.0}, {'esj': 1.0, 'ar': 0.0}, {'esj': 1.0, 'ar': 0.0, 'esm': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "table_ext_ff_1_conditioned = get_conditioned_table(table_ext_ff_1, {\"ff\": 1.})\n",
    "\n",
    "display(table_ext_ff_1_conditioned[table_ext_ff_1_conditioned['sum_lp'] > -1e7])\n",
    "\n",
    "possible_actual_causes = minimal_cause_sets(table_ext_ff_1_conditioned, [\"ar\", \"esm\", \"esj\"], get_values=True)\n",
    "\n",
    "print(possible_actual_causes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While actual causes do not have to be explanations in Halpern's sense, one key intuition behind why one needs a notion of an explanation as defined by Halpern is that one is interested in narrowing down the search space to things that would **overlap** with actual causes if they were true and guiding our investigation in the search of actual causes. We propose an explanation, and then investigate the node values to see what the actual causes are. If this is your motivation, the approach we present allows you to focusing on possible actual causes directly and skip this extra step, by finding possible states that would **be** actual causes, if true. Interestingly, from the two explanations in Halpern's sense, only one in fact *is* a possible actual cause. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'esj': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for pac in possible_actual_causes:\n",
    "    if ExplanationHalpern(table_ext_ff_1, {\"ff\": 1.}, pac, print_report = False).explanation:\n",
    "        print(pac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice also that the bias used in the effect handlers results in smaller sets being ranked higher, which also can be useful in your search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest fire example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 7.1.2. from Halpern's *Actual Causality*. In the conjunctive model if both a lightning occurs and a match is dropped, a forest fire results, but both factors are required. In the disjunctive model, each of these factors individually is sufficient for the forest fire.\n",
    "\n",
    "Suppose all contexts are available and no setting is excluded by what the agent knows about the world. \n",
    "- In the conjunctive model, the joint nodes are an explanation of forest fire, none of the individual ones is. This is in contrast with actual causality claims, as each of the nodes is an actual cause, but the conjunction is not.\n",
    "- In the disjunctive model, the reverse is true. Each node is an explanation of forest fire, but the conjunction is not. This is in contrast with actual causality claims, as none of the individual nodes is an actual cause, but the conjunction is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyro.infer.config_enumerate\n",
    "def ff_conjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() & lightning.bool()),\n",
    "                                      event_dim=0)\n",
    "\n",
    "@pyro.infer.config_enumerate\n",
    "def ff_disjunctive():\n",
    "        u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "        u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "        match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped, event_dim=0)\n",
    "        lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "        forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() | lightning.bool()).bool(), event_dim=0)\n",
    "\n",
    "        return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "consequents_observed={\"forest_fire\": torch.tensor(True)}\n",
    "causal_candidates=[\"match_dropped\", \"lightning\"]\n",
    "causal_candidates_dict = {\"match_dropped\": 1., \"lightning\": 1.}\n",
    "antecedent_prefix = \"__antecedent\"\n",
    "\n",
    "exp_ff_con_handler =  Explanation_Evaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= 1000,\n",
    ")\n",
    "\n",
    "exp_ff_dis_handler =  Explanation_Evaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= 1000,\n",
    ")\n",
    "\n",
    "with exp_ff_con_handler as con_ff:\n",
    "        ff_conjunctive()\n",
    "\n",
    "with exp_ff_dis_handler as dis_ff:\n",
    "        ff_disjunctive()\n",
    "\n",
    "table_con_ff = get_explanation_table(con_ff[\"tr\"], con_ff[\"mwc\"], causal_candidates, consequents=[\"forest_fire\"])\n",
    "table_dis_ff = get_explanation_table(dis_ff[\"tr\"], dis_ff[\"mwc\"], causal_candidates, consequents=[\"forest_fire\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TraceENUM_ELBO works with bare model, doesn't seem to work \n",
    "# with Explanation_Evaluation\n",
    "\n",
    "# def exp_ff_conjunctive():\n",
    "#     exp_ff_con_handler =  Explanation_Evaluation(\n",
    "#     consequents_observed=consequents_observed,\n",
    "#     causal_candidates= causal_candidates,\n",
    "#     runs_n= 1000,\n",
    "#     )\n",
    "#     with exp_ff_con_handler as con_ff:\n",
    "#         ff_conjunctive()\n",
    "\n",
    "# def guide():\n",
    "#     pass\n",
    "\n",
    "# works with bare model\n",
    "#ff_conjunctive_conditioned = pyro.condition(ff_conjunctive, data={\"forest_fire\": torch.tensor(True)})\n",
    "#pyro.infer.TraceEnum_ELBO().compute_marginals(ff_conjunctive_conditioned, guide)\n",
    "\n",
    "#doesn't work here\n",
    "#pyro.infer.TraceEnum_ELBO().compute_marginals(exp_ff_conjunctive,guide)\n",
    "\n",
    "# will proceed with sampling from the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation check: True,  causal_overlap: True,  minimality: True,  possibility: True,  non-triviality: True\n",
      "explanation check: False,  causal_overlap: False,  minimality: True,  possibility: True,  non-triviality: True\n",
      "explanation check: False,  causal_overlap: True,  minimality: False,  possibility: True,  non-triviality: True\n",
      "explanation check: True,  causal_overlap: True,  minimality: True,  possibility: True,  non-triviality: True\n"
     ]
    }
   ],
   "source": [
    "# conjunction in the conjunctive model\n",
    "con_ff_explanation = ExplanationHalpern(table_con_ff, {\"forest_fire\": True}, causal_candidates_dict)\n",
    "# one of the nodes in the conjunctive model\n",
    "con_ff_explanation_match = ExplanationHalpern(table_con_ff, {\"forest_fire\": True}, {\"match_dropped\": 1.})\n",
    "\n",
    "# conjunction in the disjunctive model\n",
    "dis_ff_explanation = ExplanationHalpern(table_dis_ff, {\"forest_fire\": True}, causal_candidates_dict)\n",
    "# one of the nodes in the disjunctive model\n",
    "dis_ff_explanation_match = ExplanationHalpern(table_dis_ff, {\"forest_fire\": True}, {\"match_dropped\": 1.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended forest fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based on example 7.1.4. In April, given the electrical storm in May, the forest would have caught fire in May (and not in June). However, given the storm, if there had been an electrical storm only in May, the forest\n",
    "would not have caught fire at all; if there had been an electrical storm only in June, it would have caught fire in June. The model has five endogenous variables: `ar` for *April rains*, \n",
    "`esm` for *electric storms in May*, `esj` for *electric storms in June*, `ffm` for *forest fire in May*, `ffj` for *forest fire in June* and `ff` for *forest fire either in May or in June (or both)*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_extended():\n",
    "    u_ar = pyro.sample(\"u_ar\", dist.Bernoulli(0.5))\n",
    "    u_esm = pyro.sample(\"u_esm\", dist.Bernoulli(0.5))\n",
    "    u_esj = pyro.sample(\"u_esj\", dist.Bernoulli(0.5))\n",
    "\n",
    "    ar = pyro.deterministic(\"ar\", u_ar, event_dim=0)\n",
    "    esm = pyro.deterministic(\"esm\", u_esm, event_dim=0)\n",
    "    esj = pyro.deterministic(\"esj\", u_esj, event_dim=0)\n",
    "\n",
    "    ffm = pyro.deterministic(\"ffmt\", esm  * (1 - ar), event_dim=0).float()\n",
    "    ffj = pyro.deterministic(\"ffj\", (esj * torch.max(ar, (1 - esm))), event_dim=0).float()\n",
    "    ff = pyro.deterministic(\"ff\", torch.max(ffm, ffj), event_dim=0).float()\n",
    "    \n",
    "    return {\"u_ar\": u_ar, \"u_esm\": u_esm, \"u_esj\": u_esj, \n",
    "            \"ar\": ar, \"esm\": esm, \"esj\": esj, \"ffm\": ffm, \"ffj\": ffj, \"ff\": ff}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['u_ar', 'u_esm', 'u_esj', '__antecedent__proposal_ar', '__antecedent_ar', '__witness_ar', 'ar', '__antecedent__proposal_esm', '__antecedent_esm', '__witness_esm', 'esm', 'esj', 'ffm', 'ffj', '__consequent_ff', 'ff'])\n",
      "torch.Size([2, 2, 1, 2, 2, 1000])\n",
      "IndexSet({'ar': {0, 1}, 'esm': {0, 1}})\n",
      "torch.Size([1, 1, 1, 2, 2, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10995/1342066422.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1000], which does not match the required output shape [2, 2, 1, 1, 1, 1000]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_10995/1342066422.py:12: UserWarning: An output with one or more elements was resized since it had shape [1000], which does not match the required output shape [2, 2, 1, 1, 1, 1000]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).squeeze().float()\n",
      "/tmp/ipykernel_10995/1342066422.py:14: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 1000], which does not match the required output shape [2, 2, 1, 2, 2, 1000]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n"
     ]
    }
   ],
   "source": [
    "# with no excluded settings\n",
    "# one explanation for ff is esj\n",
    "\n",
    "\n",
    "consequents_observed={\"ff\": 1.}\n",
    "#causal_candidates_1= [\"ar\", \"esm\"]\n",
    "causal_candidates_dict_1 = {\"esm\": 1.,  \"ar\": 0.}\n",
    "causal_candidates_1= list(causal_candidates_dict_1.keys())\n",
    "\n",
    "\n",
    "exp_ff_ext1_handler =  Explanation_Evaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates_1,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= 1000,\n",
    ")\n",
    "\n",
    "with exp_ff_ext1_handler as ext_ff_1:\n",
    "    ff_extended()\n",
    "\n",
    "\n",
    "nodes = ext_ff_1['tr'].trace.nodes\n",
    "mwc = ext_ff_1['mwc']\n",
    "\n",
    "print(nodes.keys())\n",
    "\n",
    "with mwc:\n",
    "    value = nodes['ff']['value']\n",
    "    print(value.shape)\n",
    "    _indices = [i for i in causal_candidates_1 if i in indices_of(value, event_dim=0)]\n",
    "    _int_can = gather(value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "    print(indices_of(value, event_dim=0))\n",
    "    print(_int_can.shape)\n",
    "    #print(gather_observed(nodes['ff']['value'], causal_candidates_1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "table_ext_ff_1 = get_explanation_table(ext_ff_1[\"tr\"], ext_ff_1[\"mwc\"], causal_candidates_1, consequents=[\"ff\"])\n",
    "\n",
    "display(table_ext_ff_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ext_ff_1_explanation = ExplanationHalpern(table_ext_ff_1, {\"ff\": 1.}, causal_candidates_dict_1)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "exp_ff_dis_handler =  Explanation_Evaluation(\n",
    "    consequents_observed=consequents_observed,\n",
    "    causal_candidates= causal_candidates,\n",
    "    condition_on_consequent = False,\n",
    "    runs_n= 1000,\n",
    ")\n",
    "\n",
    "with exp_ff_con_handler as con_ff:\n",
    "        ff_conjunctive()\n",
    "\n",
    "\n",
    "exp_ff_extended_handler =  Explanation_Evaluation(\n",
    "    model = ff_extended,\n",
    "    antecedents={\"esj\": 1.},\n",
    "    consequents_observed={\"ff\": 1.},\n",
    "    endogenous_nodes=[\"ar\", \"esm\", \"esj\"],\n",
    ") \n",
    "\n",
    "with exp_ff_extended_handler as ext_ff1:\n",
    "    ff_extended()\n",
    "\n",
    "explanation_check(ext_ff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another is esm=1 and ar=0\n",
    "\n",
    "exp_ff_extended_handler2 =  Explanation_Evaluation(\n",
    "    model = ff_extended,\n",
    "    antecedents= {\"esm\": 1., \"ar\": 0.},\n",
    "    consequents_observed={\"ff\": 1.},\n",
    "    endogenous_nodes=[\"ar\", \"esm\", \"esj\"],\n",
    ") \n",
    "\n",
    "with exp_ff_extended_handler2 as ext_ff2:\n",
    "    ff_extended()\n",
    "\n",
    "explanation_check(ext_ff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             candidates  explanatory_status\n",
      "0                                    {}               False\n",
      "1                           {'ar': 0.0}               False\n",
      "2                           {'ar': 1.0}               False\n",
      "3                          {'esm': 1.0}               False\n",
      "4                          {'esm': 0.0}               False\n",
      "5               {'ar': 1.0, 'esm': 1.0}               False\n",
      "6               {'ar': 0.0, 'esm': 1.0}                True\n",
      "7               {'ar': 1.0, 'esm': 0.0}               False\n",
      "8               {'ar': 0.0, 'esm': 0.0}               False\n",
      "9                          {'esj': 1.0}                True\n",
      "10                         {'esj': 0.0}               False\n",
      "11              {'ar': 1.0, 'esj': 1.0}               False\n",
      "12              {'ar': 0.0, 'esj': 0.0}               False\n",
      "13              {'ar': 0.0, 'esj': 1.0}               False\n",
      "14              {'ar': 1.0, 'esj': 0.0}               False\n",
      "15             {'esm': 0.0, 'esj': 1.0}               False\n",
      "16             {'esm': 1.0, 'esj': 0.0}               False\n",
      "17             {'esm': 1.0, 'esj': 1.0}               False\n",
      "18             {'esm': 0.0, 'esj': 0.0}               False\n",
      "19  {'ar': 0.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "20  {'ar': 1.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "21  {'ar': 1.0, 'esm': 1.0, 'esj': 0.0}               False\n",
      "22  {'ar': 0.0, 'esm': 0.0, 'esj': 0.0}               False\n",
      "23  {'ar': 1.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "24  {'ar': 0.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "25  {'ar': 1.0, 'esm': 0.0, 'esj': 0.0}               False\n",
      "26  {'ar': 0.0, 'esm': 1.0, 'esj': 0.0}               False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:10: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:11: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
      "/tmp/ipykernel_35567/2123458515.py:13: UserWarning: An output with one or more elements was resized since it had shape [2, 1, 1, 1, 100], which does not match the required output shape [2, 2, 1, 1, 1, 100]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n"
     ]
    }
   ],
   "source": [
    "# explore all 27 possible explanations\n",
    "# to confirm that these are the only \n",
    "# possible explanations\n",
    "\n",
    "explanatory_status = []\n",
    "candidates = []\n",
    "\n",
    "nodes = [\"ar\", \"esm\", \"esj\"]\n",
    "subsets = [[]]\n",
    "for node in nodes:\n",
    "        subsets.extend([subset + [node] for subset in subsets])\n",
    "\n",
    "\n",
    "for subset in subsets:\n",
    "        for _ in range(50):\n",
    "                random_setting = [random.choice([0., 1.]) \n",
    "                          for _ in range(len(subset))]\n",
    "                candidate = {var: val for var, val in zip(subset, random_setting)}\n",
    "\n",
    "                if candidate in candidates:\n",
    "                        continue\n",
    "\n",
    "                candidates.append(candidate)\n",
    "\n",
    "                _ext_handler =  Explanation_Evaluation(\n",
    "                                model = ff_extended,\n",
    "                                antecedents= candidate,\n",
    "                                consequents_observed={\"ff\": 1.},\n",
    "                                endogenous_nodes=[\"ar\", \"esm\", \"esj\"],\n",
    "                                ) \n",
    "                \n",
    "                with _ext_handler as _ext_obj:\n",
    "                        ff_extended()\n",
    "\n",
    "                explanatory_status.append(explanation_check(_ext_obj))\n",
    "\n",
    "explanation_search = pd.DataFrame({\"candidates\": candidates,\n",
    "                                   \"explanatory_status\": explanatory_status})\n",
    "\n",
    "print(explanation_search)\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chirho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
