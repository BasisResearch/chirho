{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb off\n",
    "\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "from typing import Dict, List, Optional, Tuple, Union, TypeVar, Callable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "from causal_pyro.indexed.ops import IndexSet, gather, indices_of, scatter\n",
    "from causal_pyro.interventional.handlers import do\n",
    "from causal_pyro.counterfactual.handlers import MultiWorldCounterfactual, Preemptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HalpernPearlModifiedApproximate:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: Callable,\n",
    "        antecedents: Union[Dict[str, torch.Tensor], List[str]],\n",
    "        outcome: str,\n",
    "        witness_candidates: List[str],\n",
    "        observations: Optional[Dict[str, torch.Tensor]],\n",
    "        sample_size: int = 100,\n",
    "        event_dim: int = 0\n",
    "        ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.antecedents = antecedents\n",
    "        self.outcome = outcome\n",
    "        self.witness_candidates = witness_candidates\n",
    "        self.observations = observations\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        self.antecedents_dict = (\n",
    "            self.antecedents if isinstance(self.antecedents, dict)\n",
    "            else self.revert_antecedents(self.antecedents)\n",
    "        )\n",
    "    \n",
    "        self.preemptions = {candidate: functools.partial(self.preempt_with_factual,\n",
    "                                             antecedents = self.antecedents) for \n",
    "                                             candidate in self.witness_candidates}\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def revert_antecedents(antecedents: List[str]) -> Dict[str, Callable[[torch.Tensor], torch.Tensor]]:\n",
    "        return {antecedent: (lambda v: 1 - v) for antecedent in antecedents}\n",
    "\n",
    "    @staticmethod   \n",
    "    def preempt_with_factual(value: torch.Tensor, *,\n",
    "                          antecedents: List[str] = None, event_dim: int = 0):\n",
    "    \n",
    "        if antecedents is None:\n",
    "            antecedents = []\n",
    "\n",
    "        antecedents = [a for a in antecedents if a in indices_of(value, event_dim=event_dim)]\n",
    "\n",
    "        factual_value = gather(value, IndexSet(**{antecedent: {0} for antecedent in antecedents}),\n",
    "                                event_dim=event_dim)\n",
    "            \n",
    "        return scatter({\n",
    "            IndexSet(**{antecedent: {0} for antecedent in antecedents}): factual_value,\n",
    "            IndexSet(**{antecedent: {1} for antecedent in antecedents}): factual_value,\n",
    "        }, event_dim=event_dim)\n",
    "        \n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with pyro.poutine.trace() as trace:\n",
    "            with MultiWorldCounterfactual():\n",
    "                with do(actions=self.antecedents_dict):\n",
    "                    with Preemptions(actions = self.preemptions):\n",
    "                        with pyro.condition(data={k: torch.as_tensor(v) for k, v in self.observations.items()}):\n",
    "                            with pyro.plate(\"plate\", self.sample_size):\n",
    "                                self.consequent = self.model()[self.outcome]\n",
    "                                self.intervened_consequent = gather(self.consequent, IndexSet(**{ant: {1} for ant in self.antecedents}))\n",
    "                                self.observed_consequent = gather(self.consequent, IndexSet(**{ant: {0} for ant in self.antecedents}))\n",
    "                                self.consequent_differs = self.intervened_consequent != self.observed_consequent   \n",
    "                                pyro.factor(\"consequent_differs\", torch.where(self.consequent_differs, torch.tensor(0.0), torch.tensor(-1e8)))\n",
    "                            \n",
    "        self.trace = trace.trace\n",
    "\n",
    "        # # slightly hacky solution for cases with no witness candidates\n",
    "        self.existential_but_for = any(self.consequent_differs.squeeze().tolist()\n",
    "                                        ) if self.witness_candidates else self.consequent_differs.squeeze()\n",
    "        \n",
    "        witness_dict = dict()\n",
    "        if self.witness_candidates:\n",
    "            witness_keys = [\"__split_\" + candidate for candidate in self.witness_candidates]\n",
    "            witness_dict = {key: self.trace.nodes[key]['value']  for key in witness_keys}\n",
    "            witness_dict['observed'] = self.observed_consequent.squeeze()\n",
    "\n",
    "        witness_dict['intervened'] = self.intervened_consequent.squeeze()\n",
    "        witness_dict['consequent_differs'] = self.consequent_differs.squeeze()\n",
    "\n",
    "        # slightly hacky as above\n",
    "        self.witness_df = pd.DataFrame(witness_dict) if self.witness_candidates else witness_dict\n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stone throwing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sally_throws': tensor(0.),\n",
       " 'bill_throws': tensor(0.),\n",
       " 'sally_hits': tensor(0.),\n",
       " 'bill_hits': tensor(0.),\n",
       " 'bottle_shatters': tensor(0.)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stones_model():        \n",
    "    prob_sally_throws = pyro.sample(\"prob_sally_throws\", dist.Beta(1, 1))\n",
    "    prob_bill_throws = pyro.sample(\"prob_bill_throws\", dist.Beta(1, 1))\n",
    "    prob_sally_hits = pyro.sample(\"prob_sally_hits\", dist.Beta(1, 1))\n",
    "    prob_bill_hits = pyro.sample(\"prob_bill_hits\", dist.Beta(1, 1))\n",
    "    prob_bottle_shatters_if_sally = pyro.sample(\"prob_bottle_shatters_if_sally\", dist.Beta(1, 1))\n",
    "    prob_bottle_shatters_if_bill = pyro.sample(\"prob_bottle_shatters_if_bill\", dist.Beta(1, 1))\n",
    "\n",
    "\n",
    "    sally_throws = pyro.sample(\"sally_throws\", dist.Bernoulli(prob_sally_throws))\n",
    "    bill_throws = pyro.sample(\"bill_throws\", dist.Bernoulli(prob_bill_throws))\n",
    "\n",
    "    new_shp = torch.where(sally_throws == 1,prob_sally_hits , 0.0)\n",
    "\n",
    "    sally_hits = pyro.sample(\"sally_hits\",dist.Bernoulli(new_shp))\n",
    "\n",
    "    new_bhp = torch.where(\n",
    "            (\n",
    "                bill_throws.bool()\n",
    "                & (~sally_hits.bool())\n",
    "            )\n",
    "            == 1,\n",
    "            prob_bill_hits,\n",
    "            torch.tensor(0.0),\n",
    "        )\n",
    "\n",
    "\n",
    "    bill_hits = pyro.sample(\"bill_hits\", dist.Bernoulli(new_bhp))\n",
    "\n",
    "    new_bsp = torch.where(\n",
    "            bill_hits.bool() == 1,\n",
    "            prob_bottle_shatters_if_bill,\n",
    "            torch.where(\n",
    "                sally_hits.bool() == 1,\n",
    "                prob_bottle_shatters_if_sally,\n",
    "                torch.tensor(0.0),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    bottle_shatters = pyro.sample(\n",
    "            \"bottle_shatters\", dist.Bernoulli(new_bsp)\n",
    "        )\n",
    "\n",
    "    return {\n",
    "            \"sally_throws\": sally_throws,\n",
    "            \"bill_throws\": bill_throws,\n",
    "            \"sally_hits\": sally_hits,\n",
    "            \"bill_hits\": bill_hits,\n",
    "            \"bottle_shatters\": bottle_shatters,\n",
    "        }\n",
    "\n",
    "stones_model.nodes = [\n",
    "            \"sally_throws\",\n",
    "            \"bill_throws\",\n",
    "            \"sally_hits\",\n",
    "            \"bill_hits\",\n",
    "            \"bottle_shatters\",\n",
    "        ]\n",
    "\n",
    "stones_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "   __split_bill_throws  __split_bill_hits  observed  intervened  \\\n",
      "0                    1                  1       1.0         0.0   \n",
      "1                    1                  1       1.0         0.0   \n",
      "2                    0                  1       1.0         0.0   \n",
      "3                    0                  1       1.0         0.0   \n",
      "4                    0                  0       1.0         1.0   \n",
      "5                    1                  0       1.0         1.0   \n",
      "\n",
      "   consequent_differs  \n",
      "0                True  \n",
      "1                True  \n",
      "2                True  \n",
      "3                True  \n",
      "4               False  \n",
      "5               False  \n",
      "True\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(101)\n",
    "stonesHPM = HalpernPearlModifiedApproximate(\n",
    "    model = stones_model,\n",
    "    antecedents = [\"sally_throws\"],\n",
    "    outcome = \"bottle_shatters\",\n",
    "    witness_candidates = [\"bill_throws\", \"bill_hits\"],\n",
    "    observations = {\"prob_sally_throws\": 1, \n",
    "                    \"prob_bill_throws\": 1,\n",
    "                    \"prob_sally_hits\": 1,\n",
    "                    \"prob_bill_hits\": 1,\n",
    "                    \"prob_bottle_shatters_if_sally\": 1,\n",
    "                    \"prob_bottle_shatters_if_bill\": 1,\n",
    "                    \"sally_throws\": 1, \"bill_throws\": 1},\n",
    "    sample_size = 6,\n",
    "    event_dim = 0\n",
    ")\n",
    "\n",
    "stonesHPM()\n",
    "\n",
    "print(\n",
    "any(stonesHPM.consequent_differs.squeeze())\n",
    ")\n",
    "\n",
    "print(\n",
    "stonesHPM.witness_df\n",
    ")\n",
    "\n",
    "print(stonesHPM.existential_but_for)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'match_dropped': tensor(0.),\n",
       " 'lightning': tensor(0.),\n",
       " 'forest_fire': tensor(0.)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ff_conjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                       u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", torch.logical_and(match_dropped, lightning), event_dim=0).float()\n",
    "\n",
    "    return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n",
    "\n",
    "ff_conjunctive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'match_dropped': tensor(0.),\n",
       " 'lightning': tensor(1.),\n",
       " 'forest_fire': tensor(1.)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ff_disjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                       u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", torch.logical_or(match_dropped, lightning), event_dim=0).float()\n",
    "\n",
    "    return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n",
    "\n",
    "ff_disjunctive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   __split_lightning  observed  intervened  consequent_differs\n",
      "0                  0       1.0         0.0                True\n",
      "1                  1       1.0         0.0                True\n",
      "2                  1       1.0         0.0                True\n",
      "3                  0       1.0         0.0                True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# In the conjunctive model \n",
    "# Each of the two causes is a but-for cause \n",
    "pyro.set_rng_seed(101)\n",
    "ff_conjunctiveHPM = HalpernPearlModifiedApproximate(\n",
    "    model = ff_conjunctive,\n",
    "    antecedents = [\"match_dropped\"],\n",
    "    outcome = \"forest_fire\",\n",
    "    witness_candidates = [\"lightning\"],\n",
    "    observations = {\"match_dropped\": 1, \"lightning\": 1},\n",
    "    sample_size = 4,\n",
    "    event_dim = 0\n",
    ")\n",
    "\n",
    "ff_conjunctiveHPM()\n",
    "\n",
    "\n",
    "print(\n",
    "ff_conjunctiveHPM.witness_df\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "ff_conjunctiveHPM.existential_but_for\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   __split_lightning  observed  intervened  consequent_differs\n",
      "0                  0       1.0         1.0               False\n",
      "1                  1       1.0         1.0               False\n",
      "2                  1       1.0         1.0               False\n",
      "3                  0       1.0         1.0               False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the disjunctive model \n",
    "# either in the observed setting or in the preempted setting of MD\n",
    "# there still would be fire if there was no lightning\n",
    "pyro.set_rng_seed(101)\n",
    "ff_disjunctiveHPM = HalpernPearlModifiedApproximate(\n",
    "    model = ff_disjunctive,\n",
    "    antecedents = [\"match_dropped\"],\n",
    "    outcome = \"forest_fire\",\n",
    "    witness_candidates = [\"lightning\"],\n",
    "    observations = {\"match_dropped\": 1, \"lightning\": 1},\n",
    "    sample_size = 4,\n",
    "    event_dim = 0\n",
    ")\n",
    "\n",
    "ff_disjunctiveHPM()\n",
    "\n",
    "print(\n",
    "ff_disjunctiveHPM.witness_df\n",
    ")\n",
    "\n",
    "\n",
    "any(ff_disjunctiveHPM.consequent_differs.squeeze().tolist())\n",
    "\n",
    "ff_disjunctiveHPM.existential_but_for\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "{'intervened': tensor(0.), 'consequent_differs': tensor(True)}\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(101)\n",
    "ff_disjunctive_jointHPM = HalpernPearlModifiedApproximate(\n",
    "    model = ff_disjunctive,\n",
    "    antecedents = [\"match_dropped\", \"lightning\"],\n",
    "    outcome = \"forest_fire\",\n",
    "    witness_candidates = [],\n",
    "    observations = {\"match_dropped\": 1, \"lightning\": 1},\n",
    "    sample_size = 4,\n",
    "    event_dim = 0\n",
    ")\n",
    "\n",
    "ff_disjunctive_jointHPM()\n",
    "\n",
    "\n",
    "print(\n",
    "ff_disjunctive_jointHPM.existential_but_for\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "ff_disjunctive_jointHPM.witness_df\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intransitivity of actual causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monday_treatment': tensor(1.),\n",
       " 'tuesday_treatment': tensor(0.),\n",
       " 'bills_condition': tensor(0.),\n",
       " 'bill_alive': tensor(1.)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bc_function(mt, tt):\n",
    "    condition1 = (mt == 1) & (tt == 1)\n",
    "    condition2 = (mt == 1) & (tt == 0)\n",
    "    condition3 = (mt == 0) & (tt == 1)\n",
    "    condition4 = ~(condition1 | condition2 | condition3)\n",
    "\n",
    "    output = torch.where(condition1, torch.tensor(3.0), torch.tensor(0.0))\n",
    "    output = torch.where(condition2, torch.tensor(0.0), output)\n",
    "    output = torch.where(condition3, torch.tensor(1.0), output)\n",
    "    output = torch.where(condition4, torch.tensor(2.0), output)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def model_doctors():\n",
    "    u_monday_treatment = pyro.sample(\"u_monday_treatment\", dist.Bernoulli(0.5))\n",
    "\n",
    "    monday_treatment = pyro.deterministic(\n",
    "        \"monday_treatment\", u_monday_treatment, event_dim=0\n",
    "    )\n",
    "\n",
    "    tuesday_treatment = pyro.deterministic(\n",
    "        \"tuesday_treatment\",\n",
    "        torch.logical_not(monday_treatment).float(),\n",
    "        event_dim=0,\n",
    "    )\n",
    "\n",
    "    bills_condition = pyro.deterministic(\n",
    "        \"bills_condition\",\n",
    "        bc_function(monday_treatment, tuesday_treatment),\n",
    "        event_dim=0,\n",
    "    )\n",
    "\n",
    "    bill_alive = pyro.deterministic(\n",
    "        \"bill_alive\", bills_condition.not_equal(3.0).float(), event_dim=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"monday_treatment\": monday_treatment,\n",
    "        \"tuesday_treatment\": tuesday_treatment,\n",
    "        \"bills_condition\": bills_condition,\n",
    "        \"bill_alive\": bill_alive,\n",
    "    }\n",
    "\n",
    "\n",
    "# scm_doctors.ranges = {\n",
    "#     \"monday_treatment\": torch.Tensor([0.0, 1.0]),\n",
    "#     \"tuesday_treatment\": torch.Tensor([0.0, 1.0]),\n",
    "#     \"bills_condition\": torch.Tensor([0.0, 1.0, 2.0, 3.0]),\n",
    "#     \"bill_alive\": torch.Tensor([0.0, 1.0]),\n",
    "# }\n",
    "\n",
    "model_doctors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1: tensor(True) step 2: tensor(True) step 3: tensor(False)\n"
     ]
    }
   ],
   "source": [
    "doctors1_HPM = HalpernPearlModifiedApproximate(\n",
    "    model = model_doctors,\n",
    "    antecedents = [\"monday_treatment\"],\n",
    "    outcome = \"tuesday_treatment\",\n",
    "    witness_candidates = [],\n",
    "    observations = {\"u_monday_treatment\": 1},\n",
    "    sample_size = 4,\n",
    "    event_dim = 0\n",
    ")\n",
    "\n",
    "doctors1_HPM()\n",
    "\n",
    "\n",
    "doctors2_HPM = HalpernPearlModifiedApproximate(\n",
    "    model = model_doctors,\n",
    "    antecedents = [\"tuesday_treatment\"],\n",
    "    outcome = \"bill_alive\",\n",
    "    witness_candidates = [],\n",
    "    observations = {\"u_monday_treatment\": 1},\n",
    "    sample_size = 4,\n",
    "    event_dim = 0\n",
    ")\n",
    "\n",
    "doctors2_HPM()\n",
    "\n",
    "doctors3_HPM = HalpernPearlModifiedApproximate(\n",
    "    model = model_doctors,\n",
    "    antecedents = [\"monday_treatment\"],\n",
    "    outcome = \"bill_alive\",\n",
    "    witness_candidates = [],\n",
    "    observations = {\"u_monday_treatment\": 1},\n",
    "    sample_size = 4,\n",
    "    event_dim = 0\n",
    ")\n",
    "\n",
    "doctors3_HPM()\n",
    "\n",
    "\n",
    "print(\n",
    "\"step 1:\", doctors1_HPM.existential_but_for,\n",
    "\"step 2:\",  doctors2_HPM.existential_but_for,\n",
    "\"step 3:\", doctors3_HPM.existential_but_for\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friendly fire incident\n",
    "\n",
    "This comes from a causal model developed in a real-life incident investgation, as discussed in the Causalis Incident Reporting using SERAS® Reporter and SERAS® Analyst.\n",
    "\n",
    "a U.S. Special Forces air controller changing the battery on a Global Positioning System device he was using to target a Taliban outpost north of Kandahar.  Three special forces soldiers were killed and 20 were injured when a 2,000-pound, satellite-guided bomb landed, not on the Taliban outpost, but on a battalion command post occupied by American forces and a group of Afghan allies, including Hamid Karzai, now the interim prime minister.The Air Force combat controller was using a Precision Lightweight GPS Receiver to calculate the Taliban's coordinate for the attack. The controller did not realise that after he changed the device's battery, the machine was programmed to automatically come back on displaying coordinates for its own location, the official said.\n",
    "\n",
    "Minutes before the B-52 strike, the controller had used the GPS receiver to\n",
    "calculate the latitude and longitude of the Taliban position in minutes and seconds for an airstrike by a Navy F/A-18. Then, with the B-52 approaching the target, the air controller did a second calculation in “degree decimals” required by the bomber crew.  The controller had performed the calculation and recorded the position, when the receiver battery died. Without realizing the machine was programmed to come back on showing the coordinates of its\n",
    "own location, the controller mistakenly called in the American position to the B-52.\n",
    "\n",
    "Factors included in the model:\n",
    "\n",
    "1. The air controller changed the battery on the PLGR\n",
    "2. Three special forces soldiers were killed and 20 were injured\n",
    "3. B-52 fired a JDAM bomb at the Allied position\n",
    "4. The air controller was using the PLGR to calculate the Taliban's coordinates\n",
    "5. The controller did not realize that the PLGR was programmed to automatically come back on displaying coordinates for its own location\n",
    "6. The controller had used the PLGR to calculate the latitude and longitude of the Taliban position in minutes and seconds for an airstrike by a Navy F/A-18\n",
    "7. The air controller did a second calculation in “degree decimals” required by the bomber crew\n",
    "8. The controller had performed the calculation and recorded the position\n",
    "9. The controller mistakenly called in the American position to the B-52\n",
    "10. The B-52 fired a JDAM bomb at the Allied position\n",
    "11. The U.S. Air Force and Army had a training problem\n",
    "12. The PLRG resumed displaying the coordinates of its own location after the battery was changed\n",
    "13. The battery died at the crucial time\n",
    "14. The controller though he was calling in the Taliban position\n",
    "\n",
    "The DAG used in the model is as follows:\n",
    "![Friendly Fire DAG](figures/friendly_fire_dag.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_battery_change': tensor(True),\n",
       " 'f2_killed': tensor(False),\n",
       " 'f3_fired': tensor(False),\n",
       " 'f4_PLGR_now': tensor(1.),\n",
       " 'f5_unaware': tensor(0.),\n",
       " 'f6_PLGR_before': tensor(1.),\n",
       " 'f7_second_calculation': tensor(1.),\n",
       " 'f9_mistake_call': tensor(False),\n",
       " 'f10_landed': tensor(False),\n",
       " 'f11_training': tensor(0.),\n",
       " 'f12_PLGR_after': tensor(True),\n",
       " 'f13_battery_died': tensor(True),\n",
       " 'f14_wrong_position': tensor(0.)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def model_friendly_fire():\n",
    "    u_f4_PLGR_now = pyro.sample(\"u_f4_PLGR_now\", dist.Bernoulli(0.5))\n",
    "    u_f11_training = pyro.sample(\"u_f11_training\", dist.Bernoulli(0.5))\n",
    "\n",
    "    f4_PLGR_now = pyro.deterministic(\"f4_PLGR_now\", u_f4_PLGR_now, event_dim=0)\n",
    "    f11_training = pyro.deterministic(\n",
    "        \"f11_training\", u_f11_training, event_dim=0\n",
    "    )\n",
    "\n",
    "    f6_PLGR_before = pyro.deterministic(\n",
    "        \"f6_PLGR_before\", f4_PLGR_now, event_dim=0\n",
    "    )\n",
    "    f7_second_calculation = pyro.deterministic(\n",
    "        \"f7_second_calculation\", f4_PLGR_now, event_dim=0\n",
    "    )\n",
    "    f13_battery_died = pyro.deterministic(\n",
    "        \"f13_battery_died\",\n",
    "        f6_PLGR_before.bool() & f7_second_calculation.bool(),\n",
    "        event_dim=0,\n",
    "    )\n",
    "\n",
    "    f1_battery_change = pyro.deterministic(\n",
    "        \"f1_battery_change\", f13_battery_died, event_dim=0\n",
    "    )\n",
    "\n",
    "    f12_PLGR_after = pyro.deterministic(\n",
    "        \"f12_PLGR_after\", f1_battery_change, event_dim=0\n",
    "    )\n",
    "\n",
    "    f5_unaware = pyro.deterministic(\"f5_unaware\", f11_training, event_dim=0)\n",
    "\n",
    "    f14_wrong_position = pyro.deterministic(\n",
    "        \"f14_wrong_position\", f5_unaware, event_dim=0\n",
    "    )\n",
    "\n",
    "    f9_mistake_call = pyro.deterministic(\n",
    "        \"f9_mistake_call\",\n",
    "            f12_PLGR_after.bool() & \n",
    "            f14_wrong_position.bool(),\n",
    "        event_dim=0,\n",
    "    )\n",
    "\n",
    "    f3_fired = pyro.deterministic(\"f3_fired\", f9_mistake_call, event_dim=0)\n",
    "\n",
    "    f10_landed = pyro.deterministic(\n",
    "        \"f10_landed\", f3_fired.bool() &  f9_mistake_call.bool(), event_dim=0\n",
    "    )\n",
    "\n",
    "    f2_killed = pyro.deterministic(\"f2_killed\", f10_landed, event_dim=0)\n",
    "\n",
    "    return {\n",
    "        \"f1_battery_change\": f1_battery_change,\n",
    "        \"f2_killed\": f2_killed,\n",
    "        \"f3_fired\": f3_fired,\n",
    "        \"f4_PLGR_now\": f4_PLGR_now,\n",
    "        \"f5_unaware\": f5_unaware,\n",
    "        \"f6_PLGR_before\": f6_PLGR_before,\n",
    "        \"f7_second_calculation\": f7_second_calculation,\n",
    "        \"f9_mistake_call\": f9_mistake_call,\n",
    "        \"f10_landed\": f10_landed,\n",
    "        \"f11_training\": f11_training,\n",
    "        \"f12_PLGR_after\": f12_PLGR_after,\n",
    "        \"f13_battery_died\": f13_battery_died,\n",
    "        \"f14_wrong_position\": f14_wrong_position,\n",
    "    }\n",
    "\n",
    "model_friendly_fire()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuple:  True PLGR_before:  True second calculation:  True\n"
     ]
    }
   ],
   "source": [
    "friendly_fire_HPM = HalpernPearlModifiedApproximate(\n",
    "    model = model_friendly_fire,\n",
    "    antecedents = [\"f6_PLGR_before\", \"f7_second_calculation\"],\n",
    "    outcome = \"f2_killed\",\n",
    "    witness_candidates = [\"f4_PLGR_now\",\"f5_unaware\",\n",
    "    \"f11_training\",\n",
    "    \"f14_wrong_position\"],\n",
    "    observations = {\"u_f4_PLGR_now\": 1.0, \"u_f11_training\": 1.0},\n",
    "    sample_size = 20,\n",
    "    event_dim = 0\n",
    ")\n",
    "\n",
    "friendly_fire_sub1_HPM = HalpernPearlModifiedApproximate(\n",
    "    model = model_friendly_fire,\n",
    "    antecedents = [\"f6_PLGR_before\"],\n",
    "    outcome = \"f2_killed\",\n",
    "    witness_candidates = [\"f4_PLGR_now\",\"f5_unaware\",\n",
    "    \"f11_training\",\n",
    "    \"f14_wrong_position\", \"f7_second_calculation\"],\n",
    "    observations = {\"u_f4_PLGR_now\": 1.0, \"u_f11_training\": 1.0},\n",
    "    sample_size = 20,\n",
    "    event_dim = 0\n",
    ")\n",
    "\n",
    "friendly_fire_sub2_HPM = HalpernPearlModifiedApproximate(\n",
    "    model = model_friendly_fire,\n",
    "    antecedents = [\"f7_second_calculation\"],\n",
    "    outcome = \"f2_killed\",\n",
    "    witness_candidates = [\"f4_PLGR_now\",\"f5_unaware\",\n",
    "    \"f11_training\",\n",
    "    \"f14_wrong_position\", \"f6_PLGR_before\"],\n",
    "    observations = {\"u_f4_PLGR_now\": 1.0, \"u_f11_training\": 1.0},\n",
    "    sample_size = 20,\n",
    "    event_dim = 0\n",
    ")\n",
    "\n",
    "friendly_fire_HPM()\n",
    "friendly_fire_sub1_HPM()\n",
    "friendly_fire_sub2_HPM()\n",
    "\n",
    "print(\n",
    "\"tuple: \", friendly_fire_HPM.existential_but_for,\n",
    "\"PLGR_before: \", friendly_fire_sub1_HPM.existential_but_for,\n",
    "\"second calculation: \", friendly_fire_sub2_HPM.existential_but_for\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome': tensor(True)}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def voting_model():\n",
    "    u_vote0 = pyro.sample(\"u_vote0\", dist.Bernoulli(0.6))\n",
    "    u_vote1 = pyro.sample(\"u_vote1\", dist.Bernoulli(0.6))\n",
    "    u_vote2 = pyro.sample(\"u_vote2\", dist.Bernoulli(0.6))\n",
    "    u_vote3 = pyro.sample(\"u_vote3\", dist.Bernoulli(0.6))\n",
    "    u_vote4 = pyro.sample(\"u_vote4\", dist.Bernoulli(0.6))\n",
    "    u_vote5 = pyro.sample(\"u_vote5\", dist.Bernoulli(0.6))\n",
    "    \n",
    "    vote0 = pyro.deterministic(\"vote0\", u_vote0, event_dim=0)\n",
    "    vote1 = pyro.deterministic(\"vote1\", u_vote1, event_dim=0)\n",
    "    vote2 = pyro.deterministic(\"vote2\", u_vote2, event_dim=0)\n",
    "    vote3 = pyro.deterministic(\"vote3\", u_vote3, event_dim=0)\n",
    "    vote4 = pyro.deterministic(\"vote4\", u_vote4, event_dim=0)\n",
    "    vote5 = pyro.deterministic(\"vote5\", u_vote5, event_dim=0)\n",
    "\n",
    "    return {\"outcome\": vote0 + vote1 + vote2 + vote3 + vote4 +\n",
    "            vote5  > 3}\n",
    "\n",
    "voting_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "   __split_vote1  __split_vote2  __split_vote3  __split_vote4  __split_vote5  \\\n",
      "0              0              1              0              1              1   \n",
      "1              0              0              0              1              1   \n",
      "2              0              0              1              0              0   \n",
      "3              1              1              1              0              1   \n",
      "4              0              1              1              0              0   \n",
      "5              1              0              0              0              0   \n",
      "6              0              1              1              0              0   \n",
      "7              1              1              1              0              1   \n",
      "8              0              0              1              1              0   \n",
      "9              0              1              1              1              1   \n",
      "\n",
      "   observed  intervened  consequent_differs  \n",
      "0     False       False               False  \n",
      "1      True       False                True  \n",
      "2      True       False                True  \n",
      "3      True       False                True  \n",
      "4      True       False                True  \n",
      "5     False       False               False  \n",
      "6      True       False                True  \n",
      "7     False       False               False  \n",
      "8     False       False               False  \n",
      "9      True       False                True  \n",
      "odict_keys(['plate', 'u_vote0', 'u_vote1', 'u_vote2', 'u_vote3', 'u_vote4', 'u_vote5', 'vote0', 'vote1', '__split_vote1', 'vote2', '__split_vote2', 'vote3', '__split_vote3', 'vote4', '__split_vote4', 'vote5', '__split_vote5', 'consequent_differs'])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(32)\n",
    "votingHPM = HalpernPearlModifiedApproximate(\n",
    "    model = voting_model,\n",
    "    antecedents = [\"vote0\"],\n",
    "    outcome = \"outcome\",\n",
    "    witness_candidates = [f\"vote{i}\" for i in range(1,6)],\n",
    "    observations = dict(u_vote0=1., u_vote1=1., u_vote2=1.,\n",
    "                        u_vote3=0., u_vote4=0., uvote_5=0,\n",
    "                        ),\n",
    "    sample_size = 10)\n",
    "\n",
    "votingHPM()\n",
    "\n",
    "print(\n",
    "votingHPM.existential_but_for\n",
    ")\n",
    "\n",
    "print(\n",
    "votingHPM.witness_df\n",
    ")\n",
    "\n",
    "print(votingHPM.trace.nodes.keys())\n",
    "\n",
    "print(votingHPM.trace.nodes['__split_vote1']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome': tensor(True)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def voting_model():\n",
    "    u_vote0 = pyro.sample(\"u_vote0\", dist.Bernoulli(0.6))\n",
    "    u_vote1 = pyro.sample(\"u_vote1\", dist.Bernoulli(0.6))\n",
    "    u_vote2 = pyro.sample(\"u_vote2\", dist.Bernoulli(0.6))\n",
    "    u_vote3 = pyro.sample(\"u_vote3\", dist.Bernoulli(0.6))\n",
    "    u_vote4 = pyro.sample(\"u_vote4\", dist.Bernoulli(0.6))\n",
    "    u_vote5 = pyro.sample(\"u_vote5\", dist.Bernoulli(0.6))\n",
    "    u_vote6 = pyro.sample(\"u_vote6\", dist.Bernoulli(0.6))\n",
    "    u_vote7 = pyro.sample(\"u_vote7\", dist.Bernoulli(0.6))\n",
    "    u_vote8 = pyro.sample(\"u_vote8\", dist.Bernoulli(0.6))\n",
    "    u_vote9 = pyro.sample(\"u_vote9\", dist.Bernoulli(0.6))\n",
    "    u_vote10 = pyro.sample(\"u_vote10\", dist.Bernoulli(0.6))\n",
    "    \n",
    "    vote0 = pyro.deterministic(\"vote0\", u_vote0, event_dim=0)\n",
    "    vote1 = pyro.deterministic(\"vote1\", u_vote1, event_dim=0)\n",
    "    vote2 = pyro.deterministic(\"vote2\", u_vote2, event_dim=0)\n",
    "    vote3 = pyro.deterministic(\"vote3\", u_vote3, event_dim=0)\n",
    "    vote4 = pyro.deterministic(\"vote4\", u_vote4, event_dim=0)\n",
    "    vote5 = pyro.deterministic(\"vote5\", u_vote5, event_dim=0)\n",
    "    vote6 = pyro.deterministic(\"vote6\", u_vote6, event_dim=0)\n",
    "    vote7 = pyro.deterministic(\"vote7\", u_vote7, event_dim=0)\n",
    "    vote8 = pyro.deterministic(\"vote8\", u_vote8, event_dim=0)\n",
    "    vote9 = pyro.deterministic(\"vote9\", u_vote9, event_dim=0)\n",
    "    vote10 = pyro.deterministic(\"vote10\", u_vote10, event_dim=0)\n",
    "\n",
    "    return {\"outcome\": vote0 + vote1 + vote2 + vote3 + vote4 +\n",
    "            vote5 + vote6 + vote7 + vote8 + vote9 + vote10 > 5}\n",
    "\n",
    "voting_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# if you're one of six who voted for, you are an actual cause\n",
    "voting6HPM = HalpernPearlModifiedApproximate(\n",
    "    model = voting_model,\n",
    "    antecedents = [\"vote0\"],\n",
    "    outcome = \"outcome\",\n",
    "    witness_candidates = [f\"vote{i}\" for i in range(1,11)],\n",
    "    observations = dict(u_vote0=1., u_vote1=1., u_vote2=1.,\n",
    "                        u_vote3=1., u_vote4=1., uvote_5=1,\n",
    "                         u_vote6=0., u_vote7=0., u_vote8=0.,\n",
    "                        u_vote9=0., u_vote10=0.),\n",
    "    sample_size = 1000)\n",
    "\n",
    "voting6HPM()\n",
    "\n",
    "print(\n",
    "voting6HPM.existential_but_for\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "   __split_vote1  __split_vote2  __split_vote3  __split_vote4  __split_vote5  \\\n",
      "0              1              0              0              0              1   \n",
      "1              0              1              0              1              0   \n",
      "2              1              1              0              1              1   \n",
      "3              1              1              1              1              1   \n",
      "4              1              0              0              0              1   \n",
      "5              0              1              0              0              1   \n",
      "6              1              0              1              0              0   \n",
      "7              1              1              0              1              1   \n",
      "8              0              0              0              0              1   \n",
      "9              1              1              0              0              1   \n",
      "\n",
      "   __split_vote6  __split_vote7  __split_vote8  __split_vote9  __split_vote10  \\\n",
      "0              1              1              0              0               0   \n",
      "1              0              0              1              0               0   \n",
      "2              0              1              1              1               1   \n",
      "3              1              1              1              0               0   \n",
      "4              1              1              1              0               1   \n",
      "5              0              0              1              0               1   \n",
      "6              1              1              0              0               0   \n",
      "7              0              1              0              0               1   \n",
      "8              1              0              0              1               1   \n",
      "9              1              0              1              1               0   \n",
      "\n",
      "   observed  intervened  consequent_differs  \n",
      "0      True       False                True  \n",
      "1      True       False                True  \n",
      "2      True       False                True  \n",
      "3     False       False               False  \n",
      "4     False       False               False  \n",
      "5      True       False                True  \n",
      "6     False       False               False  \n",
      "7      True       False                True  \n",
      "8      True       False                True  \n",
      "9     False       False               False  \n"
     ]
    }
   ],
   "source": [
    "# if you're one of seven who voted for, you are an actual cause\n",
    "voting7HPM = HalpernPearlModifiedApproximate(\n",
    "    model = voting_model,\n",
    "    antecedents = [\"vote0\"],\n",
    "    outcome = \"outcome\",\n",
    "    witness_candidates = [f\"vote{i}\" for i in range(1,11)],\n",
    "    observations = dict(u_vote0=1., u_vote1=1., u_vote2=1.,\n",
    "                        u_vote3=1., u_vote4=1., uvote_5=0,\n",
    "                         u_vote6=0., u_vote7=0., u_vote8=0.,\n",
    "                        u_vote9=0., u_vote10=0.),\n",
    "    sample_size = 10)\n",
    "\n",
    "voting7HPM()\n",
    "\n",
    "print(\n",
    "voting7HPM.existential_but_for\n",
    ")\n",
    "\n",
    "print(\n",
    "    voting7HPM.witness_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__split_vote1</th>\n",
       "      <th>__split_vote2</th>\n",
       "      <th>__split_vote3</th>\n",
       "      <th>__split_vote4</th>\n",
       "      <th>observed</th>\n",
       "      <th>intervened</th>\n",
       "      <th>consequent_differs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     __split_vote1  __split_vote2  __split_vote3  __split_vote4  observed  \\\n",
       "0                1              0              0              0      True   \n",
       "1                1              1              1              0      True   \n",
       "2                1              1              1              1      True   \n",
       "3                0              1              0              1      True   \n",
       "4                0              0              0              0      True   \n",
       "..             ...            ...            ...            ...       ...   \n",
       "995              1              0              1              0      True   \n",
       "996              0              1              0              0      True   \n",
       "997              0              0              0              0      True   \n",
       "998              1              1              1              0      True   \n",
       "999              0              0              1              1      True   \n",
       "\n",
       "     intervened  consequent_differs  \n",
       "0         False                True  \n",
       "1         False                True  \n",
       "2         False                True  \n",
       "3         False                True  \n",
       "4         False                True  \n",
       "..          ...                 ...  \n",
       "995       False                True  \n",
       "996       False                True  \n",
       "997       False                True  \n",
       "998       False                True  \n",
       "999       False                True  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def voting_model_7_4():\n",
    "    u_vote0 = pyro.sample(\"u_vote0\", dist.Bernoulli(0.6))\n",
    "    u_vote1 = pyro.sample(\"u_vote1\", dist.Bernoulli(0.6))\n",
    "    u_vote2 = pyro.sample(\"u_vote2\", dist.Bernoulli(0.6))\n",
    "    u_vote3 = pyro.sample(\"u_vote3\", dist.Bernoulli(0.6))\n",
    "    u_vote4 = pyro.sample(\"u_vote4\", dist.Bernoulli(0.6))\n",
    "\n",
    "    vote0 = pyro.deterministic(\"vote0\", u_vote0, event_dim=0)\n",
    "    vote1 = pyro.deterministic(\"vote1\", u_vote1, event_dim=0)\n",
    "    vote2 = pyro.deterministic(\"vote2\", u_vote2, event_dim=0)\n",
    "    vote3 = pyro.deterministic(\"vote3\", u_vote3, event_dim=0)\n",
    "    vote4 = pyro.deterministic(\"vote4\", u_vote4, event_dim=0)\n",
    "    return {\"outcome\": vote0 + vote1 + vote2 + vote3 + vote4 >= 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
