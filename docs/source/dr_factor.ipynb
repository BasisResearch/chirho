{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doubly-robust estimation with a causal latent factor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an attempt to reproduce the synthetic data experiment in section 6 of [Doubly Robust Inference in Causal Latent Factor Models](https://arxiv.org/abs/2402.11652) using the MC-EIF one-step corrected estimator described in [Automated Efficient Estimation using Monte Carlo Efficient Influence Functions](https://arxiv.org/abs/2403.00158) and implemented in `chirho.robust`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Callable, Mapping, TypedDict\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import chirho\n",
    "from chirho.counterfactual.handlers import MultiWorldCounterfactual\n",
    "from chirho.indexed.ops import IndexSet, gather, indices_of\n",
    "from chirho.interventional.handlers import do\n",
    "from chirho.observational.handlers import condition\n",
    "from chirho.robust.ops import influence_fn\n",
    "from chirho.robust.handlers.estimators import one_step_corrected_estimator\n",
    "from chirho.robust.handlers.predictive import BatchedLatents, PredictiveModel\n",
    "\n",
    "pyro.set_rng_seed(101)\n",
    "pyro.settings.set(module_local_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: causal effect estimation with missing data and multiple measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure1](figures/dr_matcomp.png)\n",
    "\n",
    "The above image is Figure 1 from the source paper [Doubly Robust Inference in Causal Latent Factor Models](https://arxiv.org/abs/2402.11652)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: low-rank linear latent factor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1413pt\" height=\"320pt\"\n",
       " viewBox=\"0.00 0.00 1413.00 320.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 316)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-316 1409,-316 1409,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_units</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-289 394,-289 394,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"367.5\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">units</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_measurements</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"246,-39 246,-186 386,-186 386,-39 246,-39\"/>\n",
       "<text text-anchor=\"middle\" x=\"325\" y=\"-46.8\" font-family=\"Times,serif\" font-size=\"14.00\">measurements</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_measurements__CLONE</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"402,-214 402,-289 1071,-289 1071,-214 402,-214\"/>\n",
       "<text text-anchor=\"middle\" x=\"1010\" y=\"-221.8\" font-family=\"Times,serif\" font-size=\"14.00\">measurements</text>\n",
       "</g>\n",
       "<!-- unit_factors_treatment -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>unit_factors_treatment</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"269\" cy=\"-263\" rx=\"116.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-259.3\" font-family=\"Times,serif\" font-size=\"14.00\">unit_factors_treatment</text>\n",
       "</g>\n",
       "<!-- treatments -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>treatments</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"316\" cy=\"-160\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"316\" y=\"-156.3\" font-family=\"Times,serif\" font-size=\"14.00\">treatments</text>\n",
       "</g>\n",
       "<!-- unit_factors_treatment&#45;&gt;treatments -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>unit_factors_treatment&#45;&gt;treatments</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M276.97,-244.87C284.34,-229.03 295.4,-205.26 303.87,-187.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"307.1,-188.42 308.14,-177.88 300.75,-185.47 307.1,-188.42\"/>\n",
       "</g>\n",
       "<!-- unit_factors_outcome -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>unit_factors_outcome</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"126\" cy=\"-160\" rx=\"109.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126\" y=\"-156.3\" font-family=\"Times,serif\" font-size=\"14.00\">unit_factors_outcome</text>\n",
       "</g>\n",
       "<!-- outcomes -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>outcomes</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"316\" cy=\"-88\" rx=\"55.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"316\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\">outcomes</text>\n",
       "</g>\n",
       "<!-- unit_factors_outcome&#45;&gt;outcomes -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>unit_factors_outcome&#45;&gt;outcomes</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168.64,-143.29C199.15,-132.05 240.13,-116.95 271.13,-105.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"272.64,-108.7 280.82,-101.96 270.22,-102.13 272.64,-108.7\"/>\n",
       "</g>\n",
       "<!-- treatments&#45;&gt;outcomes -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>treatments&#45;&gt;outcomes</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M316,-141.7C316,-133.98 316,-124.71 316,-116.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"319.5,-116.1 316,-106.1 312.5,-116.1 319.5,-116.1\"/>\n",
       "</g>\n",
       "<!-- measurement_factors_treatment -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>measurement_factors_treatment</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"572\" cy=\"-263\" rx=\"162.47\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"572\" y=\"-259.3\" font-family=\"Times,serif\" font-size=\"14.00\">measurement_factors_treatment</text>\n",
       "</g>\n",
       "<!-- measurement_factors_treatment&#45;&gt;treatments -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>measurement_factors_treatment&#45;&gt;treatments</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M530.3,-245.55C483.77,-227.19 408.78,-197.6 360.97,-178.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"362.08,-175.42 351.49,-175 359.51,-181.93 362.08,-175.42\"/>\n",
       "</g>\n",
       "<!-- measurement_factors_outcome -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>measurement_factors_outcome</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"908\" cy=\"-263\" rx=\"155.17\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"908\" y=\"-259.3\" font-family=\"Times,serif\" font-size=\"14.00\">measurement_factors_outcome</text>\n",
       "</g>\n",
       "<!-- measurement_factors_outcome&#45;&gt;outcomes -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>measurement_factors_outcome&#45;&gt;outcomes</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M853.63,-246.11C739.29,-212.7 475.45,-135.6 365.5,-103.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"366.24,-100.04 355.66,-100.59 364.28,-106.76 366.24,-100.04\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-296.8\" font-family=\"Times,serif\" font-size=\"14.00\">unit_factors_treatment ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-281.8\" font-family=\"Times,serif\" font-size=\"14.00\">unit_factors_outcome ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-266.8\" font-family=\"Times,serif\" font-size=\"14.00\">measurement_factors_treatment ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-251.8\" font-family=\"Times,serif\" font-size=\"14.00\">measurement_factors_outcome ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-236.8\" font-family=\"Times,serif\" font-size=\"14.00\">treatments ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-221.8\" font-family=\"Times,serif\" font-size=\"14.00\">outcomes ~ Normal</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f64e3ef8130>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FactorModel(pyro.nn.PyroModule):\n",
    "    num_units: int\n",
    "    num_measurements: int\n",
    "    num_factors: int\n",
    "\n",
    "    def __init__(self, num_units: int, num_measurements: int, num_factors: int):\n",
    "        super().__init__()\n",
    "        self.num_units = num_units\n",
    "        self.num_measurements = num_measurements\n",
    "        self.num_factors = num_factors\n",
    "        self.unit_plate = pyro.plate(\"units\", self.num_units, dim=-2)\n",
    "        self.measurement_plate = pyro.plate(\"measurements\", self.num_measurements, dim=-1)\n",
    "        self.register_buffer(\"zero\", torch.tensor(0.))\n",
    "        self.register_buffer(\"one\", torch.tensor(1.))\n",
    "\n",
    "    @property\n",
    "    def unit_factors_treatment_prior(self) -> dist.Distribution:\n",
    "        return dist.Normal(self.zero, self.one).expand([self.num_factors]).to_event(1)\n",
    "\n",
    "    @property\n",
    "    def unit_factors_outcome_prior(self) -> dist.Distribution:\n",
    "        return dist.Normal(self.zero, self.one).expand([self.num_factors, 2]).to_event(2)\n",
    "\n",
    "    @property\n",
    "    def measurement_factors_treatment_prior(self) -> dist.Distribution:\n",
    "        return dist.Normal(self.zero, self.one).expand([self.num_factors]).to_event(1)\n",
    "\n",
    "    @property\n",
    "    def measurement_factors_outcome_prior(self) -> dist.Distribution:\n",
    "        return dist.Normal(self.zero, self.one).expand([self.num_factors, 2]).to_event(2)\n",
    "\n",
    "    def outcome_link_fn(self, outcome_locs: torch.Tensor) -> dist.Distribution:\n",
    "        return dist.Normal(outcome_locs, self.one)\n",
    "\n",
    "    def forward(self) -> torch.Tensor:\n",
    "        with self.unit_plate:\n",
    "            unit_factors_treatment = pyro.sample(\"unit_factors_treatment\", self.unit_factors_treatment_prior)\n",
    "            unit_factors_outcome = pyro.sample(\"unit_factors_outcome\", self.unit_factors_outcome_prior)\n",
    "\n",
    "        with self.measurement_plate:\n",
    "            measurement_factors_treatment = pyro.sample(\"measurement_factors_treatment\", self.measurement_factors_treatment_prior)\n",
    "            measurement_factors_outcome = pyro.sample(\"measurement_factors_outcome\", self.measurement_factors_outcome_prior)\n",
    "            # appease batched einsum by ensuring a batch dimension exists for unit_plate\n",
    "            if len(measurement_factors_treatment.shape) == 2:\n",
    "                measurement_factors_treatment = measurement_factors_treatment[None, ...]\n",
    "            if len(measurement_factors_outcome.shape) == 3:\n",
    "                measurement_factors_outcome = measurement_factors_outcome[None, ...]\n",
    "\n",
    "        treatment_logits = torch.einsum(\"...umk,...umk->...um\", unit_factors_treatment, measurement_factors_treatment)\n",
    "        potential_outcome_locs = torch.einsum(\"...umkt,...umkt->...umt\", unit_factors_outcome, measurement_factors_outcome)\n",
    "        with self.unit_plate, self.measurement_plate:\n",
    "            treatments = pyro.sample(\"treatments\", dist.Bernoulli(logits=treatment_logits))\n",
    "            outcome_locs = torch.where(treatments == 0, potential_outcome_locs[..., 0], potential_outcome_locs[..., 1])\n",
    "            outcomes = pyro.sample(\"outcomes\", self.outcome_link_fn(outcome_locs))\n",
    "            return outcomes\n",
    "\n",
    "model = FactorModel(\n",
    "    num_units=100,\n",
    "    num_measurements=10,\n",
    "    num_factors=3,\n",
    ")\n",
    "\n",
    "pyro.render_model(model, render_deterministic=True, render_distributions=True, render_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: synthetic data-generating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrueModel(FactorModel):\n",
    "    def __init__(self):\n",
    "        super().__init__(num_units=100, num_measurements=10, num_factors=3)\n",
    "\n",
    "true_model = TrueModel()\n",
    "\n",
    "class FactorModelDataset(TypedDict):\n",
    "    treatments: torch.Tensor\n",
    "    outcomes: torch.Tensor\n",
    "\n",
    "true_dgp: Callable[[], FactorModelDataset] = pyro.infer.Predictive(true_model, return_sites=[\"treatments\", \"outcomes\"], num_samples=1)\n",
    "\n",
    "# generate full datasets\n",
    "train_data: FactorModelDataset = true_dgp()\n",
    "test_data: FactorModelDataset = true_dgp()\n",
    "\n",
    "# TODO generate missingness masks and apply them to the datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter estimation: maximum a posteriori inference (MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eli/development/pyro/pyro/util.py:365: UserWarning: Found plate statements in guide but not model: {'measurements', 'units'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss = 4244.55126953125\n",
      "step 100 loss = 2951.724853515625\n",
      "step 200 loss = 2705.056640625\n",
      "step 300 loss = 2658.379638671875\n",
      "step 400 loss = 2644.154541015625\n",
      "step 500 loss = 2639.4833984375\n",
      "step 600 loss = 2637.599853515625\n",
      "step 700 loss = 2636.71044921875\n",
      "step 800 loss = 2636.197998046875\n",
      "step 900 loss = 2635.855712890625\n",
      "step 1000 loss = 2635.63916015625\n"
     ]
    }
   ],
   "source": [
    "class ConditionedFactorModel(pyro.nn.PyroModule):\n",
    "    model: FactorModel\n",
    "\n",
    "    def __init__(self, model: FactorModel):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, data: FactorModelDataset) -> torch.Tensor:\n",
    "        with condition(data=data):\n",
    "            return self.model()\n",
    "\n",
    "conditioned_model = ConditionedFactorModel(model)\n",
    "guide = pyro.infer.autoguide.AutoDelta(conditioned_model)\n",
    "\n",
    "elbo = pyro.infer.Trace_ELBO()(conditioned_model, guide)\n",
    "\n",
    "elbo(train_data)  # initialize guide\n",
    "\n",
    "optim = torch.optim.Adam(elbo.parameters(), lr=0.01)\n",
    "\n",
    "for step in range(1001):\n",
    "    optim.zero_grad()\n",
    "    loss = elbo(train_data)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if step % 100 == 0:\n",
    "        print(f\"step {step} loss = {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: average treatment effect (ATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATEFunctional(pyro.nn.PyroModule):\n",
    "    model: FactorModel\n",
    "    num_samples: int\n",
    "\n",
    "    def __init__(self, model: FactorModel, *, num_samples: int = 10):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.num_samples = num_samples\n",
    "        self.register_buffer(\"zero\", torch.tensor(0.))\n",
    "        self.register_buffer(\"one\", torch.tensor(1.))\n",
    "\n",
    "    def forward(self) -> torch.Tensor:\n",
    "        with MultiWorldCounterfactual() as mwc:\n",
    "            with BatchedLatents(num_particles=self.num_samples):\n",
    "                with do(actions=dict(treatments=(self.zero, self.one))):\n",
    "                    outcomes = self.model()\n",
    "\n",
    "                outcomes_treated = gather(outcomes, IndexSet(treatments={2}))\n",
    "                outcomes_untreated = gather(outcomes, IndexSet(treatments={1}))\n",
    "                ites = outcomes_treated - outcomes_untreated\n",
    "                return pyro.deterministic(\"ate\", ites.mean((-1, -2))).mean()\n",
    "\n",
    "target_functional = lambda m: ATEFunctional(m, num_samples=10)\n",
    "predictive_model: PredictiveModel[[], torch.Tensor] = PredictiveModel(model, guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plug-in estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0435, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plugin_estimator: Callable[[], torch.Tensor] = target_functional(predictive_model)\n",
    "\n",
    "plugin_estimator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-step corrected estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_estimator: Callable[[], torch.Tensor] = one_step_corrected_estimator(target_functional, test_data, num_samples_outer=101)(predictive_model)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dr_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
