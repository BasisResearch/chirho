{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doubly-robust estimation with a causal latent factor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an attempt to reproduce the synthetic data experiment in section 6 of [Doubly Robust Inference in Causal Latent Factor Models](https://arxiv.org/abs/2402.11652) using the MC-EIF one-step corrected estimator described in [Automated Efficient Estimation using Monte Carlo Efficient Influence Functions](https://arxiv.org/abs/2403.00158) and implemented in `chirho.robust`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Callable, Mapping, TypedDict\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import chirho\n",
    "from chirho.counterfactual.handlers import MultiWorldCounterfactual\n",
    "from chirho.indexed.ops import IndexSet, gather, indices_of\n",
    "from chirho.interventional.handlers import do\n",
    "from chirho.observational.handlers import condition\n",
    "from chirho.robust.ops import influence_fn\n",
    "from chirho.robust.handlers.estimators import one_step_corrected_estimator\n",
    "from chirho.robust.handlers.predictive import BatchedLatents, PredictiveModel\n",
    "\n",
    "pyro.set_rng_seed(101)\n",
    "pyro.settings.set(module_local_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: causal effect estimation with missing data and multiple measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure1](figures/dr_matcomp.png)\n",
    "\n",
    "The above image is Figure 1 from the source paper [Doubly Robust Inference in Causal Latent Factor Models](https://arxiv.org/abs/2402.11652)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: low-rank linear latent factor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1413pt\" height=\"320pt\"\n",
       " viewBox=\"0.00 0.00 1413.00 320.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 316)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-316 1409,-316 1409,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_units</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-289 394,-289 394,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"367.5\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">units</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_measurements</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"246,-39 246,-186 386,-186 386,-39 246,-39\"/>\n",
       "<text text-anchor=\"middle\" x=\"325\" y=\"-46.8\" font-family=\"Times,serif\" font-size=\"14.00\">measurements</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_measurements__CLONE</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"402,-214 402,-289 1071,-289 1071,-214 402,-214\"/>\n",
       "<text text-anchor=\"middle\" x=\"1010\" y=\"-221.8\" font-family=\"Times,serif\" font-size=\"14.00\">measurements</text>\n",
       "</g>\n",
       "<!-- unit_factors_treatment -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>unit_factors_treatment</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"269\" cy=\"-263\" rx=\"116.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-259.3\" font-family=\"Times,serif\" font-size=\"14.00\">unit_factors_treatment</text>\n",
       "</g>\n",
       "<!-- treatments -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>treatments</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"316\" cy=\"-160\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"316\" y=\"-156.3\" font-family=\"Times,serif\" font-size=\"14.00\">treatments</text>\n",
       "</g>\n",
       "<!-- unit_factors_treatment&#45;&gt;treatments -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>unit_factors_treatment&#45;&gt;treatments</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M276.97,-244.87C284.34,-229.03 295.4,-205.26 303.87,-187.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"307.1,-188.42 308.14,-177.88 300.75,-185.47 307.1,-188.42\"/>\n",
       "</g>\n",
       "<!-- unit_factors_outcome -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>unit_factors_outcome</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"126\" cy=\"-160\" rx=\"109.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126\" y=\"-156.3\" font-family=\"Times,serif\" font-size=\"14.00\">unit_factors_outcome</text>\n",
       "</g>\n",
       "<!-- outcomes -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>outcomes</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"316\" cy=\"-88\" rx=\"55.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"316\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\">outcomes</text>\n",
       "</g>\n",
       "<!-- unit_factors_outcome&#45;&gt;outcomes -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>unit_factors_outcome&#45;&gt;outcomes</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168.64,-143.29C199.15,-132.05 240.13,-116.95 271.13,-105.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"272.64,-108.7 280.82,-101.96 270.22,-102.13 272.64,-108.7\"/>\n",
       "</g>\n",
       "<!-- treatments&#45;&gt;outcomes -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>treatments&#45;&gt;outcomes</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M316,-141.7C316,-133.98 316,-124.71 316,-116.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"319.5,-116.1 316,-106.1 312.5,-116.1 319.5,-116.1\"/>\n",
       "</g>\n",
       "<!-- measurement_factors_treatment -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>measurement_factors_treatment</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"572\" cy=\"-263\" rx=\"162.47\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"572\" y=\"-259.3\" font-family=\"Times,serif\" font-size=\"14.00\">measurement_factors_treatment</text>\n",
       "</g>\n",
       "<!-- measurement_factors_treatment&#45;&gt;treatments -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>measurement_factors_treatment&#45;&gt;treatments</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M530.3,-245.55C483.77,-227.19 408.78,-197.6 360.97,-178.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"362.08,-175.42 351.49,-175 359.51,-181.93 362.08,-175.42\"/>\n",
       "</g>\n",
       "<!-- measurement_factors_outcome -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>measurement_factors_outcome</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"908\" cy=\"-263\" rx=\"155.17\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"908\" y=\"-259.3\" font-family=\"Times,serif\" font-size=\"14.00\">measurement_factors_outcome</text>\n",
       "</g>\n",
       "<!-- measurement_factors_outcome&#45;&gt;outcomes -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>measurement_factors_outcome&#45;&gt;outcomes</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M853.63,-246.11C739.29,-212.7 475.45,-135.6 365.5,-103.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"366.24,-100.04 355.66,-100.59 364.28,-106.76 366.24,-100.04\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-296.8\" font-family=\"Times,serif\" font-size=\"14.00\">unit_factors_treatment ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-281.8\" font-family=\"Times,serif\" font-size=\"14.00\">unit_factors_outcome ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-266.8\" font-family=\"Times,serif\" font-size=\"14.00\">measurement_factors_treatment ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-251.8\" font-family=\"Times,serif\" font-size=\"14.00\">measurement_factors_outcome ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-236.8\" font-family=\"Times,serif\" font-size=\"14.00\">treatments ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"1089\" y=\"-221.8\" font-family=\"Times,serif\" font-size=\"14.00\">outcomes ~ Normal</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7c1ab87eed40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FactorModel(pyro.nn.PyroModule):\n",
    "    num_units: int\n",
    "    num_measurements: int\n",
    "    num_factors: int\n",
    "\n",
    "    def __init__(self, num_units: int, num_measurements: int, num_factors: int):\n",
    "        super().__init__()\n",
    "        self.num_units = num_units\n",
    "        self.num_measurements = num_measurements\n",
    "        self.num_factors = num_factors\n",
    "        self.unit_plate = pyro.plate(\"units\", self.num_units, dim=-2)\n",
    "        self.measurement_plate = pyro.plate(\"measurements\", self.num_measurements, dim=-1)\n",
    "        self.register_buffer(\"zero\", torch.tensor(0.))\n",
    "        self.register_buffer(\"one\", torch.tensor(1.))\n",
    "\n",
    "    @property\n",
    "    def unit_factors_treatment_prior(self) -> dist.Distribution:\n",
    "        return dist.Normal(self.zero, self.one).expand([self.num_factors]).to_event(1)\n",
    "\n",
    "    @property\n",
    "    def unit_factors_outcome_prior(self) -> dist.Distribution:\n",
    "        return dist.Normal(self.zero, self.one).expand([self.num_factors, 2]).to_event(2)\n",
    "\n",
    "    @property\n",
    "    def measurement_factors_treatment_prior(self) -> dist.Distribution:\n",
    "        return dist.Normal(self.zero, self.one).expand([self.num_factors]).to_event(1)\n",
    "\n",
    "    @property\n",
    "    def measurement_factors_outcome_prior(self) -> dist.Distribution:\n",
    "        return dist.Normal(self.zero, self.one).expand([self.num_factors, 2]).to_event(2)\n",
    "\n",
    "    def outcome_link_fn(self, outcome_locs: torch.Tensor) -> dist.Distribution:\n",
    "        return dist.Normal(outcome_locs, self.one)\n",
    "\n",
    "    def forward(self) -> torch.Tensor:\n",
    "        with self.unit_plate:\n",
    "            unit_factors_treatment = pyro.sample(\"unit_factors_treatment\", self.unit_factors_treatment_prior)\n",
    "            unit_factors_outcome = pyro.sample(\"unit_factors_outcome\", self.unit_factors_outcome_prior)\n",
    "\n",
    "        with self.measurement_plate:\n",
    "            measurement_factors_treatment = pyro.sample(\"measurement_factors_treatment\", self.measurement_factors_treatment_prior)\n",
    "            measurement_factors_outcome = pyro.sample(\"measurement_factors_outcome\", self.measurement_factors_outcome_prior)\n",
    "\n",
    "        treatment_logits = torch.einsum(\"...umk,...mk->...um\", unit_factors_treatment, measurement_factors_treatment)\n",
    "        potential_outcome_locs = torch.einsum(\"...umkt,...mkt->...umt\", unit_factors_outcome, measurement_factors_outcome)\n",
    "        with self.unit_plate, self.measurement_plate:\n",
    "            treatments = pyro.sample(\"treatments\", dist.Bernoulli(logits=treatment_logits))\n",
    "            outcome_locs = torch.where(treatments == 0, potential_outcome_locs[..., 0], potential_outcome_locs[..., 1])\n",
    "            outcomes = pyro.sample(\"outcomes\", self.outcome_link_fn(outcome_locs))\n",
    "            return outcomes\n",
    "\n",
    "model = FactorModel(\n",
    "    num_units=100,\n",
    "    num_measurements=10,\n",
    "    num_factors=3,\n",
    ")\n",
    "\n",
    "pyro.render_model(model, render_deterministic=True, render_distributions=True, render_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: synthetic data-generating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrueModel(FactorModel):\n",
    "    def __init__(self):\n",
    "        super().__init__(num_units=100, num_measurements=10, num_factors=3)\n",
    "\n",
    "true_model = TrueModel()\n",
    "\n",
    "class FactorModelDataset(TypedDict):\n",
    "    treatments: torch.Tensor\n",
    "    outcomes: torch.Tensor\n",
    "\n",
    "true_dgp: Callable[[], FactorModelDataset] = pyro.infer.Predictive(true_model, return_sites=[\"treatments\", \"outcomes\"], num_samples=2)\n",
    "\n",
    "# generate full datasets\n",
    "train_data: FactorModelDataset = true_dgp()\n",
    "test_data: FactorModelDataset = true_dgp()\n",
    "\n",
    "# TODO generate missingness masks and apply them to the datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter estimation: maximum a posteriori inference (MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eli/development/pyro/pyro/util.py:365: UserWarning: Found plate statements in guide but not model: {'units', 'measurements'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss = 5191.841796875\n",
      "step 100 loss = 3312.970947265625\n",
      "step 200 loss = 2895.181396484375\n",
      "step 300 loss = 2801.5830078125\n",
      "step 400 loss = 2778.109375\n",
      "step 500 loss = 2761.412841796875\n",
      "step 600 loss = 2744.73876953125\n",
      "step 700 loss = 2739.44775390625\n",
      "step 800 loss = 2737.70654296875\n",
      "step 900 loss = 2737.019775390625\n",
      "step 1000 loss = 2736.730712890625\n"
     ]
    }
   ],
   "source": [
    "class ConditionedFactorModel(pyro.nn.PyroModule):\n",
    "    model: FactorModel\n",
    "\n",
    "    def __init__(self, model: FactorModel):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, data: FactorModelDataset) -> torch.Tensor:\n",
    "        with condition(data=data):\n",
    "            return self.model()\n",
    "\n",
    "conditioned_model = ConditionedFactorModel(model)\n",
    "guide = pyro.infer.autoguide.AutoDelta(conditioned_model)\n",
    "\n",
    "elbo = pyro.infer.Trace_ELBO()(conditioned_model, guide)\n",
    "\n",
    "elbo(train_data)  # initialize guide\n",
    "\n",
    "optim = torch.optim.Adam(elbo.parameters(), lr=0.01)\n",
    "\n",
    "for step in range(1001):\n",
    "    optim.zero_grad()\n",
    "    loss = elbo(train_data)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if step % 100 == 0:\n",
    "        print(f\"step {step} loss = {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: average treatment effect (ATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATEFunctional(pyro.nn.PyroModule):\n",
    "    model: FactorModel\n",
    "    num_samples: int\n",
    "\n",
    "    def __init__(self, model: FactorModel, *, num_samples: int = 10):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.num_samples = num_samples\n",
    "        self.register_buffer(\"zero\", torch.tensor(0.))\n",
    "        self.register_buffer(\"one\", torch.tensor(1.))\n",
    "\n",
    "    def forward(self) -> torch.Tensor:\n",
    "        with MultiWorldCounterfactual() as mwc:\n",
    "            with BatchedLatents(num_particles=self.num_samples):\n",
    "                with do(actions=dict(treatments=(self.zero, self.one))):\n",
    "                    outcomes = self.model()\n",
    "\n",
    "                outcomes_treated = gather(outcomes, IndexSet(treatments={2}))\n",
    "                outcomes_untreated = gather(outcomes, IndexSet(treatments={1}))\n",
    "                ites = outcomes_treated - outcomes_untreated\n",
    "                return pyro.deterministic(\"ate\", ites.mean((-1, -2)))\n",
    "\n",
    "target_functional = lambda m: ATEFunctional(m, num_samples=10)\n",
    "predictive_model: PredictiveModel[[], torch.Tensor] = PredictiveModel(model, guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plug-in estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0564]],\n",
       "\n",
       "         [[-0.0566]],\n",
       "\n",
       "         [[-0.0057]],\n",
       "\n",
       "         [[-0.0647]],\n",
       "\n",
       "         [[-0.0040]],\n",
       "\n",
       "         [[-0.0571]],\n",
       "\n",
       "         [[-0.1214]],\n",
       "\n",
       "         [[-0.0126]],\n",
       "\n",
       "         [[-0.0505]],\n",
       "\n",
       "         [[-0.0719]]]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plugin_estimator: Callable[[], torch.Tensor] = target_functional(predictive_model)\n",
    "plugin_estimator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-step corrected estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[101, 100, 10]' is invalid for input of size 10201000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dr_estimator: Callable[[], torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m one_step_corrected_estimator(target_functional, test_data, num_samples_outer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m101\u001b[39m)(predictive_model)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdr_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/chirho/chirho/robust/handlers/estimators.py:41\u001b[0m, in \u001b[0;36mone_step_corrected_estimator.<locals>._corrected_functional.<locals>._estimator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_estimator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m S:\n\u001b[1;32m     40\u001b[0m     plug_in_estimate \u001b[38;5;241m=\u001b[39m plug_in_estimator(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 41\u001b[0m     correction \u001b[38;5;241m=\u001b[39m \u001b[43mcorrection_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     flat_plug_in_estimate, treespec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_pytree\u001b[38;5;241m.\u001b[39mtree_flatten(\n\u001b[1;32m     44\u001b[0m         plug_in_estimate\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m     flat_correction, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_pytree\u001b[38;5;241m.\u001b[39mtree_flatten(correction)\n",
      "File \u001b[0;32m~/development/chirho/chirho/robust/ops.py:150\u001b[0m, in \u001b[0;36minfluence_fn.<locals>._influence_functional.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled():\n\u001b[1;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling influence_fn with torch.grad enabled can lead to memory leaks. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use torch.no_grad() to avoid this issue. See example in the docstring.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m     )\n\u001b[0;32m--> 150\u001b[0m param_eif \u001b[38;5;241m=\u001b[39m \u001b[43mlinearized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mvmap(\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m d: torch\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39mjvp(\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m p: func_target(p, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), (target_params,), (d,)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m     randomness\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m )(param_eif)\n",
      "File \u001b[0;32m~/development/chirho/chirho/robust/internals/linearize.py:364\u001b[0m, in \u001b[0;36mlinearize.<locals>._fn\u001b[0;34m(points, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fn\u001b[39m(\n\u001b[1;32m    359\u001b[0m     points: Point[T],\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs,\n\u001b[1;32m    362\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ParamDict:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 364\u001b[0m         data: Point[T] \u001b[38;5;241m=\u001b[39m \u001b[43mpredictive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m         data \u001b[38;5;241m=\u001b[39m {k: data[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m points\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[1;32m    366\u001b[0m     fvp \u001b[38;5;241m=\u001b[39m make_empirical_fisher_vp(\n\u001b[1;32m    367\u001b[0m         batched_func_log_prob, log_prob_params, data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    368\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/development/pyro/pyro/infer/predictive.py:273\u001b[0m, in \u001b[0;36mPredictive.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     return_sites \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_sites \u001b[38;5;28;01melse\u001b[39;00m return_sites\n\u001b[1;32m    264\u001b[0m     posterior_samples \u001b[38;5;241m=\u001b[39m _predictive(\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguide,\n\u001b[1;32m    266\u001b[0m         posterior_samples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m         model_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m    272\u001b[0m     )\n\u001b[0;32m--> 273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_predictive\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposterior_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_sites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_sites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/development/pyro/pyro/infer/predictive.py:149\u001b[0m, in \u001b[0;36m_predictive\u001b[0;34m(model, posterior_samples, num_samples, return_sites, return_trace, parallel, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m         predictions[site] \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mexpand(shape)\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m         predictions[site] \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[101, 100, 10]' is invalid for input of size 10201000"
     ]
    }
   ],
   "source": [
    "dr_estimator: Callable[[], torch.Tensor] = one_step_corrected_estimator(target_functional, test_data, num_samples_outer=101)(predictive_model)\n",
    "dr_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
