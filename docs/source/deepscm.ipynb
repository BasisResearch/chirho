{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Deep structural causal model counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union, TypeVar\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.poutine import condition, reparam\n",
    "from pyro.nn import PyroParam, PyroSample, PyroModule\n",
    "import pyro.distributions.transforms as Transforms\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.infer import config_enumerate\n",
    "from pyro.distributions import constraints\n",
    "\n",
    "\n",
    "import causal_pyro\n",
    "from causal_pyro.query.do_messenger import do\n",
    "from causal_pyro.counterfactual.handlers import Factual, MultiWorldCounterfactual, TwinWorldCounterfactual\n",
    "from causal_pyro.reparam.soft_conditioning import TransformInferReparam\n",
    "\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import gzip\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available = torch.cuda.is_available()\n",
    "curr_device = torch.device(\"cpu\") if not available else torch.cuda.current_device()\n",
    "print(f'Cuda available: {available}')\n",
    "print(f'Current device: {curr_device}')\n",
    "\n",
    "if available:\n",
    "    device_count = torch.cuda.device_count() \n",
    "    device_name =  torch.cuda.get_device_name(0)\n",
    "    print(f'Device count: {device_count}')\n",
    "    print(f'Device name: {device_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Normalizing flows and counterfactuals\n",
    "\n",
    "Much of the causal inference literature has focused on relatively simple\n",
    "causal models with low dimensional data. In order to perform\n",
    "counterfactual reasoning in more complex domains with high dimensional\n",
    "data, Palowski et al. [@pawlowski2020deep] introduced *deep structural\n",
    "causal models* (Deep SCMs): SCMs with neural networks as the functional\n",
    "mechanisms between variables.\n",
    "\n",
    "Specifically, the neural networks are\n",
    "*normalizing flows*. A normalizing flow transforms a base probability\n",
    "distribution (often a simple distribution, such as a multivariate\n",
    "Gaussian) through a sequence of invertible transformations into a more\n",
    "complex distribution (such as a distribution over images). When used\n",
    "within a Deep SCM, the flow's base distribution is an exogenous noise\n",
    "variable, and its output is an endogenous variable.\n",
    "\n",
    "A salient property\n",
    "of normalizing flows is that computing the likelihood of data can be\n",
    "done both exactly and efficiently, and hence training a flow to model a\n",
    "data distribution through maximum likelihood is straightforward. In\n",
    "addition, the inverse of a normalizing flow can also typically be\n",
    "efficiently computed, which renders the abduction step of a\n",
    "counterfactual---inferring the posterior over exogenous variables given\n",
    "evidence---trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Morpho-MNIST\n",
    "\n",
    "We consider a synthetic dataset based on MNIST, where the image of each digit ($X$) depends on stroke thickness ($T$) and brightness ($I$) of the image and the thickness depends on brightness as well.\n",
    "\n",
    "We assume we know full causal structure (i.e., there are no unconfounded variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_idx(path: str) -> np.ndarray:\n",
    "    \"\"\"Reads an array in IDX format from disk.\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path of the input file. Will uncompress with `gzip` if path ends in '.gz'.\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Output array of dtype ``uint8``.\n",
    "    References\n",
    "    ----------\n",
    "    http://yann.lecun.com/exdb/mnist/\n",
    "    \"\"\"\n",
    "    open_fcn = gzip.open if path.endswith('.gz') else open\n",
    "    with open_fcn(path, 'rb') as f:\n",
    "        idx_dtype, ndim = struct.unpack('BBBB', f.read(4))[2:]\n",
    "        shape = struct.unpack('>' + 'I' * ndim, f.read(4 * ndim))\n",
    "        buffer_length = int(np.prod(shape))\n",
    "        data = np.frombuffer(f.read(buffer_length), dtype=np.uint8).reshape(shape).astype(np.float32)\n",
    "        return data\n",
    "    \n",
    "path = os.path.join(os.getcwd(), \"../datasets/morphomnist/\")\n",
    "metrics = pd.read_csv(path + \"train-morpho.csv\", index_col= 'index')\n",
    "# raw_labels = load_idx(path+\"train-labels-idx1-ubyte.gz\")\n",
    "raw_images = load_idx(path+\"train-images-idx3-ubyte.gz\")\n",
    "\n",
    "thickness = torch.tensor(metrics[\"thickness\"], dtype=torch.float32, device=curr_device)\n",
    "intensity = torch.tensor(metrics[\"intensity\"], dtype=torch.float32, device=curr_device)\n",
    "# labels = torch.tensor(raw_labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "rows = 2\n",
    "columns = 2\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(raw_images[0])\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(raw_images[1])\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(raw_images[2])\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(raw_images[3])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = skimage.measure.block_reduce(raw_images, block_size=(1, 2, 2))\n",
    "images = torch.tensor(images, dtype=torch.float32, device=curr_device)\n",
    "im_size = images.shape[1]\n",
    "# im_size = torch.tensor(im_size)\n",
    "im_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "rows = 2\n",
    "columns = 2\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(images[0].cpu())\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(images[1].cpu())\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(images[2].cpu())\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(images[3].cpu())\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: deep structural causal model\n",
    "\n",
    "The following code models morphological transformations of MNIST,\n",
    "defining a causal generative model over digits that contains endogenous\n",
    "variables to control the width $t$ and intensity $i$ of the stroke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntensityTransform(Transforms.ComposeTransformModule):\n",
    "    def __init__(self, intensity_size: int, thickness_size: int, hidden_dims: List[int], weight: torch.Tensor, bias: torch.Tensor):\n",
    "        self.intensity_size = intensity_size\n",
    "        self.thickness_size = thickness_size\n",
    "        self.hidden_dims = hidden_dims\n",
    "        super().__init__([\n",
    "            Transforms.ConditionalAffineAutoregressive(pyro.nn.ConditionalAutoRegressiveNN(\n",
    "                intensity_size,\n",
    "                thickness_size,\n",
    "                hidden_dims=list(hidden_dims),\n",
    "                nonlinearity=torch.nn.Identity(),\n",
    "            )),\n",
    "            Transforms.SigmoidTransform(),\n",
    "            Transforms.AffineTransform(loc=bias, scale=weight),\n",
    "        ])\n",
    "\n",
    "\n",
    "class ThicknessTransform(Transforms.ComposeTransformModule):\n",
    "    def __init__(self, thickness_size: int, weight: torch.Tensor, bias: torch.Tensor):\n",
    "        self.thickness_size = thickness_size\n",
    "        super().__init__([\n",
    "            Transforms.Spline(thickness_size),\n",
    "            Transforms.AffineTransform(loc=bias, scale=weight),\n",
    "            Transforms.ExpTransform()\n",
    "        ])\n",
    "    \n",
    "\n",
    "class PreprocessTransform(Transforms.ComposeTransformModule):\n",
    "    def __init__(self, alpha: float, num_bits: int):\n",
    "        self.alpha = alpha\n",
    "        self.num_bits = num_bits\n",
    "        super().__init__([\n",
    "            Transforms.AffineTransform(0., (1. / 2 ** num_bits)),\n",
    "            Transforms.AffineTransform(alpha, (1 - alpha)),\n",
    "            Transforms.SigmoidTransform().inv,\n",
    "        ])\n",
    "\n",
    "\n",
    "class ImgAffineCouplingTransform(Transforms.AffineCoupling):\n",
    "            \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        *,\n",
    "        log_scale_min_clip: float = -1.,\n",
    "        log_scale_max_clip: float = 5.0,\n",
    "        nonlinearity: torch.nn.Module = torch.nn.LeakyReLU()  # TODO nn.functional?\n",
    "    ):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        super().__init__(\n",
    "            self.input_dim // 2,\n",
    "            pyro.nn.DenseNN(\n",
    "                self.input_dim // 2,\n",
    "                [self.hidden_dim * self.input_dim],\n",
    "                [self.input_dim - self.input_dim // 2, self.input_dim - self.input_dim // 2],\n",
    "                nonlinearity=nonlinearity,\n",
    "            ),\n",
    "            log_scale_min_clip=log_scale_min_clip,\n",
    "            log_scale_max_clip=log_scale_max_clip,\n",
    "        )\n",
    "\n",
    "\n",
    "class ConditionalPermute(Transforms.ConditionalTransformModule):\n",
    "    def __init__(self, size: int):\n",
    "        self.size = size\n",
    "        super().__init__(event_dim=1)\n",
    "\n",
    "    def condition(self, context: torch.Tensor):\n",
    "        return Transforms.Permute(torch.randperm(self.size, device=context.device))\n",
    "\n",
    "\n",
    "class ConditionalImgTransform(ConditionalComposeTransformModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        thickness_size: int,\n",
    "        intensity_size: int,\n",
    "        *,\n",
    "        alpha: float = 0.001,\n",
    "        num_bits: int = 2,\n",
    "        momentum: float = 0.05,\n",
    "        log_scale_min_clip: float = -1.,\n",
    "        log_scale_max_clip: float = 5.0,\n",
    "    ):\n",
    "        self.input_dim = input_dim \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.preprocess_transform = PreprocessTransform(alpha, num_bits)\n",
    "        self.f_X = Transforms.ConditionalAffineAutoregressive(\n",
    "            pyro.nn.ConditionalAutoRegressiveNN(\n",
    "                self.input_dim,\n",
    "                thickness_size + intensity_size,\n",
    "                [hidden_dim * self.input_dim],\n",
    "                nonlinearity=torch.nn.Identity()\n",
    "            ),\n",
    "            log_scale_min_clip=log_scale_min_clip,\n",
    "            log_scale_max_clip=log_scale_max_clip,\n",
    "        )\n",
    "        self.norm = Transforms.BatchNorm(self.input_dim, momentum=momentum)\n",
    "        self.perm1 = ConditionalPermute(self.input_dim)\n",
    "        self.img_affine_coupling = ImgAffineCouplingTransform(\n",
    "            self.input_dim,\n",
    "            hidden_dim,\n",
    "            log_scale_min_clip=log_scale_min_clip,\n",
    "            log_scale_max_clip=log_scale_max_clip,\n",
    "        )\n",
    "        self.perm2 = ConditionalPermute(self.input_dim)\n",
    "        self.img_auto = ImgAffineCouplingTransform(\n",
    "            self.input_dim,\n",
    "            hidden_dim,\n",
    "            log_scale_min_clip=log_scale_min_clip,\n",
    "            log_scale_max_clip=log_scale_max_clip,\n",
    "        )\n",
    "        self.norm_2 = Transforms.BatchNorm(self.input_dim, momentum=momentum)\n",
    "        super().__init__([\n",
    "            self.preprocess_transform,\n",
    "            self.f_X,\n",
    "            self.norm,\n",
    "            self.perm1,\n",
    "            self.img_affine_coupling,\n",
    "            self.perm2,\n",
    "            self.img_auto,\n",
    "            self.norm_2,\n",
    "        ])\n",
    "\n",
    "\n",
    "class ConditionalComposeTransformModule(Transforms.ConditionalTransformModule):\n",
    "    def __init__(self, transforms: List[Union[Transforms.TransformModule, Transforms.ConditionalTransformModule]]):\n",
    "        self.transforms = [\n",
    "            Transforms.ConstantConditionalTransform(t)\n",
    "            if not isinstance(t, Transforms.ConditionalTransform)\n",
    "            else t\n",
    "            for t in transforms\n",
    "        ]\n",
    "        super().__init__(event_dim=transforms[0].event_dim)\n",
    "\n",
    "    def condition(self, context: torch.Tensor):\n",
    "        return Transforms.ComposeTransformModule([t.condition(context) for t in self.transforms])\n",
    "\n",
    "\n",
    "def StandardNormal(*event_shape: int, **kwargs) -> Union[dist.Independent, dist.Normal]:\n",
    "    return dist.Normal(\n",
    "        torch.zeros((), **kwargs),\n",
    "        torch.ones((), **kwargs),\n",
    "    ).expand(event_shape).to_event(len(event_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class new_DeepSCM(PyroModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        im_size: int,\n",
    "        hidden_dim: int,\n",
    "        thickness_size: int,\n",
    "        intensity_size: int,\n",
    "        alpha: float,\n",
    "        num_bits: int,\n",
    "        thickness_flow_bias: torch.Tensor,\n",
    "        thickness_flow_weight: torch.Tensor,\n",
    "        intensity_flow_bias: torch.Tensor,\n",
    "        intensity_flow_weight: torch.Tensor,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # tensor sizes\n",
    "        self.thickness_size = thickness_size\n",
    "        self.intensity_size = intensity_size\n",
    "        self.im_size = im_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = self.im_size * self.im_size\n",
    "  \n",
    "        # Thickness parameters\n",
    "        self.thickness_transform = ThicknessTransform(\n",
    "            thickness_size,\n",
    "            thickness_flow_weight,\n",
    "            thickness_flow_bias\n",
    "        )\n",
    "        \n",
    "        # Intensity parameters\n",
    "        self.intensity_transform = IntensityTransform(\n",
    "            intensity_size,\n",
    "            thickness_size,\n",
    "            [hidden_dim],\n",
    "            intensity_flow_weight,\n",
    "            intensity_flow_bias\n",
    "        )\n",
    "        \n",
    "        # Image parameters\n",
    "        self.img_transform = ConditionalImgTransform(\n",
    "            self.input_dim,\n",
    "            hidden_dim,\n",
    "            alpha,\n",
    "            num_bits,\n",
    "            thickness_size,\n",
    "            intensity_size,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def cond_dist(\n",
    "        transform: Union[Transforms.Transform, Transforms.ConditionalTransform],\n",
    "        U_dist: dist.TorchDistributionMixin,\n",
    "        *contexts: torch.Tensor\n",
    "    ) -> dist.Distribution:\n",
    "        if not contexts:\n",
    "            assert isinstance(transform, Transforms.Transform)\n",
    "            return dist.TransformedDistribution(U_dist, transform)\n",
    "        batch_shape = torch.broadcast_shapes(*(c.shape[:-1] for c in contexts))\n",
    "        context = torch.cat([c.expand(batch_shape + (-1,)) for c in contexts], dim=-1)\n",
    "        U_dist = U_dist.expand(torch.broadcast_shapes(batch_shape, U_dist.batch_shape))\n",
    "        return dist.ConditionalTransformedDistribution(U_dist, transform).condition(context=context)\n",
    "\n",
    "    def forward(self):\n",
    "        # Thickness:\n",
    "        UT_dist = StandardNormal(self.thickness_size, device=self.device)\n",
    "        T = pyro.sample(\"T\", self.cond_dist(self.thickness_transform, UT_dist))\n",
    "\n",
    "        # Intensity:\n",
    "        UI_dist = StandardNormal(self.intensity_size, device=self.device)\n",
    "        I = pyro.sample(\"I\", self.cond_dist(self.intensity_transform, UI_dist, T))\n",
    "\n",
    "        # Image:\n",
    "        UX_dist = StandardNormal(self.im_size ** 2, device=self.device)\n",
    "        with pyro.poutine.scale(scale=1 / self.im_size ** 2):\n",
    "            X = pyro.sample(\"X\", self.cond_dist(self.img_transform, UX_dist, T, I))\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"intensity_flow_bias\": intensity.min(),\n",
    "\"intensity_flow_weight\": (intensity.max() - intensity.min()),\n",
    "\"thickness_flow_bias\": thickness.log().mean(),\n",
    "\"thickness_flow_weight\": thickness.log().std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSCM(PyroModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Thickness parameters\n",
    "        thickness_param = Transforms.Spline(1)\n",
    "        thickness_param.domain = constraints.positive\n",
    "        self.thickness_param = thickness_param\n",
    "        \n",
    "        # Intensity parameters\n",
    "        intensity_net = pyro.nn.ConditionalAutoRegressiveNN(1, 1, hidden_dims=[10], nonlinearity=torch.nn.Identity())\n",
    "        intensity_param = Transforms.ConditionalAffineAutoregressive(intensity_net)\n",
    "        intensity_param.codomain = constraints.positive\n",
    "        self.intensity_param = intensity_param\n",
    "        \n",
    "        # Image parameters\n",
    "        input_dim = im_size*im_size\n",
    "        nn_f_X = pyro.nn.ConditionalAutoRegressiveNN(input_dim, 2, [10*input_dim], nonlinearity=torch.nn.Identity())\n",
    "        f_X = Transforms.ConditionalAffineAutoregressive(nn_f_X, log_scale_min_clip=-1., log_scale_max_clip=5.)\n",
    "        f_X.domain = constraints.positive\n",
    "        self.f_X = f_X\n",
    "        norm = Transforms.BatchNorm(input_dim, momentum=0.05)\n",
    "        self.norm = norm\n",
    "        split_dim = input_dim // 2\n",
    "        param_dims = [input_dim-split_dim, input_dim-split_dim]\n",
    "#         auto_nn_0 = pyro.nn.AutoRegressiveNN(input_dim, [10*input_dim], nonlinearity=torch.nn.Identity())\n",
    "#         img_affine_coupling = Transforms.AffineAutoregressive(auto_nn_0, log_scale_min_clip=-1., log_scale_max_clip=5.)\n",
    "        nn_affine_coupling = pyro.nn.DenseNN(split_dim, [10*input_dim], param_dims, nonlinearity=torch.nn.LeakyReLU())\n",
    "        img_affine_coupling = Transforms.AffineCoupling(split_dim, nn_affine_coupling, log_scale_min_clip=-1., log_scale_max_clip=5.0)\n",
    "        self.img_affine_coupling = img_affine_coupling\n",
    "        \n",
    "#         auto_nn = pyro.nn.AutoRegressiveNN(input_dim, [10*input_dim], nonlinearity=torch.nn.Identity())\n",
    "#         img_auto = Transforms.AffineAutoregressive(auto_nn, log_scale_min_clip=-1., log_scale_max_clip=5.)\n",
    "        nn_affine_coupling_2 = pyro.nn.DenseNN(split_dim, [10*input_dim], param_dims, nonlinearity=torch.nn.LeakyReLU())\n",
    "        img_auto = Transforms.AffineCoupling(split_dim, nn_affine_coupling_2, log_scale_min_clip=-1., log_scale_max_clip=5.0)\n",
    "        self.img_auto = img_auto\n",
    "        norm_2 = Transforms.BatchNorm(input_dim, momentum=0.05)\n",
    "        self.norm_2 = norm_2\n",
    "    \n",
    "    def forward(self):\n",
    "        # Thickness:\n",
    "        UT = dist.Normal(torch.tensor(0., device=curr_device), torch.tensor(1., device=curr_device)).expand([1]).to_event(1)\n",
    "        thickness_flow_loc = params[\"thickness_flow_bias\"]\n",
    "        thickness_flow_scale = params[\"thickness_flow_weight\"]\n",
    "        thickness_flow_lognorm = Transforms.AffineTransform(loc=thickness_flow_loc, scale=thickness_flow_scale)\n",
    "        t_transforms = [\n",
    "            self.thickness_param,\n",
    "            thickness_flow_lognorm,\n",
    "            Transforms.ExpTransform()\n",
    "        ]\n",
    "        T = pyro.sample(\"T\", dist.TransformedDistribution(UT, t_transforms))\n",
    "        \n",
    "        # Intensity:\n",
    "        UI = dist.Normal(torch.tensor(0., device=curr_device), torch.tensor(1., device=curr_device)).expand([1]).to_event(1)\n",
    "        intensity_flow_loc = params[\"intensity_flow_bias\"]\n",
    "        intensity_flow_scale = params[\"intensity_flow_weight\"]\n",
    "        intensity_flow_norm = Transforms.AffineTransform(loc=intensity_flow_loc, scale=intensity_flow_scale)\n",
    "        intensity_tranforms = [\n",
    "            self.intensity_param,\n",
    "            Transforms.SigmoidTransform(), \n",
    "            intensity_flow_norm\n",
    "        ]\n",
    "#         T = T.expand(torch.broadcast_shapes(T.shape[:-1]) + T.shape[-1:])\n",
    "        I_ = dist.ConditionalTransformedDistribution(UI, intensity_tranforms)\n",
    "        I = I_.condition(context=T)\n",
    "        I = pyro.sample(\"I\", I)\n",
    "\n",
    "        \n",
    "        # Image:\n",
    "        UX = dist.Normal(torch.tensor(0., device=curr_device), torch.tensor(1., device=curr_device)).expand([im_size*im_size]).to_event(1)\n",
    "        \n",
    "        # Preprocessing\n",
    "        alpha = 0.001\n",
    "        num_bits = 2\n",
    "        s = Transforms.SigmoidTransform()\n",
    "        preprocess_transform = Transforms.ComposeTransform([\n",
    "            Transforms.AffineTransform(0., (1. / 2 ** num_bits)),\n",
    "            Transforms.AffineTransform(alpha, (1 - alpha)),\n",
    "            s.inv\n",
    "        ])\n",
    "    \n",
    "        batch_shape = torch.broadcast_shapes(T.shape[:-1], I.shape[:-1])\n",
    "        T = T.expand(batch_shape + T.shape[-1:])\n",
    "        I = I.expand(batch_shape + I.shape[-1:])\n",
    "        \n",
    "        assert T.shape == I.shape\n",
    "        \n",
    "        f_X = self.f_X.condition(context=torch.cat((T, I), dim=-1))\n",
    "        \n",
    "#         assert torch.cat((T, I), dim=-1).shape == (2, )\n",
    "        perm1 = Transforms.Permute(torch.randperm(im_size*im_size, device=curr_device))\n",
    "        perm2 = Transforms.Permute(torch.randperm(im_size*im_size, device=curr_device))\n",
    "        \n",
    "        h_X = dist.TransformedDistribution(UX, [preprocess_transform,\n",
    "                                                f_X,\n",
    "                                                self.norm,\n",
    "                                                perm1,\n",
    "                                                self.img_affine_coupling,\n",
    "                                                perm2,\n",
    "                                                self.img_auto,\n",
    "                                                self.norm_2\n",
    "                                               ])\n",
    "        with pyro.poutine.scale(scale=1/(im_size*im_size)):\n",
    "            X = pyro.sample(\"X\", h_X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scm = DeepSCM().to(device=curr_device)\n",
    "print(list(dict(scm.named_parameters()).keys()))\n",
    "# print(pyro.poutine.trace(scm).get_trace().log_prob_sum())\n",
    "pyro.render_model(scm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torch.nn.functional.normalize(scm().cpu().detach().reshape((im_size, im_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervened_scm = do(scm, {\"I\": torch.randn(1, device = curr_device)})\n",
    "pyro.render_model(intervened_scm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditioned_scm(model):\n",
    "    def query_model(t_obs, i_obs, x_obs):\n",
    "        with pyro.condition(data={\"X\": x_obs, \"T\": t_obs, \"I\": i_obs}), \\\n",
    "                pyro.plate(\"data\", size=x_obs.shape[0], dim=-1):\n",
    "            return model()\n",
    "    return query_model\n",
    "\n",
    "scm = DeepSCM().to(device=curr_device)\n",
    "conditioned_model = conditioned_scm(scm)\n",
    "imgs = conditioned_model(thickness[:3, None], intensity[:3, None], images[:3].reshape(-1, im_size*im_size))\n",
    "pyro.render_model(conditioned_model, model_args=(thickness[:2][..., None], intensity[:2][..., None], images[:2].reshape(-1, im_size*im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.0001\n",
    "num_iterations = 2\n",
    "adam_params = {\"lr\": initial_lr, \"betas\": (0.95, 0.999)}\n",
    "optimizer = pyro.optim.Adam(adam_params)\n",
    "empty_guide = lambda *args: None\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# n = math.ceil(len(dataset/batch_size))\n",
    "scaled_model = pyro.poutine.scale(conditioned_model, scale=1/(batch_size))\n",
    "svi = SVI(scaled_model, empty_guide, optimizer, loss=pyro.infer.Trace_ELBO())\n",
    "dataset = [(thickness[i], intensity[i], images[i]) for i in range(images.shape[0])]\n",
    "n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "loss =[]\n",
    "for j in range(num_iterations):\n",
    "    data = iter(DataLoader(dataset, batch_size=batch_size, shuffle=True))\n",
    "    for i in range(n):\n",
    "        t_obs, i_obs, x_obs = next(data)\n",
    "        loss.append(svi.step(t_obs[..., None], i_obs[..., None], x_obs.reshape(-1, im_size*im_size)))\n",
    "    if j%100 == 0:\n",
    "        print(sum(loss[-n:])/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive = pyro.infer.Predictive(condition(scm, data = {\"T\": thickness[0][..., None], \"I\": intensity[0][..., None]}), guide=empty_guide, num_samples=4)\n",
    "img = predictive()[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "rows = 2\n",
    "columns = 2\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(torch.nn.functional.normalize(img[0].cpu().reshape((im_size, im_size))))\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(torch.nn.functional.normalize(img[1].cpu().reshape((im_size, im_size))))\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(torch.nn.functional.normalize(img[2].cpu().reshape((im_size, im_size))))\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(torch.nn.functional.normalize(img[3].cpu().reshape((im_size, im_size))))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: counterfactual data generation\n",
    "\n",
    "Next we ask a *counterfactual* question: given an observed digit $X$, what\n",
    "would the digit have been had $t$ been $t + 1$?\n",
    "\n",
    "To compute this quantity we would normally:\n",
    "   1. invert the model to find latent exogenous noise $u$\n",
    "   2. construct an intervened model\n",
    "   3. re-simulate the forward model on the $u$ [@pearl2011algorithmization].  \n",
    "\n",
    "However, we can equivalently\n",
    "represent this process with inference in a single, expanded\n",
    "probabilistic program containing two copies of every deterministic\n",
    "statement (a so-called \\\"twin network\\\" representation of\n",
    "counterfactuals, first described in Chapter 7 of [@pearl] and extended\n",
    "to the PPL setting in [@tavares_2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs = images[0]\n",
    "plt.imshow(x_obs.cpu().detach().reshape((im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_scm_query(model: DeepSCM):\n",
    "    def query_model(x_obs):\n",
    "        with MultiWorldCounterfactual(dim=-1), \\\n",
    "            do(actions={'I': torch.tensor([190.0], device=model.device)}), \\\n",
    "                condition(data={\"X\": x_obs.reshape(-1, model.input_dim).to(device=model.device)}):\n",
    "                    return model()\n",
    "    return query_model\n",
    "\n",
    "cf_model = pyro.poutine.reparam(config={\"X_observed\": TransformInferReparam()})(\n",
    "    deep_scm_query(\n",
    "        scm\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pdb on\n",
    "fig = plt.figure()\n",
    "plt.title(\"Twin World Counterfactual Model\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "rows = 1\n",
    "columns = 2\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(cf_model(x_obs)[\"X\"][0][0].cpu().reshape((14, 14)))\n",
    "plt.title(\"Actual Model\")\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(torch.nn.functional.normalize(cf_model(x_obs)[\"X\"][0][1].cpu().reshape((14, 14))))\n",
    "plt.title(\"Intervened Model\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all counterfactuals, this estimand is not identified in general\n",
    "without further assumptions: learning parameters $\\theta$ that match\n",
    "observed data does not guarantee that the counterfactual distribution\n",
    "will match that of the true causal model. \n",
    "\n",
    "However, as discussed in the\n",
    "original paper [@pawlowski2020deep] in the context of modeling MRI\n",
    "images, there are a number of valid practical reasons one might wish to\n",
    "compute it anyway, such as explanation or expert evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
