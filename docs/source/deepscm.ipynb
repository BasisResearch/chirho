{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Deep structural causal model counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/archana/opt/anaconda3/envs/deepscm/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union, TypeVar\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.poutine import condition, reparam\n",
    "from pyro.nn import PyroParam, PyroSample, PyroModule\n",
    "import pyro.distributions.transforms as Transforms\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.infer import config_enumerate\n",
    "from pyro.distributions import constraints\n",
    "\n",
    "\n",
    "import causal_pyro\n",
    "from causal_pyro.query.do_messenger import do\n",
    "from causal_pyro.counterfactual.handlers import Factual, MultiWorldCounterfactual, TwinWorldCounterfactual\n",
    "\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import gzip\n",
    "import struct\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Normalizing flows and counterfactuals\n",
    "\n",
    "Much of the causal inference literature has focused on relatively simple\n",
    "causal models with low dimensional data. In order to perform\n",
    "counterfactual reasoning in more complex domains with high dimensional\n",
    "data, Palowski et al. [@pawlowski2020deep] introduced *deep structural\n",
    "causal models* (Deep SCMs): SCMs with neural networks as the functional\n",
    "mechanisms between variables.\n",
    "\n",
    "Specifically, the neural networks are\n",
    "*normalizing flows*. A normalizing flow transforms a base probability\n",
    "distribution (often a simple distribution, such as a multivariate\n",
    "Gaussian) through a sequence of invertible transformations into a more\n",
    "complex distribution (such as a distribution over images). When used\n",
    "within a Deep SCM, the flow's base distribution is an exogenous noise\n",
    "variable, and its output is an endogenous variable.\n",
    "\n",
    "A salient property\n",
    "of normalizing flows is that computing the likelihood of data can be\n",
    "done both exactly and efficiently, and hence training a flow to model a\n",
    "data distribution through maximum likelihood is straightforward. In\n",
    "addition, the inverse of a normalizing flow can also typically be\n",
    "efficiently computed, which renders the abduction step of a\n",
    "counterfactual---inferring the posterior over exogenous variables given\n",
    "evidence---trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Morpho-MNIST\n",
    "\n",
    "We consider a synthetic dataset based on MNIST, where the image of each digit ($X$) depends on stroke thickness ($T$) and brightness ($I$) of the image and the thickness depends on brightness as well.\n",
    "\n",
    "We assume we know full causal structure (i.e., there are no unconfounded variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_idx(path: str) -> np.ndarray:\n",
    "    \"\"\"Reads an array in IDX format from disk.\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path of the input file. Will uncompress with `gzip` if path ends in '.gz'.\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Output array of dtype ``uint8``.\n",
    "    References\n",
    "    ----------\n",
    "    http://yann.lecun.com/exdb/mnist/\n",
    "    \"\"\"\n",
    "    open_fcn = gzip.open if path.endswith('.gz') else open\n",
    "    with open_fcn(path, 'rb') as f:\n",
    "        idx_dtype, ndim = struct.unpack('BBBB', f.read(4))[2:]\n",
    "        shape = struct.unpack('>' + 'I' * ndim, f.read(4 * ndim))\n",
    "        buffer_length = int(np.prod(shape))\n",
    "        data = np.frombuffer(f.read(buffer_length), dtype=np.uint8).reshape(shape).astype(np.float32)\n",
    "        return data\n",
    "    \n",
    "path = os.path.join(os.getcwd(), \"../datasets/morphomnist_num_5/\")\n",
    "metrics = pd.read_csv(path + \"train-morpho.csv\", index_col= 'index')\n",
    "# raw_labels = load_idx(path+\"train-labels-idx1-ubyte.gz\")\n",
    "raw_images = load_idx(path+\"train-images-idx3-ubyte.gz\")\n",
    "\n",
    "thickness = torch.tensor(metrics[\"thickness\"], dtype=torch.float32)\n",
    "intensity = torch.tensor(metrics[\"intensity\"], dtype=torch.float32)\n",
    "# labels = torch.tensor(raw_labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "rows = 2\n",
    "columns = 2\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(raw_images[0])\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(raw_images[1])\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(raw_images[2])\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(raw_images[3])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = skimage.measure.block_reduce(raw_images, block_size=(1, 2, 2))\n",
    "images = torch.tensor(images, dtype=torch.float32)\n",
    "im_size = images.shape[1]\n",
    "# im_size = torch.tensor(im_size)\n",
    "im_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 13.5, 13.5, -0.5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAGFCAYAAAB9krNlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAMIUlEQVR4nO3ce6zXdR3H8d/vHBCUI95QUAg1b6A5p1MnVGoXrEhXZt6alz80M8285LQ2V2lbOrugKy/Ycm1FM1ktXUNTyywDFRMTUiMwr+gUlAOhCOecX3/0TyW+xlvO2fkdeTz+fp3v7zv++D75/PNptlqtVgMA2KCOwX4BAGhnQgkAgVACQCCUABAIJQAEQgkAgVACQCCUABAM29jhtI7jB/I9YJPc3Td7sF+Bt+HbQTvbmG+HEyUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAwbLBf4N2iY6utavttRpf2Kz6yW2m/5fLe0v7FKcNL+1HLWqX9mJnzSnuAduFECQCBUAJAIJQAEAglAARCCQCBUAJAIJQAEAglAARCCQCBUAJAIJQAEAzZu16bI0aU9n+/9oDS/piDF5T2F+90V2k/trP2/iOatbtYp/z1uNK+r3tUaT/i8drdtsDQUP229h4yubRfenLt+a3O2r3S+5z3aGm/MZwoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAgiF712ujr3j/394vlPan7/Dn0n77jto/5b63nlfab7PHa6X92BOeKe1Hr11b2gODo3PMDqX9E1fsUdrPmPbz0v7Tox4s7f9Y/NR8fv5ppX2zs//Pf06UABAIJQAEQgkAgVACQCCUABAIJQAEQgkAgVACQCCUABAIJQAEQgkAwZC967W1fl3tDz5cu+v1zHMvKO0vPO/W0n7Pr8wv7Rt9vbV57enAIOncYfvSfuffvFnaH7X1XaX9JbNPLe1vuH1Nad/x6OLSfre1j5X2A/Htc6IEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhuxdrwNt7E0Pl/b3njq5tF88c1JpP/nqFaV97z+eKu2B/rH6xMNK+1lXf7e0/9xXLy7tl93eKu13XzOvtK8aivdQO1ECQCCUABAIJQAEQgkAgVACQCCUABAIJQAEQgkAgVACQCCUABAIJQAE7np9G63160r7l08aV9ofecuTpf3JdzxQ2l957uml/Ra/rd1tC2zYS9Nr346Rzdrzu55bW9r3rVlT+wHewokSAAKhBIBAKAEgEEoACIQSAAKhBIBAKAEgEEoACIQSAAKhBIBAKAEgcNdrP+l5+tnSftnUztL+8jnHlPY/u+ma0v7cAz5Z2veu7C7toV08/7WpA/r8yZcuLe1v+/0+pf3rl60q7bs+XpqzAU6UABAIJQAEQgkAgVACQCCUABAIJQAEQgkAgVACQCCUABAIJQAEQgkAgbte+8m6jx1c21/4amk/532zSvsn1m1Z2veteaO0h3bROXp0aX/HF68u7ef8q3YX63WHHlHanzK6djfsD+77VGnf1XiqtOetnCgBIBBKAAiEEgACoQSAQCgBIBBKAAiEEgACoQSAQCgBIBBKAAiEEgCCzeau18693lvaP3f1yNL+kUNnlvbdfWtL+wPv+XJpP/mKFaV9a/3TpT20i95Vq0r708+6sLR/+jOleaM5sre0f//3LirtJ8yYW9qz6ZwoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAgra56/XN6YeU9l2XPF/a/3KvX5T2HcX/Qxw8/5TSfvzFtbte91ryl9K+p7SGzccWd84v7fe+c4BehCHDiRIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASBom7teu3cfXto/u2hiaX/QXeeX9hPuWV3aj3toYWnfW1oDMFicKAEgEEoACIQSAAKhBIBAKAEgEEoACIQSAAKhBIBAKAEgEEoACIQSAIK2uet1p+vm1vYD9B4A8N+cKAEgEEoACIQSAAKhBIBAKAEgEEoACIQSAAKhBIBAKAEgEEoACIQSAIJmq9VqDfZLAEC7cqIEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgGDYxg6ndRw/kO8Bm+zuvtmD/QpsgG8H7WxjvhtOlAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAglAAQCCUABEIJAMGwwX4Bhq7O7bYr7ftWry7tWz09pT2w6YaN36W0X33IhAF6k//Y6oU3SvvW/IX9/g5OlAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIG7XoeQ5oH7lfZPHT+6tP/otAWl/fXj7y3tJ994Tmk/8Yq5pT1sDqp3sTZntUr7W/b8VWnf1TGytK/q7qvd9XrS0Wf0+zs4UQJAIJQAEAglAARCCQCBUAJAIJQAEAglAARCCQCBUAJAIJQAEAglAATueu0nzREjSvvWnB3Lv3HbpJ+U9mc8M620v+OR/Uv7oy6YVNpPnPdgaQ9DUrNZ3NfOK0tn7FDaP7n3T0v77r7a3bA3rhxf2s95pfadWbRo19J+0ov/LO03hhMlAARCCQCBUAJAIJQAEAglAARCCQCBUAJAIJQAEAglAARCCQCBUAJA4K7XfrLk5n1L++O2X1D+jWM/dFJp37t4aWm/d2N+aQ+bg8599iztp85eVNrf+tSBpf2Ea4aX9ofPOqu077p/SWnf++prpX2j9VJpvlejtu8trTeOEyUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIFQAkDgrte3sfK0KaX9kg/dUNp/45X9SvtGo9HoPmBMad9VvOsVeKvnrtqitL9szJOl/Y/nHl7a73xf7U7mLVut0n4g7kod6pwoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAAqEEgEAoASAQSgAIhBIAgs3nrtdD9y/Nr/3mD0v7I888u7R/cco7+Kf/7JrSvGt2/SeA/9U18s0Bff7iY2r3RH/poA+U9s8fu11p3/PCstJ+c+BECQCBUAJAIJQAEAglAARCCQCBUAJAIJQAEAglAARCCQCBUAJAIJQAEGw+d70+tLA0v3z/w0v7Ea8/XNrvc+nY0r7RaDT+tmC38t8Am2a701aV9vudeU5pf/QJc0v7mRPmlfaTZpxa2u96grte/58TJQAEQgkAgVACQCCUABAIJQAEQgkAgVACQCCUABAIJQAEQgkAgVACQNA2d70u/8KU0n7d1s3S/j03LSrtV02bXNqPu2Bpab/LlitK+0aj0ej51rrSvrf8C/Du17H11qV9c1hnaT/hytrdrb9bXvv2NS5/tDTftuuN2vN5CydKAAiEEgACoQSAQCgBIBBKAAiEEgACoQSAQCgBIBBKAAiEEgACoQSAoG3uel0/qnZ368KLri/tl5+/prT/zvJVpf09N9bua1z9o4dK+0aj0Wj0vVr/G3iX69xxx9L+E39YXNqfPPrx0v7Klz9Y2l8+dkZp32iMLK1X/2mn0n6bxpLSfnPgRAkAgVACQCCUABAIJQAEQgkAgVACQCCUABAIJQAEQgkAgVACQCCUABC0zV2vO39/bmk//eYjaj/Q1yrNe1fV7nod05hX2gP9o3ePnUv7s7e9s7Qf3hxV2n973IOl/ddfPqy0v/3XU0v7iVf5Nm0qJ0oACIQSAAKhBIBAKAEgEEoACIQSAAKhBIBAKAEgEEoACIQSAAKhBICgbe56repd2T3YrwC0gwceK82nn3hG7fmdzdJ8i2dWlPY9Tz9b2k9s1O7FZtM5UQJAIJQAEAglAARCCQCBUAJAIJQAEAglAARCCQCBUAJAIJQAEAglAARD9q5XgHei4/5HB/T5PQP6dAaDEyUABEIJAIFQAkAglAAQCCUABEIJAIFQAkAglAAQCCUABEIJAIFQAkDQbLVarcF+CQBoV06UABAIJQAEQgkAgVACQCCUABAIJQAEQgkAgVACQCCUABD8GzJZiMU4DzfFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "rows = 2\n",
    "columns = 2\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(images[0])\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(images[1])\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(images[2])\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(images[3])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: deep structural causal model\n",
    "\n",
    "The following code models morphological transformations of MNIST,\n",
    "defining a causal generative model over digits that contains endogenous\n",
    "variables to control the width $t$ and intensity $i$ of the stroke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"intensity_flow_bias\": intensity.min(),\n",
    "\"intensity_flow_weight\": (intensity.max() - intensity.min()),\n",
    "\"thickness_flow_bias\": thickness.log().mean(),\n",
    "\"thickness_flow_weight\": thickness.log().std()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSCM(PyroModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Thickness parameters\n",
    "        thickness_param = Transforms.Spline(1)\n",
    "        thickness_param.domain = constraints.positive\n",
    "        self.thickness_param = thickness_param\n",
    "        \n",
    "        # Intensity parameters\n",
    "        intensity_net = pyro.nn.ConditionalAutoRegressiveNN(1, 1, hidden_dims=[10], nonlinearity=torch.nn.Identity())\n",
    "        intensity_param = Transforms.ConditionalAffineAutoregressive(intensity_net)\n",
    "        intensity_param.codomain = constraints.positive\n",
    "        self.intensity_param = intensity_param\n",
    "        \n",
    "        # Image parameters\n",
    "        input_dim = im_size*im_size\n",
    "        nn_f_X = pyro.nn.ConditionalAutoRegressiveNN(input_dim, 2, [5*input_dim], nonlinearity=torch.nn.Identity())\n",
    "        f_X = Transforms.ConditionalAffineAutoregressive(nn_f_X, log_scale_min_clip=-1., log_scale_max_clip=5.)\n",
    "        f_X.domain = constraints.positive\n",
    "        self.f_X = f_X\n",
    "        norm = Transforms.BatchNorm(input_dim, momentum=0.05)\n",
    "        self.norm = norm\n",
    "        split_dim = input_dim // 2\n",
    "        param_dims = [input_dim-split_dim, input_dim-split_dim]\n",
    "        nn_affine_coupling = pyro.nn.DenseNN(split_dim, [10*input_dim], param_dims, nonlinearity=torch.nn.Identity())\n",
    "        img_affine_coupling = Transforms.AffineCoupling(split_dim, nn_affine_coupling, log_scale_min_clip=-1., log_scale_max_clip=5.0)\n",
    "        self.img_affine_coupling = img_affine_coupling\n",
    "        norm_2 = Transforms.BatchNorm(input_dim, momentum=0.05)\n",
    "        self.norm_2 = norm_2\n",
    "#         auto_nn = pyro.nn.AutoRegressiveNN(input_dim, [3*input_dim], nonlinearity=torch.nn.Identity())\n",
    "#         img_auto = Transforms.AffineAutoregressive(auto_nn, log_scale_min_clip=-1., log_scale_max_clip=5.)\n",
    "        nn_affine_coupling_2 = pyro.nn.DenseNN(split_dim, [10*input_dim], param_dims, nonlinearity=torch.nn.Identity())\n",
    "        img_auto = Transforms.AffineCoupling(split_dim, nn_affine_coupling_2, log_scale_min_clip=-1., log_scale_max_clip=5.0)\n",
    "        self.img_auto = img_auto\n",
    "    \n",
    "    def forward(self):\n",
    "        # Thickness:\n",
    "        UT = dist.Normal(0, 1).expand([1]).to_event(1)\n",
    "        thickness_flow_loc = params[\"thickness_flow_bias\"]\n",
    "        thickness_flow_scale = params[\"thickness_flow_weight\"]\n",
    "        thickness_flow_lognorm = Transforms.AffineTransform(loc=thickness_flow_loc, scale=thickness_flow_scale)\n",
    "        t_transforms = [\n",
    "            self.thickness_param,\n",
    "            thickness_flow_lognorm,\n",
    "            Transforms.ExpTransform()\n",
    "        ]\n",
    "        T = pyro.sample(\"T\", dist.TransformedDistribution(UT, t_transforms))\n",
    "        \n",
    "        # Intensity:\n",
    "        UI = dist.Normal(0, 1).expand([1]).to_event(1)\n",
    "        intensity_flow_loc = params[\"intensity_flow_bias\"]\n",
    "        intensity_flow_scale = params[\"intensity_flow_weight\"]\n",
    "        intensity_flow_norm = Transforms.AffineTransform(loc=intensity_flow_loc, scale=intensity_flow_scale)\n",
    "        intensity_tranforms = [\n",
    "            self.intensity_param,\n",
    "            Transforms.SigmoidTransform(), \n",
    "            intensity_flow_norm\n",
    "        ]\n",
    "#         T = T.expand(torch.broadcast_shapes(T.shape[:-1]) + T.shape[-1:])\n",
    "        I_ = dist.ConditionalTransformedDistribution(UI, intensity_tranforms)\n",
    "        I = I_.condition(context=T)\n",
    "        I = pyro.sample(\"I\", I)\n",
    "        \n",
    "        # Image:\n",
    "        UX = dist.Normal(0, 1).expand([im_size*im_size]).to_event(1)\n",
    "        \n",
    "        # Preprocessing\n",
    "        alpha = 0.001\n",
    "        num_bits = 2\n",
    "        s = Transforms.SigmoidTransform()\n",
    "        preprocess_transform = Transforms.ComposeTransform([\n",
    "            Transforms.AffineTransform(0., (1. / 2 ** num_bits)),\n",
    "            Transforms.AffineTransform(alpha, (1 - alpha)),\n",
    "            s.inv\n",
    "        ])\n",
    "    \n",
    "        batch_shape = torch.broadcast_shapes(T.shape[:-1], I.shape[:-1])\n",
    "        T = T.expand(batch_shape + T.shape[-1:])\n",
    "        I = I.expand(batch_shape + I.shape[-1:])\n",
    "        \n",
    "        assert T.shape == I.shape\n",
    "        \n",
    "        f_X = self.f_X.condition(context=torch.cat((T, I), dim=-1))\n",
    "        \n",
    "#         assert torch.cat((T, I), dim=-1).shape == (2, )\n",
    "        \n",
    "        h_X = dist.TransformedDistribution(UX, [preprocess_transform,\n",
    "                                               f_X,\n",
    "                                               self.norm,\n",
    "                                               self.img_affine_coupling,\n",
    "                                               self.norm_2,\n",
    "                                               self.img_auto])\n",
    "        X = pyro.sample(\"X\", h_X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/archana/opt/anaconda3/envs/deepscm/lib/python3.10/site-packages/pyro/nn/auto_reg_nn.py:179: UserWarning: ConditionalAutoRegressiveNN input_dim = 1. Consider using an affine transformation instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thickness_param.unnormalized_widths', 'thickness_param.unnormalized_heights', 'thickness_param.unnormalized_derivatives', 'thickness_param.unnormalized_lambdas', 'intensity_param.nn.layers.0.weight', 'intensity_param.nn.layers.0.bias', 'intensity_param.nn.layers.1.weight', 'intensity_param.nn.layers.1.bias', 'f_X.nn.layers.0.weight', 'f_X.nn.layers.0.bias', 'f_X.nn.layers.1.weight', 'f_X.nn.layers.1.bias', 'norm.gamma', 'norm.beta', 'img_affine_coupling.nn.layers.0.weight', 'img_affine_coupling.nn.layers.0.bias', 'img_affine_coupling.nn.layers.1.weight', 'img_affine_coupling.nn.layers.1.bias', 'norm_2.gamma', 'norm_2.beta', 'img_auto.nn.layers.0.weight', 'img_auto.nn.layers.0.bias', 'img_auto.nn.layers.1.weight', 'img_auto.nn.layers.1.bias']\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.0 (20221023.0053)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"89pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 89.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 85,-184 85,4 -4,4\"/>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"54\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">I</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;I -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.46,-144.05C44.48,-136.32 40.87,-126.96 37.52,-118.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.88,-117.27 34.02,-109.2 34.35,-119.79 40.88,-117.27\"/>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;X -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.65,-143.91C59.68,-133.57 61.98,-120.09 63,-108 64.34,-92.06 64.34,-87.94 63,-72 62.32,-63.97 61.08,-55.33 59.73,-47.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.17,-46.79 57.93,-37.58 56.29,-48.05 63.17,-46.79\"/>\n",
       "</g>\n",
       "<!-- I&#45;&gt;X -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>I&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.54,-72.05C36.52,-64.32 40.13,-54.96 43.48,-46.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"46.65,-47.79 46.98,-37.2 40.12,-45.27 46.65,-47.79\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fdefc0bf670>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scm = DeepSCM()\n",
    "print(list(dict(scm.named_parameters()).keys()))\n",
    "# print(pyro.poutine.trace(scm).get_trace().log_prob_sum())\n",
    "pyro.render_model(scm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fde8bf80fa0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(scm().detach().reshape((im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.0 (20221023.0053)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"63\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">I</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;I -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.65,-72.76C50.42,-64.55 45.19,-54.37 40.42,-45.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"43.68,-43.79 36,-36.49 37.46,-46.99 43.68,-43.79\"/>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"99\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;X -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M71.35,-72.76C75.58,-64.55 80.81,-54.37 85.58,-45.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"88.54,-46.99 90,-36.49 82.32,-43.79 88.54,-46.99\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fdefc9d0a90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervened_scm = do(scm, {\"I\": torch.randn(1)})\n",
    "pyro.render_model(intervened_scm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.0 (20221023.0053)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"114pt\" height=\"243pt\"\n",
       " viewBox=\"0.00 0.00 114.00 243.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 239)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-239 110,-239 110,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_data</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-227 98,-227 98,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"78.5\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"53\" cy=\"-201\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"53\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"43\" cy=\"-129\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"43\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">I</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;I -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.53,-182.7C49.47,-175.32 48.22,-166.52 47.04,-158.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"50.54,-158.01 45.66,-148.6 43.61,-159 50.54,-158.01\"/>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"53\" cy=\"-57\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"53\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;X -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.24,-184.02C69.12,-173.86 75.94,-160.18 79,-147 82.62,-131.41 82.62,-126.59 79,-111 76.85,-101.73 72.84,-92.22 68.6,-83.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71.81,-82.43 63.96,-75.31 65.66,-85.77 71.81,-82.43\"/>\n",
       "</g>\n",
       "<!-- I&#45;&gt;X -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>I&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45.47,-110.7C46.53,-103.32 47.78,-94.52 48.96,-86.25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.39,-87 50.34,-76.6 45.46,-86.01 52.39,-87\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fde8bef2c20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conditioned_scm(model):\n",
    "    def query_model(t_obs, i_obs, x_obs):\n",
    "        with pyro.condition(data={\"X\": x_obs, \"T\": t_obs, \"I\": i_obs}), \\\n",
    "                pyro.plate(\"data\", size=x_obs.shape[0], dim=-1):\n",
    "            return model()\n",
    "    return query_model\n",
    "\n",
    "conditioned_model = conditioned_scm(scm)\n",
    "imgs = conditioned_model(thickness[:3, None], intensity[:3, None], images[:3].reshape(-1, im_size*im_size))\n",
    "pyro.render_model(conditioned_model, model_args=(thickness[:2][..., None], intensity[:2][..., None], images[:2].reshape(-1, im_size*im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 1---\n",
      "\n",
      "490567.1973876953\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)):\n\u001b[1;32m     17\u001b[0m     t_obs, i_obs, x_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data)\n\u001b[0;32m---> 18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43msvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_obs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_obs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_obs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim_size\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mim_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepscm/lib/python3.10/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m poutine\u001b[38;5;241m.\u001b[39mtrace(param_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepscm/lib/python3.10/site-packages/pyro/infer/trace_elbo.py:157\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainable_params \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m    154\u001b[0m         surrogate_loss_particle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     ):\n\u001b[1;32m    156\u001b[0m         surrogate_loss_particle \u001b[38;5;241m=\u001b[39m surrogate_loss_particle \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles\n\u001b[0;32m--> 157\u001b[0m         \u001b[43msurrogate_loss_particle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m warn_if_nan(loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepscm/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepscm/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepscm/lib/python3.10/site-packages/pyro/util.py:84\u001b[0m, in \u001b[0;36mwarn_if_nan.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     80\u001b[0m         lineno \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mf_lineno\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(value) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m     83\u001b[0m     value\u001b[38;5;241m.\u001b[39mregister_hook(\n\u001b[0;32m---> 84\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: warn_if_nan(\n\u001b[1;32m     85\u001b[0m             x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg, filename\u001b[38;5;241m=\u001b[39mfilename, lineno\u001b[38;5;241m=\u001b[39mlineno\n\u001b[1;32m     86\u001b[0m         )\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch_isnan(value):\n\u001b[1;32m     90\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn_explicit(\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered NaN\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m         filename,\n\u001b[1;32m     94\u001b[0m         lineno,\n\u001b[1;32m     95\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_lr = 0.0001\n",
    "epochs = 10\n",
    "\n",
    "adam_params = {\"lr\": initial_lr, \"betas\": (0.90, 0.999)}\n",
    "optimizer = pyro.optim.Adam(adam_params)\n",
    "empty_guide = lambda *args: None\n",
    "svi = SVI(conditioned_model, empty_guide, optimizer, loss=pyro.infer.Trace_ELBO(num_particles=4, vectorize_particles=True))\n",
    "predictive = pyro.infer.Predictive(scm, guide=empty_guide, num_samples=32)\n",
    "dataset = [(thickness[i], intensity[i], images[i]) for i in range(images.shape[0])]\n",
    "\n",
    "\n",
    "for j in range(epochs):\n",
    "    data = iter(DataLoader(dataset, batch_size=256, shuffle=True))\n",
    "    pyro.clear_param_store()\n",
    "    print(f\"---Epoch {j + 1}---\\n\")\n",
    "    for i in range(len(data)):\n",
    "        t_obs, i_obs, x_obs = next(data)\n",
    "        loss = svi.step(t_obs[..., None], i_obs[..., None], x_obs.reshape(-1, im_size*im_size))\n",
    "        if i%10 == 0:\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = predictive()[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "rows = 2\n",
    "columns = 2\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(img[0].reshape((im_size, im_size)))\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(img[1].reshape((im_size, im_size)))\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(img[2].reshape((im_size, im_size)))\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(img[3].reshape((im_size, im_size)))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: counterfactual data generation\n",
    "\n",
    "Next we ask a *counterfactual* question: given an observed digit $X$, what\n",
    "would the digit have been had $t$ been $t + 1$?\n",
    "\n",
    "To compute this quantity we would normally:\n",
    "   1. invert the model to find latent exogenous noise $u$\n",
    "   2. construct an intervened model\n",
    "   3. re-simulate the forward model on the $u$ [@pearl2011algorithmization].  \n",
    "\n",
    "However, we can equivalently\n",
    "represent this process with inference in a single, expanded\n",
    "probabilistic program containing two copies of every deterministic\n",
    "statement (a so-called \\\"twin network\\\" representation of\n",
    "counterfactuals, first described in Chapter 7 of [@pearl] and extended\n",
    "to the PPL setting in [@tavares_2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs = images[0]\n",
    "plt.imshow(x_obs.detach().reshape((im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_scm_query(model : DeepSCM):\n",
    "    def query_model(x_obs):\n",
    "        with TwinWorldCounterfactual(dim=-1), \\\n",
    "        do(actions={'I': torch.tensor([190.0])}), \\\n",
    "            condition(data={\"X\": x_obs.reshape(-1, im_size*im_size)}):\n",
    "                return model()\n",
    "    return query_model\n",
    "\n",
    "cf_model = deep_scm_query(predictive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title(\"Twin World Counterfactual Model\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "rows = 1\n",
    "columns = 2\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(cf_model(x_obs)[\"X\"][0][0].reshape((14, 14)))\n",
    "plt.title(\"Actual Model\")\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(cf_model(x_obs)[\"X\"][0][1].reshape((14, 14)))\n",
    "plt.title(\"Intervened Model\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all counterfactuals, this estimand is not identified in general\n",
    "without further assumptions: learning parameters $\\theta$ that match\n",
    "observed data does not guarantee that the counterfactual distribution\n",
    "will match that of the true causal model. \n",
    "\n",
    "However, as discussed in the\n",
    "original paper [@pawlowski2020deep] in the context of modeling MRI\n",
    "images, there are a number of valid practical reasons one might wish to\n",
    "compute it anyway, such as explanation or expert evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
