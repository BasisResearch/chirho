{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Deep structural causal model counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union, TypeVar\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.poutine import condition, reparam\n",
    "from pyro.nn import PyroParam, PyroSample, PyroModule\n",
    "import pyro.distributions.transforms as Transforms\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.infer import config_enumerate\n",
    "from pyro.distributions import constraints\n",
    "\n",
    "\n",
    "import causal_pyro\n",
    "from causal_pyro.query.do_messenger import do\n",
    "from causal_pyro.counterfactual.handlers import Factual, MultiWorldCounterfactual, TwinWorldCounterfactual\n",
    "from causal_pyro.reparam.soft_conditioning import TransformInferReparam\n",
    "\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import gzip\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: False\n",
      "Current device: cpu\n"
     ]
    }
   ],
   "source": [
    "available = torch.cuda.is_available()\n",
    "curr_device = torch.device(\"cpu\") if not available else torch.cuda.current_device()\n",
    "print(f'Cuda available: {available}')\n",
    "print(f'Current device: {curr_device}')\n",
    "\n",
    "if available:\n",
    "    device_count = torch.cuda.device_count() \n",
    "    device_name =  torch.cuda.get_device_name(0)\n",
    "    print(f'Device count: {device_count}')\n",
    "    print(f'Device name: {device_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Normalizing flows and counterfactuals\n",
    "\n",
    "Much of the causal inference literature has focused on relatively simple\n",
    "causal models with low dimensional data. In order to perform\n",
    "counterfactual reasoning in more complex domains with high dimensional\n",
    "data, Palowski et al. [@pawlowski2020deep] introduced *deep structural\n",
    "causal models* (Deep SCMs): SCMs with neural networks as the functional\n",
    "mechanisms between variables.\n",
    "\n",
    "Specifically, the neural networks are\n",
    "*normalizing flows*. A normalizing flow transforms a base probability\n",
    "distribution (often a simple distribution, such as a multivariate\n",
    "Gaussian) through a sequence of invertible transformations into a more\n",
    "complex distribution (such as a distribution over images). When used\n",
    "within a Deep SCM, the flow's base distribution is an exogenous noise\n",
    "variable, and its output is an endogenous variable.\n",
    "\n",
    "A salient property\n",
    "of normalizing flows is that computing the likelihood of data can be\n",
    "done both exactly and efficiently, and hence training a flow to model a\n",
    "data distribution through maximum likelihood is straightforward. In\n",
    "addition, the inverse of a normalizing flow can also typically be\n",
    "efficiently computed, which renders the abduction step of a\n",
    "counterfactual---inferring the posterior over exogenous variables given\n",
    "evidence---trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Morpho-MNIST\n",
    "\n",
    "We consider a synthetic dataset based on MNIST, where the image of each digit ($X$) depends on stroke thickness ($T$) and brightness ($I$) of the image and the thickness depends on brightness as well.\n",
    "\n",
    "We assume we know full causal structure (i.e., there are no unconfounded variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_idx(path: str) -> np.ndarray:\n",
    "    \"\"\"Reads an array in IDX format from disk.\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path of the input file. Will uncompress with `gzip` if path ends in '.gz'.\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Output array of dtype ``uint8``.\n",
    "    References\n",
    "    ----------\n",
    "    http://yann.lecun.com/exdb/mnist/\n",
    "    \"\"\"\n",
    "    open_fcn = gzip.open if path.endswith('.gz') else open\n",
    "    with open_fcn(path, 'rb') as f:\n",
    "        idx_dtype, ndim = struct.unpack('BBBB', f.read(4))[2:]\n",
    "        shape = struct.unpack('>' + 'I' * ndim, f.read(4 * ndim))\n",
    "        buffer_length = int(np.prod(shape))\n",
    "        data = np.frombuffer(f.read(buffer_length), dtype=np.uint8).reshape(shape).astype(np.float32)\n",
    "        return data\n",
    "    \n",
    "path = os.path.join(os.getcwd(), \"../datasets/morphomnist/\")\n",
    "raw_metrics = pd.read_csv(path + \"train-morpho.csv\", index_col= 'index')\n",
    "raw_labels = load_idx(path+\"train-labels-idx1-ubyte.gz\")\n",
    "raw_images = load_idx(path+\"train-images-idx3-ubyte.gz\")\n",
    "\n",
    "images = skimage.measure.block_reduce(raw_images, block_size=(1, 2, 2))\n",
    "images = torch.tensor(images, dtype=torch.float32, device=curr_device)\n",
    "labels = torch.tensor(raw_labels, dtype=torch.float32)\n",
    "thickness = torch.tensor(raw_metrics[\"thickness\"], dtype=torch.float32, device=curr_device)\n",
    "intensity = torch.tensor(raw_metrics[\"intensity\"], dtype=torch.float32, device=curr_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 13.5, 13.5, -0.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "rows = 2\n",
    "columns = 2\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(images[0].cpu())\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(images[1].cpu())\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(images[2].cpu())\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(images[3].cpu())\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: deep structural causal model\n",
    "\n",
    "The following code models morphological transformations of MNIST,\n",
    "defining a causal generative model over digits that contains endogenous\n",
    "variables to control the width $t$ and intensity $i$ of the stroke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantParamTransformModule(dist.torch_transform.TransformModule):\n",
    "    def __init__(self, transform: Transforms.Transform):\n",
    "        super().__init__()\n",
    "        self._transform = transform\n",
    "        self.domain = transform.domain\n",
    "        self.codomain = transform.codomain\n",
    "        self.bijective = transform.bijective\n",
    "        \n",
    "    @property\n",
    "    def sign(self):\n",
    "        return self._transform.sign\n",
    "        \n",
    "    def _call(self, x):\n",
    "        return self._transform(x)\n",
    "    \n",
    "    def _inverse(self, y):\n",
    "        return self._transform.inv(y)\n",
    "    \n",
    "    def log_abs_det_jacobian(self, x, y):\n",
    "        return self._transform.log_abs_det_jacobian(x, y)\n",
    "\n",
    "\n",
    "class ComposeTransformModule(Transforms.ComposeTransformModule):\n",
    "    def __init__(self, transforms: List[Transforms.Transform]):\n",
    "        super().__init__([\n",
    "            ConstantParamTransformModule(t) if not isinstance(t, torch.nn.Module) else t for t in transforms\n",
    "        ])\n",
    "\n",
    "\n",
    "class ConditionalComposeTransformModule(dist.conditional.ConditionalTransformModule):\n",
    "    def __init__(self, transforms: List):\n",
    "        self.transforms = [\n",
    "            dist.conditional.ConstantConditionalTransform(t)\n",
    "            if not isinstance(t, dist.conditional.ConditionalTransform)\n",
    "            else t\n",
    "            for t in transforms\n",
    "        ]\n",
    "        super().__init__()\n",
    "\n",
    "    def condition(self, context: torch.Tensor):\n",
    "        return ComposeTransformModule([t.condition(context) for t in self.transforms])\n",
    "    \n",
    "\n",
    "class ConditionalAffineTransform(dist.conditional.ConditionalTransformModule):\n",
    "    def __init__(self, context_nn: torch.nn.Module, event_dim=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.event_dim = event_dim\n",
    "        self.context_nn = context_nn\n",
    "\n",
    "    def condition(self, context):\n",
    "        loc, log_scale = self.context_nn(context)\n",
    "        return Transforms.AffineTransform(loc, torch.nn.functional.softplus(log_scale), event_dim=self.event_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThicknessTransform(ComposeTransformModule):\n",
    "    def __init__(self, thickness_size: int, weight: torch.Tensor, bias: torch.Tensor):\n",
    "        self.thickness_size = thickness_size\n",
    "        super().__init__([\n",
    "            Transforms.Spline(thickness_size),\n",
    "            Transforms.AffineTransform(loc=bias, scale=weight, event_dim=0),\n",
    "            Transforms.ExpTransform()\n",
    "        ])\n",
    "\n",
    "\n",
    "class IntensityTransform(ConditionalComposeTransformModule):\n",
    "    def __init__(self, intensity_size: int, thickness_size: int, hidden_dims: List[int], weight: torch.Tensor, bias: torch.Tensor):\n",
    "        self.intensity_size = intensity_size\n",
    "        self.thickness_size = thickness_size\n",
    "        self.hidden_dims = hidden_dims\n",
    "        intensity_nn = pyro.nn.DenseNN(\n",
    "            thickness_size,\n",
    "            hidden_dims,\n",
    "            param_dims=[intensity_size, intensity_size],\n",
    "            nonlinearity=torch.nn.ReLU()\n",
    "        )\n",
    "        super().__init__([\n",
    "            ConditionalAffineTransform(intensity_nn, event_dim=0),\n",
    "            Transforms.SigmoidTransform(),\n",
    "            Transforms.AffineTransform(loc=bias, scale=weight, event_dim=0),\n",
    "        ])\n",
    "        self.intensity_nn = intensity_nn\n",
    "\n",
    "\n",
    "class ImageCouplingLayer(Transforms.ConditionalAffineCoupling):\n",
    "            \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        *,\n",
    "        nonlinearity: torch.nn.Module = torch.nn.LeakyReLU()\n",
    "    ):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        super().__init__(\n",
    "            self.input_dim // 2,\n",
    "            pyro.nn.ConditionalDenseNN(\n",
    "                self.input_dim // 2,\n",
    "                2,\n",
    "                [self.hidden_dim * self.input_dim],\n",
    "                param_dims=[self.input_dim - self.input_dim // 2, self.input_dim - self.input_dim // 2],\n",
    "                nonlinearity=nonlinearity,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n",
    "class ImageTransform(ConditionalComposeTransformModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        im_size: int,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        thickness_size: int,\n",
    "        intensity_size: int,\n",
    "        alpha: float,\n",
    "        num_bits: int,\n",
    "        *,\n",
    "        momentum: float = 0.05,\n",
    "        nonlinearity = torch.nn.LeakyReLU(),\n",
    "    ):\n",
    "        preprocess_transform = Transforms.ComposeTransform([\n",
    "            Transforms.AffineTransform(0., 1. / 2 ** num_bits),\n",
    "            Transforms.AffineTransform(alpha, (1 - alpha)),\n",
    "            Transforms.SigmoidTransform().inv,\n",
    "        ])\n",
    "        \n",
    "        f_X = ImageCouplingLayer(input_dim, hidden_dim, nonlinearity=nonlinearity)\n",
    "        norm1 = Transforms.BatchNorm(input_dim, momentum=momentum)\n",
    "        perm1 = Transforms.Permute(torch.randperm(input_dim))\n",
    "        \n",
    "        img_affine_coupling = ImageCouplingLayer(input_dim, hidden_dim, nonlinearity=nonlinearity)\n",
    "        norm2 = Transforms.BatchNorm(input_dim, momentum=momentum)\n",
    "        perm2 = Transforms.Permute(torch.randperm(input_dim))\n",
    "        \n",
    "        img_auto = ImageCouplingLayer(input_dim, hidden_dim, nonlinearity=nonlinearity)\n",
    "        norm3 = Transforms.BatchNorm(input_dim, momentum=momentum)\n",
    "        \n",
    "        # output_scaling_net = pyro.nn.DenseNN(2, [hidden_dim, hidden_dim], param_dims=[1, 1])\n",
    "        # output_scaling = ConditionalAffineTransform(output_scaling_net, event_dim=1)\n",
    "#         output_scaling = Transforms.ComposeTransform([\n",
    "#             Transforms.SigmoidTransform(),\n",
    "#             Transforms.AffineTransform(alpha, (1 - alpha)).inv,\n",
    "#             Transforms.AffineTransform(0., 1. / 2 ** num_bits).inv,\n",
    "#         ])\n",
    "        \n",
    "        super().__init__([\n",
    "            preprocess_transform,\n",
    "            f_X,\n",
    "            norm1,\n",
    "            perm1,\n",
    "            img_affine_coupling,\n",
    "            norm2,\n",
    "            perm2,\n",
    "            img_auto,\n",
    "            norm3,\n",
    "            #output_scaling,\n",
    "        ])\n",
    "        self.im_size = im_size\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # for parameter storage...\n",
    "        self.preprocess_transform = preprocess_transform\n",
    "        self.f_X = f_X\n",
    "        self.norm1 = norm1\n",
    "        self.perm1 = perm1\n",
    "        self.img_affine_coupling = img_affine_coupling\n",
    "        self.norm2 = norm2\n",
    "        self.perm2 = perm2\n",
    "        self.img_auto = img_auto\n",
    "        self.norm3 = norm3\n",
    "        #self.output_scaling = output_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSCM(PyroModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        thickness_transform: ThicknessTransform,\n",
    "        intensity_transform: IntensityTransform,\n",
    "        img_transform: ImageTransform,\n",
    "        *,\n",
    "        include_thickness: bool = True,\n",
    "        include_intensity: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.include_thickness = include_thickness\n",
    "        self.include_intensity = include_intensity\n",
    "        \n",
    "        self.thickness_transform = thickness_transform\n",
    "        self.intensity_transform = intensity_transform\n",
    "        self.img_transform = img_transform\n",
    "\n",
    "        # tensor sizes\n",
    "        self.thickness_size = self.thickness_transform.thickness_size\n",
    "        self.intensity_size = self.intensity_transform.intensity_size\n",
    "        self.im_size = self.img_transform.im_size\n",
    "        self.input_dim = self.im_size * self.im_size\n",
    "\n",
    "    @staticmethod\n",
    "    def StandardNormal(*event_shape: int, **kwargs) -> Union[dist.Independent, dist.Normal]:\n",
    "        return dist.Normal(\n",
    "            torch.zeros((), **kwargs),\n",
    "            torch.ones((), **kwargs),\n",
    "        ).expand(event_shape).to_event(len(event_shape))\n",
    "    \n",
    "    @staticmethod\n",
    "    def cond_dist(\n",
    "        transform: Union[Transforms.Transform, dist.conditional.ConditionalTransform],\n",
    "        U_dist: dist.Distribution,\n",
    "        *contexts: torch.Tensor\n",
    "    ) -> dist.Distribution:\n",
    "        if not contexts:\n",
    "            assert isinstance(transform, Transforms.Transform)\n",
    "            return dist.TransformedDistribution(U_dist, transform)\n",
    "        batch_shape = torch.broadcast_shapes(*(c.shape[:-1] for c in contexts))\n",
    "        context = torch.cat([c.expand(batch_shape + (-1,)) for c in contexts], dim=-1)\n",
    "        U_dist = U_dist.expand(torch.broadcast_shapes(batch_shape, U_dist.batch_shape))\n",
    "        return dist.ConditionalTransformedDistribution(U_dist, [transform]).condition(context=context)\n",
    "\n",
    "    def forward(self):\n",
    "        # Thickness:\n",
    "        UT_dist = self.StandardNormal(self.thickness_size, device=self.device)\n",
    "        T_dist = self.cond_dist(self.thickness_transform, UT_dist)\n",
    "        T = pyro.sample(\"T\", T_dist.mask(self.include_thickness))\n",
    "\n",
    "        # Intensity:\n",
    "        UI_dist = self.StandardNormal(self.intensity_size, device=self.device)\n",
    "        I_dist = self.cond_dist(self.intensity_transform, UI_dist, T)\n",
    "        I = pyro.sample(\"I\", I_dist.mask(self.include_intensity))\n",
    "\n",
    "        # Image:\n",
    "        UX_dist = self.StandardNormal(self.im_size ** 2, device=self.device)\n",
    "        X_dist = self.cond_dist(self.img_transform, UX_dist, T, I)\n",
    "        with pyro.poutine.scale(scale=1. / self.im_size ** 2):\n",
    "            X = pyro.sample(\"X\", X_dist)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"634pt\" height=\"553pt\"\n",
       " viewBox=\"0.00 0.00 634.00 553.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 549)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-549 630,-549 630,4 -4,4\"/>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-308.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M29.14,-290.32C35.17,-242.01 52.3,-104.72 59.62,-46.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.1,-46.45 60.87,-36.09 56.16,-45.58 63.1,-46.45\"/>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"99\" cy=\"-308.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\">I</text>\n",
       "</g>\n",
       "<!-- I&#45;&gt;X -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>I&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M96.86,-290.32C90.83,-242.01 73.7,-104.72 66.38,-46.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"69.84,-45.58 65.13,-36.09 62.9,-46.45 69.84,-45.58\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\">T ~ TransformedDistribution</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-514.8\" font-family=\"Times,serif\" font-size=\"14.00\">I ~ TransformedDistribution</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-499.8\" font-family=\"Times,serif\" font-size=\"14.00\">X ~ TransformedDistribution</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-484.8\" font-family=\"Times,serif\" font-size=\"14.00\">thickness_transform$$$0.unnormalized_widths : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-469.8\" font-family=\"Times,serif\" font-size=\"14.00\">thickness_transform$$$0.unnormalized_heights : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-454.8\" font-family=\"Times,serif\" font-size=\"14.00\">thickness_transform$$$0.unnormalized_derivatives : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-439.8\" font-family=\"Times,serif\" font-size=\"14.00\">thickness_transform$$$0.unnormalized_lambdas : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-424.8\" font-family=\"Times,serif\" font-size=\"14.00\">intensity_transform$$$intensity_nn.layers.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-409.8\" font-family=\"Times,serif\" font-size=\"14.00\">intensity_transform$$$intensity_nn.layers.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-394.8\" font-family=\"Times,serif\" font-size=\"14.00\">intensity_transform$$$intensity_nn.layers.1.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-379.8\" font-family=\"Times,serif\" font-size=\"14.00\">intensity_transform$$$intensity_nn.layers.1.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-364.8\" font-family=\"Times,serif\" font-size=\"14.00\">intensity_transform$$$intensity_nn.layers.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\">intensity_transform$$$intensity_nn.layers.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$f_X.nn.layers.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$f_X.nn.layers.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$f_X.nn.layers.1.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-289.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$f_X.nn.layers.1.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-274.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$norm1.gamma : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-259.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$norm1.beta : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-244.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$img_affine_coupling.nn.layers.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$img_affine_coupling.nn.layers.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-214.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$img_affine_coupling.nn.layers.1.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-199.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$img_affine_coupling.nn.layers.1.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-184.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$norm2.gamma : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-169.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$norm2.beta : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-154.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$img_auto.nn.layers.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-139.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$img_auto.nn.layers.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$img_auto.nn.layers.1.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-109.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$img_auto.nn.layers.1.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-94.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$norm3.gamma : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-79.8\" font-family=\"Times,serif\" font-size=\"14.00\">img_transform$$$norm3.beta : Real()</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fed6d8d0a00>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "# Thickness parameters\n",
    "thickness_size = 1\n",
    "thickness_flow_bias = thickness.log().mean()\n",
    "thickness_flow_weight = thickness.log().std()\n",
    "\n",
    "thickness_transform = ThicknessTransform(\n",
    "    thickness_size,\n",
    "    thickness_flow_weight[..., None].detach(),\n",
    "    thickness_flow_bias[..., None].detach()\n",
    ")\n",
    "\n",
    "# Intensity parameters\n",
    "intensity_size = 1\n",
    "intensity_hidden_dim = 5\n",
    "intensity_flow_bias = intensity.min()\n",
    "intensity_flow_weight = intensity.max() - intensity.min()\n",
    "\n",
    "intensity_transform = IntensityTransform(\n",
    "    intensity_size,\n",
    "    thickness_size,\n",
    "    [intensity_hidden_dim] * 2,\n",
    "    intensity_flow_weight[..., None].detach(),\n",
    "    intensity_flow_bias[..., None].detach()\n",
    ")\n",
    "\n",
    "# Image parameters\n",
    "im_size = images.shape[-1]\n",
    "input_dim = im_size ** 2\n",
    "img_hidden_dim = 10\n",
    "alpha = 0.05\n",
    "num_bits = 3  #* torch.log(torch.as_tensor(im_size)).item()\n",
    "\n",
    "img_transform = ImageTransform(\n",
    "    im_size,\n",
    "    input_dim,\n",
    "    img_hidden_dim,\n",
    "    thickness_size,\n",
    "    intensity_size,\n",
    "    alpha=alpha,\n",
    "    num_bits=num_bits,\n",
    "    nonlinearity=torch.nn.ReLU(),\n",
    ")\n",
    "\n",
    "scm = DeepSCM(thickness_transform, intensity_transform, img_transform, include_thickness=False, include_intensity=False)\n",
    "scm = scm.to(device=curr_device)\n",
    "pyro.render_model(scm, render_params=True, render_distributions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"166pt\" height=\"171pt\"\n",
       " viewBox=\"0.00 0.00 166.00 171.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 167)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-167 162,-167 162,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_data</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-155 150,-155 150,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"126\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"115\" cy=\"-129\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"115\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"79\" cy=\"-57\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"79\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.65,-111.76C102.29,-103.28 96.85,-92.71 91.96,-83.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"94.99,-81.44 87.3,-74.15 88.77,-84.64 94.99,-81.44\"/>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"43\" cy=\"-129\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"43\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">I</text>\n",
       "</g>\n",
       "<!-- I&#45;&gt;X -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>I&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M51.35,-111.76C55.71,-103.28 61.15,-92.71 66.04,-83.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"69.23,-84.64 70.7,-74.15 63.01,-81.44 69.23,-84.64\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fed6d6f6880>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConditionedDeepSCM(PyroModule):\n",
    "    def __init__(self, model: DeepSCM):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, t_obs, i_obs, x_obs):\n",
    "        with pyro.condition(data={\"X\": x_obs, \"T\": t_obs, \"I\": i_obs}), \\\n",
    "                pyro.poutine.scale(scale=1 / x_obs.shape[0]), \\\n",
    "                pyro.plate(\"data\", size=x_obs.shape[0], dim=-1):\n",
    "            return self.model()\n",
    "\n",
    "conditioned_model = ConditionedDeepSCM(scm)\n",
    "pyro.render_model(conditioned_model, model_args=(thickness[:5][..., None], intensity[:5][..., None], images[:5].reshape(-1, im_size*im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 0: 26.646177291870117\n",
      "Epoch 0, batch 100: 16.364002227783203\n",
      "Epoch 0, batch 200: 14.757111549377441\n",
      "Epoch 1, batch 0: 14.658082008361816\n",
      "Epoch 1, batch 100: 14.767887115478516\n",
      "Epoch 1, batch 200: 14.714831352233887\n",
      "Epoch 2, batch 0: 14.848043441772461\n",
      "Epoch 2, batch 100: 14.965642929077148\n",
      "Epoch 2, batch 200: 14.429343223571777\n",
      "Epoch 3, batch 0: 14.305461883544922\n",
      "Epoch 3, batch 100: 13.844612121582031\n",
      "Epoch 3, batch 200: 13.621527671813965\n",
      "Epoch 4, batch 0: 13.698339462280273\n",
      "Epoch 4, batch 100: 13.562868118286133\n",
      "Epoch 4, batch 200: 14.20223617553711\n",
      "Epoch 5, batch 0: 15.376070022583008\n",
      "Epoch 5, batch 100: 16.414485931396484\n",
      "Epoch 5, batch 200: 17.727069854736328\n",
      "Epoch 6, batch 0: 18.8656063079834\n",
      "Epoch 6, batch 100: 19.346153259277344\n",
      "Epoch 6, batch 200: 20.23540496826172\n",
      "Epoch 7, batch 0: 20.574909210205078\n",
      "Epoch 7, batch 100: 20.202390670776367\n",
      "Epoch 7, batch 200: 20.901287078857422\n",
      "Epoch 8, batch 0: 21.14459800720215\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12982/2155096043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_obs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/pyro/pyro/infer/elbo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifferentiable_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/pyro/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mdifferentiable_loss\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0msurrogate_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             loss_particle, surrogate_loss_particle = self._differentiable_loss_particle(\n\u001b[1;32m    123\u001b[0m                 \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/pyro/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/development/pyro/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         model_trace, guide_trace = get_importance_trace(\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;34m\"flat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_plate_nesting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         )\n",
      "\u001b[0;32m~/development/pyro/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mmodel_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_subsample_sites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mmodel_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mguide_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/pyro/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mcompute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"log_prob\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                         log_p = site[\"fn\"].log_prob(\n\u001b[0m\u001b[1;32m    231\u001b[0m                             \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/distributions/transformed_distribution.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mevent_dim\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_dim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             log_prob = log_prob - _sum_rightmost(transform.log_abs_det_jacobian(x, y),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/distributions/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/distributions/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inv_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_abs_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/distributions/transforms.py\u001b[0m in \u001b[0;36m_inv_call\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0my_old\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_x_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/pyro/pyro/distributions/transforms/affine_coupling.py\u001b[0m in \u001b[0;36m_inverse\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Now that we can split on an arbitrary dimension, we have do a bit of reshaping...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mlog_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_scale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_scale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/pyro/pyro/nn/dense_nn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, context)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/pyro/pyro/nn/dense_nn.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Shape the output, squeezing the parameter dimension if all ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "lr_decay = 0.95\n",
    "initial_lr = 1e-5\n",
    "adam_params = {\"lr\": initial_lr} #, \"betas\": (0.95, 0.999)}\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        thickness[..., None].detach(),\n",
    "        intensity[..., None].detach(),\n",
    "        images.reshape(-1, images.shape[-1] ** 2).detach(),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "guide = pyro.infer.autoguide.AutoDelta(conditioned_model)\n",
    "elbo = pyro.infer.Trace_ELBO()(conditioned_model, guide)\n",
    "optimizer = torch.optim.Adam(elbo.parameters(), **adam_params)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, lr_decay)\n",
    "\n",
    "#elbo = torch.jit.trace(elbo, next(iter(dataloader)))\n",
    "\n",
    "losses = []\n",
    "for j in range(num_epochs):\n",
    "    for i, (t_obs, i_obs, x_obs) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = elbo(t_obs, i_obs, x_obs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch {j}, batch {i}: {losses[-1]}\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fed6ca704c0>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(67382080.) tensor(-1.1638e+08)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 13.5, 13.5, -0.5)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictive = pyro.infer.Predictive(condition(scm, data = {\"T\": thickness[0:1][..., None], \"I\": intensity[0:1][..., None]}), guide=guide, num_samples=4)\n",
    "img = predictive()[\"X\"]\n",
    "print((img[0] - img[1]).max(), (img[0] - img[1]).min())\n",
    "\n",
    "fig = plt.figure()\n",
    "rows = 2\n",
    "columns = 2\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(torch.nn.functional.normalize(img[0].cpu().reshape((im_size, im_size))))\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(torch.nn.functional.normalize(img[1].cpu().reshape((im_size, im_size))))\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 3)\n",
    "plt.imshow(torch.nn.functional.normalize(img[2].cpu().reshape((im_size, im_size))))\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 4)\n",
    "plt.imshow(torch.nn.functional.normalize(img[3].cpu().reshape((im_size, im_size))))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: counterfactual data generation\n",
    "\n",
    "Next we ask a *counterfactual* question: given an observed digit $X$, what\n",
    "would the digit have been had $t$ been $t + 1$?\n",
    "\n",
    "To compute this quantity we would normally:\n",
    "   1. invert the model to find latent exogenous noise $u$\n",
    "   2. construct an intervened model\n",
    "   3. re-simulate the forward model on the $u$ [@pearl2011algorithmization].  \n",
    "\n",
    "However, we can equivalently\n",
    "represent this process with inference in a single, expanded\n",
    "probabilistic program containing two copies of every deterministic\n",
    "statement (a so-called \\\"twin network\\\" representation of\n",
    "counterfactuals, first described in Chapter 7 of [@pearl] and extended\n",
    "to the PPL setting in [@tavares_2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs = images[0]\n",
    "plt.imshow(x_obs.cpu().detach().reshape((im_size, im_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_scm_query(model: DeepSCM):\n",
    "    def query_model(x_obs):\n",
    "        with MultiWorldCounterfactual(dim=-1), \\\n",
    "            do(actions={'I': torch.tensor([190.0], device=model.device)}), \\\n",
    "                condition(data={\"X\": x_obs.reshape(-1, model.input_dim).to(device=model.device)}):\n",
    "                    return model()\n",
    "    return query_model\n",
    "\n",
    "cf_model = pyro.poutine.reparam(config={\"X_observed\": TransformInferReparam()})(\n",
    "    deep_scm_query(\n",
    "        scm\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title(\"Twin World Counterfactual Model\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "rows = 1\n",
    "columns = 2\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(cf_model(x_obs)[\"X\"][0][0].cpu().reshape((14, 14)))\n",
    "plt.title(\"Actual Model\")\n",
    "plt.axis('off')\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(torch.nn.functional.normalize(cf_model(x_obs)[\"X\"][0][1].cpu().reshape((14, 14))))\n",
    "plt.title(\"Intervened Model\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all counterfactuals, this estimand is not identified in general\n",
    "without further assumptions: learning parameters $\\theta$ that match\n",
    "observed data does not guarantee that the counterfactual distribution\n",
    "will match that of the true causal model. \n",
    "\n",
    "However, as discussed in the\n",
    "original paper [@pawlowski2020deep] in the context of modeling MRI\n",
    "images, there are a number of valid practical reasons one might wish to\n",
    "compute it anyway, such as explanation or expert evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"intensity_flow_bias\": intensity.min(),\n",
    "\"intensity_flow_weight\": (intensity.max() - intensity.min()),\n",
    "\"thickness_flow_bias\": thickness.log().mean(),\n",
    "\"thickness_flow_weight\": thickness.log().std()}\n",
    "\n",
    "class old_DeepSCM(PyroModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Thickness parameters\n",
    "        thickness_param = Transforms.Spline(1)\n",
    "        thickness_param.domain = constraints.positive\n",
    "        self.thickness_param = thickness_param\n",
    "        \n",
    "        # Intensity parameters\n",
    "        intensity_net = pyro.nn.ConditionalAutoRegressiveNN(1, 1, hidden_dims=[10], nonlinearity=torch.nn.Identity())\n",
    "        intensity_param = Transforms.ConditionalAffineAutoregressive(intensity_net)\n",
    "        intensity_param.codomain = constraints.positive\n",
    "        self.intensity_param = intensity_param\n",
    "        \n",
    "        # Image parameters\n",
    "        input_dim = im_size*im_size\n",
    "        nn_f_X = pyro.nn.ConditionalAutoRegressiveNN(input_dim, 2, [10*input_dim], nonlinearity=torch.nn.Identity())\n",
    "        f_X = Transforms.ConditionalAffineAutoregressive(nn_f_X, log_scale_min_clip=-1., log_scale_max_clip=5.)\n",
    "        f_X.domain = constraints.positive\n",
    "        self.f_X = f_X\n",
    "        norm = Transforms.BatchNorm(input_dim, momentum=0.05)\n",
    "        self.norm = norm\n",
    "        split_dim = input_dim // 2\n",
    "        param_dims = [input_dim-split_dim, input_dim-split_dim]\n",
    "#         auto_nn_0 = pyro.nn.AutoRegressiveNN(input_dim, [10*input_dim], nonlinearity=torch.nn.Identity())\n",
    "#         img_affine_coupling = Transforms.AffineAutoregressive(auto_nn_0, log_scale_min_clip=-1., log_scale_max_clip=5.)\n",
    "        nn_affine_coupling = pyro.nn.DenseNN(split_dim, [10*input_dim], param_dims, nonlinearity=torch.nn.LeakyReLU())\n",
    "        img_affine_coupling = Transforms.AffineCoupling(split_dim, nn_affine_coupling, log_scale_min_clip=-1., log_scale_max_clip=5.0)\n",
    "        self.img_affine_coupling = img_affine_coupling\n",
    "        \n",
    "#         auto_nn = pyro.nn.AutoRegressiveNN(input_dim, [10*input_dim], nonlinearity=torch.nn.Identity())\n",
    "#         img_auto = Transforms.AffineAutoregressive(auto_nn, log_scale_min_clip=-1., log_scale_max_clip=5.)\n",
    "        nn_affine_coupling_2 = pyro.nn.DenseNN(split_dim, [10*input_dim], param_dims, nonlinearity=torch.nn.LeakyReLU())\n",
    "        img_auto = Transforms.AffineCoupling(split_dim, nn_affine_coupling_2, log_scale_min_clip=-1., log_scale_max_clip=5.0)\n",
    "        self.img_auto = img_auto\n",
    "        norm_2 = Transforms.BatchNorm(input_dim, momentum=0.05)\n",
    "        self.norm_2 = norm_2\n",
    "    \n",
    "    def forward(self):\n",
    "        # Thickness:\n",
    "        UT = dist.Normal(torch.tensor(0., device=curr_device), torch.tensor(1., device=curr_device)).expand([1]).to_event(1)\n",
    "        thickness_flow_loc = params[\"thickness_flow_bias\"]\n",
    "        thickness_flow_scale = params[\"thickness_flow_weight\"]\n",
    "        thickness_flow_lognorm = Transforms.AffineTransform(loc=thickness_flow_loc, scale=thickness_flow_scale)\n",
    "        t_transforms = [\n",
    "            self.thickness_param,\n",
    "            thickness_flow_lognorm,\n",
    "            Transforms.ExpTransform()\n",
    "        ]\n",
    "        T = pyro.sample(\"T\", dist.TransformedDistribution(UT, t_transforms))\n",
    "        \n",
    "        # Intensity:\n",
    "        UI = dist.Normal(torch.tensor(0., device=curr_device), torch.tensor(1., device=curr_device)).expand([1]).to_event(1)\n",
    "        intensity_flow_loc = params[\"intensity_flow_bias\"]\n",
    "        intensity_flow_scale = params[\"intensity_flow_weight\"]\n",
    "        intensity_flow_norm = Transforms.AffineTransform(loc=intensity_flow_loc, scale=intensity_flow_scale)\n",
    "        intensity_tranforms = [\n",
    "            self.intensity_param,\n",
    "            Transforms.SigmoidTransform(), \n",
    "            intensity_flow_norm\n",
    "        ]\n",
    "#         T = T.expand(torch.broadcast_shapes(T.shape[:-1]) + T.shape[-1:])\n",
    "        I_ = dist.ConditionalTransformedDistribution(UI, intensity_tranforms)\n",
    "        I = I_.condition(context=T)\n",
    "        I = pyro.sample(\"I\", I)\n",
    "\n",
    "        \n",
    "        # Image:\n",
    "        UX = dist.Normal(torch.tensor(0., device=curr_device), torch.tensor(1., device=curr_device)).expand([im_size*im_size]).to_event(1)\n",
    "        \n",
    "        # Preprocessing\n",
    "        alpha = 0.001\n",
    "        num_bits = 2\n",
    "        s = Transforms.SigmoidTransform()\n",
    "        preprocess_transform = Transforms.ComposeTransform([\n",
    "            Transforms.AffineTransform(0., (1. / 2 ** num_bits)),\n",
    "            Transforms.AffineTransform(alpha, (1 - alpha)),\n",
    "            s.inv\n",
    "        ])\n",
    "    \n",
    "        batch_shape = torch.broadcast_shapes(T.shape[:-1], I.shape[:-1])\n",
    "        T = T.expand(batch_shape + T.shape[-1:])\n",
    "        I = I.expand(batch_shape + I.shape[-1:])\n",
    "        \n",
    "        assert T.shape == I.shape\n",
    "        \n",
    "        f_X = self.f_X.condition(context=torch.cat((T, I), dim=-1))\n",
    "        \n",
    "#         assert torch.cat((T, I), dim=-1).shape == (2, )\n",
    "        perm1 = Transforms.Permute(torch.randperm(im_size*im_size, device=curr_device))\n",
    "        perm2 = Transforms.Permute(torch.randperm(im_size*im_size, device=curr_device))\n",
    "        \n",
    "        h_X = dist.TransformedDistribution(UX, [preprocess_transform,\n",
    "                                                f_X,\n",
    "                                                self.norm,\n",
    "                                                perm1,\n",
    "                                                self.img_affine_coupling,\n",
    "                                                perm2,\n",
    "                                                self.img_auto,\n",
    "                                                self.norm_2\n",
    "                                               ])\n",
    "        with pyro.poutine.scale(scale=1/(im_size*im_size)):\n",
    "            X = pyro.sample(\"X\", h_X)\n",
    "        return X\n",
    "\n",
    "# scm = DeepSCM().to(device=curr_device)\n",
    "# print(list(dict(scm.named_parameters()).keys()))\n",
    "# print(pyro.poutine.trace(scm).get_trace().log_prob_sum())\n",
    "# pyro.render_model(scm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
