{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Deep structural causal model counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb off\n",
    "\n",
    "from typing import Dict, List, Optional, Tuple, Union, TypeVar\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import struct\n",
    "\n",
    "import torch\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.transforms as Transforms\n",
    "from pyro.nn import PyroParam, PyroSample, PyroModule\n",
    "\n",
    "import causal_pyro\n",
    "from causal_pyro.query.do_messenger import do\n",
    "from causal_pyro.counterfactual.handlers import Factual, MultiWorldCounterfactual\n",
    "from causal_pyro.reparam.soft_conditioning import TransformInferReparam\n",
    "\n",
    "pyro.clear_param_store()\n",
    "pyro.settings.set(module_local_params=True)\n",
    "pyro.set_rng_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Normalizing flows and counterfactuals\n",
    "\n",
    "Much of the causal inference literature has focused on relatively simple\n",
    "causal models with low dimensional data. In order to perform\n",
    "counterfactual reasoning in more complex domains with high dimensional\n",
    "data, Palowski et al. [@pawlowski2020deep] introduced *deep structural\n",
    "causal models* (Deep SCMs): SCMs with neural networks as the functional\n",
    "mechanisms between variables.\n",
    "\n",
    "Specifically, the neural networks are\n",
    "*normalizing flows*. A normalizing flow transforms a base probability\n",
    "distribution (often a simple distribution, such as a multivariate\n",
    "Gaussian) through a sequence of invertible transformations into a more\n",
    "complex distribution (such as a distribution over images). When used\n",
    "within a Deep SCM, the flow's base distribution is an exogenous noise\n",
    "variable, and its output is an endogenous variable.\n",
    "\n",
    "A salient property\n",
    "of normalizing flows is that computing the likelihood of data can be\n",
    "done both exactly and efficiently, and hence training a flow to model a\n",
    "data distribution through maximum likelihood is straightforward. In\n",
    "addition, the inverse of a normalizing flow can also typically be\n",
    "efficiently computed, which renders the abduction step of a\n",
    "counterfactual---inferring the posterior over exogenous variables given\n",
    "evidence---trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Morpho-MNIST\n",
    "\n",
    "We consider a synthetic dataset based on MNIST, where the image of each digit ($X$) depends on stroke thickness ($T$) and brightness ($I$) of the image and the thickness depends on brightness as well.\n",
    "\n",
    "We assume we know full causal structure (i.e., there are no unconfounded variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_idx(path: str) -> np.ndarray:\n",
    "    with (gzip.open(path, 'rb') if path.endswith('.gz') else open(path, 'rb')) as f:\n",
    "        idx_dtype, ndim = struct.unpack('BBBB', f.read(4))[2:]\n",
    "        shape = struct.unpack('>' + 'I' * ndim, f.read(4 * ndim))\n",
    "        buffer_length = int(np.prod(shape))\n",
    "        return np.frombuffer(f.read(buffer_length), dtype=np.uint8).reshape(shape).astype(np.float32)\n",
    "    \n",
    "DATA_PATH = os.path.join(os.getcwd(), \"../datasets/morphomnist/\")\n",
    "DIGIT = 5\n",
    "\n",
    "raw_images = load_idx(os.path.join(DATA_PATH, \"train-images-idx3-ubyte.gz\"))\n",
    "raw_images = skimage.measure.block_reduce(raw_images, block_size=(1, 2, 2))\n",
    "\n",
    "raw_labels = load_idx(os.path.join(DATA_PATH, \"train-labels-idx1-ubyte.gz\"))\n",
    "raw_metrics = pd.read_csv(os.path.join(DATA_PATH, \"train-morpho.csv\"), index_col= 'index')\n",
    "raw_thickness = np.array(raw_metrics[\"thickness\"])[..., None]\n",
    "raw_intensity = np.array(raw_metrics[\"intensity\"])[..., None]\n",
    "\n",
    "digit_indices = (raw_labels == DIGIT) if DIGIT is not None else (raw_labels == raw_labels)\n",
    "\n",
    "labels = torch.tensor(raw_labels[digit_indices]).to(torch.long).requires_grad_(False).detach()\n",
    "images = torch.tensor(raw_images[np.broadcast_to(digit_indices[..., None, None], raw_images.shape)].reshape(-1, 1, *raw_images.shape[-2:])).to(torch.float32).requires_grad_(False).detach()\n",
    "thickness = torch.tensor(raw_thickness[digit_indices]).to(torch.float32).requires_grad_(False).detach()\n",
    "intensity = torch.tensor(raw_intensity[digit_indices]).to(torch.float32).requires_grad_(False).detach()\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(4):\n",
    "    fig.add_subplot(2, 2, i + 1)\n",
    "    plt.imshow(images[i, 0])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: deep structural causal model\n",
    "\n",
    "The following code models morphological transformations of MNIST,\n",
    "defining a causal generative model over digits that contains endogenous\n",
    "variables to control the width $t$ and intensity $i$ of the stroke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantParamTransformModule(dist.torch_transform.TransformModule):\n",
    "    def __init__(self, transform: Transforms.Transform):\n",
    "        super().__init__()\n",
    "        self._transform = transform\n",
    "        self.domain = transform.domain\n",
    "        self.codomain = transform.codomain\n",
    "        self.bijective = transform.bijective\n",
    "        \n",
    "    @property\n",
    "    def sign(self):\n",
    "        return self._transform.sign\n",
    "        \n",
    "    def _call(self, x):\n",
    "        return self._transform(x)\n",
    "    \n",
    "    def _inverse(self, y):\n",
    "        return self._transform.inv(y)\n",
    "    \n",
    "    def log_abs_det_jacobian(self, x, y):\n",
    "        return self._transform.log_abs_det_jacobian(x, y)\n",
    "    \n",
    "    def with_cache(self, *args):\n",
    "        return self._transform.with_cache(*args)\n",
    "\n",
    "\n",
    "class ComposeTransformModule(Transforms.ComposeTransformModule):\n",
    "    def __init__(self, transforms: List[Transforms.Transform]):\n",
    "        super().__init__([\n",
    "            ConstantParamTransformModule(t) if not isinstance(t, torch.nn.Module) else t for t in transforms\n",
    "        ])\n",
    "        \n",
    "\n",
    "class InverseConditionalTransformModule(dist.conditional.ConditionalTransformModule):\n",
    "    \n",
    "    def __init__(self, transform: dist.conditional.ConditionalTransform):\n",
    "        super().__init__()\n",
    "        self._transform = transform\n",
    "    \n",
    "    @property\n",
    "    def inv(self) -> dist.conditional.ConditionalTransform:\n",
    "        return self._transform\n",
    "    \n",
    "    def condition(self, context: torch.Tensor):\n",
    "        return self._transform.condition(context).inv\n",
    "\n",
    "\n",
    "class ConditionalComposeTransformModule(dist.conditional.ConditionalTransformModule):\n",
    "    def __init__(self, transforms: List):\n",
    "        self.transforms = [\n",
    "            dist.conditional.ConstantConditionalTransform(t)\n",
    "            if not isinstance(t, dist.conditional.ConditionalTransform)\n",
    "            else t\n",
    "            for t in transforms\n",
    "        ]\n",
    "        super().__init__()\n",
    "        # for parameter storage...  TODO is this necessary?\n",
    "        self._transforms_module = torch.nn.ModuleList([t for t in transforms if isinstance(t, torch.nn.Module)])\n",
    "        \n",
    "    @property\n",
    "    def inv(self):\n",
    "        return InverseConditionalTransformModule(self)\n",
    "\n",
    "    def condition(self, context: torch.Tensor):\n",
    "        return ComposeTransformModule([t.condition(context) for t in self.transforms]).with_cache(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThicknessTransform(ComposeTransformModule):\n",
    "    def __init__(self, thickness_size: int, weight: float, bias: float):\n",
    "        self.thickness_size = thickness_size\n",
    "        super().__init__([\n",
    "            Transforms.Spline(thickness_size, bound=1.),\n",
    "            Transforms.AffineTransform(loc=bias, scale=weight),\n",
    "            Transforms.biject_to(dist.constraints.positive),\n",
    "        ])\n",
    "\n",
    "class IntensityTransform(ConditionalComposeTransformModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        intensity_size: int,\n",
    "        thickness_size: int,\n",
    "        hidden_dims: List[int],\n",
    "        weight: float,\n",
    "        bias: float,\n",
    "        *,\n",
    "        count_bins: int = 8,\n",
    "        nonlinearity=torch.nn.ReLU(),\n",
    "    ):\n",
    "        self.intensity_size = intensity_size\n",
    "        self.thickness_size = thickness_size\n",
    "        self.hidden_dims = hidden_dims\n",
    "        \n",
    "        intensity_nn = pyro.nn.DenseNN(\n",
    "            thickness_size,\n",
    "            hidden_dims,\n",
    "            param_dims=[\n",
    "                intensity_size * count_bins,\n",
    "                intensity_size * count_bins,\n",
    "                intensity_size * (count_bins - 1),\n",
    "                intensity_size * count_bins,\n",
    "            ],\n",
    "            nonlinearity=nonlinearity,\n",
    "        )\n",
    "        super().__init__([\n",
    "            Transforms.ConditionalSpline(intensity_nn, intensity_size, count_bins),\n",
    "            Transforms.AffineTransform(loc=bias, scale=weight),\n",
    "            Transforms.SoftplusTransform(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation for the images is somewhat involved. Much of the neural network architecture is taken from [this PyTorch tutorial] on normalizing flows, which readers are encouraged to peruse for further background on normalizing flows in general and this architecture in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatELU(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Activation function that applies ELU in both direction (inverted and plain).\n",
    "    Allows non-linearity while providing strong gradients for any input (important for final convolution)\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        return torch.cat([torch.nn.functional.elu(x), torch.nn.functional.elu(-x)], dim=-3)\n",
    "\n",
    "\n",
    "class LayerNormChannels(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, c_in: int, eps: float = 1e-5):\n",
    "        \"\"\"\n",
    "        This module applies layer norm across channels in an image.\n",
    "        Inputs:\n",
    "            c_in - Number of channels of the input\n",
    "            eps - Small constant to stabilize std\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.gamma = torch.nn.Parameter(torch.ones(1, c_in, 1, 1))\n",
    "        self.beta = torch.nn.Parameter(torch.zeros(1, c_in, 1, 1))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-3, keepdim=True)\n",
    "        var = x.var(dim=-3, unbiased=False, keepdim=True)\n",
    "        y = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        y = y * self.gamma + self.beta\n",
    "        return y\n",
    "\n",
    "\n",
    "class GatedConv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, c_in: int, c_hidden: int):\n",
    "        \"\"\"\n",
    "        This module applies a two-layer convolutional ResNet block with input gate\n",
    "        Inputs:\n",
    "            c_in - Number of channels of the input\n",
    "            c_hidden - Number of hidden dimensions we want to model (usually similar to c_in)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            ConcatELU(),\n",
    "            torch.nn.Conv2d(2*c_in, c_hidden, kernel_size=3, padding=1),\n",
    "            ConcatELU(),\n",
    "            torch.nn.Conv2d(2*c_hidden, 2*c_in, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        val, gate = out.chunk(2, dim=-3)\n",
    "        return x + val * torch.sigmoid(gate)\n",
    "\n",
    "\n",
    "class GatedConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, c_in: int, c_hidden: int, num_layers: int, eps: float = 1e-5):\n",
    "        \"\"\"\n",
    "        Module that summarizes the previous blocks to a full convolutional neural network.\n",
    "        Inputs:\n",
    "            c_in - Number of input channels\n",
    "            c_hidden - Number of hidden dimensions to use within the network\n",
    "            c_out - Number of output channels.\n",
    "            num_layers - Number of gated ResNet blocks to apply\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        c_out = 2 * c_in\n",
    "        layers = []\n",
    "        layers += [torch.nn.Conv2d(c_in, c_hidden, kernel_size=3, padding=1)]\n",
    "        for layer_index in range(num_layers):\n",
    "            layers += [\n",
    "                GatedConv(c_hidden, c_hidden),\n",
    "                LayerNormChannels(c_hidden, eps=eps)\n",
    "            ]\n",
    "        layers += [\n",
    "            ConcatELU(),\n",
    "            torch.nn.Conv2d(2*c_hidden, c_out, kernel_size=3, padding=1)\n",
    "        ]\n",
    "        self.nn = torch.nn.Sequential(*layers)\n",
    "\n",
    "        self.nn[-1].weight.data.zero_()\n",
    "        self.nn[-1].bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)\n",
    "\n",
    "\n",
    "class MaskedAffineCoupling(dist.torch_transform.TransformModule):\n",
    "    bijective = True\n",
    "    domain = dist.constraints.independent(dist.constraints.real, 3)\n",
    "    codomain = dist.constraints.independent(dist.constraints.real, 3)\n",
    "\n",
    "    def __init__(self, network: torch.nn.Module, mask: torch.Tensor, c_in: int, h: int, w: int):\n",
    "        \"\"\"\n",
    "        Coupling layer inside a normalizing flow.\n",
    "        Inputs:\n",
    "            network - A PyTorch nn.Module constituting the deep neural network for mu and sigma.\n",
    "                      Output shape should be twice the channel size as the input.\n",
    "            mask - Binary mask (0 or 1) where 0 denotes that the element should be transformed,\n",
    "                   while 1 means the latent will be used as input to the NN.\n",
    "            c_in - Number of input channels\n",
    "        \"\"\"\n",
    "        self.c_in = c_in\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.scaling_factor = torch.nn.Parameter(torch.zeros(c_in, device=mask.device))\n",
    "        self.register_buffer('mask', mask)\n",
    "        \n",
    "    def with_cache(self, *args):\n",
    "        return self\n",
    "        \n",
    "    def _net(self, x):\n",
    "        s, t = self.network(x * self.mask).chunk(2, dim=-3)\n",
    "\n",
    "        # Stabilize scaling output\n",
    "        s_fac = self.scaling_factor.exp().view(1, -1, 1, 1)\n",
    "        s = torch.tanh(s / s_fac) * s_fac\n",
    "\n",
    "        # Mask outputs (only transform parts where self.mask == 0)\n",
    "        return s * (1 - self.mask), t * (1 - self.mask)\n",
    "        \n",
    "    def log_abs_det_jacobian(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        s, _ = self._net(x)\n",
    "        return s.sum(dim=[-1,-2,-3])\n",
    "    \n",
    "    def _inverse(self, y: torch.Tensor) -> torch.Tensor:\n",
    "        s, t = self._net(y)\n",
    "        return (y * torch.exp(-s)) - t\n",
    "    \n",
    "    def _call(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        s, t = self._net(x)\n",
    "        return (x + t) * torch.exp(s)\n",
    "\n",
    "\n",
    "class ImageTransform(ConditionalComposeTransformModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        im_size: int,\n",
    "        input_channels: int,\n",
    "        thickness_size: int,\n",
    "        intensity_size: int,\n",
    "        num_blocks: int,\n",
    "        layers_per_block: int,\n",
    "        hidden_channels: int,\n",
    "        *,\n",
    "        num_cond_blocks: int = 1,\n",
    "        alpha: float = 1e-5,\n",
    "        bn_momentum: float = 0.05,\n",
    "        ln_momentum: float = 1e-5,\n",
    "        nonlinearity = torch.nn.ReLU(),\n",
    "    ):\n",
    "        self.im_size = im_size\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_blocks = num_blocks\n",
    "        self.layers_per_block = layers_per_block\n",
    "        \n",
    "        self.num_cond_blocks = num_cond_blocks\n",
    "        \n",
    "        self.flat_input_size = input_channels * im_size * im_size\n",
    "        \n",
    "        layers = []\n",
    "\n",
    "        # dequantization\n",
    "        layers += [\n",
    "            Transforms.IndependentTransform(\n",
    "                Transforms.ComposeTransform([\n",
    "                    Transforms.AffineTransform(0., 1. / 256),\n",
    "                    Transforms.AffineTransform(alpha, (1 - alpha)),\n",
    "                    Transforms.SigmoidTransform().inv,\n",
    "            ]), 3)\n",
    "        ]\n",
    "        \n",
    "        # image flow with convolutional blocks\n",
    "        for i in range(num_blocks):\n",
    "            layers += [\n",
    "                MaskedAffineCoupling(\n",
    "                    GatedConvNet(input_channels, hidden_channels, layers_per_block, eps=ln_momentum),\n",
    "                    self.create_checkerboard_mask(im_size, im_size, invert=(i%2==1)),\n",
    "                    input_channels,\n",
    "                    im_size,\n",
    "                    im_size,\n",
    "                ),\n",
    "            ]\n",
    "            \n",
    "        # conditioning on context\n",
    "        layers += [Transforms.ReshapeTransform((input_channels, im_size, im_size), (self.flat_input_size,))]\n",
    "        for i in range(self.num_cond_blocks):\n",
    "            layers += [\n",
    "                Transforms.ConditionalAffineAutoregressive(\n",
    "                    pyro.nn.ConditionalAutoRegressiveNN(\n",
    "                        self.flat_input_size,\n",
    "                        thickness_size + intensity_size,\n",
    "                        [2 * self.flat_input_size] * 2,\n",
    "                        nonlinearity=nonlinearity,\n",
    "                        skip_connections=True,\n",
    "                    ),\n",
    "                ),\n",
    "            ]  \n",
    "        layers += [Transforms.ReshapeTransform((self.flat_input_size,), (input_channels, im_size, im_size))]\n",
    "        \n",
    "        super().__init__(layers)\n",
    "            \n",
    "    @staticmethod\n",
    "    def create_checkerboard_mask(h: int, w: int, invert=False):\n",
    "        x, y = torch.arange(h, dtype=torch.int32), torch.arange(w, dtype=torch.int32)\n",
    "        xx, yy = torch.meshgrid(x, y, indexing='ij')\n",
    "        mask = torch.fmod(xx + yy, 2).to(torch.float32).view(1, 1, h, w)\n",
    "        return mask if not invert else (1. - mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of these components defined, we can finally define the high-level causal model we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"333pt\" height=\"205pt\"\n",
       " viewBox=\"0.00 0.00 332.50 205.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 201)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-201 328.5,-201 328.5,4 -4,4\"/>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"54\" cy=\"-170.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-166.8\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">I</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;I -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M48.27,-152.85C44.73,-142.55 40.1,-129.09 36.07,-117.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"39.28,-115.94 32.72,-107.62 32.66,-118.22 39.28,-115.94\"/>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;X -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>T&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.15,-152.61C59.28,-140.29 61.9,-123.17 63,-108 64.16,-92.04 64.34,-87.94 63,-72 62.28,-63.5 60.93,-54.31 59.49,-46.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.91,-45.29 57.65,-36.09 56.03,-46.56 62.91,-45.29\"/>\n",
       "</g>\n",
       "<!-- I&#45;&gt;X -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>I&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"107.5\" y=\"-181.8\" font-family=\"Times,serif\" font-size=\"14.00\">T ~ TransformedDistribution</text>\n",
       "<text text-anchor=\"start\" x=\"107.5\" y=\"-166.8\" font-family=\"Times,serif\" font-size=\"14.00\">I ~ TransformedDistribution</text>\n",
       "<text text-anchor=\"start\" x=\"107.5\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">X ~ TransformedDistribution</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f17381a7f70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeepSCM(PyroModule):\n",
    "    \n",
    "    thickness_support = dist.constraints.positive\n",
    "    intensity_support = dist.constraints.positive\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        thickness_transform: ThicknessTransform,\n",
    "        intensity_transform: IntensityTransform,\n",
    "        image_transform: ImageTransform,\n",
    "        *,\n",
    "        include_thickness: bool = True,\n",
    "        include_intensity: bool = True,\n",
    "        include_image: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # mechanisms\n",
    "        self.thickness_transform = thickness_transform\n",
    "        self.intensity_transform = intensity_transform\n",
    "        self.image_transform = image_transform.inv  # generative direction is inverse\n",
    "        \n",
    "        # base dist buffers\n",
    "        self.register_buffer(\"base_loc\", torch.tensor(0.))\n",
    "        self.register_buffer(\"base_scale\", torch.tensor(1.))\n",
    "\n",
    "        # tensor sizes\n",
    "        self.thickness_size = self.thickness_transform.thickness_size\n",
    "        self.intensity_size = self.intensity_transform.intensity_size\n",
    "        self.im_size = self.image_transform._transform.im_size\n",
    "        self.im_input_channels = self.image_transform._transform.input_channels\n",
    "        \n",
    "        # prior masks\n",
    "        self.include_thickness = include_thickness\n",
    "        self.include_intensity = include_intensity\n",
    "        self.include_image = include_image\n",
    "\n",
    "    def StandardNormal(self, *event_shape: int) -> Union[dist.Independent, dist.Normal]:\n",
    "        return dist.Normal(self.base_loc, self.base_scale).expand(event_shape).to_event(len(event_shape))\n",
    "    \n",
    "    @staticmethod\n",
    "    def cond_dist(\n",
    "        transform: Union[Transforms.Transform, dist.conditional.ConditionalTransform],\n",
    "        U_dist: dist.Distribution,\n",
    "        *contexts: torch.Tensor\n",
    "    ) -> dist.Distribution:\n",
    "        if contexts:\n",
    "            batch_shape = torch.broadcast_shapes(*(c.shape[:-1] for c in contexts))\n",
    "            U_dist = U_dist.expand(torch.broadcast_shapes(batch_shape, U_dist.batch_shape))\n",
    "            context = torch.cat([c.expand(batch_shape + (-1,)) for c in contexts], dim=-1)\n",
    "            transform = transform.condition(context)\n",
    "        return dist.TransformedDistribution(U_dist, transform)\n",
    "\n",
    "    def forward(self):\n",
    "        # Thickness:\n",
    "        UT_dist = self.StandardNormal(self.thickness_size)\n",
    "        T_dist = self.cond_dist(self.thickness_transform, UT_dist)\n",
    "        T = pyro.sample(\"T\", T_dist.mask(self.include_thickness))\n",
    "        T_unconstrained = Transforms.biject_to(self.thickness_support).inv(T)\n",
    "\n",
    "        # Intensity:\n",
    "        UI_dist = self.StandardNormal(self.intensity_size)\n",
    "        I_dist = self.cond_dist(self.intensity_transform, UI_dist, T_unconstrained)\n",
    "        I = pyro.sample(\"I\", I_dist.mask(self.include_intensity))\n",
    "        I_unconstrained = Transforms.biject_to(self.intensity_support).inv(I)\n",
    "\n",
    "        # Image:\n",
    "        UX_dist = self.StandardNormal(self.im_input_channels, self.im_size, self.im_size)\n",
    "        X_dist = self.cond_dist(self.image_transform, UX_dist, T_unconstrained, I_unconstrained)\n",
    "        X = pyro.sample(\"X\", X_dist.mask(self.include_image))\n",
    "\n",
    "        return X\n",
    "\n",
    "thickness_transform = ThicknessTransform(\n",
    "    thickness.shape[-1],\n",
    "    weight=thickness.log().mean().detach().item(),\n",
    "    bias=thickness.log().std().detach().item(),\n",
    ")\n",
    "\n",
    "intensity_transform = IntensityTransform(\n",
    "    intensity.shape[-1],\n",
    "    thickness.shape[-1],\n",
    "    hidden_dims=[16],\n",
    "    weight=intensity.min().detach().item(),\n",
    "    bias=(intensity.max() - intensity.min()).detach().item(),\n",
    "    nonlinearity=torch.nn.ELU(),\n",
    "    count_bins=4,\n",
    ")\n",
    "\n",
    "image_transform = ImageTransform(\n",
    "    images.shape[-1],\n",
    "    1,\n",
    "    thickness.shape[-1],\n",
    "    intensity.shape[-1],\n",
    "    num_blocks=8,\n",
    "    layers_per_block=3,\n",
    "    hidden_channels=16,\n",
    "    nonlinearity=torch.nn.ELU(),\n",
    ")\n",
    "\n",
    "model = DeepSCM(thickness_transform, intensity_transform, image_transform, include_thickness=True, include_intensity=True, include_image=True)\n",
    "pyro.render_model(model, render_distributions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"358pt\" height=\"252pt\"\n",
       " viewBox=\"0.00 0.00 357.50 251.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 247.5)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-247.5 353.5,-247.5 353.5,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_observations</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-235.5 116,-235.5 116,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"62\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">observations</text>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"61\" cy=\"-209.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"61\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"43\" cy=\"-129\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"43\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">I</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;I -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.09,-191.47C54.78,-181.39 51.8,-168.39 49.18,-156.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.54,-155.96 46.9,-147 45.72,-157.53 52.54,-155.96\"/>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"62\" cy=\"-57\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"62\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;X -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>T&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.29,-191.82C71.54,-179.61 76.77,-162.53 79,-147 81.27,-131.16 81.47,-126.81 79,-111 77.62,-102.18 75.02,-92.82 72.26,-84.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75.51,-83.13 68.89,-74.86 68.9,-85.45 75.51,-83.13\"/>\n",
       "</g>\n",
       "<!-- I&#45;&gt;X -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>I&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.6,-111.05C49.75,-103.14 52.35,-93.54 54.76,-84.69\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"58.2,-85.36 57.44,-74.79 51.45,-83.52 58.2,-85.36\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">T ~ TransformedDistribution</text>\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\">I ~ TransformedDistribution</text>\n",
       "<text text-anchor=\"start\" x=\"132.5\" y=\"-190.8\" font-family=\"Times,serif\" font-size=\"14.00\">X ~ TransformedDistribution</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f1740730250>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConditionedDeepSCM(PyroModule):\n",
    "    def __init__(self, model: DeepSCM):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, t_obs, i_obs, x_obs):\n",
    "        with pyro.condition(data={\"X\": x_obs, \"T\": t_obs, \"I\": i_obs}), \\\n",
    "                pyro.poutine.scale(scale=1 / x_obs.shape[0]), \\\n",
    "                pyro.plate(\"observations\", size=x_obs.shape[0], dim=-1):\n",
    "            return self.model()\n",
    "\n",
    "conditioned_model = ConditionedDeepSCM(model)\n",
    "pyro.render_model(conditioned_model, model_args=(thickness[:2], intensity[:2], images[:2]), render_distributions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type               | Params\n",
      "---------------------------------------------\n",
      "0 | model | ConditionedDeepSCM | 607 K \n",
      "1 | guide | AutoDelta          | 0     \n",
      "2 | elbo  | ELBOModule         | 607 K \n",
      "---------------------------------------------\n",
      "607 K     Trainable params\n",
      "0         Non-trainable params\n",
      "607 K     Total params\n",
      "2.428     Total estimated model params size (MB)\n",
      "/home/eli/development/causal_pyro/.env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1595: PossibleUserWarning: The number of training batches (43) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c43f5fb7df241dc904f8e6e61ca053c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "adam_params = {\"lr\": 1e-3}\n",
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "\n",
    "class LightningSVI(pl.LightningModule):\n",
    "    def __init__(self, model: ConditionedDeepSCM, guide: PyroModule, elbo: pyro.infer.ELBO, optim_params: dict):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.guide = guide\n",
    "        self.elbo = elbo(self.model, self.guide)\n",
    "        self._optim_params = optim_params\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        t_obs, i_obs, x_obs = batch\n",
    "        x_obs = x_obs + torch.rand_like(x_obs)\n",
    "        loss = self.elbo(t_obs, i_obs, x_obs)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam([\n",
    "#             dict(params=self.model.model.thickness_transform.parameters()),\n",
    "#             dict(params=self.model.model.intensity_transform.parameters()),\n",
    "#             dict(params=self.guide.parameters()),\n",
    "#             dict(params=self.model.model.image_transform.parameters(), lr=self._optim_params[\"lr\"] / self.model.model.im_size ** 2)\n",
    "#         ], **self._optim_params)\n",
    "        optimizer = torch.optim.Adam(self.elbo.parameters(), **self._optim_params)\n",
    "        return optimizer\n",
    "        \n",
    "guide = pyro.infer.autoguide.AutoDelta(conditioned_model)\n",
    "elbo = pyro.infer.Trace_ELBO()\n",
    "lightning_svi = LightningSVI(conditioned_model, guide, elbo, adam_params)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(thickness, intensity, images),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    gradient_clip_val=1.0,\n",
    "    accelerator=\"gpu\",\n",
    "    default_root_dir=os.path.join(\"./lightning_logs/deepscm_ckpt\", \"deepscm_joint\"),\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(save_weights_only=True, mode=\"min\", monitor=\"train_loss\"),\n",
    "    ],\n",
    ")\n",
    "trainer.fit(model=lightning_svi, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictive = pyro.infer.Predictive(model, guide=guide, num_samples=1000, parallel=True).to(device=torch.device(\"cpu\"))\n",
    "samples = predictive()\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.hist(thickness[..., 0], bins=50, alpha=0.5, density=True, label=\"observed\")\n",
    "plt.hist(samples[\"T\"][..., 0], bins=50, alpha=0.5, density=True, label=\"sampled\")\n",
    "plt.title(\"Thickness\")\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.hist(intensity[..., 0], bins=50, alpha=0.5, density=True, label=\"observed\")\n",
    "plt.hist(samples[\"I\"][..., 0], bins=50, alpha=0.5, density=True, label=\"sampled\")\n",
    "plt.title(\"Intensity\")\n",
    "plt.legend()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"Images\")\n",
    "plt.axis(\"off\")\n",
    "for i in range(2 * 2):\n",
    "    fig.add_subplot(2, 2, i + 1)\n",
    "    plt.imshow(samples[\"X\"][i].squeeze())\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: counterfactual data generation\n",
    "\n",
    "Next we ask a *counterfactual* question: given an observed digit $X$, what\n",
    "would the digit have been had $t$ been $t + 1$?\n",
    "\n",
    "To compute this quantity we would normally:\n",
    "   1. invert the model to find latent exogenous noise $u$\n",
    "   2. construct an intervened model\n",
    "   3. re-simulate the forward model on the $u$ [@pearl2011algorithmization].  \n",
    "\n",
    "However, we can equivalently\n",
    "represent this process with inference in a single, expanded\n",
    "probabilistic program containing two copies of every deterministic\n",
    "statement (a so-called \\\"twin network\\\" representation of\n",
    "counterfactuals, first described in Chapter 7 of [@pearl] and extended\n",
    "to the PPL setting in [@tavares_2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CounterfactualDeepSCM(PyroModule):\n",
    "    def __init__(self, model: DeepSCM):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x_obs: torch.Tensor, i_act: torch.Tensor):\n",
    "        with MultiWorldCounterfactual(dim=-2), \\\n",
    "                plate(\"observations\", size=x_obs.shape[0], dim=-1), \\\n",
    "                do(actions={\"I\": i_act}), \\\n",
    "                condition(data={\"X\": x_obs}):\n",
    "            return model()\n",
    "\n",
    "cf_model = CounterfactualDeepSCM(model)\n",
    "pyro.render_model(cf_model, model_args=(images[:1], intensity[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all counterfactuals, this estimand is not identified in general\n",
    "without further assumptions: learning parameters $\\theta$ that match\n",
    "observed data does not guarantee that the counterfactual distribution\n",
    "will match that of the true causal model. \n",
    "\n",
    "However, as discussed in the\n",
    "original paper [@pawlowski2020deep] in the context of modeling MRI\n",
    "images, there are a number of valid practical reasons one might wish to\n",
    "compute it anyway, such as explanation or expert evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "2bdfcdbd368c30fa36f32c37bcc33f6323158b752539e151107ac7b028e21443"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
