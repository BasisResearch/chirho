{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Model Transformation-based Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union, TypeVar\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample, PyroParam\n",
    "from pyro.contrib.autoname import scope\n",
    "from pyro.poutine import condition, reparam\n",
    "\n",
    "import causal_pyro\n",
    "from causal_pyro.query.do_messenger import do\n",
    "from causal_pyro.counterfactual.handlers import Factual, MultiWorldCounterfactual, TwinWorldCounterfactual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider two types of counterfactuals; one of the form:\n",
    "\n",
    "    Given $X$ was observed as $x$, what would $Y$ have been had $X$ been $x'$,\n",
    "\n",
    "and another of the form\n",
    "\n",
    "    Given $X$ was observed as $x$ and $Y$ was observed as $y$, what would $Y$ have been had $X$ been $x'$?.\n",
    "\n",
    "The former type is potentially identifiable without an SCM using\n",
    "observational or interventional data [@pearl; @richardson2013single].\n",
    "*Effect of treatment on the treated* is a useful example of the former\n",
    "that is widely useful.\n",
    "\n",
    "The second type of counterfactual is called a\n",
    "\"twin-world counterfactual\\\" because it predicts $Y$ in a world where we\n",
    "*do* $X=x'$ conditional on information from a world where $X=x$ already\n",
    "caused $Y=y$ [@pearl].\n",
    "\n",
    "Structural counterfactuals enable interesting\n",
    "counterfactual quantities such as probability of necessity and\n",
    "sufficiency, and have interesting applications in generative\n",
    "explanations as well as quantifying regret, blame, and responsibility in\n",
    "decision theory and agent modeling.\n",
    "\n",
    "However, inferring twin-world counterfactual counterfactuals require an explicit SCM.\n",
    "Further, if the SCM is misspecified, it can produce incorrect counterfactual inferences\n",
    "even if it is a perfect statistical fit for observational and\n",
    "interventional data.\n",
    "\n",
    "How do we do select the \"right\\\" surrogate SCM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Reparameterization Tricks\n",
    "\n",
    "A tempting approach is to simply convert a directed generative model\n",
    "into an SCM using \"reparameterization tricks\\\"\n",
    "[@kingma2015variational; @jang2016categorical], methods that shunt\n",
    "randomness to *exogenous* variables to facilitate back-propagation\n",
    "through *endogenous* variables.\n",
    "\n",
    "The problem is that in general a causal generative model can yield\n",
    "different SCMs depending on how it is reparameterized, and the different\n",
    "SCMs might yield different counterfactual inferences. To illustrate,\n",
    "consider the following causal generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"134pt\" height=\"116pt\"\n viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\n<!-- x_1 -->\n<g id=\"node1\" class=\"node\">\n<title>x_1</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x_1</text>\n</g>\n<!-- y -->\n<g id=\"node3\" class=\"node\">\n<title>y</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n</g>\n<!-- x_1&#45;&gt;y -->\n<g id=\"edge1\" class=\"edge\">\n<title>x_1&#45;&gt;y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64\"/>\n</g>\n<!-- x_2 -->\n<g id=\"node2\" class=\"node\">\n<title>x_2</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x_2</text>\n</g>\n<!-- x_2&#45;&gt;y -->\n<g id=\"edge2\" class=\"edge\">\n<title>x_2&#45;&gt;y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f26c48fdd30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cgmodel(theta):\n",
    "    x_1 = pyro.sample(\"x_1\", dist.Bernoulli(0.5))\n",
    "    x_2 = pyro.sample(\"x_2\", dist.Bernoulli(0.5))\n",
    "    y = pyro.sample(\"y\", dist.Categorical(probs=theta[..., x_1.long(), x_2.long(), :]))\n",
    "    return y\n",
    "\n",
    "pyro.render_model(cgmodel, model_args=(torch.rand(2, 2, 2),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wished to \"reparameterize\\\" this into an SCM. To accomplish\n",
    "this, we shunt the randomness in the Bernoulli and categorical\n",
    "distributions to *exogenous* variables $N_{X_1}$, $N_{X_2}$, and $N_{Y}$\n",
    "through deterministic transformations $f_{X_1}$, $f_{X_2}$, and $f_{Y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_dgp():\n",
    "    n_x1 = pyro.sample(\"n_x1\", dist.Bernoulli(0.5))\n",
    "    n_x2 = pyro.sample(\"n_x2\", dist.Bernoulli(0.5))\n",
    "    n_y = pyro.sample(\"n_y\", dist.Categorical(logits=torch.ones(3)))\n",
    "    x_1 = f_X1(n_x1)\n",
    "    x_2 = f_X2(n_x2)\n",
    "    y = f_Y(x_1, x_2, n_y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, $f_{Y,a}$ and $f_{Y,b}$ are two different alternatives for\n",
    "$f_Y$ above that would each yield the same observational and\n",
    "interventional distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_Ya(x_1, x_2, n_y):\n",
    "    if x_1 != x_2:\n",
    "        if n_y == 0:\n",
    "            return x_1\n",
    "        else:\n",
    "            return x_2\n",
    "    else:\n",
    "        return n_y\n",
    "\n",
    "def f_Yb(x_1, x_2, n_y):\n",
    "    if x_1 != x_2:\n",
    "        if n_y == 0:\n",
    "            return x_1\n",
    "        else:\n",
    "            return x_2\n",
    "    else:\n",
    "        return 2-n_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "However, they would produce different counterfactual inferences. Suppose\n",
    "we conditioned scmmodel on the observation\n",
    "$\\{X_1 = 1, X_2 = 0, Y = 0 \\}$ and we are interested in the\n",
    "counterfactual query \"what would $Y$ have been if $X_1$ had been 0?\" \n",
    "\n",
    "In this degenerate case, we would infer a point value $N_Y = 0$. When we\n",
    "re-execute the model after setting both $N_Y$ and $X_1$ to 0, $f_{Y,a}$\n",
    "would yield 0, and $f_{Y,b}$ would yield 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monotonicity as Inductive Bias\n",
    "\n",
    "One solution is to limit ourselves to reparameterizations where key\n",
    "counterfactual queries are identifiable from observational and\n",
    "interventional data. [@pearl] named this constraint *monotonicity* and\n",
    "defined it for the binary outcome case. [@oberst2019counterfactual]\n",
    "extended the definition to categorical variables and showed that the\n",
    "Gumbel-softmax reparameterization trick ([@jang2016categorical])\n",
    "produced a monotonic SCM. [@ness2019integrating] extended the definition\n",
    "to binomial and Poisson outcomes and provided a probabilistic\n",
    "programming implementation.\n",
    "\n",
    "In machine learning, we often talk about the inductive bias of a model,\n",
    "such as how convolutional neural networks with max-pooling favor\n",
    "translation invariance. In contrast to inductive biases implicit in\n",
    "architecture, a strength of the probabilistic programming community is\n",
    "that we favor explicit inductive biases, i.e. constraining inference\n",
    "with domain knowledge built into the model.\n",
    "\n",
    "Monotonicity is an example of an explicit inductive bias. To illustrate,\n",
    "suppose Anne has the flu but still goes to work. Jon is exposed to Anne\n",
    "($X_1 = 1$) and and a few days later, Jon got the flu ($Y = 1)$. Jon is\n",
    "may or may not have had exposure to the flu on the bus ($X_2$), which is\n",
    "unknown. Given knowledge that Jon was exposed to Anne and he got the\n",
    "flu, what are the chances he wouldn't have gotten the flu if Anne had\n",
    "stayed home ($P(Y_{X_1=0}=0|X_1=1, Y=1)$)?\n",
    "\n",
    "Given sufficient data, we could build a good probabilistic model of\n",
    "$P(X_1, X_2, Y)$. Theoretically we know that if we were to apply a\n",
    "monotonic reparameterization (specifically with respect to $X_1$ and\n",
    "$Y$) to an SCM then we could use that model to infer the above\n",
    "counterfactual. How would we know if monotonicity is a valid\n",
    "counterfactual inductive bias in this case?\n",
    "\n",
    "We can answer with a simple thought experiment. Is it conceivable that\n",
    "some strange group of coworkers could have the flu, but then *be cured\n",
    "by* exposure to Anne? That would be a case of non-monotonicity. In this\n",
    "case that is implausible, and thus monotonicity is a safe assumption.\n",
    "\n",
    "Suppose, however, that $X_1$ were email promotion and $Y$ were sales,\n",
    "and we were interested in if John would have bought a product if he\n",
    "hadn't seen an email promotion. In our thought experiment we would ask\n",
    "it is plausible for some people who intended to buy a product to be\n",
    "annoyed enough by an email promotion that they then decided not to buy.\n",
    "In that case, monotonicity would not be a safe assumption, since\n",
    "non-monotonicity is plausible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b21c0b9d110a5a3043a375d760ca16faf426bffca7e8cbf746b0d228ab037b0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
