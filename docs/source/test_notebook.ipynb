{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "import pytest\n",
    "import torch\n",
    "\n",
    "from chirho.counterfactual.handlers.counterfactual import MultiWorldCounterfactual\n",
    "from chirho.explainable.handlers import ExtractSupports\n",
    "from chirho.explainable.handlers.components import undo_split\n",
    "from chirho.explainable.handlers.explanation import SearchForExplanation, SplitSubsets\n",
    "from chirho.explainable.handlers.preemptions import Preemptions\n",
    "from chirho.indexed.ops import IndexSet, gather\n",
    "from chirho.observational.handlers.condition import condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_independent():\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5))\n",
    "    Y = pyro.sample(\"Y\", dist.Bernoulli(0.5))\n",
    "    return {\"X\": X, \"Y\": Y}\n",
    "\n",
    "def model_connected():\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5))\n",
    "    Y = pyro.sample(\"Y\", dist.Bernoulli(X))\n",
    "    return {\"X\": X, \"Y\": Y}\n",
    "\n",
    "with ExtractSupports() as supports_independent:\n",
    "    model_independent()\n",
    "\n",
    "with ExtractSupports() as supports_connected:\n",
    "    model_connected()\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc_ind:\n",
    "    with SearchForExplanation(\n",
    "        supports=supports_independent.supports,\n",
    "        antecedents={\"X\": torch.tensor(1.0)},\n",
    "        consequents={\"Y\": torch.tensor(1.0)},\n",
    "        witnesses={},\n",
    "        alternatives={\"X\": torch.tensor(0.0)},\n",
    "        antecedent_bias=-0.5,\n",
    "        consequent_scale=0,\n",
    "    ):\n",
    "        with pyro.plate(\"sample\", size=3):\n",
    "            with pyro.poutine.trace() as trace_independent:\n",
    "                model_independent()\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc_con:\n",
    "    with SearchForExplanation(\n",
    "        supports=supports_connected.supports,\n",
    "        antecedents={\"X\": torch.tensor(1.0)},\n",
    "        consequents={\"Y\": torch.tensor(1.0)},\n",
    "        witnesses={},\n",
    "        alternatives={\"X\": torch.tensor(0.0)},\n",
    "        antecedent_bias=-0.5,\n",
    "        consequent_scale=0,\n",
    "    ):\n",
    "        with pyro.plate(\"sample\", size=3):\n",
    "            with pyro.poutine.trace() as trace_connected:\n",
    "                model_connected()\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc_rev:\n",
    "    with SearchForExplanation(\n",
    "        supports=supports_connected.supports,\n",
    "        antecedents={\"Y\": torch.tensor(1.0)},\n",
    "        consequents={\"X\": torch.tensor(1.0)},\n",
    "        witnesses={},\n",
    "        alternatives={\"Y\": torch.tensor(0.0)},\n",
    "        antecedent_bias=-0.5,\n",
    "        consequent_scale=0,\n",
    "    ):\n",
    "        with pyro.plate(\"sample\", size=3):\n",
    "            with pyro.poutine.trace() as trace_reverse:\n",
    "                model_connected()\n",
    "\n",
    "trace_connected.trace.compute_log_prob()\n",
    "trace_independent.trace.compute_log_prob()\n",
    "trace_reverse.trace.compute_log_prob()\n",
    "\n",
    "Y_values_ind = trace_independent.trace.nodes[\"Y\"][\"value\"]\n",
    "\n",
    "log_probs_ind = trace_independent.trace.nodes[\"__cause____consequent_Y\"][\n",
    "    \"fn\"\n",
    "].log_factor\n",
    "\n",
    "with mwc_ind:\n",
    "    nec_log_probs_ind = gather(log_probs_ind, IndexSet(**{\"X\": {1}}))\n",
    "    suff_log_probs_ind = gather(log_probs_ind, IndexSet(**{\"X\": {2}}))\n",
    "\n",
    "if torch.any(Y_values_ind == 1.0):\n",
    "    assert nec_log_probs_ind.sum().exp() == 0.0\n",
    "else:\n",
    "    assert nec_log_probs_ind.sum().exp() == 1.0\n",
    "\n",
    "assert torch.all(log_probs_ind.sum().exp() == 0)\n",
    "\n",
    "if torch.any(Y_values_ind == 0.0):\n",
    "    assert suff_log_probs_ind.sum().exp() == 0.0\n",
    "else:\n",
    "    assert suff_log_probs_ind.sum().exp() == 1.0\n",
    "\n",
    "assert torch.all(\n",
    "    trace_connected.trace.nodes[\"__cause____consequent_Y\"][\"fn\"].log_factor.sum()\n",
    "    == 0\n",
    ")\n",
    "\n",
    "log_probs_rev = trace_reverse.trace.nodes[\"__cause____consequent_X\"][\"fn\"].log_factor\n",
    "with mwc_rev:\n",
    "    nec_log_probs_rev=gather(log_probs_rev, IndexSet(**{\"Y\": {1}}))\n",
    "    suff_log_probs_rev=gather(log_probs_rev, IndexSet(**{\"Y\": {2}}))\n",
    "\n",
    "X_values_rev = trace_reverse.trace.nodes[\"X\"][\"value\"]\n",
    "if torch.any(X_values_rev == 1.0):\n",
    "    assert (\n",
    "        nec_log_probs_rev\n",
    "        .sum()\n",
    "        .exp()\n",
    "        == 0.0\n",
    "    )\n",
    "else:\n",
    "    assert (\n",
    "        nec_log_probs_rev\n",
    "        .sum()\n",
    "        .exp()\n",
    "        == 1.0\n",
    "    )\n",
    "\n",
    "if torch.any(X_values_rev == 0.0):\n",
    "    assert (\n",
    "        suff_log_probs_rev\n",
    "        .sum()\n",
    "        .exp()\n",
    "        == 0.0\n",
    "    )\n",
    "else:\n",
    "    assert (\n",
    "        suff_log_probs_rev\n",
    "        .sum()\n",
    "        .exp()\n",
    "        == 1.0\n",
    "    )\n",
    "\n",
    "assert torch.all(\n",
    "    log_probs_rev.sum()\n",
    "    .exp()\n",
    "    == 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "import pytest\n",
    "import torch\n",
    "\n",
    "from chirho.counterfactual.handlers.counterfactual import MultiWorldCounterfactual\n",
    "from chirho.counterfactual.ops import split\n",
    "from chirho.explainable.handlers import random_intervention, sufficiency_intervention\n",
    "from chirho.explainable.handlers.components import (  # consequent_eq_neq,\n",
    "    ExtractSupports,\n",
    "    consequent_eq,\n",
    "    consequent_eq_neq,\n",
    "    consequent_neq,\n",
    "    undo_split,\n",
    ")\n",
    "from chirho.explainable.internals import uniform_proposal\n",
    "from chirho.explainable.ops import preempt\n",
    "from chirho.indexed.ops import IndexSet, gather, indices_of\n",
    "from chirho.interventional.handlers import do\n",
    "from chirho.interventional.ops import intervene\n",
    "from chirho.observational.handlers.condition import Factors\n",
    "\n",
    "SUPPORT_CASES = [\n",
    "    pyro.distributions.constraints.real,\n",
    "    pyro.distributions.constraints.boolean,\n",
    "    pyro.distributions.constraints.positive,\n",
    "    pyro.distributions.constraints.interval(0, 10),\n",
    "    pyro.distributions.constraints.interval(-5, 5),\n",
    "    pyro.distributions.constraints.integer_interval(0, 2),\n",
    "    pyro.distributions.constraints.integer_interval(0, 100),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.1000), <function sufficiency_intervention.<locals>._sufficiency_intervention at 0x1290a5ab0>)\n",
      "torch.Size([3, 1, 1, 1, 1])\n",
      "torch.Size([3, 1, 1, 1, 1])\n",
      "consequent_shape IndexSet({'w': {0, 1, 2}})\n",
      "torch.Size([1, 1, 1, 1, 1])\n",
      "torch.Size([1, 1, 1, 1, 1])\n",
      "tensor([[[[[1.3788]]]]])\n",
      "tensor([[[[[0.0001]]]]])\n",
      "tensor([[[[[1.3788]]]]])\n",
      "torch.Size([1, 1, 1, 1, 1])\n",
      "torch.Size([1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# \"event_shape\", [(), (3,), (3, 2)]\n",
    "# \"plate_size\", [4, 50, 200]\n",
    "\n",
    "event_shape = ()\n",
    "\n",
    "factors = {\n",
    "    \"consequent\": consequent_eq_neq(\n",
    "        support=constraints.independent(constraints.real, len(event_shape)),\n",
    "        # proposed_consequent=torch.Tensor([0.01], event_shape),\n",
    "        proposed_consequent=torch.tensor(0.01).expand(event_shape),\n",
    "        antecedents=[\"w\"],\n",
    "    )\n",
    "}\n",
    "\n",
    "# w_initial = (\n",
    "#     dist.Normal(0, 0.1).expand(event_shape).to_event(len(event_shape)).sample()\n",
    "# )\n",
    "\n",
    "# @Factors(factors=factors)\n",
    "def model_ce():\n",
    "    w = pyro.sample(\"w\", dist.Normal(0, 0.1).expand(event_shape).to_event(len(event_shape)))\n",
    "    consequent = pyro.deterministic(\"consequent\", w * torch.tensor(0.1), event_dim = len(event_shape))\n",
    "    assert w.shape == consequent.shape\n",
    "    print(w.shape)\n",
    "    print(consequent.shape)\n",
    "\n",
    "antecedents = {\n",
    "    \"w\": (\n",
    "        torch.tensor(0.1).expand(event_shape),\n",
    "        sufficiency_intervention(\n",
    "            constraints.independent(constraints.real, len(event_shape)), [\"w\"]\n",
    "        ),\n",
    "    )\n",
    "}\n",
    "\n",
    "print(antecedents[\"w\"])\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc_ce:\n",
    "    with do(actions=antecedents):\n",
    "        with Factors(factors=factors):\n",
    "            with pyro.poutine.trace() as trace_ce:\n",
    "                model_ce()\n",
    "\n",
    "nd = trace_ce.trace.nodes\n",
    "trace_ce.trace.compute_log_prob()\n",
    "with mwc_ce:\n",
    "    eq_neq_log_probs_fact = gather(\n",
    "        nd[\"__factor_consequent\"][\"fn\"].log_factor,\n",
    "        IndexSet(**{\"w\": {0}}, event_dim=len(event_shape)),\n",
    "    )\n",
    "    eq_neq_log_probs_nec = gather(\n",
    "        nd[\"__factor_consequent\"][\"fn\"].log_factor,\n",
    "        IndexSet(**{\"w\": {1}}, event_dim=len(event_shape)),\n",
    "    )\n",
    "    print(\"consequent_shape\", indices_of(nd[\"consequent\"][\"value\"].shape))\n",
    "    consequent_suff = gather(\n",
    "        nd[\"consequent\"][\"value\"], IndexSet(**{\"w\": {2}}, event_dim=len(event_shape))\n",
    "    )\n",
    "    eq_neq_log_probs_suff = gather(\n",
    "        nd[\"__factor_consequent\"][\"fn\"].log_factor, IndexSet(**{\"w\": {2}}), event_dim=len(event_shape)\n",
    "    )\n",
    "\n",
    "    print(eq_neq_log_probs_suff.shape)\n",
    "    print(eq_neq_log_probs_fact.shape)\n",
    "    print(eq_neq_log_probs_suff)\n",
    "    print(consequent_suff)\n",
    "    print(dist.Normal(0.0, 0.1).log_prob(consequent_suff - torch.tensor(0.01)))\n",
    "\n",
    "    print(eq_neq_log_probs_nec.shape)\n",
    "    print(consequent_suff.shape)\n",
    "\n",
    "    assert torch.equal(\n",
    "        eq_neq_log_probs_fact, torch.zeros(eq_neq_log_probs_fact.shape)\n",
    "    )\n",
    "    assert eq_neq_log_probs_nec.shape == consequent_suff.shape\n",
    "    assert torch.equal(\n",
    "        eq_neq_log_probs_suff,\n",
    "        dist.Normal(0.0, 0.1).log_prob(consequent_suff - torch.tensor(0.01)),\n",
    "    )\n",
    "    assert eq_neq_log_probs_nec.sum().exp() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.1000, 0.1000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(0.1).expand(event_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
