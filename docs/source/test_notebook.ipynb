{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "import pytest\n",
    "import torch\n",
    "\n",
    "from chirho.counterfactual.handlers.counterfactual import MultiWorldCounterfactual\n",
    "from chirho.explainable.handlers import ExtractSupports\n",
    "from chirho.explainable.handlers.components import undo_split\n",
    "from chirho.explainable.handlers.explanation import SearchForExplanation, SplitSubsets\n",
    "from chirho.explainable.handlers.preemptions import Preemptions\n",
    "from chirho.indexed.ops import IndexSet, gather\n",
    "from chirho.observational.handlers.condition import condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_independent():\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5))\n",
    "    Y = pyro.sample(\"Y\", dist.Bernoulli(0.5))\n",
    "    return {\"X\": X, \"Y\": Y}\n",
    "\n",
    "def model_connected():\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5))\n",
    "    Y = pyro.sample(\"Y\", dist.Bernoulli(X))\n",
    "    return {\"X\": X, \"Y\": Y}\n",
    "\n",
    "with ExtractSupports() as supports_independent:\n",
    "    model_independent()\n",
    "\n",
    "with ExtractSupports() as supports_connected:\n",
    "    model_connected()\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc_ind:\n",
    "    with SearchForExplanation(\n",
    "        supports=supports_independent.supports,\n",
    "        antecedents={\"X\": torch.tensor(1.0)},\n",
    "        consequents={\"Y\": torch.tensor(1.0)},\n",
    "        witnesses={},\n",
    "        alternatives={\"X\": torch.tensor(0.0)},\n",
    "        antecedent_bias=-0.5,\n",
    "        consequent_scale=0,\n",
    "    ):\n",
    "        with pyro.plate(\"sample\", size=3):\n",
    "            with pyro.poutine.trace() as trace_independent:\n",
    "                model_independent()\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc_con:\n",
    "    with SearchForExplanation(\n",
    "        supports=supports_connected.supports,\n",
    "        antecedents={\"X\": torch.tensor(1.0)},\n",
    "        consequents={\"Y\": torch.tensor(1.0)},\n",
    "        witnesses={},\n",
    "        alternatives={\"X\": torch.tensor(0.0)},\n",
    "        antecedent_bias=-0.5,\n",
    "        consequent_scale=0,\n",
    "    ):\n",
    "        with pyro.plate(\"sample\", size=3):\n",
    "            with pyro.poutine.trace() as trace_connected:\n",
    "                model_connected()\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc_rev:\n",
    "    with SearchForExplanation(\n",
    "        supports=supports_connected.supports,\n",
    "        antecedents={\"Y\": torch.tensor(1.0)},\n",
    "        consequents={\"X\": torch.tensor(1.0)},\n",
    "        witnesses={},\n",
    "        alternatives={\"Y\": torch.tensor(0.0)},\n",
    "        antecedent_bias=-0.5,\n",
    "        consequent_scale=0,\n",
    "    ):\n",
    "        with pyro.plate(\"sample\", size=3):\n",
    "            with pyro.poutine.trace() as trace_reverse:\n",
    "                model_connected()\n",
    "\n",
    "trace_connected.trace.compute_log_prob()\n",
    "trace_independent.trace.compute_log_prob()\n",
    "trace_reverse.trace.compute_log_prob()\n",
    "\n",
    "Y_values_ind = trace_independent.trace.nodes[\"Y\"][\"value\"]\n",
    "\n",
    "log_probs_ind = trace_independent.trace.nodes[\"__cause____consequent_Y\"][\n",
    "    \"fn\"\n",
    "].log_factor\n",
    "\n",
    "with mwc_ind:\n",
    "    nec_log_probs_ind = gather(log_probs_ind, IndexSet(**{\"X\": {1}}))\n",
    "    suff_log_probs_ind = gather(log_probs_ind, IndexSet(**{\"X\": {2}}))\n",
    "\n",
    "if torch.any(Y_values_ind == 1.0):\n",
    "    assert nec_log_probs_ind.sum().exp() == 0.0\n",
    "else:\n",
    "    assert nec_log_probs_ind.sum().exp() == 1.0\n",
    "\n",
    "assert torch.all(log_probs_ind.sum().exp() == 0)\n",
    "\n",
    "if torch.any(Y_values_ind == 0.0):\n",
    "    assert suff_log_probs_ind.sum().exp() == 0.0\n",
    "else:\n",
    "    assert suff_log_probs_ind.sum().exp() == 1.0\n",
    "\n",
    "assert torch.all(\n",
    "    trace_connected.trace.nodes[\"__cause____consequent_Y\"][\"fn\"].log_factor.sum()\n",
    "    == 0\n",
    ")\n",
    "\n",
    "log_probs_rev = trace_reverse.trace.nodes[\"__cause____consequent_X\"][\"fn\"].log_factor\n",
    "with mwc_rev:\n",
    "    nec_log_probs_rev=gather(log_probs_rev, IndexSet(**{\"Y\": {1}}))\n",
    "    suff_log_probs_rev=gather(log_probs_rev, IndexSet(**{\"Y\": {2}}))\n",
    "\n",
    "X_values_rev = trace_reverse.trace.nodes[\"X\"][\"value\"]\n",
    "if torch.any(X_values_rev == 1.0):\n",
    "    assert (\n",
    "        nec_log_probs_rev\n",
    "        .sum()\n",
    "        .exp()\n",
    "        == 0.0\n",
    "    )\n",
    "else:\n",
    "    assert (\n",
    "        nec_log_probs_rev\n",
    "        .sum()\n",
    "        .exp()\n",
    "        == 1.0\n",
    "    )\n",
    "\n",
    "if torch.any(X_values_rev == 0.0):\n",
    "    assert (\n",
    "        suff_log_probs_rev\n",
    "        .sum()\n",
    "        .exp()\n",
    "        == 0.0\n",
    "    )\n",
    "else:\n",
    "    assert (\n",
    "        suff_log_probs_rev\n",
    "        .sum()\n",
    "        .exp()\n",
    "        == 1.0\n",
    "    )\n",
    "\n",
    "assert torch.all(\n",
    "    log_probs_rev.sum()\n",
    "    .exp()\n",
    "    == 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "import pytest\n",
    "import torch\n",
    "\n",
    "from chirho.counterfactual.handlers.counterfactual import MultiWorldCounterfactual\n",
    "from chirho.counterfactual.ops import split\n",
    "from chirho.explainable.handlers import random_intervention, sufficiency_intervention\n",
    "from chirho.explainable.handlers.components import (  # consequent_eq_neq,\n",
    "    ExtractSupports,\n",
    "    consequent_eq,\n",
    "    consequent_eq_neq,\n",
    "    consequent_neq,\n",
    "    undo_split,\n",
    ")\n",
    "from chirho.explainable.internals import uniform_proposal\n",
    "from chirho.explainable.ops import preempt\n",
    "from chirho.indexed.ops import IndexSet, gather, indices_of\n",
    "from chirho.interventional.handlers import do\n",
    "from chirho.interventional.ops import intervene\n",
    "from chirho.observational.handlers.condition import Factors\n",
    "\n",
    "SUPPORT_CASES = [\n",
    "    pyro.distributions.constraints.real,\n",
    "    pyro.distributions.constraints.boolean,\n",
    "    pyro.distributions.constraints.positive,\n",
    "    pyro.distributions.constraints.interval(0, 10),\n",
    "    pyro.distributions.constraints.interval(-5, 5),\n",
    "    pyro.distributions.constraints.integer_interval(0, 2),\n",
    "    pyro.distributions.constraints.integer_interval(0, 100),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.1000, 0.1000],\n",
      "        [0.1000, 0.1000],\n",
      "        [0.1000, 0.1000]]), <function sufficiency_intervention.<locals>._sufficiency_intervention at 0x117471090>)\n",
      "torch.Size([3, 200, 1, 1, 1, 3, 2])\n",
      "torch.Size([3, 200, 1, 1, 1, 3, 2])\n",
      "torch.Size([3, 200, 1, 1, 1])\n",
      "IndexSet({'w': {0, 1, 2}})\n",
      "torch.Size([1, 200, 1, 1, 1])\n",
      "tensor([8.2223, 8.2605, 8.2698, 8.2651, 8.2059, 8.2255, 8.2357, 8.2512, 8.2502,\n",
      "        8.2338, 8.2549, 8.2659, 8.2067, 8.2874, 8.2593, 8.2138, 8.2624, 8.2358,\n",
      "        8.2504, 8.2528, 8.2693, 8.2498, 8.2330, 8.2527, 8.2848, 8.2551, 8.2632,\n",
      "        8.2444, 8.2634, 8.2679, 8.2186, 8.2608, 8.2668, 8.2299, 8.2255, 8.2452,\n",
      "        8.2578, 8.2228, 8.2077, 8.2434, 8.2753, 8.2417, 8.2302, 8.2745, 8.2561,\n",
      "        8.2670, 8.2126, 8.1921, 8.2064, 8.2119, 8.2018, 8.2624, 8.2835, 8.2358,\n",
      "        8.2572, 8.2236, 8.2636, 8.2805, 8.2737, 8.2429, 8.2934, 8.2900, 8.2351,\n",
      "        8.2445, 8.2874, 8.2032, 8.2813, 8.2572, 8.2831, 8.1908, 8.2640, 8.2324,\n",
      "        8.2388, 8.2196, 8.1854, 8.2169, 8.2461, 8.2587, 8.2622, 8.2779, 8.1432,\n",
      "        8.2537, 8.2587, 8.2255, 8.2579, 8.2912, 8.2718, 8.2197, 8.2741, 8.1804,\n",
      "        8.2239, 8.2054, 8.2258, 8.2436, 8.2472, 8.2409, 8.2440, 8.2629, 8.2243,\n",
      "        8.1986, 8.2141, 8.2541, 8.2466, 8.2300, 8.2669, 8.2352, 8.1884, 8.2629,\n",
      "        8.2058, 8.2178, 8.2016, 8.2505, 8.2392, 8.2789, 8.2030, 8.2791, 8.2193,\n",
      "        8.2642, 8.2685, 8.2620, 8.2207, 8.2672, 8.2679, 8.2307, 8.2637, 8.2569,\n",
      "        8.1876, 8.2197, 8.2292, 8.2649, 8.2795, 8.2729, 8.2724, 8.2431, 8.2749,\n",
      "        8.2591, 8.2754, 8.2746, 8.2614, 8.2827, 8.2503, 8.2111, 8.2960, 8.2382,\n",
      "        8.2530, 8.2601, 8.2914, 8.1994, 8.2730, 8.2401, 8.2144, 8.2753, 8.1479,\n",
      "        8.2504, 8.2285, 8.2278, 8.2596, 8.2714, 8.1941, 8.2225, 8.2368, 8.2446,\n",
      "        8.2508, 8.2507, 8.2706, 8.2435, 8.2760, 8.2226, 8.2589, 8.2172, 8.2673,\n",
      "        8.2001, 8.2097, 8.2031, 8.2222, 8.2703, 8.2663, 8.2525, 8.2092, 8.2163,\n",
      "        8.2552, 8.2340, 8.1277, 8.2174, 8.2297, 8.2459, 8.2473, 8.2527, 8.2096,\n",
      "        8.2376, 8.2717, 8.1996, 8.2468, 8.2721, 8.2439, 8.2273, 8.2801, 8.1984,\n",
      "        8.2448, 8.2416])\n",
      "tensor([[[[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]],\n",
      "\n",
      "\n",
      "         [[[-inf]]]]])\n",
      "tensor(1648.5946)\n",
      "tensor([[[[[8.2223]]],\n",
      "\n",
      "\n",
      "         [[[8.2605]]],\n",
      "\n",
      "\n",
      "         [[[8.2698]]],\n",
      "\n",
      "\n",
      "         [[[8.2651]]],\n",
      "\n",
      "\n",
      "         [[[8.2059]]],\n",
      "\n",
      "\n",
      "         [[[8.2255]]],\n",
      "\n",
      "\n",
      "         [[[8.2357]]],\n",
      "\n",
      "\n",
      "         [[[8.2512]]],\n",
      "\n",
      "\n",
      "         [[[8.2502]]],\n",
      "\n",
      "\n",
      "         [[[8.2338]]],\n",
      "\n",
      "\n",
      "         [[[8.2549]]],\n",
      "\n",
      "\n",
      "         [[[8.2659]]],\n",
      "\n",
      "\n",
      "         [[[8.2067]]],\n",
      "\n",
      "\n",
      "         [[[8.2874]]],\n",
      "\n",
      "\n",
      "         [[[8.2593]]],\n",
      "\n",
      "\n",
      "         [[[8.2138]]],\n",
      "\n",
      "\n",
      "         [[[8.2624]]],\n",
      "\n",
      "\n",
      "         [[[8.2358]]],\n",
      "\n",
      "\n",
      "         [[[8.2504]]],\n",
      "\n",
      "\n",
      "         [[[8.2528]]],\n",
      "\n",
      "\n",
      "         [[[8.2693]]],\n",
      "\n",
      "\n",
      "         [[[8.2498]]],\n",
      "\n",
      "\n",
      "         [[[8.2330]]],\n",
      "\n",
      "\n",
      "         [[[8.2527]]],\n",
      "\n",
      "\n",
      "         [[[8.2848]]],\n",
      "\n",
      "\n",
      "         [[[8.2551]]],\n",
      "\n",
      "\n",
      "         [[[8.2632]]],\n",
      "\n",
      "\n",
      "         [[[8.2444]]],\n",
      "\n",
      "\n",
      "         [[[8.2634]]],\n",
      "\n",
      "\n",
      "         [[[8.2679]]],\n",
      "\n",
      "\n",
      "         [[[8.2186]]],\n",
      "\n",
      "\n",
      "         [[[8.2608]]],\n",
      "\n",
      "\n",
      "         [[[8.2668]]],\n",
      "\n",
      "\n",
      "         [[[8.2299]]],\n",
      "\n",
      "\n",
      "         [[[8.2255]]],\n",
      "\n",
      "\n",
      "         [[[8.2452]]],\n",
      "\n",
      "\n",
      "         [[[8.2578]]],\n",
      "\n",
      "\n",
      "         [[[8.2228]]],\n",
      "\n",
      "\n",
      "         [[[8.2077]]],\n",
      "\n",
      "\n",
      "         [[[8.2434]]],\n",
      "\n",
      "\n",
      "         [[[8.2753]]],\n",
      "\n",
      "\n",
      "         [[[8.2417]]],\n",
      "\n",
      "\n",
      "         [[[8.2302]]],\n",
      "\n",
      "\n",
      "         [[[8.2745]]],\n",
      "\n",
      "\n",
      "         [[[8.2561]]],\n",
      "\n",
      "\n",
      "         [[[8.2670]]],\n",
      "\n",
      "\n",
      "         [[[8.2126]]],\n",
      "\n",
      "\n",
      "         [[[8.1921]]],\n",
      "\n",
      "\n",
      "         [[[8.2064]]],\n",
      "\n",
      "\n",
      "         [[[8.2119]]],\n",
      "\n",
      "\n",
      "         [[[8.2018]]],\n",
      "\n",
      "\n",
      "         [[[8.2624]]],\n",
      "\n",
      "\n",
      "         [[[8.2835]]],\n",
      "\n",
      "\n",
      "         [[[8.2358]]],\n",
      "\n",
      "\n",
      "         [[[8.2572]]],\n",
      "\n",
      "\n",
      "         [[[8.2236]]],\n",
      "\n",
      "\n",
      "         [[[8.2636]]],\n",
      "\n",
      "\n",
      "         [[[8.2805]]],\n",
      "\n",
      "\n",
      "         [[[8.2737]]],\n",
      "\n",
      "\n",
      "         [[[8.2429]]],\n",
      "\n",
      "\n",
      "         [[[8.2934]]],\n",
      "\n",
      "\n",
      "         [[[8.2900]]],\n",
      "\n",
      "\n",
      "         [[[8.2351]]],\n",
      "\n",
      "\n",
      "         [[[8.2445]]],\n",
      "\n",
      "\n",
      "         [[[8.2874]]],\n",
      "\n",
      "\n",
      "         [[[8.2032]]],\n",
      "\n",
      "\n",
      "         [[[8.2813]]],\n",
      "\n",
      "\n",
      "         [[[8.2572]]],\n",
      "\n",
      "\n",
      "         [[[8.2831]]],\n",
      "\n",
      "\n",
      "         [[[8.1908]]],\n",
      "\n",
      "\n",
      "         [[[8.2640]]],\n",
      "\n",
      "\n",
      "         [[[8.2324]]],\n",
      "\n",
      "\n",
      "         [[[8.2388]]],\n",
      "\n",
      "\n",
      "         [[[8.2196]]],\n",
      "\n",
      "\n",
      "         [[[8.1854]]],\n",
      "\n",
      "\n",
      "         [[[8.2169]]],\n",
      "\n",
      "\n",
      "         [[[8.2461]]],\n",
      "\n",
      "\n",
      "         [[[8.2587]]],\n",
      "\n",
      "\n",
      "         [[[8.2622]]],\n",
      "\n",
      "\n",
      "         [[[8.2779]]],\n",
      "\n",
      "\n",
      "         [[[8.1432]]],\n",
      "\n",
      "\n",
      "         [[[8.2537]]],\n",
      "\n",
      "\n",
      "         [[[8.2587]]],\n",
      "\n",
      "\n",
      "         [[[8.2255]]],\n",
      "\n",
      "\n",
      "         [[[8.2579]]],\n",
      "\n",
      "\n",
      "         [[[8.2912]]],\n",
      "\n",
      "\n",
      "         [[[8.2718]]],\n",
      "\n",
      "\n",
      "         [[[8.2197]]],\n",
      "\n",
      "\n",
      "         [[[8.2741]]],\n",
      "\n",
      "\n",
      "         [[[8.1804]]],\n",
      "\n",
      "\n",
      "         [[[8.2239]]],\n",
      "\n",
      "\n",
      "         [[[8.2054]]],\n",
      "\n",
      "\n",
      "         [[[8.2258]]],\n",
      "\n",
      "\n",
      "         [[[8.2436]]],\n",
      "\n",
      "\n",
      "         [[[8.2472]]],\n",
      "\n",
      "\n",
      "         [[[8.2409]]],\n",
      "\n",
      "\n",
      "         [[[8.2440]]],\n",
      "\n",
      "\n",
      "         [[[8.2629]]],\n",
      "\n",
      "\n",
      "         [[[8.2243]]],\n",
      "\n",
      "\n",
      "         [[[8.1986]]],\n",
      "\n",
      "\n",
      "         [[[8.2141]]],\n",
      "\n",
      "\n",
      "         [[[8.2541]]],\n",
      "\n",
      "\n",
      "         [[[8.2466]]],\n",
      "\n",
      "\n",
      "         [[[8.2300]]],\n",
      "\n",
      "\n",
      "         [[[8.2669]]],\n",
      "\n",
      "\n",
      "         [[[8.2352]]],\n",
      "\n",
      "\n",
      "         [[[8.1884]]],\n",
      "\n",
      "\n",
      "         [[[8.2629]]],\n",
      "\n",
      "\n",
      "         [[[8.2058]]],\n",
      "\n",
      "\n",
      "         [[[8.2178]]],\n",
      "\n",
      "\n",
      "         [[[8.2016]]],\n",
      "\n",
      "\n",
      "         [[[8.2505]]],\n",
      "\n",
      "\n",
      "         [[[8.2392]]],\n",
      "\n",
      "\n",
      "         [[[8.2789]]],\n",
      "\n",
      "\n",
      "         [[[8.2030]]],\n",
      "\n",
      "\n",
      "         [[[8.2791]]],\n",
      "\n",
      "\n",
      "         [[[8.2193]]],\n",
      "\n",
      "\n",
      "         [[[8.2642]]],\n",
      "\n",
      "\n",
      "         [[[8.2685]]],\n",
      "\n",
      "\n",
      "         [[[8.2620]]],\n",
      "\n",
      "\n",
      "         [[[8.2207]]],\n",
      "\n",
      "\n",
      "         [[[8.2672]]],\n",
      "\n",
      "\n",
      "         [[[8.2679]]],\n",
      "\n",
      "\n",
      "         [[[8.2307]]],\n",
      "\n",
      "\n",
      "         [[[8.2637]]],\n",
      "\n",
      "\n",
      "         [[[8.2569]]],\n",
      "\n",
      "\n",
      "         [[[8.1876]]],\n",
      "\n",
      "\n",
      "         [[[8.2197]]],\n",
      "\n",
      "\n",
      "         [[[8.2292]]],\n",
      "\n",
      "\n",
      "         [[[8.2649]]],\n",
      "\n",
      "\n",
      "         [[[8.2795]]],\n",
      "\n",
      "\n",
      "         [[[8.2729]]],\n",
      "\n",
      "\n",
      "         [[[8.2724]]],\n",
      "\n",
      "\n",
      "         [[[8.2431]]],\n",
      "\n",
      "\n",
      "         [[[8.2749]]],\n",
      "\n",
      "\n",
      "         [[[8.2591]]],\n",
      "\n",
      "\n",
      "         [[[8.2754]]],\n",
      "\n",
      "\n",
      "         [[[8.2746]]],\n",
      "\n",
      "\n",
      "         [[[8.2614]]],\n",
      "\n",
      "\n",
      "         [[[8.2827]]],\n",
      "\n",
      "\n",
      "         [[[8.2503]]],\n",
      "\n",
      "\n",
      "         [[[8.2111]]],\n",
      "\n",
      "\n",
      "         [[[8.2960]]],\n",
      "\n",
      "\n",
      "         [[[8.2382]]],\n",
      "\n",
      "\n",
      "         [[[8.2530]]],\n",
      "\n",
      "\n",
      "         [[[8.2601]]],\n",
      "\n",
      "\n",
      "         [[[8.2914]]],\n",
      "\n",
      "\n",
      "         [[[8.1994]]],\n",
      "\n",
      "\n",
      "         [[[8.2730]]],\n",
      "\n",
      "\n",
      "         [[[8.2401]]],\n",
      "\n",
      "\n",
      "         [[[8.2144]]],\n",
      "\n",
      "\n",
      "         [[[8.2753]]],\n",
      "\n",
      "\n",
      "         [[[8.1479]]],\n",
      "\n",
      "\n",
      "         [[[8.2504]]],\n",
      "\n",
      "\n",
      "         [[[8.2285]]],\n",
      "\n",
      "\n",
      "         [[[8.2278]]],\n",
      "\n",
      "\n",
      "         [[[8.2596]]],\n",
      "\n",
      "\n",
      "         [[[8.2714]]],\n",
      "\n",
      "\n",
      "         [[[8.1941]]],\n",
      "\n",
      "\n",
      "         [[[8.2225]]],\n",
      "\n",
      "\n",
      "         [[[8.2368]]],\n",
      "\n",
      "\n",
      "         [[[8.2446]]],\n",
      "\n",
      "\n",
      "         [[[8.2508]]],\n",
      "\n",
      "\n",
      "         [[[8.2507]]],\n",
      "\n",
      "\n",
      "         [[[8.2706]]],\n",
      "\n",
      "\n",
      "         [[[8.2435]]],\n",
      "\n",
      "\n",
      "         [[[8.2760]]],\n",
      "\n",
      "\n",
      "         [[[8.2226]]],\n",
      "\n",
      "\n",
      "         [[[8.2589]]],\n",
      "\n",
      "\n",
      "         [[[8.2172]]],\n",
      "\n",
      "\n",
      "         [[[8.2673]]],\n",
      "\n",
      "\n",
      "         [[[8.2001]]],\n",
      "\n",
      "\n",
      "         [[[8.2097]]],\n",
      "\n",
      "\n",
      "         [[[8.2031]]],\n",
      "\n",
      "\n",
      "         [[[8.2222]]],\n",
      "\n",
      "\n",
      "         [[[8.2703]]],\n",
      "\n",
      "\n",
      "         [[[8.2663]]],\n",
      "\n",
      "\n",
      "         [[[8.2525]]],\n",
      "\n",
      "\n",
      "         [[[8.2092]]],\n",
      "\n",
      "\n",
      "         [[[8.2163]]],\n",
      "\n",
      "\n",
      "         [[[8.2552]]],\n",
      "\n",
      "\n",
      "         [[[8.2340]]],\n",
      "\n",
      "\n",
      "         [[[8.1277]]],\n",
      "\n",
      "\n",
      "         [[[8.2174]]],\n",
      "\n",
      "\n",
      "         [[[8.2297]]],\n",
      "\n",
      "\n",
      "         [[[8.2459]]],\n",
      "\n",
      "\n",
      "         [[[8.2473]]],\n",
      "\n",
      "\n",
      "         [[[8.2527]]],\n",
      "\n",
      "\n",
      "         [[[8.2096]]],\n",
      "\n",
      "\n",
      "         [[[8.2376]]],\n",
      "\n",
      "\n",
      "         [[[8.2717]]],\n",
      "\n",
      "\n",
      "         [[[8.1996]]],\n",
      "\n",
      "\n",
      "         [[[8.2468]]],\n",
      "\n",
      "\n",
      "         [[[8.2721]]],\n",
      "\n",
      "\n",
      "         [[[8.2439]]],\n",
      "\n",
      "\n",
      "         [[[8.2273]]],\n",
      "\n",
      "\n",
      "         [[[8.2801]]],\n",
      "\n",
      "\n",
      "         [[[8.1984]]],\n",
      "\n",
      "\n",
      "         [[[8.2448]]],\n",
      "\n",
      "\n",
      "         [[[8.2416]]]]])\n"
     ]
    }
   ],
   "source": [
    "# \"event_shape\", [(), (3,), (3, 2)]\n",
    "# \"plate_size\", [4, 50, 200]\n",
    "\n",
    "plate_size = 200\n",
    "event_shape = (3,2)\n",
    "\n",
    "factors = {\n",
    "    \"consequent\": consequent_eq_neq(\n",
    "        support=constraints.independent(constraints.real, len(event_shape)),\n",
    "        # proposed_consequent=torch.Tensor([0.01], event_shape),\n",
    "        proposed_consequent=torch.tensor(0.01).expand(event_shape),\n",
    "        antecedents=[\"w\"],\n",
    "    )\n",
    "}\n",
    "\n",
    "# w_initial = (\n",
    "#     dist.Normal(0, 0.1).expand(event_shape).to_event(len(event_shape)).sample()\n",
    "# )\n",
    "\n",
    "@Factors(factors=factors)\n",
    "@pyro.plate(\"data\", size=plate_size, dim=-4)\n",
    "def model_ce():\n",
    "    w = pyro.sample(\"w\", dist.Normal(0, 0.1).expand(event_shape).to_event(len(event_shape)))\n",
    "    consequent = pyro.deterministic(\"consequent\", w * torch.tensor(0.1), event_dim = len(event_shape))\n",
    "    assert w.shape == consequent.shape\n",
    "    print(w.shape)\n",
    "    print(consequent.shape)\n",
    "\n",
    "antecedents = {\n",
    "    \"w\": (\n",
    "        torch.tensor(0.1).expand(event_shape),\n",
    "        sufficiency_intervention(\n",
    "            constraints.independent(constraints.real, len(event_shape)), [\"w\"]\n",
    "        ),\n",
    "    )\n",
    "}\n",
    "\n",
    "print(antecedents[\"w\"])\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc_ce:\n",
    "    with do(actions=antecedents):\n",
    "        with pyro.poutine.trace() as trace_ce:\n",
    "            model_ce()\n",
    "\n",
    "trace_ce.trace.compute_log_prob()\n",
    "nd = trace_ce.trace.nodes\n",
    "with mwc_ce:\n",
    "    eq_neq_log_probs_fact = gather(\n",
    "        nd[\"__factor_consequent\"][\"fn\"].log_factor,\n",
    "        IndexSet(**{\"w\": {0}})\n",
    "    )\n",
    "\n",
    "    print(nd[\"__factor_consequent\"][\"fn\"].log_factor.shape)\n",
    "    print(indices_of(nd[\"__factor_consequent\"][\"fn\"].log_factor))\n",
    "    print(eq_neq_log_probs_fact.shape)\n",
    "\n",
    "    eq_neq_log_probs_nec = gather(\n",
    "        nd[\"__factor_consequent\"][\"fn\"].log_factor,\n",
    "        IndexSet(**{\"w\": {1}})\n",
    "    )\n",
    "    # print(\"consequent_shape\", indices_of(nd[\"consequent\"][\"value\"].shape, event_dim=len(event_shape)))\n",
    "    consequent_suff = gather(\n",
    "        nd[\"consequent\"][\"value\"], IndexSet(**{\"w\": {2}}), event_dim=len(event_shape)\n",
    "    )\n",
    "    eq_neq_log_probs_suff = gather(\n",
    "        nd[\"__factor_consequent\"][\"fn\"].log_factor, IndexSet(**{\"w\": {2}})\n",
    "    )\n",
    "\n",
    "    # print(eq_neq_log_probs_suff.shape)\n",
    "    # print(eq_neq_log_probs_fact.shape)\n",
    "    print(eq_neq_log_probs_suff.squeeze())\n",
    "    # print(consequent_suff)\n",
    "    # print(dist.Normal(0.0, 0.1).log_prob(consequent_suff - torch.tensor(0.01)))\n",
    "\n",
    "    print(eq_neq_log_probs_nec)\n",
    "    # print(consequent_suff.shape)\n",
    "\n",
    "    assert torch.equal(\n",
    "        eq_neq_log_probs_fact, torch.zeros(eq_neq_log_probs_fact.shape)\n",
    "    )\n",
    "\n",
    "    print(dist.Normal(0.0, 0.1).log_prob(consequent_suff - torch.tensor(0.01)).sum().squeeze())\n",
    "    # assert eq_neq_log_probs_nec.shape == consequent_suff.shape\n",
    "\n",
    "    result = dist.Normal(0.0, 0.1).log_prob(consequent_suff - torch.tensor(0.01))\n",
    "    for _ in range(len(event_shape)):\n",
    "        result = torch.sum(result, dim=-1)\n",
    "\n",
    "    print(result)\n",
    "\n",
    "    assert torch.allclose(\n",
    "        eq_neq_log_probs_suff.squeeze(),\n",
    "        result.squeeze(),\n",
    "    )\n",
    "    assert eq_neq_log_probs_nec.sum().exp().item() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.1000, 0.1000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(0.1).expand(event_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_independent(event_shape):\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    Y = pyro.sample(\"Y\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    return {\"X\": X, \"Y\": Y}\n",
    "\n",
    "\n",
    "def model_connected(event_shape):\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    Y = pyro.deterministic(\"Y\", X, event_dim = len(event_shape))\n",
    "    return {\"X\": X, \"Y\": Y}\n",
    "\n",
    "\n",
    "# @pytest.mark.parametrize(\"ante_cons\", [(\"Y\", \"X\")])\n",
    "# @pytest.mark.parametrize(\n",
    "#     \"model\",\n",
    "#     [\n",
    "#         model_independent,\n",
    "#         model_connected\n",
    "#     ],\n",
    "# )\n",
    "# @pytest.mark.parametrize(\"event_shape\", [(), (3,), (3, 2)], ids=str)\n",
    "def test_edge_eq_neq(model, ante_cons, event_shape):\n",
    "    with ExtractSupports() as supports:\n",
    "        model(event_shape)\n",
    "\n",
    "    antecedent = ante_cons[0]\n",
    "    consequent = ante_cons[1]\n",
    "\n",
    "    with MultiWorldCounterfactual() as mwc:\n",
    "        with SearchForExplanation(\n",
    "            supports=supports.supports,\n",
    "            antecedents={antecedent: torch.tensor(1.0).expand(event_shape)},\n",
    "            consequents={consequent: torch.tensor(1.0).expand(event_shape)},\n",
    "            witnesses={},\n",
    "            alternatives={antecedent: torch.tensor(0.0).expand(event_shape)},\n",
    "            antecedent_bias=-0.5,\n",
    "            consequent_scale=0,\n",
    "        ):\n",
    "            with pyro.plate(\"sample\", size=3):\n",
    "                with pyro.poutine.trace() as trace:\n",
    "                    model(event_shape)\n",
    "\n",
    "    trace.trace.compute_log_prob()\n",
    "\n",
    "    cons_values = trace.trace.nodes[consequent][\"value\"]\n",
    "\n",
    "    log_probs = trace.trace.nodes[f\"__cause____consequent_{consequent}\"][\n",
    "        \"fn\"\n",
    "    ].log_factor\n",
    "\n",
    "    with mwc:\n",
    "        nec_log_probs = gather(log_probs, IndexSet(**{antecedent: {1}}))\n",
    "        suff_log_probs = gather(log_probs, IndexSet(**{antecedent: {2}}))\n",
    "\n",
    "    if torch.any(cons_values == 1.0):\n",
    "        assert nec_log_probs.sum().exp() == 0.0\n",
    "    else:\n",
    "        assert nec_log_probs.sum().exp() == 1.0\n",
    "\n",
    "    assert torch.all(log_probs.sum().exp() == 0)\n",
    "\n",
    "    if torch.any(cons_values == 0.0):\n",
    "        assert suff_log_probs.sum().exp() == 0.0\n",
    "    else:\n",
    "        assert suff_log_probs.sum().exp() == 1.0\n",
    "\n",
    "    assert torch.all(\n",
    "        trace.trace.nodes[f\"__cause____consequent_{consequent}\"][\"fn\"].log_factor.sum().exp()\n",
    "        == 0\n",
    "    )\n",
    "\n",
    "test_edge_eq_neq(model_connected, (\"Y\", \"X\"), (3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_three_converge(event_shape):\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    Y = pyro.sample(\"Y\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    Z = pyro.deterministic(\"Z\", torch.min(X, Y), event_dim=len(event_shape))\n",
    "    return {\"X\": X, \"Y\": Y, \"Z\": Z}\n",
    "\n",
    "\n",
    "# X -> Y, X -> Z\n",
    "def model_three_diverge(event_shape):\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    Y = pyro.deterministic(\"Y\", X, event_dim=len(event_shape))\n",
    "    Z = pyro.deterministic(\"Z\", X, event_dim=len(event_shape))\n",
    "    return {\"X\": X, \"Y\": Y, \"Z\": Z}\n",
    "\n",
    "\n",
    "# X -> Y -> Z\n",
    "def model_three_chain(event_shape):\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    Y = pyro.deterministic(\"Y\", X, event_dim=len(event_shape))\n",
    "    Z = pyro.deterministic(\"Z\", Y, event_dim=len(event_shape))\n",
    "    return {\"X\": X, \"Y\": Y, \"Z\": Z}\n",
    "\n",
    "\n",
    "# X -> Y, X -> Z, Y -> Z\n",
    "def model_three_complete(event_shape):\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    Y = pyro.deterministic(\"Y\", X, event_dim=len(event_shape))\n",
    "    Z = pyro.deterministic(\"Z\", torch.max(X, Y), event_dim=len(event_shape))\n",
    "    return {\"X\": X, \"Y\": Y, \"Z\": Z}\n",
    "\n",
    "\n",
    "# X -> Y    Z\n",
    "def model_three_isolate(event_shape):\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    Y = pyro.deterministic(\"Y\", X, event_dim=len(event_shape))\n",
    "    Z = pyro.sample(\"Z\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    return {\"X\": X, \"Y\": Y, \"Z\": Z}\n",
    "\n",
    "\n",
    "# X     Y    Z\n",
    "def model_three_independent(event_shape):\n",
    "    X = pyro.sample(\"X\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    Y = pyro.sample(\"Y\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    Z = pyro.sample(\"Z\", dist.Bernoulli(0.5).expand(event_shape).to_event(len(event_shape)))\n",
    "    return {\"X\": X, \"Y\": Y, \"Z\": Z}\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"ante_cons\", [(\"X\", \"Y\", \"Z\"), (\"X\", \"Z\", \"Y\")])\n",
    "@pytest.mark.parametrize(\n",
    "    \"model\",\n",
    "    [\n",
    "        model_three_converge,\n",
    "        model_three_diverge,\n",
    "        model_three_chain,\n",
    "        # model_three_complete,\n",
    "        # model_three_isolate,\n",
    "        # model_three_independent,\n",
    "    ],\n",
    ")\n",
    "@pytest.mark.parametrize(\"event_shape\", [(), (3,), (3, 2)], ids=str)\n",
    "def test_eq_neq_three_variables(model, ante_cons, event_shape):\n",
    "    ante1, ante2, cons = ante_cons\n",
    "    with ExtractSupports() as supports:\n",
    "        model(event_shape)\n",
    "        for var, sup in supports.supports.items():\n",
    "            if isinstance(sup, constraints.independent):\n",
    "                sup.base_constraint = constraints.boolean\n",
    "            else:\n",
    "                sup.base_constraint = constraints.boolean\n",
    "        \n",
    "\n",
    "    with MultiWorldCounterfactual() as mwc:\n",
    "        with SearchForExplanation(\n",
    "            supports=supports.supports,\n",
    "            antecedents={ante1: torch.tensor(1.0).expand(event_shape), ante2: torch.tensor(1.0).expand(event_shape)},\n",
    "            consequents={cons: torch.tensor(1.0).expand(event_shape)},\n",
    "            witnesses={},\n",
    "            alternatives={ante1: torch.tensor(0.0).expand(event_shape), ante2: torch.tensor(0.0).expand(event_shape)},\n",
    "            antecedent_bias=-0.5,\n",
    "            consequent_scale=0,\n",
    "        ):\n",
    "            with pyro.plate(\"sample\", size=1):\n",
    "                with pyro.poutine.trace() as trace:\n",
    "                    model(event_shape)\n",
    "\n",
    "    trace.trace.compute_log_prob()\n",
    "    nodes = trace.trace.nodes\n",
    "\n",
    "    values = nodes[cons][\"value\"]\n",
    "    log_probs = nodes[f\"__cause____consequent_{cons}\"][\"fn\"].log_factor\n",
    "\n",
    "    fact_worlds = IndexSet(**{name: {0} for name in [ante1, ante2]})\n",
    "    nec_worlds = IndexSet(**{name: {1} for name in [ante1, ante2]})\n",
    "    suff_worlds = IndexSet(**{name: {2} for name in [ante1, ante2]})\n",
    "    with mwc:\n",
    "        assert indices_of(log_probs) == {ante1: {0, 1, 2}, ante2: {0, 1, 2}}\n",
    "\n",
    "        fact_lp = gather(log_probs, fact_worlds)\n",
    "        fact_value = gather(values, fact_worlds, event_dim=len(event_shape))\n",
    "        assert fact_lp.exp().item() == 1\n",
    "\n",
    "        nec_value = gather(values, nec_worlds, event_dim=len(event_shape))\n",
    "        nec_lp = gather(log_probs, nec_worlds)\n",
    "\n",
    "        if torch.equal(nec_value, fact_value) & (not torch.allclose(nec_value, torch.tensor(0.0))):\n",
    "            assert nec_lp.exp().item() == 0.0\n",
    "        elif torch.allclose(nec_value, torch.tensor(0.0)):\n",
    "            assert nec_lp.exp().item() == 1.0\n",
    "\n",
    "        suff_value = gather(values, suff_worlds, event_dim=len(event_shape))\n",
    "        suff_lp = gather(log_probs, suff_worlds)\n",
    "\n",
    "        if torch.equal(suff_value, fact_value) & (not torch.allclose(suff_value, torch.tensor(1.0))):\n",
    "            assert suff_lp.exp().item() == 0.0\n",
    "        elif torch.allclose(suff_value, torch.tensor(1.0)):\n",
    "            assert suff_lp.exp().item() == 1.0\n",
    "\n",
    "    assert torch.allclose(log_probs.squeeze().fill_diagonal_(0.0), torch.tensor(0.0))\n",
    "\n",
    "test_eq_neq_three_variables(model_three_converge, (\"X\", \"Z\", \"Y\"), (3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
