{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from typing import Dict, List, Optional,  Union, Callable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import random\n",
    "\n",
    "from causal_pyro.indexed.ops import IndexSet, gather, indices_of, scatter\n",
    "from causal_pyro.interventional.handlers import do\n",
    "from causal_pyro.counterfactual.handlers import MultiWorldCounterfactual, Preemptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HalpernPearlModifiedApproximate:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: Callable,\n",
    "        antecedents: Union[Dict[str, torch.Tensor], List[str]],\n",
    "        outcome: str,\n",
    "        witness_candidates: List[str],\n",
    "        observations: Optional[Dict[str, torch.Tensor]],\n",
    "        sample_size: int = 100,\n",
    "        event_dim: int = 0\n",
    "        ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.antecedents = antecedents\n",
    "        self.outcome = outcome\n",
    "        self.witness_candidates = witness_candidates\n",
    "        self.nodes = antecedents + [outcome] + witness_candidates\n",
    "        self.observations = observations\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        self.antecedents_dict = (\n",
    "            self.antecedents if isinstance(self.antecedents, dict)\n",
    "            else self.revert_antecedents(self.antecedents)\n",
    "        )\n",
    "    \n",
    "        self.preemptions = {candidate: functools.partial(self.preempt_with_factual,\n",
    "                                             antecedents = self.antecedents) for \n",
    "                                             candidate in self.witness_candidates}\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def revert_antecedents(antecedents: List[str]) -> Dict[str, Callable[[torch.Tensor], torch.Tensor]]:\n",
    "        return {antecedent: (lambda v: 1 - v) for antecedent in antecedents}\n",
    "\n",
    "    @staticmethod   \n",
    "    def preempt_with_factual(value: torch.Tensor, *,\n",
    "                          antecedents: List[str] = None, event_dim: int = 0):\n",
    "    \n",
    "        if antecedents is None:\n",
    "            antecedents = []\n",
    "\n",
    "        antecedents = [a for a in antecedents if a in indices_of(value, event_dim=event_dim)]\n",
    "\n",
    "        factual_value = gather(value, IndexSet(**{antecedent: {0} for antecedent in antecedents}),\n",
    "                                event_dim=event_dim)\n",
    "            \n",
    "        return scatter({\n",
    "            IndexSet(**{antecedent: {0} for antecedent in antecedents}): factual_value,\n",
    "            IndexSet(**{antecedent: {1} for antecedent in antecedents}): factual_value,\n",
    "        }, event_dim=event_dim)\n",
    "        \n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with pyro.poutine.trace() as trace:\n",
    "            with MultiWorldCounterfactual():\n",
    "                with do(actions=self.antecedents_dict):\n",
    "                    with Preemptions(actions = self.preemptions):\n",
    "                        with pyro.condition(data={k: torch.as_tensor(v) for k, v in self.observations.items()}):\n",
    "                            with pyro.plate(\"plate\", self.sample_size):\n",
    "                                self.consequent = self.model()[self.outcome]\n",
    "                                self.intervened_consequent = gather(self.consequent, IndexSet(**{ant: {1} for ant in self.antecedents}))\n",
    "                                self.observed_consequent = gather(self.consequent, IndexSet(**{ant: {0} for ant in self.antecedents}))\n",
    "                                self.consequent_differs = self.intervened_consequent != self.observed_consequent   \n",
    "                                pyro.factor(\"consequent_differs\", torch.where(self.consequent_differs, torch.tensor(0.0), torch.tensor(-1e8)))\n",
    "                            \n",
    "        self.trace = trace.trace\n",
    "        self.nodes_trace = {node: self.trace.nodes[node]['value'] for node in self.nodes}\n",
    "        \n",
    "        \n",
    "         # slightly hacky solution for odd witness candidate sets\n",
    "        if  isinstance(self.consequent_differs.squeeze().tolist(), bool):\n",
    "            self.existential_but_for = self.consequent_differs.squeeze()\n",
    "        else:\n",
    "            #if (len(self.consequent_differs.squeeze().tolist() )>1):\n",
    "            self.existential_but_for = any(self.consequent_differs.squeeze().tolist()                )  \n",
    "\n",
    "\n",
    "        witness_dict = dict()\n",
    "        if self.witness_candidates:\n",
    "            witness_keys = [\"__split_\" + candidate for candidate in self.witness_candidates]\n",
    "            witness_dict = {key: self.trace.nodes[key]['value']  for key in witness_keys}\n",
    "            \n",
    "\n",
    "        witness_dict['observed'] = self.observed_consequent.squeeze()\n",
    "        witness_dict['intervened'] = self.intervened_consequent.squeeze()\n",
    "        witness_dict['consequent_differs'] = self.consequent_differs.squeeze()\n",
    "\n",
    "        # slightly hacky as above\n",
    "        self.witness_df = pd.DataFrame(witness_dict) if self.witness_candidates else witness_dict\n",
    "\n",
    "        if self.witness_candidates:\n",
    "            self.witness_df['witness_size'] = self.witness_df[witness_keys].sum(axis = 1)\n",
    "            satisfactory = self.witness_df[self.witness_df['consequent_differs'] == True]\n",
    "            \n",
    "        self.minimal_witness_size = satisfactory['witness_size'].min() if self.witness_candidates else 0\n",
    "        self.responsibility_internal = 1/(len(self.antecedents) + self.minimal_witness_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HalpernPearlResponsibilityApproximate:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: Callable,\n",
    "        nodes: List,\n",
    "        antecedent: str,\n",
    "        outcome: str,\n",
    "        observations: Dict[str, torch.Tensor], \n",
    "        runs_n: int \n",
    "    ):\n",
    "        self.model = model\n",
    "        self.nodes = nodes\n",
    "        self.antecedent = antecedent\n",
    "        self.outcome = outcome\n",
    "        self.observations = observations\n",
    "        self.runs_n = runs_n\n",
    "        \n",
    "        self.minimal_antecedents_cache = []\n",
    "        self.antecedent_sizes = []\n",
    "        self.existential_but_fors = []\n",
    "        self.minimal_witness_sizes = []\n",
    "        self.responsibilities = []\n",
    "        self.HPMs = []\n",
    "\n",
    "    def __call__(self):\n",
    "        \n",
    "        for step in range(1,self.runs_n):\n",
    "\n",
    "            nodes = self.nodes\n",
    "            if self.outcome in nodes:\n",
    "                nodes.remove(self.outcome) \n",
    "            \n",
    "            companion_size = random.randint(0,len(nodes))\n",
    "            companion_candidates = random.sample(self.nodes, companion_size)\n",
    "            witness_candidates = [node for node in self.nodes if \n",
    "                                node != self.antecedent and \n",
    "                                node != self.outcome and \n",
    "                                    node not in companion_candidates]\n",
    "\n",
    "            HPM = HalpernPearlModifiedApproximate(\n",
    "                model = self.model,\n",
    "                antecedents = companion_candidates,\n",
    "                outcome = self.outcome,\n",
    "                witness_candidates = witness_candidates,\n",
    "                observations = self.observations,\n",
    "                sample_size = 1000)\n",
    "            \n",
    "            HPM()\n",
    "\n",
    "            self.HPMs.append(HPM)\n",
    "\n",
    "\n",
    "            if  HPM.existential_but_for:\n",
    "\n",
    "\n",
    "                subset_in_cache = any([s.issubset(set(HPM.antecedents)) for s in self.minimal_antecedents_cache])\n",
    "                if not subset_in_cache:\n",
    "                    self.minimal_antecedents_cache.append(set(HPM.antecedents))\n",
    "\n",
    "                    if self.antecedent in HPM.antecedents:\n",
    "                        self.antecedent_sizes.append(len(HPM.antecedents))\n",
    "                        self.existential_but_fors.append(HPM.existential_but_for)\n",
    "                        self.minimal_witness_sizes.append(HPM.minimal_witness_size)\n",
    "                        self.responsibilities.append(HPM.responsibility_internal)\n",
    "\n",
    "\n",
    "        self.denumerators = [x + y for x, y in zip(self.antecedent_sizes, self.minimal_witness_sizes)]\n",
    "\n",
    "        self.responsibilityDF = pd.DataFrame(\n",
    "            {\"existential_but_for\": [bool(value) for value in self.existential_but_fors],\n",
    "                \"antecedent_size\": self.antecedent_sizes, \n",
    "                \"minimal_witness_size\": self.minimal_witness_sizes,\n",
    "                \"denumerator\": self.denumerators,\n",
    "                \"responsibility\": self.responsibilities\n",
    "            }\n",
    "            )\n",
    "        if len(self.responsibilityDF['existential_but_for']) == 0:\n",
    "            self.responsibility = 0\n",
    "        else:\n",
    "            min_denumerator = min(self.responsibilityDF['denumerator'])\n",
    "            self.responsibility = 1/min_denumerator\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firing_squad_model():\n",
    "    probs = pyro.sample(\"probs\", dist.Dirichlet(torch.ones(5)))\n",
    "\n",
    "    who_has_bullet = pyro.sample(\"who_has_bullet\", dist.OneHotCategorical(probs))\n",
    "\n",
    "    mark0 = pyro.deterministic(\"mark0\", torch.tensor([who[0] for who in who_has_bullet]), event_dim=0)\n",
    "    mark1 = pyro.deterministic(\"mark1\", torch.tensor([who[1] for who in who_has_bullet]), event_dim=0)\n",
    "    mark2 = pyro.deterministic(\"mark2\", torch.tensor([who[2] for who in who_has_bullet]), event_dim=0)\n",
    "    mark3 = pyro.deterministic(\"mark3\", torch.tensor([who[3] for who in who_has_bullet]), event_dim=0)\n",
    "    mark4 = pyro.deterministic(\"mark4\", torch.tensor([who[4] for who in who_has_bullet]), event_dim=0)\n",
    "\n",
    "    dead = pyro.deterministic(\"dead\", mark0 + mark1 + mark2 + mark3 + \n",
    "                                mark4  > 0)\n",
    "    \n",
    "    return {\"probs\": probs,\n",
    "            \"mark0\": mark0,\n",
    "            \"mark1\": mark1,\n",
    "            \"mark2\": mark2,\n",
    "\n",
    "            \"mark3\": mark3,\n",
    "            \"mark4\": mark4, \n",
    "            \"dead\": dead}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2000)\n"
     ]
    }
   ],
   "source": [
    "# Halpern's strategy: assign weights to models\n",
    "# and take the weighted average\n",
    "\n",
    "pyro.set_rng_seed(102)\n",
    "\n",
    "marksman0_responsibilities = []\n",
    "for who in range(0,5):\n",
    "    probs = torch.zeros(5)\n",
    "    probs[who] = 1.0\n",
    "\n",
    "\n",
    "    responsibility_marksmen_HPR = HalpernPearlResponsibilityApproximate(\n",
    "        model = firing_squad_model,\n",
    "        nodes = [\"mark\" + str(i) for i in range(0,5)],\n",
    "        antecedent = \"mark0\", outcome = \"dead\",\n",
    "        observations = {\"probs\": probs,},\n",
    "                        runs_n=50)\n",
    "\n",
    "    responsibility_marksmen_HPR()\n",
    "    marksman0_responsibilities.append(responsibility_marksmen_HPR.responsibility)\n",
    "\n",
    "weights = torch.full((5,), .2)\n",
    "\n",
    "# if your pr(mark0) = i, \n",
    "# the blame in this case is i as well \n",
    "\n",
    "print(torch.dot(torch.tensor(marksman0_responsibilities), weights))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blame for voters\n",
    "\n",
    "The general phenomenon in the voting setup: if $a$ voted for and $b$ against, $a>b$, a voter voting for has degree of responsibility $\\frac{1}{\\lceil (a-b)/2\\rceil}$. So much is in Halpern. Now let's go beyond, what if you decide whether to vote and consider your blame if your candidate looses and you didn't vote? Still a somewhat simplistic setup: eight other people are about to vote, each outcome among them you consider equally likely, and you consider the blame associated with you skipping the voting if your candidate fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_to_vote_model():\n",
    "    u_a = pyro.sample(\"u_a\", dist.Categorical(logits=torch.ones(8)))\n",
    "    u_skip = pyro.sample(\"u_skip\", dist.Bernoulli(0.5))\n",
    "\n",
    "    a = pyro.deterministic(\"a\", u_a, event_dim=0)\n",
    "    skip = pyro.deterministic(\"skip\", u_skip, event_dim=0)\n",
    "\n",
    "    result = pyro.deterministic(\"result\", \n",
    "                            (a + 1 - skip) > torch.ceil(9 - skip)/2)\n",
    "\n",
    "    return {\"a\": a, \"against\": 8-a, \"voted\": 1 - skip, \"result\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor(4),\n",
       " 'against': tensor(4),\n",
       " 'voted': tensor(0.),\n",
       " 'result': tensor(False)}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_to_vote_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your skipping is not an actual cause if a=1\n",
    "\n",
    "skipping1HPM = HalpernPearlModifiedApproximate(\n",
    "    model = choose_to_vote_model,\n",
    "    antecedents = [\"skip\"],\n",
    "    outcome = \"result\",\n",
    "    witness_candidates = [\"a\"],\n",
    "    observations = dict(u_a=1.),\n",
    "    sample_size = 100)\n",
    "\n",
    "skipping1HPM()\n",
    "\n",
    "skipping1HPM.existential_but_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but it is, if a = 4\n",
    "skipping4HPM = HalpernPearlModifiedApproximate(\n",
    "    model = choose_to_vote_model,\n",
    "    antecedents = [\"skip\"],\n",
    "    outcome = \"result\",\n",
    "    witness_candidates = [\"a\"],\n",
    "    observations = dict(u_a=4.),\n",
    "    sample_size = 100)\n",
    "\n",
    "skipping4HPM()\n",
    "\n",
    "skipping4HPM.existential_but_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with this model responsibilities follow the same pattern\n",
    "\n",
    "skipping1HPR = HalpernPearlResponsibilityApproximate(\n",
    "    model = choose_to_vote_model,\n",
    "    nodes = [\"a\", \"skip\"],\n",
    "    antecedent = \"skip\", outcome = \"result\",\n",
    "    observations = dict(u_a=1.), \n",
    "    runs_n=50\n",
    "    )\n",
    "\n",
    "skipping1HPR()\n",
    "skipping1HPR.responsibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   existential_but_for  antecedent_size  minimal_witness_size  denumerator  \\\n",
      "0                 True                2                     0            2   \n",
      "1                 True                1                     0            1   \n",
      "\n",
      "   responsibility  \n",
      "0             0.5  \n",
      "1             1.0   1.0\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(102)\n",
    "skipping4HPR = HalpernPearlResponsibilityApproximate(\n",
    "    model = choose_to_vote_model,\n",
    "    nodes = [\"a\", \"skip\"],\n",
    "    antecedent = \"skip\", outcome = \"result\",\n",
    "    observations = dict(u_a=4.), \n",
    "    runs_n=50\n",
    "    )\n",
    "\n",
    "skipping4HPR()\n",
    "print(\n",
    "skipping4HPR.responsibilityDF,\n",
    "skipping4HPR.responsibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome': tensor(0.)}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but now suppose we work with a wide model\n",
    "\n",
    "def choosing_to_vote_wide_model():\n",
    "    u_vote0 = pyro.sample(\"u_vote0\", dist.Bernoulli(0.6))\n",
    "    u_vote1 = pyro.sample(\"u_vote1\", dist.Bernoulli(0.6))\n",
    "    u_vote2 = pyro.sample(\"u_vote2\", dist.Bernoulli(0.6))\n",
    "    u_vote3 = pyro.sample(\"u_vote3\", dist.Bernoulli(0.6))\n",
    "    u_vote4 = pyro.sample(\"u_vote4\", dist.Bernoulli(0.6))\n",
    "    u_vote5 = pyro.sample(\"u_vote5\", dist.Bernoulli(0.6))\n",
    "    u_vote6 = pyro.sample(\"u_vote6\", dist.Bernoulli(0.6))\n",
    "    u_vote7 = pyro.sample(\"u_vote7\", dist.Bernoulli(0.6))\n",
    "    u_skip = pyro.sample(\"u_skip\", dist.Bernoulli(0.5))\n",
    "\n",
    "    vote0 = pyro.deterministic(\"vote0\", u_vote0, event_dim=0)\n",
    "    vote1 = pyro.deterministic(\"vote1\", u_vote1, event_dim=0)\n",
    "    vote2 = pyro.deterministic(\"vote2\", u_vote2, event_dim=0)\n",
    "    vote3 = pyro.deterministic(\"vote3\", u_vote3, event_dim=0)\n",
    "    vote4 = pyro.deterministic(\"vote4\", u_vote4, event_dim=0)\n",
    "    vote5 = pyro.deterministic(\"vote5\", u_vote5, event_dim=0)\n",
    "    vote6 = pyro.deterministic(\"vote6\", u_vote6, event_dim=0)\n",
    "    vote7 = pyro.deterministic(\"vote7\", u_vote7, event_dim=0)\n",
    "    skip = pyro.deterministic(\"skip\", u_skip, event_dim=0)\n",
    "\n",
    "\n",
    "    outcome = pyro.deterministic(\"outcome\", vote0 + vote1 + vote2 + vote3 + \n",
    "                                 vote4 + vote5 + vote6 + vote7 + 1 - skip > 4)\n",
    "    return {\"outcome\": outcome.float()}\n",
    "\n",
    "choosing_to_vote_wide_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if a = 1, skipping is still not an actual cause\n",
    "\n",
    "skipping_wide1HPM = HalpernPearlModifiedApproximate(\n",
    "    model = choosing_to_vote_wide_model,\n",
    "    antecedents = [\"skip\"],\n",
    "    outcome = \"outcome\",\n",
    "    witness_candidates = [f\"vote{i}\" for i in range(0,8)],\n",
    "    observations = dict(u_vote0=1., u_vote1=0., u_vote2=0.,\n",
    "                        u_vote3=0., u_vote4=0., u_vote5=0,\n",
    "                        u_vote6=0., u_vote7=0.),\n",
    "    sample_size = 1000)\n",
    "\n",
    "skipping_wide1HPM()\n",
    "skipping_wide1HPM.existential_but_for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if a = 4, skipping is  an actual cause\n",
    "\n",
    "skipping_wide4HPM = HalpernPearlModifiedApproximate(\n",
    "    model = choosing_to_vote_wide_model,\n",
    "    antecedents = [\"skip\"],\n",
    "    outcome = \"outcome\",\n",
    "    witness_candidates = [f\"vote{i}\" for i in range(0,8)],\n",
    "    observations = dict(u_vote0=1., u_vote1=1., u_vote2=1.,\n",
    "                        u_vote3=1., u_vote4=0., u_vote5=0,\n",
    "                        u_vote6=0., u_vote7=0.),\n",
    "    sample_size = 1000)\n",
    "\n",
    "skipping_wide4HPM()\n",
    "skipping_wide4HPM.existential_but_for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if a = 1 your responsibility is now 1/4\n",
    "# because if you voted for\n",
    "# and three other voters changed their mind\n",
    "# the outcome would be different\n",
    "\n",
    "skipping_wide1HPR = HalpernPearlResponsibilityApproximate(\n",
    "    model = choosing_to_vote_wide_model,\n",
    "    nodes = [f\"vote{i}\" for i in range(0,8,)] + [\"skip\"],\n",
    "    antecedent = \"skip\", outcome = \"outcome\",\n",
    "    observations =  dict(u_vote0=1., u_vote1=0., u_vote2=0.,\n",
    "                        u_vote3=0., u_vote4=0., u_vote5=0,\n",
    "                        u_vote6=0., u_vote7=0.), \n",
    "    runs_n=500\n",
    "    )\n",
    "\n",
    "skipping_wide1HPR()\n",
    "skipping_wide1HPR.responsibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above illustrates why what Halpern called the naive definition of responsibility used in Halpern is what it is called: it is highly sensitive to modeling choices and needs to be improved. This is a story for another occasion. Meawhile, let's assume that the wide model is the intended one and see what can be said about blame for failure before the voting happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_pyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
