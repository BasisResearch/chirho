@article{loftus1994using,
  title={Using confidence intervals in within-subject designs},
  author={Loftus, Geoffrey and Masson, Michael},
  journal={Psychonomic Bulletin \& Review},
  volume={1},
  number={4},
  pages={476--490},
  year={1994},
  publisher={Springer}
}

@book{shadish2002experimental,
  title={Experimental and quasi-experimental designs for generalized causal inference/William R. Shedish, Thomas D. Cook, Donald T. Campbell.},
  author={Shadish, William and Cook, Thomas and Campbell, Donald Thomas and others},
  year={2002},
  publisher={Boston: Houghton Mifflin,}
}

@techreport{doudchenko2016balancing,
  title={Balancing, regression, difference-in-differences and synthetic control methods: A synthesis},
  author={Doudchenko, Nikolay and Imbens, Guido W},
  year={2016},
  institution={National Bureau of Economic Research}
}

@article{feller2015hierarchical,
  title={Hierarchical models for causal effects},
  author={Feller, Avi and Gelman, Andrew},
  journal={Emerging Trends in the Social and Behavioral Sciences: An interdisciplinary, searchable, and linkable resource},
  pages={1--16},
  year={2015},
  publisher={Wiley Online Library}
}

@article{moodie2007demystifying,
  title={Demystifying optimal dynamic treatment regimes},
  author={Moodie, Erica EM and Richardson, Thomas S and Stephens, David A},
  journal={Biometrics},
  volume={63},
  number={2},
  pages={447--455},
  year={2007},
  publisher={Wiley Online Library}
}

@inproceedings{correa2020calculus,
  author = "Correa, J. and Bareinboim, E.",
  title = "A Calculus For Stochastic Interventions: Causal Effect Identification and Surrogate Experiments",
  booktitle = "Proceedings of the 34th AAAI Conference on Artificial Intelligence",
  year = "2020",
  address = "New York, NY",
  publisher = "AAAI Press"
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{jensen2020object,
  title={Object conditioning for causal inference},
  author={Jensen, David and Burroni, Javier and Rattigan, Matthew},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1072--1082},
  year={2020},
  organization={PMLR}
}

@inproceedings{malinsky2019potential,
  title={A potential outcomes calculus for identifying conditional path-specific effects},
  author={Malinsky, Daniel and Shpitser, Ilya and Richardson, Thomas},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={3080--3088},
  year={2019},
  organization={PMLR}
}

@article{wong2020computational,
  title={Computational causal inference},
  author={Wong, Jeffrey C},
  journal={arXiv preprint arXiv:2007.10979},
  year={2020}
}

@article{ding2018causal,
  title={Causal inference: A missing data perspective},
  author={Ding, Peng and Li, Fan and others},
  journal={Statistical Science},
  volume={33},
  number={2},
  pages={214--237},
  year={2018},
  publisher={Institute of Mathematical Statistics}
}

@article{pearl2011algorithmization,
  title={The algorithmization of counterfactuals},
  author={Pearl, Judea},
  journal={Annals of Mathematics and Artificial Intelligence},
  volume={61},
  number={1},
  pages={29--39},
  year={2011},
  publisher={Springer}
}

@article{wang2019blessings,
  title={The blessings of multiple causes},
  author={Wang, Yixin and Blei, David M},
  journal={Journal of the American Statistical Association},
  volume={114},
  number={528},
  pages={1574--1596},
  year={2019},
  publisher={Taylor \& Francis}
}

@article{bouneffouf2019survey,
  title={A survey on practical applications of multi-armed and contextual bandits},
  author={Bouneffouf, Djallel and Rish, Irina},
  journal={arXiv preprint arXiv:1904.10040},
  year={2019}
}

@article{zheng2021copula,
  title={Copula-based Sensitivity Analysis for Multi-Treatment Causal Inference with Unobserved Confounding},
  author={Zheng, Jiajing and D'Amour, Alexander and Franks, Alexander},
  journal={arXiv preprint arXiv:2102.09412},
  year={2021}
}

@book{gelman2006data,
  title={Data Analysis Using Regression and Multilevel/Hierarchical Models},
  author={Gelman, Andrew and Hill, Jennifer},
  year={2006},
  publisher={Cambridge University Press}
}

@article{franks2019flexible,
  title={Flexible sensitivity analysis for observational studies without observable implications},
  author={Franks, AlexanderM and D’Amour, Alexander and Feller, Avi},
  journal={Journal of the American Statistical Association},
  year={2019},
  publisher={Taylor \& Francis}
}

@inproceedings{witty2020causal,
  title={Causal inference using Gaussian processes with structured latent confounders},
  author={Witty, Sam and Takatsu, Kenta and Jensen, David and Mansinghka, Vikash},
  booktitle={International Conference on Machine Learning},
  pages={10313--10323},
  year={2020},
  organization={PMLR}
}



@inproceedings{oberst2019counterfactual,
  title={Counterfactual off-policy evaluation with gumbel-max structural causal models},
  author={Oberst, Michael and Sontag, David},
  booktitle={International Conference on Machine Learning},
  pages={4881--4890},
  year={2019},
  organization={PMLR}
}

@article{louizos2017causal,
  title={Causal effect inference with deep latent-variable models},
  author={Louizos, Christos and Shalit, Uri and Mooij, Joris and Sontag, David and Zemel, Richard and Welling, Max},
  journal={arXiv preprint arXiv:1705.08821},
  year={2017}
}

@inproceedings{kallus2019interval,
  title={Interval estimation of individual-level causal effects under unobserved confounding},
  author={Kallus, Nathan and Mao, Xiaojie and Zhou, Angela},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={2281--2290},
  year={2019},
  organization={PMLR}
}

@Misc{probprog2021instructions,
    title = {Formatting Instructions for {PROBPROG 2021} Abstracts},
    author = {van den Broeck, Guy and Murray, Lawrence and Tristan, Jean-Baptiste and van de Meent, Jan-Willem},
    year = {2021},
    howpublished = {\url{https://probprog.cc/2021/probprog-2021-style.zip}}
}
@inproceedings{witty2020,
    title={Bayesian Causal Inference via Probabilistic Program Synthesis},
    author={Sam Witty and Alexander Lew and David Jensen and Vikash Mansinghka},
    booktitle={Proceedings of the Second Conference on Probabilistic Programming},
    year={2020},
}
@Manual{Fear05,
  title =        {Publication quality tables in {\LaTeX}},
  author =       {Simon Fear},
  year =         2005,
  month =        apr,
  note =         {\url{http://www.ctan.org/pkg/booktabs}}
}

@book{lamport:latex,
author = "Leslie Lamport",
title = "\it {\LaTeX}: A Document Preparation System",
publisher = "Addison-Wesley",
address = "Reading, MA.",
year = 1986}

 @article{shpitser_2012,
title = {What Counterfactuals Can be Tested},
author = {Shpitser, Ilya and Pearl, Judea},
translator = {Pearl,},
url = {https://arxiv.org/abs/1206.5294},
year = {2012},
urldate = {2019-04-09},
journal = {Arxiv},
sciwheel-projects = {Causality and Y0-{SCUC}}
}

@inproceedings{winn2012causality,
  title={Causality with gates},
  author={Winn, John},
  booktitle={Artificial Intelligence and Statistics},
  pages={1314--1322},
  year={2012},
  organization={PMLR}
}

@book{pearl2001bayesian,
author = {Pearl, Judea},
year = {2001},
month = {01},
pages = {19-36},
title = {Bayesianism and Causality, or, Why I am Only a Half-Bayesian},
volume = {24},
isbn = {978-90-481-5920-8},
publisher = {Springer, Dordrecht},
doi = {10.1007/978-94-017-1586-7_2}
}


@article{ibeling_2019,
title = {On Open-Universe Causal Reasoning},
author = {Ibeling, Duligur and Icard, Thomas},
url = {https://arxiv.org/abs/1907.02170},
year = {2019},
month = {jul},
day = {4},
urldate = {2020-08-03},
journal = {arXiv},
sciwheel-projects = {Causality},
abstract = {We extend two kinds of causal models, structural equation models and simulation models, to infinite variable spaces. This enables a semantics for conditionals founded on a calculus of intervention, and axiomatization of causal reasoning for rich, expressive generative models---including those in which a causal representation exists only implicitly---in an open-universe setting. Further, we show that under suitable restrictions the two kinds of models are equivalent, perhaps surprisingly as their axiomatizations differ substantially in the general case. We give a series of complete axiomatizations in which the open-universe nature of the setting is seen to be essential.}
}

@article{lattimore_2019,
title = {Replacing the do-calculus with Bayes rule},
author = {Lattimore, Finnian and Rohde, David},
url = {https://arxiv.org/abs/1906.07125},
year = {2019},
month = {jun},
day = {17},
urldate = {2021-04-28},
journal = {arXiv},
sciwheel-projects = {Causality},
abstract = {The concept of causality has a controversial history. The question of whether it is possible to represent and address causal problems with probability theory, or if fundamentally new mathematics such as the do calculus is required has been hotly debated, e.g. Pearl (2001) states "the building blocks of our scientific and everyday knowledge are elementary facts such as "mud does not cause rain" and "symptoms do not cause disease" and those facts, strangely enough, cannot be expressed in the vocabulary of probability calculus". This has lead to a dichotomy between advocates of causal graphical modeling and the do calculus, and researchers applying Bayesian methods. In this paper we demonstrate that, while it is critical to explicitly model our assumptions on the impact of intervening in a system, provided we do so, estimating causal effects can be done entirely within the standard Bayesian paradigm. The invariance assumptions underlying causal graphical models can be encoded in ordinary Probabilistic graphical models, allowing causal estimation with Bayesian statistics, equivalent to the do calculus. Elucidating the connections between these approaches is a key step toward enabling the insights provided by each to be combined to solve real problems.}
}

@misc{bhattacharya2020semiparametric,
      title={Semiparametric Inference For Causal Effects In Graphical Models With Hidden Variables}, 
      author={Rohit Bhattacharya and Razieh Nabi and Ilya Shpitser},
      year={2020},
      eprint={2003.12659},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{brul_2018,
title = {Causal programming: inference with structural causal models as finding instances of a relation},
author = {Brulé, Joshua},
url = {https://arxiv.org/abs/1805.01960},
year = {2018},
month = {may},
day = {4},
urldate = {2020-12-21},
journal = {arXiv},
sciwheel-projects = {Causality},
abstract = {This paper proposes a causal inference relation and causal programming as general frameworks for causal inference with structural causal models. A tuple, \$\textbackslashlangle M, I, Q, F \textbackslashrangle\$, is an instance of the relation if a formula, \$F\$, computes a causal query, \$Q\$, as a function of known population probabilities, \$I\$, in every model entailed by a set of model assumptions, \$M\$. Many problems in causal inference can be viewed as the problem of enumerating instances of the relation that satisfy given criteria. This unifies a number of previously studied problems, including causal effect identification, causal discovery and recovery from selection bias. In addition, the relation supports formalizing new problems in causal inference with structural causal models, such as the problem of research design. Causal programming is proposed as a further generalization of causal inference as the problem of finding optimal instances of the relation, with respect to a cost function.}
}

@article{witty_2021,
title = {A Simulation-Based Test of Identifiability for Bayesian Causal Inference},
author = {Witty, Sam and Jensen, David and Mansinghka, Vikash},
url = {https://arxiv.org/abs/2102.11761},
year = {2021},
month = {feb},
day = {23},
urldate = {2021-03-04},
journal = {arXiv},
sciwheel-projects = {Causality},
abstract = {This paper introduces a procedure for testing the identifiability of Bayesian models for causal inference. Although the do-calculus is sound and complete given a causal graph, many practical assumptions cannot be expressed in terms of graph structure alone, such as the assumptions required by instrumental variable designs, regression discontinuity designs, and within-subjects designs. We present simulation-based identifiability ({SBI}), a fully automated identification test based on a particle optimization scheme with simulated observations. This approach expresses causal assumptions as priors over functions in a structural causal model, including flexible priors using Gaussian processes. We prove that {SBI} is asymptotically sound and complete, and produces practical finite-sample bounds. We also show empirically that {SBI} agrees with known results in graph-based identification as well as with widely-held intuitions for designs in which graph-based methods are inconclusive.}
}

@article{ghassami_2018,
title = {Budgeted Experiment Design for Causal Structure Learning},
author = {Ghassami, {AmirEmad} and Salehkaleybar, and Kiyavash, and Bareinboim,},
url = {http://dx.doi.org/10.1093/bioinformatics/btq632},
year = {2018},
month = {jun},
day = {1},
urldate = {2019-05-02},
journal = {Bioinformatics},
volume = {27},
number = {2},
doi = {10.1093/bioinformatics/btq632},
pmid = {21075743},
pmcid = {PMC3018820},
sciwheel-projects = {Causality and {COVID}-19},
abstract = {We study the problem of causal structure learning when the experimenter is limited to perform at mostknon-adaptive experiments of size1. We formulate the problem of finding the best intervention target set as an optimization problem, which aims to maximize the average number of edges whose directions are resolved. We prove that the corresponding objective function is submodular and a greedy algorithm suffices to achieve(1 1 e )approximation of the optimal value. We further present an accelerated variant of the greedy algorithm, which can lead to orders of magnitude performance speedup. We validate our proposed approach on synthetic and real graphs. The results show that compared to the purely observational setting, our algorithm orients the majority of the edges through a considerably small number of interventions.}
}
@article{lindgren_2018,
title = {[1810.11867v1] Experimental Design for Cost-Aware Learning of Causal Graphs},
author = {Lindgren, Erik M. and Kocaoglu, Murat and Dimakis, Alexandros G. and Vishwanath, Sriram},
url = {https://arxiv.org/abs/1810.11867v1},
year = {2018},
month = {oct},
day = {28},
urldate = {2019-04-14},
journal = {arXiv},
sciwheel-projects = {Causality},
abstract = {We consider the minimum cost intervention design problem: Given the essential graph of a causal graph and a cost to intervene on a variable, identify the set of interventions with minimum total cost that can learn any causal graph with the given essential graph. We first show that this problem is {NP}-hard. We then prove that we can achieve a constant factor approximation to this problem with a greedy algorithm. We then constrain the sparsity of each intervention. We develop an algorithm that returns an intervention design that is nearly optimal in terms of size for sparse graphs with sparse interventions and we discuss how to use it when there are costs on the vertices.}
}
@article{imai_2013,
title = {Experimental designs for identifying causal mechanisms},
author = {Imai, Kosuke and Tingley, Dustin and Yamamoto, Teppei},
pages = {5-51},
url = {http://doi.wiley.com/10.1111/j.1467-{985X}.2012.01032.x},
year = {2013},
month = {jan},
urldate = {2020-11-21},
journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
volume = {176},
number = {1},
issn = {09641998},
doi = {10.1111/j.1467-{985X}.2012.01032.x},
sciwheel-projects = {Causality}
}
@article{agrawal_2019,
title = {{ABCD}-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery},
author = {Agrawal, Raj and Squires, Chandler and Yang, Karren and Shanmugam, Karthik and Uhler, Caroline},
url = {https://arxiv.org/abs/1902.10347},
year = {2019},
month = {feb},
day = {27},
urldate = {2020-07-23},
journal = {arXiv},
sciwheel-projects = {Causality},
abstract = {Determining the causal structure of a set of variables is critical for both scientific inquiry and decision-making. However, this is often challenging in practice due to limited interventional data. Given that randomized experiments are usually expensive to perform, we propose a general framework and theory based on optimal Bayesian experimental design to select experiments for targeted causal discovery. That is, we assume the experimenter is interested in learning some function of the unknown graph (e.g., all descendants of a target node) subject to design constraints such as limits on the number of samples and rounds of experimentation. While it is in general computationally intractable to select an optimal experimental design strategy, we provide a tractable implementation with provable guarantees on both approximation and optimization quality based on submodularity. We evaluate the efficacy of our proposed method on both synthetic and real datasets, thereby demonstrating that our method realizes considerable performance gains over baseline strategies such as random sampling.}
}

@article{pawlowski2020deep,
  title={Deep structural causal models for tractable counterfactual inference},
  author={Pawlowski, Nick and Castro, Daniel C and Glocker, Ben},
  journal={arXiv preprint arXiv:2006.06485},
  year={2020}
}

@article{blei_2014,
title = {Build, Compute, Critique, Repeat: Data Analysis with Latent Variable Models},
author = {Blei, David M.},
pages = {203-232},
url = {http://www.annualreviews.org/doi/abs/10.1146/annurev-statistics-022513-115657},
year = {2014},
month = {jan},
day = {3},
urldate = {2020-02-06},
journal = {Annual review of statistics and its application},
volume = {1},
number = {1},
issn = {2326-8298},
doi = {10.1146/annurev-statistics-022513-115657},
sciwheel-projects = {Causality},
abstract = {We survey latent variable models for solving data-analysis problems. A latent variable model is a probabilistic model that encodes hidden patterns in the data. We uncover these patterns from their conditional distribution and use them to summarize data and form predictions. Latent variable models are important in many fields, including computational biology, natural language processing, and social network analysis. Our perspective is that models are developed iteratively: We build a model, use it to analyze data, assess how it succeeds and fails, revise it, and repeat. We describe how new research has transformed these essential activities. First, we describe probabilistic graphical models, a language for formulating latent variable models. Second, we describe mean field variational inference, a generic algorithm for approximating conditional distributions. Third, we describe how to use our analyses to solve problems: exploring the data, forming predictions, and pointing us in the direction of improved models.}
}

@article{pearl_2019,
title = {The seven tools of causal inference, with reflections on machine learning},
author = {Pearl, Judea},
pages = {54-60},
url = {http://dl.acm.org/citation.cfm?doid=3314328.3241036},
year = {2019},
month = {feb},
day = {21},
urldate = {2019-03-08},
journal = {Communications of the {ACM}},
volume = {62},
number = {3},
issn = {00010782},
doi = {10.1145/3241036},
sciwheel-projects = {Causality and {DL} and Y0-{SCUC}},
abstract = {The kind of causal inference seen in natural human thought can be "algorithmitized" to help produce human-level machine intelligence.}
}

@misc{shalit2017estimating,
      title={Estimating individual treatment effect: generalization bounds and algorithms}, 
      author={Uri Shalit and Fredrik D. Johansson and David Sontag},
      year={2017},
      eprint={1606.03976},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@book{pearl,
author = {Pearl, Judea},
title = {Causality: Models, Reasoning and Inference},
year = {2009},
isbn = {052189560X},
publisher = {Cambridge University Press},
address = {USA},
edition = {2nd},
abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studyi†ng the relationships between causal connections and statistical associations. The book will open the way for including causal analysis in the standard curricula of statistics, artificial intelligence, business, epidemiology, social sciences, and economics. Students in these fields will find natural models, simple inferential procedures, and precise mathematical definitions of causal concepts that traditional texts have evaded or made unduly complicated. The first edition of Causality has led to a paradigmatic change in the way that causality is treated in statistics, philosophy, computer science, social science, and economics. Cited in more than 3,000 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interests to students and professionals in a wide variety of fields. Anyone who wishes to elucidate meaningful relationships from data, predict effects of actions and policies, assess explanations of reported events, or form theories of causal understanding and causal speech will find this book stimulating and invaluable.}
}

@inproceedings{koppel_2020,
title = {Demystifying dependence},
author = {Koppel, James and Jackson, Daniel},
pages = {48-64},
publisher = {ACM},
url = {https://dl.acm.org/doi/10.1145/3426428.3426916},
year = {2020},
month = {nov},
day = {18},
urldate = {2020-11-27},
isbn = {9781450381789},
doi = {10.1145/3426428.3426916},
address = {New York, {NY}, {USA}},
sciwheel-projects = {Causality},
booktitle = {Proceedings of the 2020 {ACM} {SIGPLAN} International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software}
}

@article{bingham2018pyro,
author = {Bingham, Eli and Chen, Jonathan P. and Jankowiak, Martin and Obermeyer, Fritz and
          Pradhan, Neeraj and Karaletsos, Theofanis and Singh, Rohit and Szerlip, Paul and
          Horsfall, Paul and Goodman, Noah D.},
title = {{Pyro: Deep Universal Probabilistic Programming}},
journal = {Journal of Machine Learning Research},
year = {2018}
}

@techreport{tavares_2020,
title = {A Language for Counterfactual Generative Models},
author = {Tavares, Zenna and Koppel, James and Zhang, Xin and Solar-Lezama, Armando},
publisher = {{MIT} Technical Report},
url = {http://www.jameskoppel.com/publication/omega/},
year = {2020},
urldate = {2020-12-13},
sciwheel-projects = {Causality}
}

@article{perov_2019,
title = {{MultiVerse}: Causal Reasoning using Importance Sampling in Probabilistic Programming},
author = {Perov, Yura and Graham, Logan and Gourgoulias, Kostis and Richens, Jonathan G. and Lee, Ciarán M. and Baker, Adam and Johri, Saurabh},
url = {https://arxiv.org/abs/1910.08091},
year = {2019},
month = {oct},
day = {17},
urldate = {2020-02-05},
journal = {arXiv},
sciwheel-projects = {Causality},
abstract = {We elaborate on using importance sampling for causal reasoning, in particular for counterfactual inference. We show how this can be implemented natively in probabilistic programming. By considering the structure of the counterfactual query, one can significantly optimise the inference process. We also consider design choices to enable further optimisations. We introduce {MultiVerse}, a probabilistic programming prototype engine for approximate causal reasoning. We provide experimental results and compare with Pyro, an existing probabilistic programming framework with some of causal reasoning tools.}
}
@article{zucker_2021,
title = {Leveraging Structured Biological Knowledge for Counterfactual Inference: a Case Study of Viral Pathogenesis - {IEEE} Journals \& Magazine},
author = {Zucker, Jeremy and Mohammad-Taheri, Sara and Paneri, Kaushal and Bhargava, Somya and Kolambkar, Pallavi and Bakker, Craig and Teuton, Jeremy and Hoyt, Charles Tapley and Oxford, Kristie and Ness, Robert and Vitek, Olga},
url = {https://ieeexplore.ieee.org/document/9328353},
year = {2021},
month = {jan},
day = {19},
urldate = {2021-01-20},
journal = {{IEEE} Transactions on Big Data},
sciwheel-projects = {{COVID}-19 and Your publications},
abstract = {Counterfactual inference is a useful tool for comparing outcomes of interventions on complex systems. It requires us to represent the system in form of a structural causal model, complete with a causal diagram, probabilistic assumptions on exogenous variables, and functional assignments. Specifying such models can be extremely difficult in practice. The process requires substantial domain expertise, and does not scale easily to large systems, multiple systems, or novel system modifications. At the same time, many application domains, such as molecular biology, are rich in structured causal knowledge that is qualitative in nature. This manuscript proposes a general approach for querying a causal knowledge graph with a causal question and converting the qualitative result into a quantitative structural causal model that can learn from data to answer the question. We demonstrate the feasibility, accuracy and versatility of this approach using two case studies in systems biology. The first demonstrates the appropriateness of the underlying assumptions and the accuracy of the results. The second demonstrates the versatility of the approach by querying a knowledge base for the molecular determinants of a {SARS}-{CoV}-2-induced cytokine storm and performing counterfactual inference to predict the causal effect of medical countermeasures for severely ill {COVID}-19 patients.}
}
@incollection{balke_1994,
booktitle = {Uncertainty Proceedings 1994},
title = {Counterfactual probabilities: computational methods, bounds and applications},
author = {Balke, Alexander and Pearl, Judea},
pages = {46-54},
publisher = {Elsevier},
url = {https://linkinghub.elsevier.com/retrieve/pii/B9781558603325500110},
year = {1994},
urldate = {2020-07-23},
isbn = {9781558603325},
doi = {10.1016/B978-1-55860-332-5.50011-0},
sciwheel-projects = {Causality},
abstract = {Evaluation of counterfactual queries (e.g., "If A were true, would C have been true?") is important to fault diagnosis, planning, and determination of liability. In this paper we present methods for computing the probabilities of such queries using the formulation proposed in [Balke and Pearl, 1994], where the antecedent of the query is interpreted as an external action that forces the proposition A to be true. When a prior probability is available on the causal mechanisms governing the domain, counterfactual probabilities can be evaluated precisely. However, when causal knowledge is specified as conditional probabilities on the observables, only bounds can computed. This paper develops techniques for evaluating these bounds, and demonstrates their use in two applications: (1) the determination of treatment efficacy from studies in which subjects may choose their own treatment, and (2) the determination of liability in product-safety litigation.}
}
@article{vennekens_2009,
title = {{CP}-logic: A language of causal probabilistic events and its relation to logic programming},
author = {Vennekens, {JOOST} and Denecker, {MARC} and Bruynooghe, {MAURICE}},
pages = {245-308},
url = {http://www.journals.cambridge.org/{abstract\_S1471068409003767}},
year = {2009},
month = {may},
urldate = {2021-05-02},
journal = {Theory and Practice of Logic Programming},
volume = {9},
number = {03},
issn = {1471-0684},
doi = {10.1017/S1471068409003767},
sciwheel-projects = {Causality},
abstract = {This paper develops a logical language for representing probabilistic causal laws. Our interest in such a language is two-fold. First, it can be motivated as a fundamental study of the representation of causal knowledge. Causality has an inherent dynamic aspect, which has been studied at the semantical level by Shafer in his framework of probability trees. In such a dynamic context, where the evolution of a domain over time is considered, the idea of a causal law as something which guides this evolution is quite natural. In our formalization, a set of probabilistic causal laws can be used to represent a class of probability trees in a concise, flexible and modular way. In this way, our work extends Shafer's by offering a convenient logical representation for his semantical objects. Second, this language also has relevance for the area of probabilistic logic programming. In particular, we prove that the formal semantics of a theory in our language can be equivalently defined as a probability distribution over the well-founded models of certain logic programs, rendering it formally quite similar to existing languages such as {ICL} or {PRISM}. Because we can motivate and explain our language in a completely self-contained way as a representation of probabilistic causal laws, this provides a new way of explaining the intuitions behind such probabilistic logic programs: we can say precisely which knowledge such a program expresses, in terms that are equally understandable by a non-logician. Moreover, we also obtain an additional piece of knowledge representation methodology for probabilistic logic programs, by showing how they can express probabilistic causal laws.}
}
@article{baral_2007,
title = {Using the probabilistic logic programming language P-log for causal and counterfactual reasoning and non-naive conditioning},
author = {Baral, Chitta and Hunsaker, Matt},
url = {https://asu.pure.elsevier.com/en/publications/using-the-probabilistic-logic-programming-language-p-log-for-caus},
year = {2007},
urldate = {2021-05-02},
journal = {{IJCAI} : proceedings of the conference / sponsored by the International Joint Conferences on Artificial Intelligence},
sciwheel-projects = {Causality},
abstract = {P-log is a probabilistic logic programming language, which combines both logic programming style knowledge representation and probabilistic reasoning. In earlier papers various advantages of P-log have been discussed. In this paper we further elaborate on the {KR} prowess of P-log by showing that: (i) it can be used for causal and counterfactual reasoning and (ii) it provides an elaboration tolerant way for non-naive conditioning.}
}
@article{genewein_2020,
title = {Algorithms for Causal Reasoning in Probability Trees},
author = {Genewein, Tim and {McGrath}, Tom and Déletang, Grégoire and Mikulik, Vladimir and Martic, Miljan and Legg, Shane and Ortega, Pedro A.},
url = {https://arxiv.org/abs/2010.12237},
year = {2020},
month = {oct},
day = {23},
urldate = {2020-10-28},
journal = {arXiv},
sciwheel-projects = {Causality},
abstract = {Probability trees are one of the simplest models of causal generative processes. They possess clean semantics and -- unlike causal Bayesian networks -- they can represent context-specific causal dependencies, which are necessary for e.g. causal induction. Yet, they have received little attention from the {AI} and {ML} community. Here we present concrete algorithms for causal reasoning in discrete probability trees that cover the entire causal hierarchy (association, intervention, and counterfactuals), and operate on arbitrary propositional and causal events. Our work expands the domain of causal reasoning to a very general class of discrete stochastic processes.}
}
@article{everitt_2021,
title = {Agent Incentives: A Causal Perspective},
author = {Everitt, Tom and Carey, Ryan and Langlois, Eric and Ortega, Pedro A and Legg, Shane},
url = {https://arxiv.org/abs/2102.01685},
year = {2021},
month = {feb},
day = {2},
urldate = {2021-03-13},
journal = {arXiv},
sciwheel-projects = {Causality},
abstract = {We present a framework for analysing agent incentives using causal influence diagrams. We establish that a well-known criterion for value of information is complete. We propose a new graphical criterion for value of control, establishing its soundness and completeness. We also introduce two new concepts for incentive analysis: response incentives indicate which changes in the environment affect an optimal decision, while instrumental control incentives establish whether an agent can influence its utility via a variable X. For both new concepts, we provide sound and complete graphical criteria. We show by example how these results can help with evaluating the safety and fairness of an {AI} system.}
}
@article{amin_2021,
title = {A Pearl pearl, or How to teach a good old fashioned AI new tricks},
author = {Amin, Nada and Byrd, William and Cottam, Joseph and Parent, Marc-Antoine and Zucker, Jeremy},
url = {https://github.com/namin/pearl-pearl},
year = {2021},
month = {May},
day = {6},
urldate = {2021-05-06},
journal = {arXiv},
abstract = {Causal reasoning is a basic component of human intelligence.
However, causal information has proven difficult for AI and machine learning applications to incorporate.
This omission hinders such systems as they cannot take advantage of this important information during reasoning or explanation. 
Recent advances in formal causal reasoning open new possibilities to include causal reasoning in such systems.
We show that causal reasoning can be represented in a Truth Maintenance Systems (TMS), 
  and thus enable expert systems to reason causally.
The integration is 
   complete (demonstrated by the  ability to answer all six `Firing Squad' questions), 
   simple (only 200 lines of Common Lisp),
   and practical (through an application to medical diagnosis).
This paper outlines the implementation and shows how to use a TMS augmented with causal reasoning.}
}

@article{schuler_2017,
title = {Targeted maximum likelihood estimation for causal inference in observational studies.},
author = {Schuler, Megan S and Rose, Sherri},
pages = {65-73},
url = {http://dx.doi.org/10.1093/aje/kww165},
year = {2017},
month = {jan},
day = {1},
urldate = {2018-03-30},
journal = {American Journal of Epidemiology},
volume = {185},
number = {1},
doi = {10.1093/aje/kww165},
pmid = {27941068},
sciwheel-projects = {Causality},
abstract = {Estimation of causal effects using observational data continues to grow in popularity in the epidemiologic literature. While many applications of causal effect estimation use propensity score methods or G-computation, targeted maximum likelihood estimation ({TMLE}) is a well-established alternative method with desirable statistical properties. {TMLE} is a doubly robust maximum-likelihood-based approach that includes a secondary "targeting" step that optimizes the bias-variance tradeoff for the target parameter. Under standard causal assumptions, estimates can be interpreted as causal effects. Because {TMLE} has not been as widely implemented in epidemiologic research, we aim to provide an accessible presentation of {TMLE} for applied researchers. We give step-by-step instructions for using {TMLE} to estimate the average treatment effect in the context of an observational study. We discuss conceptual similarities and differences between {TMLE} and 2 common estimation approaches (G-computation and inverse probability weighting) and present findings on their relative performance using simulated data. Our simulation study compares methods under parametric regression misspecification; our results highlight {TMLE}'s property of double robustness. Additionally, we discuss best practices for {TMLE} implementation, particularly the use of ensembled machine learning algorithms. Our simulation study demonstrates all methods using super learning, highlighting that incorporation of machine learning may outperform parametric regression in observational data settings. \copyright The Author 2016. Published by Oxford University Press on behalf of the Johns Hopkins Bloomberg School of Public Health. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.}
}
@incollection{kennedy_2014,
booktitle = {Wiley statsref: statistics reference online},
title = {Semiparametric Theory},
author = {Kennedy, Edward H.},
editor = {Balakrishnan, N. and Colton, Theodore and Everitt, Brian and Piegorsch, Walter and Ruggeri, Fabrizio and Teugels, Jozef L.},
pages = {1-7},
publisher = {John Wiley \& Sons, Ltd},
url = {http://doi.wiley.com/10.1002/9781118445112.stat08083},
year = {2014},
month = {apr},
day = {14},
urldate = {2020-12-21},
isbn = {9781118445112},
doi = {10.1002/9781118445112.stat08083},
address = {Chichester, {UK}},
sciwheel-projects = {Causality},
abstract = {In this paper we give a brief review of semiparametric theory, using as a running example the common problem of estimating an average causal effect. Semiparametric models allow at least part of the data-generating process to be unspecified and unrestricted, and can often yield robust estimators that nonetheless behave similarly to those based on parametric likelihood assumptions, e.g., fast rates of convergence to normal limiting distributions. We discuss the basics of semiparametric theory, focusing on influence functions.}
}
@inproceedings{tran_2004,
title = {Encoding Probabilistic Causal Model in Probabilistic Action Language},
author = {Tran, Nam and Baral, Chitta},
publisher = {AAAI},
url = {https://aaai.org/Library/{AAAI}/2004/aaai04-049.php},
year = {2004},
urldate = {2021-05-02},
sciwheel-projects = {Causality},
abstract = {Pearl's probabilistic causal model has been used in many domains to reason about causality. Pearl's treatment of actions is very different from the way actions are represented explicitly in action languages. In this paper we show how to {encode Pearl's} probabilistic causal model in the action language {PAL thus} relating this two distinct approaches to reasoning about actions.}
}
@inproceedings{laurent_2018,
title = {Counterfactual resimulation for causal analysis of rule-based models \textbar Proceedings of the 27th International Joint Conference on Artificial Intelligence},
author = {Laurent, Jonathan and Yang, Jean and Fontana, Walter},
publisher = {International Joint Conferences on Artificial Intelligence},
url = {https://dl.acm.org/doi/abs/10.5555/3304889.3304920},
year = {2018},
month = {jul},
urldate = {2020-12-10},
sciwheel-projects = {Causality and {COVID}-19},
abstract = {Models based on rules that express local and heterogeneous mechanisms of stochastic interactions between structured agents are an important tool for investigating the dynamical behavior of complex systems, especially in molecular biology. Given a simulated trace of events, the challenge is to construct a causal diagram that explains how a phenomenon of interest occurred. Counterfactual analysis can provide distinctive insights, but its standard definition is not applicable in rule-based models because they are not readily expressible in terms of structural equations. We provide a semantics of counterfactual statements that addresses this challenge by sampling counterfactual trajectories that are probabilistically as close to the factual trace as a given intervention permits them to be. We then show how counterfactual dependencies give rise to explanations in terms of relations of enablement and prevention between events.}
}
@article{dowhypaper,
title={DoWhy: An End-to-End Library for Causal Inference},
author={Sharma, Amit and Kiciman, Emre},
journal={arXiv preprint arXiv:2011.04216},
year={2020}
}
@article{textor_2016,
title = {Robust causal inference using directed acyclic graphs: the R package 'dagitty'.},
author = {Textor, Johannes and van der Zander, Benito and Gilthorpe, Mark S and Liskiewicz, Maciej and Ellison, George Th},
pages = {1887-1894},
url = {http://dx.doi.org/10.1093/ije/dyw341},
year = {2016},
month = {dec},
day = {1},
urldate = {2021-02-24},
journal = {International Journal of Epidemiology},
volume = {45},
number = {6},
doi = {10.1093/ije/dyw341},
pmid = {28089956},
sciwheel-projects = {Causality},
abstract = {Directed acyclic graphs ({DAGs}), which offer systematic representations of causal relationships, have become an established framework for the analysis of causal inference in epidemiology, often being used to determine covariate adjustment sets for minimizing confounding bias. {DAGitty} is a popular web application for drawing and analysing {DAGs}. Here we introduce the R package 'dagitty', which provides access to all of the capabilities of the {DAGitty} web application within the R platform for statistical computing, and also offers several new functions. We describe how the R package 'dagitty' can be used to: evaluate whether a {DAG} is consistent with the dataset it is intended to represent; enumerate 'statistically equivalent' but causally different {DAGs}; and identify exposure-outcome adjustment sets that are valid for causally different but statistically equivalent {DAGs}. This functionality enables epidemiologists to detect causal misspecifications in {DAGs} and make robust inferences that remain valid for a range of different {DAGs}. The R package 'dagitty' is available through the comprehensive R archive network ({CRAN}) at [https://cran.r-project.org/web/packages/dagitty/]. The source code is available on github at [https://github.com/jtextor/dagitty]. The web application '{DAGitty}' is free software, licensed under the {GNU} general public licence ({GPL}) version 2 and is available at [http://dagitty.net/]. \copyright The Author 2017; all rights reserved. Published by Oxford University Press on behalf of the International Epidemiological Association.}
}
@misc{pgmpy,
title = {pgmpy},
url = {https://pgmpy.org/index.html},
urldate = {2021-05-02},
year = {2021},
sciwheel-projects = {Causality},
type = {WEBSITE}
}

@article{bareinboim_2016,
title = {Causal inference and the data-fusion problem.},
author = {Bareinboim, Elias and Pearl, Judea},
pages = {7345-7352},
url = {http://dx.doi.org/10.1073/pnas.1510507113},
year = {2016},
month = {jul},
day = {5},
urldate = {2019-03-08},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
volume = {113},
number = {27},
doi = {10.1073/pnas.1510507113},
pmid = {27382148},
pmcid = {PMC4941504},
sciwheel-projects = {Causality and Y0-{SCUC}},
abstract = {We review concepts, principles, and tools that unify current approaches to causal analysis and attend to new challenges presented by big data. In particular, we address the problem of data fusion-piecing together multiple datasets collected under heterogeneous conditions (i.e., different populations, regimes, and sampling methods) to obtain valid answers to queries of interest. The availability of multiple heterogeneous datasets presents new opportunities to big data analysts, because the knowledge that can be acquired from combined data would not be possible from any individual source alone. However, the biases that emerge in heterogeneous environments require new analytical tools. Some of these biases, including confounding, sampling selection, and cross-population biases, have been addressed in isolation, largely in restricted parametric models. We here present a general, nonparametric framework for handling these biases and, ultimately, a theoretical solution to the problem of data fusion in causal inference tasks.}
}

@inproceedings{hal-02911619,
  TITLE = {{aGrUM/pyAgrum : a Toolbox to Build Models and Algorithms for Probabilistic Graphical Models in Python}},
  AUTHOR = {Ducamp, Gaspard and Bonnard, Philippe and De Sainte Marie, Christian and Wuillemin, Pierre-Henri},
  URL = {https://hal.archives-ouvertes.fr/hal-02911619},
  BOOKTITLE = {{10th International Conference on Probabilistic Graphical Models}},
  ADDRESS = {Sk{{\o}}rping, Denmark},
  SERIES = {Proceedings of Machine Learning Research},
  VOLUME = {138},
  PAGES = {173-184},
  YEAR = {2020},
  MONTH = Sep,
  KEYWORDS = {Bayesian Networks ; Probabilistic Graphical Models ; c++ ; python},
  PDF = {https://hal.archives-ouvertes.fr/hal-02911619/file/paper39.pdf},
  HAL_ID = {hal-02911619},
  HAL_VERSION = {v1},
}
@article{tikka_2017,
title = {Identifying Causal Effects with {theR} Packagecausaleffect},
author = {Tikka, Santtu and Karvanen, Juha},
pages = {1-30},
url = {http://www.jstatsoft.org/v76/i12/},
year = {2017},
urldate = {2019-12-28},
journal = {Journal of statistical software},
volume = {76},
number = {12},
issn = {1548-7660},
doi = {10.18637/jss.v076.i12},
sciwheel-projects = {Causality},
abstract = {Do-calculus is concerned with estimating the interventional distribution of an action from the observed joint probability distribution of the variables in a given causal structure. All identifiable causal effects can be derived using the rules of do-calculus, but the rules themselves do not give any direct indication whether the effect in question is identifiable or not. Shpitser and Pearl (2006b) constructed an algorithm for identifying joint interventional distributions in causal models, which contain unobserved variables and induce directed acyclic graphs. This algorithm can be seen as a repeated application of the rules of do-calculus and known properties of probabilities, and it ultimately either derives an expression for the causal distribution, or fails to identify the effect, in which case the effect is non-identifiable. In this paper, the R package causaleffect is presented, which provides an implementation of this algorithm. Functionality of causaleffect is also demonstrated through examples.}
}
@misc{y0,
title = {$Y_0$ Documentation },
author = {Zucker, Jeremy and Cottam, Joseph and Hoyt, Charles Tapley and Bakker, Craig and Weems, Zachary},
url = {https://y0.readthedocs.io/en/latest/},
urldate = {2021-05-02},
year = {2021},
sciwheel-projects = {Causality},
type = {WEBSITE}
}

@article{richardson2013single,
  title={Single world intervention graphs (SWIGs): A unification of the counterfactual and graphical approaches to causality},
  author={Richardson, Thomas S and Robins, James M},
  journal={Center for the Statistics and the Social Sciences, University of Washington Series. Working Paper},
  volume={128},
  number={30},
  pages={2013},
  year={2013}
}

@article{kingma2015variational,
  title={Variational dropout and the local reparameterization trick},
  author={Kingma, Diederik P and Salimans, Tim and Welling, Max},
  journal={arXiv preprint arXiv:1506.02557},
  year={2015}
}
@article{ness2019integrating,
  title={Integrating Markov processes with structural causal modeling enables counterfactual inference in complex systems},
  author={Ness, Robert Osazuwa and Paneri, Kaushal and Vitek, Olga},
  journal={arXiv preprint arXiv:1911.02175},
  year={2019}
}

@article{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}
