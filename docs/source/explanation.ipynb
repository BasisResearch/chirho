{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import contextlib\n",
    "import collections\n",
    "from typing import Callable, Iterable, TypeVar, Mapping, List, Dict\n",
    "\n",
    "import random\n",
    "\n",
    "import pyro\n",
    "import torch  # noqa: F401\n",
    "\n",
    "from chirho.counterfactual.handlers.selection import get_factual_indices\n",
    "from chirho.indexed.ops import IndexSet, cond, gather, indices_of, scatter\n",
    "\n",
    "S = TypeVar(\"S\")\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "import pyro\n",
    "import chirho\n",
    "import pyro.distributions as dist\n",
    "import pyro.infer\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from chirho.counterfactual.handlers.counterfactual import (MultiWorldCounterfactual,\n",
    "        Preemptions)\n",
    "from chirho.counterfactual.handlers.explanation import (\n",
    "    SearchForCause,\n",
    "    consequent_differs,\n",
    "    random_intervention,\n",
    "    undo_split,\n",
    "    uniform_proposal,\n",
    ")\n",
    "from chirho.counterfactual.ops import preempt, split\n",
    "from chirho.indexed.ops import IndexSet, gather, indices_of\n",
    "from chirho.observational.handlers.condition import Factors, condition\n",
    "from chirho.interventional.ops import Intervention, intervene\n",
    "from chirho.interventional.handlers import do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def ExplainCauses(\n",
    "    antecedents: Mapping[str, Intervention[T]]\n",
    "    | Mapping[str, pyro.distributions.constraints.Constraint],\n",
    "    witnesses: Mapping[str, Intervention[T]] | Iterable[str],\n",
    "    consequents: Mapping[str, Callable[[T], float | torch.Tensor]]\n",
    "    | Iterable[str],\n",
    "    *,\n",
    "    antecedent_bias: float = 0.0,\n",
    "    witness_bias: float = 0.0,\n",
    "    consequent_eps: float = -1e8,\n",
    "    antecedent_prefix: str = \"__antecedent_\",\n",
    "    witness_prefix: str = \"__witness_\",\n",
    "    consequent_prefix: str = \"__consequent_\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Effect handler for causal explanation.\n",
    "\n",
    "    :param antecedents: A mapping from antecedent names to interventions.\n",
    "    :param witnesses: A mapping from witness names to interventions.\n",
    "    :param consequents: A mapping from consequent names to factor functions.\n",
    "    \"\"\"\n",
    "    if isinstance(\n",
    "        next(iter(antecedents.values())),\n",
    "        pyro.distributions.constraints.Constraint,\n",
    "    ):\n",
    "        antecedents = {\n",
    "            a: random_intervention(s, name=f\"{antecedent_prefix}_proposal_{a}\")\n",
    "            for a, s in antecedents.items()\n",
    "        }\n",
    "\n",
    "    if not isinstance(witnesses, collections.abc.Mapping):\n",
    "        witnesses = {\n",
    "            w: undo_split(antecedents=list(antecedents.keys()))\n",
    "            for w in witnesses\n",
    "        }\n",
    "\n",
    "    if not isinstance(consequents, collections.abc.Mapping):\n",
    "        consequents = {\n",
    "            c: consequent_differs(\n",
    "                antecedents=list(antecedents.keys()), eps=consequent_eps\n",
    "            )\n",
    "            for c in consequents\n",
    "        }\n",
    "\n",
    "    if len(consequents) == 0:\n",
    "        raise ValueError(\"must have at least one consequent\")\n",
    "\n",
    "    if len(antecedents) == 0:\n",
    "        raise ValueError(\"must have at least one antecedent\")\n",
    "\n",
    "    if set(consequents.keys()) & set(antecedents.keys()):\n",
    "        raise ValueError(\n",
    "            \"consequents and possible antecedents must be disjoint\"\n",
    "        )\n",
    "\n",
    "    if set(consequents.keys()) & set(witnesses.keys()):\n",
    "        raise ValueError(\"consequents and possible witnesses must be disjoint\")\n",
    "\n",
    "    antecedent_handler = SearchForCause(\n",
    "        actions=antecedents, bias=antecedent_bias, prefix=antecedent_prefix\n",
    "    )\n",
    "    witness_handler = Preemptions(\n",
    "        actions=witnesses, bias=witness_bias, prefix=witness_prefix\n",
    "    )\n",
    "    consequent_handler = Factors(factors=consequents, prefix=consequent_prefix)\n",
    "\n",
    "    with antecedent_handler, witness_handler, consequent_handler:\n",
    "        with pyro.poutine.trace() as logging_tr:\n",
    "            yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_observed(value, antecedents, witnesses):\n",
    "    _indices = [\n",
    "            i for i in list(antecedents.keys()) + witnesses if i in indices_of(value, event_dim=0)\n",
    "        ]\n",
    "    _int_can = gather(\n",
    "    value, IndexSet(**{i: {0} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "def gather_intervened(value, antecedents, witnesses):\n",
    "    _indices = [\n",
    "            i for i in list(antecedents.keys()) + witnesses if i in indices_of(value, event_dim=0)\n",
    "        ]\n",
    "    _int_can = gather(\n",
    "    value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "def get_table(trace, mwc, antecedents, witnesses, consequents):\n",
    "\n",
    "    values_table = {}\n",
    "    nodes = trace.trace.nodes\n",
    "\n",
    "    if isinstance(antecedents, dict):\n",
    "        antecedents = list(antecedents.keys())\n",
    "\n",
    "    with mwc:\n",
    "\n",
    "        for antecedent_str in antecedents:\n",
    "                \n",
    "            obs_ant = gather_observed(nodes[antecedent_str][\"value\"], antecedents, witnesses)\n",
    "            int_ant = gather_intervened(nodes[antecedent_str][\"value\"], antecedents, witnesses)\n",
    "\n",
    "            values_table[f\"{antecedent_str}_obs\"] = obs_ant.squeeze().tolist()\n",
    "            values_table[f\"{antecedent_str}_int\"] = int_ant.squeeze().tolist()\n",
    "            \n",
    "            apr_ant = nodes[f\"__antecedent_{antecedent_str}\"][\"value\"]\n",
    "            values_table[f\"apr_{antecedent_str}\"] = apr_ant.squeeze().tolist()\n",
    "            \n",
    "            values_table[f\"apr_{antecedent_str}_lp\"] = nodes[f\"__antecedent_{antecedent_str}\"][\"fn\"].log_prob(apr_ant)\n",
    "\n",
    "        if witnesses:\n",
    "            for candidate in witnesses:\n",
    "                obs_candidate = gather_observed(nodes[candidate][\"value\"], antecedents, witnesses)\n",
    "                int_candidate = gather_intervened(nodes[candidate][\"value\"], antecedents, witnesses)\n",
    "                values_table[f\"{candidate}_obs\"] = obs_candidate.squeeze().tolist()\n",
    "                values_table[f\"{candidate}_int\"] = int_candidate.squeeze().tolist()\n",
    "\n",
    "                wpr_con = nodes[f\"__witness_{candidate}\"][\"value\"]\n",
    "                values_table[f\"wpr_{candidate}\"] = wpr_con.squeeze().tolist()\n",
    "            \n",
    "\n",
    "        for consequent in consequents:\n",
    "            obs_consequent = gather_observed(nodes[consequent][\"value\"], antecedents, witnesses)\n",
    "            int_consequent = gather_intervened(nodes[consequent][\"value\"], antecedents, witnesses)\n",
    "            con_lp = nodes[f\"__consequent_{consequent}\"]['fn'].log_prob(torch.tensor(1)) #TODO: this feels like a hack\n",
    "            _indices_lp = [\n",
    "            i for i in list(antecedents.keys()) + witnesses if i in indices_of(con_lp)]\n",
    "            int_con_lp = gather(con_lp, IndexSet(**{i: {1} for i in _indices_lp}), event_dim=0,)      \n",
    "\n",
    "\n",
    "            values_table[f\"{consequent}_obs\"] = obs_consequent.squeeze().tolist()   \n",
    "            values_table[f\"{consequent}_int\"] = int_consequent.squeeze().tolist()\n",
    "            values_table[f\"{consequent}_lp\"] = int_con_lp.squeeze().tolist()   \n",
    "\n",
    "    values_df = pd.DataFrame(values_table)\n",
    "\n",
    "    values_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    summands = [col for col in values_df.columns if col.endswith('lp')]\n",
    "    values_df[\"sum_log_prob\"] =  values_df[summands].sum(axis = 1)\n",
    "    values_df.sort_values(by = \"sum_log_prob\", ascending = False, inplace = True)\n",
    "\n",
    "    return values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this reduces the actual causality check to checking a property of the resulting sums of log probabilities\n",
    "# for the antecedent preemption and the consequent differs nodes\n",
    "\n",
    "def ac_check(trace, mwc, antecedents, witnesses, consequents):\n",
    "\n",
    "     table = get_table(trace, mwc, antecedents, witnesses, consequents)\n",
    "     \n",
    "     if (list(table['sum_log_prob'])[0]<= -1e8):\n",
    "          print(\"No resulting difference to the consequent in the sample.\")\n",
    "          return\n",
    "     \n",
    "     winners = table[table['sum_log_prob'] == table['sum_log_prob'].max()]\n",
    "     \n",
    "\n",
    "     ac_flags = []\n",
    "     for index, row in winners.iterrows():\n",
    "          active_antecedents = []\n",
    "          for antecedent in antecedents:\n",
    "               if row[f\"apr_{antecedent}\"] == 0:\n",
    "                    active_antecedents.append(antecedent)\n",
    "\n",
    "          ac_flags.append(set(active_antecedents) == set(antecedents))\n",
    "\n",
    "     if not any(ac_flags):\n",
    "          print(\"The antecedent set is not minimal.\")\n",
    "     else:\n",
    "          print(\"The antecedent set is an actual cause.\")\n",
    "\n",
    "     return any(ac_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'match_dropped': tensor(0.),\n",
       " 'lightning': tensor(0.),\n",
       " 'forest_fire': tensor(0.)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ff_conjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                       u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", match_dropped.bool() & lightning.bool(),\n",
    "                                     event_dim=0).float()\n",
    "\n",
    "    return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n",
    "    \n",
    "def ff_disjunctive():\n",
    "        u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "        u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "        match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                        u_match_dropped.bool(), event_dim=0)\n",
    "        lightning = pyro.deterministic(\"lightning\", u_lightning.bool(), event_dim=0)\n",
    "        forest_fire = pyro.deterministic(\"forest_fire\", (match_dropped.bool() | lightning.bool()).bool(), event_dim=0).bool()\n",
    "\n",
    "        return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n",
    "\n",
    "\n",
    "ff_conjunctive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'match_dropped': 1.0, 'lightning': 1.0}\n"
     ]
    }
   ],
   "source": [
    "def tensorize_dictionary(dictionary):\n",
    "    return {k: torch.as_tensor(v) for k, v in dictionary.items()}\n",
    "\n",
    "def boolean_constraints_from_list(list):\n",
    "    return {k: pyro.distributions.constraints.boolean for k in list}\n",
    "\n",
    "# Example 7.1.2. from the book\n",
    "\n",
    "# all contexts available, no settings excluded by what \n",
    "# the agent knows about the world\n",
    "# in the conjunctive model, the joint nodes are an explanation of forest fire\n",
    "\n",
    "# these are explanation candidates\n",
    "antecedents = {\"match_dropped\": 1.0, \"lightning\": 1.0}\n",
    "print(antecedents)\n",
    "consequents = [\"forest_fire\"]\n",
    "all_nodes = [\"match_dropped\", \"lightning\", \"forest_fire\"]\n",
    "causal_candidates = [node for node in all_nodes if node not in consequents]\n",
    "causal_candidate_constraints = boolean_constraints_from_list(causal_candidates)\n",
    "\n",
    "\n",
    "#sufficiency_assumptions = antecedents.copy()\n",
    "#sufficiency_assumptions['forest_fire'] = True\n",
    "#sufficiency_assumptions = tensorize_dictionary(sufficiency_assumptions)\n",
    "# adding conditioning on this leads to errors?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['u_match_dropped', 'u_lightning', '__antecedent__proposal_match_dropped', '__antecedent_match_dropped', '__witness_match_dropped', 'match_dropped', '__antecedent__proposal_lightning', '__antecedent_lightning', '__witness_lightning', 'lightning', 'forest_fire_factual', 'forest_fire_counterfactual', '__consequent_forest_fire', 'forest_fire'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fake_causal_constraint = {\"match_dropped\": pyro.distributions.constraints.boolean}\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc:\n",
    "    with ExplainCauses(antecedents = causal_candidate_constraints, \n",
    "                      witnesses = causal_candidates, consequents = consequents):\n",
    "            with condition(data = {\"forest_fire\": torch.tensor(True)}):\n",
    "                with pyro.plate(\"sample\", 10):\n",
    "                    with pyro.poutine.trace() as tr:\n",
    "                        ff_conjunctive()\n",
    "                \n",
    "print(tr.trace.nodes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/explanation.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/explanation.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ff_conjunctive_table \u001b[39m=\u001b[39m get_table(tr, mwc, causal_candidates, causal_candidates, consequents)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/explanation.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m display(ff_conjunctive_table)\n",
      "\u001b[1;32m/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/explanation.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/explanation.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m nodes \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39mnodes\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/explanation.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mwith\u001b[39;00m mwc:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/explanation.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mfor\u001b[39;00m antecedent_str \u001b[39min\u001b[39;00m antecedents\u001b[39m.\u001b[39;49mkeys():\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/explanation.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         obs_ant \u001b[39m=\u001b[39m gather_observed(nodes[antecedent_str][\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m], antecedents, witnesses)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/chirho/docs/source/explanation.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         int_ant \u001b[39m=\u001b[39m gather_intervened(nodes[antecedent_str][\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m], antecedents, witnesses)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "ff_conjunctive_table = get_table(tr, mwc, causal_candidates, causal_candidates, consequents)\n",
    "display(ff_conjunctive_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chirho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
