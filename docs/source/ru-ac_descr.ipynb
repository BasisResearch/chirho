{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Causality: modified Halpern-Pearl definition\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline (placeholders for now)\n",
    "\n",
    "\n",
    "\n",
    "[Intuitions and potential applications](#intuitions-and-potential-applications)\n",
    "\n",
    "[Structural causal models](#structural-causal-models)\n",
    "\n",
    "[Halpern-Pearl modified definition of actual causality](#halpern-pearl-modified-definition-of-actual-causality)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Setup](#setup)\n",
    "\n",
    "[Overview: mediation analysis](#overview:-mediation-analysis)\n",
    "- [Task: identify the (in)direct causal role of a variable](#task-identify-the-indirect-causal-role-of-a-variable)\n",
    "- [Challenge: conditioning on mediators might open paths](#challenge-conditioning-on-mediators-might-open-paths)\n",
    "- [Definitions](#definitions)\n",
    "- [Assumptions](#assumptions)\n",
    "\n",
    "[Example: the effect of family interventions on future substance use](#example-the-effect-of-family-interventions-on-future-substance-use)\n",
    "- [Variables](#variables)\n",
    "- [Motivations](#motivations)\n",
    "- [Source](#source)\n",
    "  \n",
    "[Causal Probabilistic Program](#causal-probabilistic-program)\n",
    "- [Model description](#model-description)\n",
    "- [Prior description](#prior-description)\n",
    "\n",
    "[Causal Query: average natural direct effect (ANDE)](#causal-query-average-natural-direct-effect-ande)\n",
    "\n",
    "[Causal Inference](#causal-inference)\n",
    "\n",
    "[Results](#results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuitions and potential applications\n",
    "\n",
    "\n",
    "Actual causality (sometimes called **token causality** or **specific causality**) is usually contrasted with type causality (sometimes called **general causality**). While the latter is concerned with general statements (such as \"smoking causes cancer\"), actual causality focuses on particular events, Consider questions of the following type:\n",
    "\n",
    "- **Friendly Fire**: On March 24, 2002, A B-52 bomber fired a Joint Direct Attack Munition at a US battalion command post, killing three and injuring twenty special forces soldiers. Out of multiple potential contributing factors, which were **actually** responsible for the incident?\n",
    "  \n",
    "- **Schizophrenia** : The disease arises from the interaction between multiple genetic and environmental factors. Given a particular patient and what we know about them, which of these factors **actually** caused her state?\n",
    "  \n",
    "- **Explainable AI**: Your loan application has been refused. The bank representative informs you the decision was made using predictive modeling to estimate the probability of default. They give you a list of various factors considered in the prediction. But which of these factors **actually** resulted in the rejection, and what were their contributions?\n",
    "  \n",
    "These are questions about **actual causality**. While having answers to such questions is not directly useful for prediction tasks, they are useeful for understanding how we can prevent undesirable outcomes similar to ones that we have observed or promote the occurence of desirable outcomes in contexts similar to the ones in which they had been observed. These context-sensitive causality questions are also an essential element of blame and responsibility assignment.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural causal models\n",
    "\n",
    "While statistical information might help address questions of actual causality is not enough. One needs causal theories of how the relevant aspect of the world works, and information about what at least some the actual facts in the case at hand were. For this reason, a major approach to the notion proposed by Halpern and Pearl [CITE ACTUAL CAUSALITY BOOK] (on which we focus in this notebook), is formulated within the framework of structural causal models, which can represent such information.\n",
    "\n",
    "The notion is defined in the context of a deterministic structural causal model (SCMs). One major component thereof are **variables**. For instance, in a very simple model for a forest-fire problem, we might consider a model with three binary variables: $FF$ (forest fire), $L$  (lightnining) and $MD$ (match dropped) and some variable $U$ determines the values of $MD$ and $L$. Moreover, some of those variables/nodes are connected with directed **edges**. For instance, in the example at hand, the model contains two edges that go from $U$ to $MD$ and from $U$ to L$, and two edges that go from $L$ to $FF$ and from $MD$ to $FF$. Each influence is represented also by a *structural equation* - for instance, $FF = max(L, MD)$, if either of the two factors is sufficient for a forest fire. SCMs come also with a **context**, which is the values of *exogenous variables* whose values are not determined by the structural equations, but rather by factors outside the model. In our example, one context might be that both a match has been dropped and a lightning occured. Variables whose values are fixed by structural equations once a context is chosen are called **endogenous variables**. In our simple example, $MD$, $L$ and $F$ are endogenous.\n",
    "\n",
    "More formally, a causal model $M$ is a tuple $\\langle S, F\\rangle$, where:\n",
    "\n",
    "- $S$ is a signature, that is a tuple $\\langle U, V, R\\rangle$, where $U$ is a set of exogenous variables, $V$ is a set of endogenous variables and $R: U \\cup V \\mapsto R(Y)$, where $R(Y)\\neq \\emptyset$, that is $R$ assigns non-empty ranges to exogenous and endogenous variables.\n",
    "- To each endogenous $X\\in V$ $F$ assigns a function $F_X$ which maps the cross-product of $R(Z)$'s for $Z\\in U\\cup V - \\{X}\\$ to $R(X)$. In other words, $F_X$ determins the value of $X$ given the values of other variables in the model (some of them might be redundant). The intuition is taht these functions correspond to structural equations of the form $X = F_X(U, V)$ which are to be read from right to left: if the values of $U\\cup V$ are fixed to be such-and-such, say $\\vec{u}$ and $\\vec{v}$, this causes $X$ to take the value $F_x(\\vec{u}, \\vec{v})$.\n",
    "\n",
    "A deterministic causal model, $\\langle M, \\vec{u}\\rangle$ is a causal model $M$ together with fixed settings $\\vec{u}$ of its exogenous variables $U$. Interventions in $M$, say to make $Y$ have value $y$, is to replace the structural equation for $Y$ of the form $Y = F_Y(U, V)$ with $Y = y$. $\\langle M, \\vec{u}\\rangle \\models [Y \\leftarrow y](X = x)$ means: in the deterministic model obtained from $\\langle M, \\vec{u}\\rangle$ by intervening on $Y$ to have value $y$ $X$ has value $x$. Sometimes, instead of $X = x$ one might be interested in a more general claim $\\varphi$ involving potentially multiple variables, in which case the notation is $\\langle M, \\vec{u}\\rangle \\models [Y \\leftarrow y](\\varphi)$. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Halpern-Pearl modified definition of actual causality\n",
    "\n",
    "\n",
    "Notice that the straightforward counterfactual strategy (*would the event have taken place had the antecedent not taken place?*) is insufficient as a definition of actual causality. For instance, it would consider each member of a firing squad not a cause of the victim's death if each of the firing squad members would not change the outcome by not shooting. Hence a somewhat more elaborate definition is needed. Here is one by Halpern-Pearl, called Halpern-Pearl's modifed definition of actual causality.\n",
    "\n",
    "Given an SCM $M$ and a vector of its exogenous variable settings $\\vec{u}$ we'll write $(M, \\vec{u})\\models [ \\vec{Y} \\leftarrow \\vec{y}]\\psi$ just in case $\\psi$ holds in $(M',\\vec{u})$, where $M'$ is the intervened model obtained by replacing the structural equation(s) for $\\vec{Y}$ in $M$ with $\\vec{Y_i} = \\vec{y_i}$. On MHP, $\\vec{X}=\\vec{x}$ is the actual cause of $\\varphi$ in $(M,\\vec{u})$ just in case:\n",
    "\n",
    "AC1. Factivity: $(M, \\vec{u}) \\models [\\vec{X} = \\vec{x} \\wedge \\varphi]$\n",
    "\n",
    "AC2. Necessity:\n",
    "\n",
    "$\\exists \\vec{W}, \\vec{x}'(M, \\vec{u})\\models [\\vec{X} \\leftarrow \\vec{x}', \\vec{W} = \\vec{w}^{\\star}]   \\neg \\varphi$,\n",
    "where $\\vec{w}^\\star$ are the actual values of $\\vec{W}$, i.e. $(M, \\vec{u}) \\models \\vec{W} = \\vec{w}^\\star$.\n",
    "\n",
    "AC3. Minimality: $\\vec{x}$ is a subset-minimal set of potential causes satisfying AC2.\n",
    "\n",
    "AC1 requires that both the antecedent and the consequent hold. The intuition behind AC2 is that for $\\vec{X}=\\vec{x}$ to be the actual cause of $\\varphi$, there needs to be a vector of witness nodes $\\vec{W}$ and a vector $\\vec{x'}$ of *alternative* settings of $\\vec{X}$ such that if $\\vec{W}$ are intervened to have their actual values $\\vec{w\\star}$, and $\\vec{X}$ are intervened to have values $\\vec{x'}$, $\\varphi$ no longer holds in the resulting model. AC3 requires that the antecedent should be a minimal one satisfying AC2."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
