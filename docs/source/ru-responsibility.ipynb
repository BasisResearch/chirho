{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from typing import Dict, List, Optional,  Union, Callable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import random\n",
    "\n",
    "from causal_pyro.indexed.ops import IndexSet, gather, indices_of, scatter\n",
    "from causal_pyro.interventional.handlers import do\n",
    "from causal_pyro.counterfactual.handlers import MultiWorldCounterfactual, Preemptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HalpernPearlModifiedApproximate:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: Callable,\n",
    "        antecedents: Union[Dict[str, torch.Tensor], List[str]],\n",
    "        outcome: str,\n",
    "        witness_candidates: List[str],\n",
    "        observations: Optional[Dict[str, torch.Tensor]],\n",
    "        sample_size: int = 100,\n",
    "        event_dim: int = 0\n",
    "        ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.antecedents = antecedents\n",
    "        self.outcome = outcome\n",
    "        self.witness_candidates = witness_candidates\n",
    "        self.observations = observations\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        self.antecedents_dict = (\n",
    "            self.antecedents if isinstance(self.antecedents, dict)\n",
    "            else self.revert_antecedents(self.antecedents)\n",
    "        )\n",
    "    \n",
    "        self.preemptions = {candidate: functools.partial(self.preempt_with_factual,\n",
    "                                             antecedents = self.antecedents) for \n",
    "                                             candidate in self.witness_candidates}\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def revert_antecedents(antecedents: List[str]) -> Dict[str, Callable[[torch.Tensor], torch.Tensor]]:\n",
    "        return {antecedent: (lambda v: 1 - v) for antecedent in antecedents}\n",
    "\n",
    "    @staticmethod   \n",
    "    def preempt_with_factual(value: torch.Tensor, *,\n",
    "                          antecedents: List[str] = None, event_dim: int = 0):\n",
    "    \n",
    "        if antecedents is None:\n",
    "            antecedents = []\n",
    "\n",
    "        antecedents = [a for a in antecedents if a in indices_of(value, event_dim=event_dim)]\n",
    "\n",
    "        factual_value = gather(value, IndexSet(**{antecedent: {0} for antecedent in antecedents}),\n",
    "                                event_dim=event_dim)\n",
    "            \n",
    "        return scatter({\n",
    "            IndexSet(**{antecedent: {0} for antecedent in antecedents}): factual_value,\n",
    "            IndexSet(**{antecedent: {1} for antecedent in antecedents}): factual_value,\n",
    "        }, event_dim=event_dim)\n",
    "        \n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with pyro.poutine.trace() as trace:\n",
    "            with MultiWorldCounterfactual():\n",
    "                with do(actions=self.antecedents_dict):\n",
    "                    with Preemptions(actions = self.preemptions):\n",
    "                        with pyro.condition(data={k: torch.as_tensor(v) for k, v in self.observations.items()}):\n",
    "                            with pyro.plate(\"plate\", self.sample_size):\n",
    "                                self.consequent = self.model()[self.outcome]\n",
    "                                self.intervened_consequent = gather(self.consequent, IndexSet(**{ant: {1} for ant in self.antecedents}))\n",
    "                                self.observed_consequent = gather(self.consequent, IndexSet(**{ant: {0} for ant in self.antecedents}))\n",
    "                                self.consequent_differs = self.intervened_consequent != self.observed_consequent   \n",
    "                                pyro.factor(\"consequent_differs\", torch.where(self.consequent_differs, torch.tensor(0.0), torch.tensor(-1e8)))\n",
    "                            \n",
    "        self.trace = trace.trace\n",
    "\n",
    "        # # slightly hacky solution for cases with no witness candidates\n",
    "        self.existential_but_for = any(self.consequent_differs.squeeze().tolist()\n",
    "                                        ) if self.witness_candidates else self.consequent_differs.squeeze()\n",
    "        \n",
    "        witness_dict = dict()\n",
    "        if self.witness_candidates:\n",
    "            witness_keys = [\"__split_\" + candidate for candidate in self.witness_candidates]\n",
    "            witness_dict = {key: self.trace.nodes[key]['value']  for key in witness_keys}\n",
    "            \n",
    "\n",
    "        witness_dict['observed'] = self.observed_consequent.squeeze()\n",
    "        witness_dict['intervened'] = self.intervened_consequent.squeeze()\n",
    "        witness_dict['consequent_differs'] = self.consequent_differs.squeeze()\n",
    "\n",
    "        # slightly hacky as above\n",
    "        self.witness_df = pd.DataFrame(witness_dict) if self.witness_candidates else witness_dict\n",
    "\n",
    "        if self.witness_candidates:\n",
    "            self.witness_df['witness_size'] = self.witness_df[witness_keys].sum(axis = 1)\n",
    "            satisfactory = self.witness_df[self.witness_df['consequent_differs'] == True]\n",
    "            \n",
    "        self.minimal_witness_size = satisfactory['witness_size'].min() if self.witness_candidates else 0\n",
    "        self.responsibility = 1/(len(self.antecedents) + self.minimal_witness_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome': tensor(False)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def voting_model():\n",
    "    u_vote0 = pyro.sample(\"u_vote0\", dist.Bernoulli(0.6))\n",
    "    u_vote1 = pyro.sample(\"u_vote1\", dist.Bernoulli(0.6))\n",
    "    u_vote2 = pyro.sample(\"u_vote2\", dist.Bernoulli(0.6))\n",
    "    u_vote3 = pyro.sample(\"u_vote3\", dist.Bernoulli(0.6))\n",
    "    u_vote4 = pyro.sample(\"u_vote4\", dist.Bernoulli(0.6))\n",
    "    u_vote5 = pyro.sample(\"u_vote5\", dist.Bernoulli(0.6))\n",
    "\n",
    "    vote0 = pyro.deterministic(\"vote0\", u_vote0, event_dim=0)\n",
    "    vote1 = pyro.deterministic(\"vote1\", u_vote1, event_dim=0)\n",
    "    vote2 = pyro.deterministic(\"vote2\", u_vote2, event_dim=0)\n",
    "    vote3 = pyro.deterministic(\"vote3\", u_vote3, event_dim=0)\n",
    "    vote4 = pyro.deterministic(\"vote4\", u_vote4, event_dim=0)\n",
    "    vote5 = pyro.deterministic(\"vote5\", u_vote5, event_dim=0)\n",
    "    return {\"outcome\": vote0 + vote1 + vote2 + vote3 + vote4 +vote5 > 3}\n",
    "\n",
    "voting_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# if you're one of four voters who voted for, you are an actual cause\n",
    "voting4HPM = HalpernPearlModifiedApproximate(\n",
    "    model = voting_model,\n",
    "    antecedents = [\"vote0\"],\n",
    "    outcome = \"outcome\",\n",
    "    witness_candidates = [f\"vote{i}\" for i in range(1,6)],\n",
    "    observations = dict(u_vote0=1., u_vote1=1., u_vote2=1.,\n",
    "                        u_vote3=1., u_vote4=0., u_vote_5=0),\n",
    "    sample_size = 1000)\n",
    "\n",
    "voting4HPM()\n",
    "\n",
    "print(\n",
    "voting4HPM.existential_but_for\n",
    ")\n",
    "\n",
    "print(\n",
    "voting4HPM.minimal_witness_size\n",
    ")\n",
    "\n",
    "print(voting4HPM.responsibility)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# if you're one of four voters who voted for, you are an actual cause\n",
    "voting5HPM = HalpernPearlModifiedApproximate(\n",
    "    model = voting_model,\n",
    "    antecedents = [\"vote0\"],\n",
    "    outcome = \"outcome\",\n",
    "    witness_candidates = [f\"vote{i}\" for i in range(1,6)],\n",
    "    observations = dict(u_vote0=1., u_vote1=1., u_vote2=1.,\n",
    "                        u_vote3=1., u_vote4=1., u_vote_5=0),\n",
    "    sample_size = 1000)\n",
    "\n",
    "voting5HPM()\n",
    "\n",
    "print(\n",
    "voting5HPM.existential_but_for\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "witness_sizes = []\n",
    "existential_but_fors = []\n",
    "minimal_witness_sizes = []\n",
    "\n",
    "for step in range(1,15):\n",
    "\n",
    "    voters = [f\"vote{i}\" for i in range(1,6,)]\n",
    "    companion_size = random.randint(0,len(voters))\n",
    "    companion_candidates = [\"vote0\"] +  random.sample(voters, companion_size)\n",
    "    witness_candidates = [f\"vote{i}\" for i in range(1,6) if f\"vote{i}\" not in companion_candidates]\n",
    "    witness_sizes.append(len(witness_candidates))\n",
    "\n",
    "\n",
    "    voting_run_HPM = HalpernPearlModifiedApproximate(\n",
    "        model = voting_model,\n",
    "        antecedents = companion_candidates,\n",
    "        outcome = \"outcome\",\n",
    "        witness_candidates = witness_candidates,\n",
    "        observations = dict(u_vote0=1., u_vote1=1., u_vote2=1.,\n",
    "                            u_vote3=1., u_vote4=1., u_vote_5=1.),\n",
    "        sample_size = 1000)\n",
    "\n",
    "    voting_run_HPM()\n",
    "\n",
    "    existential_but_fors.append(voting_run_HPM.existential_but_for)\n",
    "    minimal_witness_sizes.append(voting_run_HPM.minimal_witness_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "voting4HPM = HalpernPearlModifiedApproximate(\n",
    "    model = voting_model,\n",
    "    antecedents = [\"vote0\"],\n",
    "    outcome = \"outcome\",\n",
    "    witness_candidates = [f\"vote{i}\" for i in range(1,6)],\n",
    "    observations = dict(u_vote0=1., u_vote1=1., u_vote2=1.,\n",
    "                        u_vote3=1., u_vote4=0., u_vote_5=0),\n",
    "    sample_size = 1000)\n",
    "\n",
    "voting4HPM()\n",
    "\n",
    "print(\n",
    "voting4HPM.existential_but_for\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_pyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
