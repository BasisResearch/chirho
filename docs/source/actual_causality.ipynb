{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import contextlib\n",
    "import collections\n",
    "from typing import Callable, Iterable, TypeVar, Mapping, List, Dict\n",
    "\n",
    "import pyro\n",
    "import torch  # noqa: F401\n",
    "\n",
    "from chirho.counterfactual.handlers.selection import get_factual_indices\n",
    "from chirho.indexed.ops import IndexSet, cond, gather, indices_of, scatter\n",
    "\n",
    "S = TypeVar(\"S\")\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "import pyro\n",
    "import chirho\n",
    "import pyro.distributions as dist\n",
    "import pyro.infer\n",
    "import pytest\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from chirho.counterfactual.handlers.counterfactual import (MultiWorldCounterfactual,\n",
    "        Preemptions)\n",
    "from chirho.counterfactual.handlers.explanation import (\n",
    "    SearchForCause,\n",
    "    consequent_differs,\n",
    "    random_intervention,\n",
    "    undo_split,\n",
    "    uniform_proposal,\n",
    ")\n",
    "from chirho.counterfactual.ops import preempt, split\n",
    "from chirho.indexed.ops import IndexSet, gather, indices_of\n",
    "from chirho.observational.handlers.condition import Factors, condition\n",
    "from chirho.interventional.ops import Intervention, intervene\n",
    "from chirho.interventional.handlers import do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def ExplainCauses(\n",
    "    antecedents: Mapping[str, Intervention[T]]\n",
    "    | Mapping[str, pyro.distributions.constraints.Constraint],\n",
    "    witnesses: Mapping[str, Intervention[T]] | Iterable[str],\n",
    "    consequents: Mapping[str, Callable[[T], float | torch.Tensor]]\n",
    "    | Iterable[str],\n",
    "    *,\n",
    "    antecedent_bias: float = 0.0,\n",
    "    witness_bias: float = 0.0,\n",
    "    consequent_eps: float = -1e8,\n",
    "    antecedent_prefix: str = \"__antecedent_\",\n",
    "    witness_prefix: str = \"__witness_\",\n",
    "    consequent_prefix: str = \"__consequent_\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Effect handler for causal explanation.\n",
    "\n",
    "    :param antecedents: A mapping from antecedent names to interventions.\n",
    "    :param witnesses: A mapping from witness names to interventions.\n",
    "    :param consequents: A mapping from consequent names to factor functions.\n",
    "    \"\"\"\n",
    "    if isinstance(\n",
    "        next(iter(antecedents.values())),\n",
    "        pyro.distributions.constraints.Constraint,\n",
    "    ):\n",
    "        antecedents = {\n",
    "            a: random_intervention(s, name=f\"{antecedent_prefix}_proposal_{a}\")\n",
    "            for a, s in antecedents.items()\n",
    "        }\n",
    "\n",
    "    if not isinstance(witnesses, collections.abc.Mapping):\n",
    "        witnesses = {\n",
    "            w: undo_split(antecedents=list(antecedents.keys()))\n",
    "            for w in witnesses\n",
    "        }\n",
    "\n",
    "    if not isinstance(consequents, collections.abc.Mapping):\n",
    "        consequents = {\n",
    "            c: consequent_differs(\n",
    "                antecedents=list(antecedents.keys()), eps=consequent_eps\n",
    "            )\n",
    "            for c in consequents\n",
    "        }\n",
    "\n",
    "    if len(consequents) == 0:\n",
    "        raise ValueError(\"must have at least one consequent\")\n",
    "\n",
    "    if len(antecedents) == 0:\n",
    "        raise ValueError(\"must have at least one antecedent\")\n",
    "\n",
    "    if set(consequents.keys()) & set(antecedents.keys()):\n",
    "        raise ValueError(\n",
    "            \"consequents and possible antecedents must be disjoint\"\n",
    "        )\n",
    "\n",
    "    if set(consequents.keys()) & set(witnesses.keys()):\n",
    "        raise ValueError(\"consequents and possible witnesses must be disjoint\")\n",
    "\n",
    "    antecedent_handler = SearchForCause(\n",
    "        actions=antecedents, bias=antecedent_bias, prefix=antecedent_prefix\n",
    "    )\n",
    "    witness_handler = Preemptions(\n",
    "        actions=witnesses, bias=witness_bias, prefix=witness_prefix\n",
    "    )\n",
    "    consequent_handler = Factors(factors=consequents, prefix=consequent_prefix)\n",
    "\n",
    "    with antecedent_handler, witness_handler, consequent_handler:\n",
    "        with pyro.poutine.trace() as logging_tr:\n",
    "            yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_observed(value, antecedents, witnesses):\n",
    "    _indices = [\n",
    "            i for i in list(antecedents.keys()) + witnesses if i in indices_of(value, event_dim=0)\n",
    "        ]\n",
    "    _int_can = gather(\n",
    "    value, IndexSet(**{i: {0} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "def gather_intervened(value, antecedents, witnesses):\n",
    "    _indices = [\n",
    "            i for i in list(antecedents.keys()) + witnesses if i in indices_of(value, event_dim=0)\n",
    "        ]\n",
    "    _int_can = gather(\n",
    "    value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "def get_table(trace, mwc, antecedents, witnesses, consequents):\n",
    "\n",
    "    values_table = {}\n",
    "    nodes = trace.trace.nodes\n",
    "\n",
    "    with mwc:\n",
    "\n",
    "        for antecedent_str in antecedents.keys():\n",
    "                \n",
    "            obs_ant = gather_observed(nodes[antecedent_str][\"value\"], antecedents, witnesses)\n",
    "            int_ant = gather_intervened(nodes[antecedent_str][\"value\"], antecedents, witnesses)\n",
    "\n",
    "            values_table[f\"{antecedent_str}_obs\"] = obs_ant.squeeze().tolist()\n",
    "            values_table[f\"{antecedent_str}_int\"] = int_ant.squeeze().tolist()\n",
    "            \n",
    "            apr_ant = nodes[f\"__antecedent_{antecedent_str}\"][\"value\"]\n",
    "            values_table[f\"apr_{antecedent_str}\"] = apr_ant.squeeze().tolist()\n",
    "            \n",
    "            values_table[f\"apr_{antecedent_str}_lp\"] = nodes[f\"__antecedent_{antecedent_str}\"][\"fn\"].log_prob(apr_ant)\n",
    "\n",
    "        for candidate in witnesses:\n",
    "            obs_candidate = gather_observed(nodes[candidate][\"value\"], antecedents, witnesses)\n",
    "            int_candidate = gather_intervened(nodes[candidate][\"value\"], antecedents, witnesses)\n",
    "            values_table[f\"{candidate}_obs\"] = obs_candidate.squeeze().tolist()\n",
    "            values_table[f\"{candidate}_int\"] = int_candidate.squeeze().tolist()\n",
    "\n",
    "            wpr_con = nodes[f\"__witness_{candidate}\"][\"value\"]\n",
    "            values_table[f\"wpr_{candidate}\"] = apr_ant.squeeze().tolist()\n",
    "            \n",
    "\n",
    "        for consequent in consequents:\n",
    "            obs_consequent = gather_observed(nodes[consequent][\"value\"], antecedents, witnesses)\n",
    "            int_consequent = gather_intervened(nodes[consequent][\"value\"], antecedents, witnesses)\n",
    "            con_lp = nodes[f\"__consequent_{consequent}\"]['fn'].log_prob(torch.tensor(1)) #TODO: this feels like a hack\n",
    "            _indices_lp = [\n",
    "            i for i in list(antecedents.keys()) + witnesses if i in indices_of(con_lp)]\n",
    "            int_con_lp = gather(con_lp, IndexSet(**{i: {1} for i in _indices_lp}), event_dim=0,)      \n",
    "\n",
    "\n",
    "            values_table[f\"{consequent}_obs\"] = obs_consequent.squeeze().tolist()   \n",
    "            values_table[f\"{consequent}_int\"] = int_consequent.squeeze().tolist()\n",
    "            values_table[f\"{consequent}_lp\"] = int_con_lp.squeeze().tolist()   \n",
    "\n",
    "    values_df = pd.DataFrame(values_table)\n",
    "\n",
    "    values_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    summands = [col for col in values_df.columns if col.endswith('lp')]\n",
    "    values_df[\"sum_log_prob\"] =  values_df[summands].sum(axis = 1)\n",
    "    values_df.sort_values(by = \"sum_log_prob\", ascending = False, inplace = True)\n",
    "\n",
    "    return values_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stone-throwing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyro.infer.config_enumerate\n",
    "def stones_model():        \n",
    "    prob_sally_throws = pyro.sample(\"prob_sally_throws\", dist.Beta(1, 1))\n",
    "    prob_bill_throws = pyro.sample(\"prob_bill_throws\", dist.Beta(1, 1))\n",
    "    prob_sally_hits = pyro.sample(\"prob_sally_hits\", dist.Beta(1, 1))\n",
    "    prob_bill_hits = pyro.sample(\"prob_bill_hits\", dist.Beta(1, 1))\n",
    "    prob_bottle_shatters_if_sally = pyro.sample(\"prob_bottle_shatters_if_sally\", dist.Beta(1, 1))\n",
    "    prob_bottle_shatters_if_bill = pyro.sample(\"prob_bottle_shatters_if_bill\", dist.Beta(1, 1))\n",
    "\n",
    "    sally_throws = pyro.sample(\"sally_throws\", dist.Bernoulli(prob_sally_throws))\n",
    "    bill_throws = pyro.sample(\"bill_throws\", dist.Bernoulli(prob_bill_throws))\n",
    "\n",
    "\n",
    "    new_shp = torch.where(sally_throws == 1,prob_sally_hits, 0.0)\n",
    "\n",
    "    sally_hits = pyro.sample(\"sally_hits\",dist.Bernoulli(new_shp))\n",
    "\n",
    "    new_bhp = torch.where(\n",
    "        bill_throws.bool() & (~sally_hits.bool()),\n",
    "        prob_bill_hits,\n",
    "        torch.tensor(0.0),\n",
    "    )\n",
    "\n",
    "    bill_hits = pyro.sample(\"bill_hits\", dist.Bernoulli(new_bhp))\n",
    "    \n",
    "\n",
    "    new_bsp = torch.where(bill_hits.bool(), prob_bottle_shatters_if_bill,\n",
    "            torch.where(sally_hits.bool(),prob_bottle_shatters_if_sally,torch.tensor(0.0),),)\n",
    "\n",
    "    bottle_shatters = pyro.sample(\"bottle_shatters\", dist.Bernoulli(new_bsp))\n",
    "\n",
    "    return {\"sally_throws\": sally_throws, \"bill_throws\": bill_throws,  \"sally_hits\": sally_hits,\n",
    "            \"bill_hits\": bill_hits,  \"bottle_shatters\": bottle_shatters,}\n",
    "\n",
    "stones_model.nodes = [\"sally_throws\",\"bill_throws\", \"sally_hits\", \"bill_hits\",\"bottle_shatters\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = {\"prob_sally_throws\": 1.0, \n",
    "                \"prob_bill_throws\": 1.0,\n",
    "                \"prob_sally_hits\": 1.0,\n",
    "                \"prob_bill_hits\": 1.0,\n",
    "                \"prob_bottle_shatters_if_sally\": 1.0,\n",
    "                \"prob_bottle_shatters_if_bill\": 1.0,\n",
    "                \"sally_throws\": 1.0, \"bill_throws\": 1.0}\n",
    "\n",
    "observations_tensorized = {k: torch.as_tensor(v) for k, v in observations.items()}\n",
    "\n",
    "antecedents = {\"sally_throws\": 0.0}\n",
    "antencedent_bias = 0.1\n",
    "witnesses = [\"bill_throws\", \"bill_hits\"]\n",
    "consequents = [\"bottle_shatters\"]\n",
    "\n",
    "#TODO? fails silently when consequents is a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with MultiWorldCounterfactual() as mwc:\n",
    "    with ExplainCauses(antecedents = antecedents, antecedent_bias= antencedent_bias,\n",
    "                        witnesses = witnesses,\n",
    "                        consequents = consequents):\n",
    "        with condition(data = observations_tensorized):\n",
    "            with pyro.plate(\"sample\", 200):\n",
    "                with pyro.poutine.trace() as tr:\n",
    "                    stones_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sally_throws_obs</th>\n",
       "      <th>sally_throws_int</th>\n",
       "      <th>apr_sally_throws</th>\n",
       "      <th>apr_sally_throws_lp</th>\n",
       "      <th>bill_throws_obs</th>\n",
       "      <th>bill_throws_int</th>\n",
       "      <th>wpr_bill_throws</th>\n",
       "      <th>bill_hits_obs</th>\n",
       "      <th>bill_hits_int</th>\n",
       "      <th>wpr_bill_hits</th>\n",
       "      <th>bottle_shatters_obs</th>\n",
       "      <th>bottle_shatters_int</th>\n",
       "      <th>bottle_shatters_lp</th>\n",
       "      <th>sum_log_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.162907e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.510826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-100000000.0</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.916291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-100000000.0</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sally_throws_obs  sally_throws_int  apr_sally_throws  apr_sally_throws_lp  \\\n",
       "1               1.0               0.0                 0            -0.916291   \n",
       "0               1.0               1.0                 1            -0.510826   \n",
       "5               1.0               0.0                 0            -0.916291   \n",
       "\n",
       "   bill_throws_obs  bill_throws_int  wpr_bill_throws  bill_hits_obs  \\\n",
       "1              1.0              1.0                0            0.0   \n",
       "0              1.0              1.0                1            0.0   \n",
       "5              1.0              1.0                0            0.0   \n",
       "\n",
       "   bill_hits_int  wpr_bill_hits  bottle_shatters_obs  bottle_shatters_int  \\\n",
       "1            0.0              0                  1.0                  0.0   \n",
       "0            0.0              1                  1.0                  1.0   \n",
       "5            1.0              0                  1.0                  1.0   \n",
       "\n",
       "   bottle_shatters_lp  sum_log_prob  \n",
       "1                 0.0 -9.162907e-01  \n",
       "0        -100000000.0 -1.000000e+08  \n",
       "5        -100000000.0 -1.000000e+08  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stones_table = get_table(tr, mwc, antecedents, witnesses, consequents)\n",
    "display(stones_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this reduces the actual causality check to checking a property of the resulting sums of log probabilities\n",
    "# for the antecedent preemption and the consequent differs nodes\n",
    "\n",
    "def ac_check(trace, mwc, antecedents, witnesses, consequents):\n",
    "\n",
    "     table = get_table(trace, mwc, antecedents, witnesses, consequents)\n",
    "     \n",
    "     if all(table['sum_log_prob'] <= -1e8):\n",
    "          print(\"No resulting difference to the consequent in the sample.\")\n",
    "          return\n",
    "     \n",
    "     # winners = table[table['sum_log_prob'] == table['sum_log_prob'].max()]\n",
    "\n",
    "     # print(winners)\n",
    "     \n",
    "     # ac_flags = []\n",
    "     # for index, row in winners.iterrows():\n",
    "     #      active_antecedents = []\n",
    "     #      for antecedent in antecedents:\n",
    "     #           if row[f\"apr_{antecedent}\"] == 0:\n",
    "     #                active_antecedents.append(antecedent)\n",
    "\n",
    "     #      ac_flags.append(set(active_antecedents) == set(antecedents))\n",
    "\n",
    "     # if not any(ac_flags):\n",
    "     #      print(\"The antecedent set is not minimal.\")\n",
    "     # else:\n",
    "     #      print(\"The antecedent set is an actual cause.\")\n",
    "\n",
    "     # return any(ac_flags)\n",
    "\n",
    "     \n",
    "     # winners = table.iloc[0]\n",
    "     # active_antecedents = []\n",
    "     # for antecedent in antecedents:\n",
    "     #      if winner['preempted_'+antecedent] == 0:\n",
    "     #           active_antecedents.append(antecedent)\n",
    "\n",
    "     # ac_flag = set(active_antecedents) == set(antecedents)\n",
    "        \n",
    "     # if not ac_flag:\n",
    "     #      print(\"The antecedent set is not minimal.\")\n",
    "     # else:\n",
    "     #      print(\"The antecedent set is an actual cause.\")\n",
    "\n",
    "     # return ac_flag\n",
    "\n",
    "\n",
    "\n",
    "ac_check(tr, mwc, antecedents, witnesses, consequents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rafal/L2projects/chirho/docs/source/actual_causality.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rafal/L2projects/chirho/docs/source/actual_causality.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ac_check(tr, mwc, antecedents, witnesses, consequents)\n",
      "\u001b[1;32m/home/rafal/L2projects/chirho/docs/source/actual_causality.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafal/L2projects/chirho/docs/source/actual_causality.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mac_check\u001b[39m(trace, mwc, antecedents, witnesses, consequents):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafal/L2projects/chirho/docs/source/actual_causality.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m      table \u001b[39m=\u001b[39m get_table(trace, mwc, antecedents, witnesses, consequents)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rafal/L2projects/chirho/docs/source/actual_causality.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m      \u001b[39mif\u001b[39;00m \u001b[39mlist\u001b[39;49m(table[\u001b[39m'\u001b[39;49m\u001b[39msum_log_prob\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m]) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1e8\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafal/L2projects/chirho/docs/source/actual_causality.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m           \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo resulting difference to the consequent in the sample.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/L2projects/chirho/docs/source/actual_causality.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m           \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resulting difference to the consequent in the sample.\n"
     ]
    }
   ],
   "source": [
    "def gather_observed(value):\n",
    "    _indices = [\n",
    "            i for i in list(antecedents.keys()) + witnesses if i in indices_of(value, event_dim=0)\n",
    "        ]\n",
    "    _int_can = gather(\n",
    "    value, IndexSet(**{i: {0} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "def gather_intervened(value):\n",
    "    _indices = [\n",
    "            i for i in list(antecedents.keys()) + witnesses if i in indices_of(value, event_dim=0)\n",
    "        ]\n",
    "    _int_can = gather(\n",
    "    value, IndexSet(**{i: {1} for i in _indices}), event_dim=0,)\n",
    "    return _int_can\n",
    "\n",
    "\n",
    "def get_table(trace, antecedents, witnesses, consequents):\n",
    "\n",
    "    values_table = {}\n",
    "    trace = tr\n",
    "    nodes = trace.trace.nodes\n",
    "\n",
    "    with mwc:\n",
    "\n",
    "        for antecedent_str in antecedents.keys():\n",
    "                \n",
    "            obs_ant = gather_observed(nodes[antecedent_str][\"value\"])\n",
    "            int_ant = gather_intervened(nodes[antecedent_str][\"value\"])\n",
    "\n",
    "            values_table[f\"{antecedent_str}_obs\"] = obs_ant.squeeze().tolist()\n",
    "            values_table[f\"{antecedent_str}_int\"] = int_ant.squeeze().tolist()\n",
    "            \n",
    "            apr_ant = nodes[f\"__antecedent_{antecedent_str}\"][\"value\"]\n",
    "            values_table[f\"apr_{antecedent_str}\"] = apr_ant.squeeze().tolist()\n",
    "            \n",
    "            values_table[f\"apr_{antecedent_str}_lp\"] = nodes[f\"__antecedent_{antecedent_str}\"][\"fn\"].log_prob(apr_ant)\n",
    "\n",
    "        for candidate in witnesses:\n",
    "            obs_candidate = gather_observed(nodes[candidate][\"value\"])\n",
    "            int_candidate = gather_intervened(nodes[candidate][\"value\"])\n",
    "            values_table[f\"{candidate}_obs\"] = obs_candidate.squeeze().tolist()\n",
    "            values_table[f\"{candidate}_int\"] = int_candidate.squeeze().tolist()\n",
    "\n",
    "            wpr_con = nodes[f\"__witness_{candidate}\"][\"value\"]\n",
    "            values_table[f\"wpr_{candidate}\"] = apr_ant.squeeze().tolist()\n",
    "            \n",
    "\n",
    "        for consequent in consequents:\n",
    "            obs_consequent = gather_observed(nodes[consequent][\"value\"])\n",
    "            int_consequent = gather_intervened(nodes[consequent][\"value\"])\n",
    "            con_lp = nodes[f\"__consequent_{consequent}\"]['fn'].log_prob(torch.tensor(1)) #TODO: this feels like a hack\n",
    "            _indices_lp = [\n",
    "            i for i in list(antecedents.keys()) + witnesses if i in indices_of(con_lp)]\n",
    "            int_con_lp = gather(con_lp, IndexSet(**{i: {1} for i in _indices_lp}), event_dim=0,)      \n",
    "\n",
    "\n",
    "            values_table[f\"{consequent}_obs\"] = obs_consequent.squeeze().tolist()   \n",
    "            values_table[f\"{consequent}_int\"] = int_consequent.squeeze().tolist()\n",
    "            values_table[f\"{consequent}_lp\"] = int_con_lp.squeeze().tolist()   \n",
    "\n",
    "    values_df = pd.DataFrame(values_table)\n",
    "\n",
    "    values_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    summands = [col for col in values_df.columns if col.endswith('lp')]\n",
    "    values_df[\"sum_log_prob\"] =  values_df[summands].sum(axis = 1)\n",
    "    values_df.sort_values(by = \"sum_log_prob\", ascending = False, inplace = True)\n",
    "\n",
    "    return values_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chirho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
