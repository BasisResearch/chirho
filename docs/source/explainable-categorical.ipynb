{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable reasoning with ChiRho (categorical variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The **Explainable Reasoning with ChiRho** package aims to provide a systematic, unified approach to causal explanation computations in terms of different probabilistic queries over expanded causal models that are constructed from a single generic program transformation applied to an arbitrary causal model represented as a ChiRho program. The approach of reducing causal queries to probabilistic computations on transformed causal models is the foundational idea behind all of ChiRho. The key strategy underlying \"causal explanation\" queries is their use of auxiliary variables representing uncertainty about which interventions or preemptions to apply, implicitly inducing a search space over counterfactuals.\n",
    "\n",
    "The goal of this notebook is to illustrate how the package can be used to provide approximate method of answering a range of causal explanation queries with respect to models in which categorical variables play the key role.\n",
    "\n",
    "In [another notebook](https://basisresearch.github.io/chirho/actual_causality.html) we illustrate how the module allows for a faithful reconstruction of a particular notion of local explanation (the so-called Halpern-Pearl modified definition of actual causality [(J. Halpern, MIT Press, 2016)](https://mitpress.mit.edu/9780262537131/actual-causality/)), which inspired some of the conceptual steps underlying the current implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "[Introduction and motivations](#intuitions-and-motivations)\n",
    "    \n",
    "- [The but-for condition](#the-but-for-condtition)\n",
    "\n",
    "- [Witness nodes and context sensitivity](#witness-nodes-and-context-sensitivity)\n",
    "\n",
    "[Simplified actual causality](#simplified-actual-causality)\n",
    "\n",
    "[Probability of causation](#probability-of-causation)\n",
    "\n",
    "[Causal explanation](#causal-explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TORCH_CUDA_ARCH_LIST=\"\"\n"
     ]
    }
   ],
   "source": [
    "%env TORCH_CUDA_ARCH_LIST=\"\"\n",
    "import os\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "import torch\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from chirho.observational.handlers import condition\n",
    "from chirho.counterfactual.handlers.counterfactual import MultiWorldCounterfactual\n",
    "from chirho.explainable.handlers import SearchForExplanation\n",
    "                                            \n",
    "from chirho.indexed.ops import (IndexSet, gather, indices_of) \n",
    "from chirho.interventional.handlers import do\n",
    "\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "runs_n = 5 if smoke_test else 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and motivations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a very simple model, in which a forest fire can be caused by exactly one of two things: a match being dropped (`match_dropped`), or a lightning strike (`lightning`), and either of these factors alone is already deterministcally sufficient for the `forest_fire` to occur. In general, you think a match being dropped is more likely than a lightning strike (we use fairly large probabilities for the sake of example transparency). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"296pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 296.19 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 292.19,-112 292.19,4 -4,4\"/>\n",
       "<!-- match_dropped -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>match_dropped</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"82.54\" cy=\"-90\" rx=\"82.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"82.54\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">match_dropped</text>\n",
       "</g>\n",
       "<!-- forest_fire -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>forest_fire</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"158.54\" cy=\"-18\" rx=\"57.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"158.54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">forest_fire</text>\n",
       "</g>\n",
       "<!-- match_dropped&#45;&gt;forest_fire -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>match_dropped&#45;&gt;forest_fire</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M100.55,-72.41C110.37,-63.37 122.68,-52.03 133.43,-42.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.94,-44.58 140.92,-35.23 131.2,-39.43 135.94,-44.58\"/>\n",
       "</g>\n",
       "<!-- lightning -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>lightning</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"235.54\" cy=\"-90\" rx=\"52.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"235.54\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">lightning</text>\n",
       "</g>\n",
       "<!-- lightning&#45;&gt;forest_fire -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>lightning&#45;&gt;forest_fire</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M217.68,-72.76C207.67,-63.66 195.02,-52.16 183.99,-42.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"186.06,-39.28 176.3,-35.15 181.35,-44.46 186.06,-39.28\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f6c91831f00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ff_disjunctive():\n",
    "        match_dropped = pyro.sample(\"match_dropped\", dist.Bernoulli(0.7)) # notice uneven probs here\n",
    "        lightning = pyro.sample(\"lightning\", dist.Bernoulli(0.4))\n",
    "\n",
    "        forest_fire = pyro.deterministic(\"forest_fire\", torch.max(match_dropped, lightning), event_dim=0)\n",
    "\n",
    "        return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n",
    "\n",
    "# each run is stochastic\n",
    "ff_disjunctive()\n",
    "\n",
    "pyro.render_model(ff_disjunctive) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose in this particular case you know a forest fire has occured, a match has been dropped, but no lightning occured. This further assumption can be introduced by conditioning on these observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'match_dropped': tensor(1.), 'lightning': tensor(0.), 'forest_fire': tensor(1.)}\n"
     ]
    }
   ],
   "source": [
    "observations = {\"match_dropped\": torch.tensor(1.), \n",
    "                \"lightning\": torch.tensor(0.),\n",
    "                \"forest_fire\": torch.tensor(1.)}\n",
    "\n",
    "with condition(data = observations):\n",
    "    with pyro.poutine.trace() as tr:\n",
    "        ff_disjunctive()\n",
    "\n",
    "print({key: tr.trace.nodes[key][\"value\"] for key in tr.trace.nodes.keys()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a particular context like this, if you know what happened, or at least know the values of some of the variables at play, you might be interested in using the model to answer **a range of causal-explanation related questions**.\n",
    "\n",
    "- Did the dropped match actually cause the fire?\n",
    "- Suppose you only know that the forest fire occurred, what are the likely explanations? How likely are they?\n",
    "- Suppose you know both factors occurred, to what extent should they be deemed responsible for this outcome?\n",
    "\n",
    "Let's see how these can be addressed using ChiRho. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The but-for condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial intuition that you might have is that in this situation, `match_dropped` is a cause of `forest_fire`, because had the match not been dropped, the forest fire would not have occurred, or, in other words, there would be no forest fire but for the match being dropped. The `Search for Explanation` handler can be used to test for this condition, and returns the expected result in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['__antecedent_match_dropped', 'match_dropped', 'lightning', 'forest_fire_factual', 'forest_fire_counterfactual', '__consequent_forest_fire', 'forest_fire'])\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(101)\n",
    "\n",
    "# you can manually specify \n",
    "# the alternative value(s) of the antecedent(s)\n",
    "# for a contrastive comparison\n",
    "antecedents = {\"match_dropped\": 0.0} \n",
    "\n",
    "\n",
    "witnesses = {} # ignore witnesses for now\n",
    "\n",
    "consequents = {\"forest_fire\": constraints.boolean}\n",
    "# you need to specify the outcome distro\n",
    "# in general there's a separate handler that provides \n",
    "# some assistance, we'll illustrate its use later\n",
    "\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc:  # needed to keep track of multiple scenarios\n",
    "    with SearchForExplanation(antecedents = antecedents, \n",
    "                              witnesses = witnesses,\n",
    "                              consequents = consequents,\n",
    "                              consequent_scale= 1e-8):\n",
    "        with condition(data = observations):\n",
    "            with pyro.plate(\"sample\", 10): # run a few times\n",
    "                with pyro.poutine.trace() as tr:\n",
    "                    ff_disjunctive()\n",
    "\n",
    "print(tr.trace.nodes.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, we used `SearchForExplanation` to investigate what would have happened to the consequent(s) if we intervened on the antecedent(s) as specified, and we ran the model a few times as the run now contains stochastic elements. The trace now contains more information.\n",
    "\n",
    "1.  We have randomly intervened (for now, with uniform Bernoulli distribution) on `match_dropped` as specified in `antecedents`. `__antecedent_match_dropped` now contains information about whether a given intervention has been preempted (that is, it has value `0` if the intervention wasn't blocked in a given run, and 1 if the intervention was blocked). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__antecedent_match_dropped: tensor([1, 0, 0, 0, 1, 0, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "nd = (tr.trace.nodes)\n",
    "print(\"__antecedent_match_dropped:\", nd[\"__antecedent_match_dropped\"][\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you might think that randomly preempting the intervention from happening is an unnecessary complication, and in this particular case it in fact is. However, the functionality is generally useful for searching through multiple antecedent sets. For this simple example we could suppress this by shifting the uniform preemption probability down by .5, to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__antecedent_match_dropped: tensor([1, 0, 1, 0, 0, 1, 0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(100)\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc:  \n",
    "    with SearchForExplanation(antecedents = antecedents,\n",
    "                              # lower the probability of antecedent preemption \n",
    "                              # from .5 (default) to .4 \n",
    "                              witnesses = witnesses, \n",
    "                              consequents = consequents,\n",
    "                              # this is a scale for scoring changes to the consequent\n",
    "                              consequent_scale= 1e-8):\n",
    "        with condition(data = observations):\n",
    "            with pyro.plate(\"sample\", 10): \n",
    "                with pyro.poutine.trace() as tr:\n",
    "                    ff_disjunctive()\n",
    "\n",
    "tr.trace.compute_log_prob()\n",
    "nd = (tr.trace.nodes)\n",
    "\n",
    "print(\"__antecedent_match_dropped:\", nd[\"__antecedent_match_dropped\"][\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `match_dropped` and `forest_fire` now contain values for the factual and the counterfactual scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexSet({'match_dropped': {0, 1}})\n",
      "Antecedent Factual:\n",
      " tensor([[[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]]])\n",
      "Antecedent Counterfactual:\n",
      " tensor([[[[[1., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]]]])\n",
      "Consequent Factual:\n",
      " tensor([[[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]]])\n",
      "Consequent Counterfactual:\n",
      " tensor([[[[[1., 0., 1., 0., 0., 1., 0., 0., 0., 1.]]]]])\n"
     ]
    }
   ],
   "source": [
    "with mwc: # use the same mwc context\n",
    "    # each potential upstream intervention extends the indices\n",
    "    print( indices_of(nd[\"match_dropped\"][\"value\"]))\n",
    "    # you can use the indices to pick the right values with gather\n",
    "    antecedent_factual = gather(nd[\"match_dropped\"][\"value\"], IndexSet(**{'match_dropped': {0}}))\n",
    "    antecedent_counterfactual = gather(nd[\"match_dropped\"][\"value\"], IndexSet(**{'match_dropped': {1}}))\n",
    "\n",
    "    consequent_factual = gather(nd[\"forest_fire\"][\"value\"], IndexSet(**{'match_dropped': {0}}))\n",
    "    consequent_counterfactual = gather(nd[\"forest_fire\"][\"value\"], IndexSet(**{'match_dropped': {1}}))\n",
    "\n",
    "\n",
    "print(\"Antecedent Factual:\\n\", antecedent_factual)\n",
    "print(\"Antecedent Counterfactual:\\n\", antecedent_counterfactual)\n",
    "print(\"Consequent Factual:\\n\", consequent_factual)\n",
    "print(\"Consequent Counterfactual:\\n\", consequent_counterfactual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. While we already see that here the answer is positive, the counterfactual value of the consequent would be different, to handle more general cases, `__consequent_forest_fire` records the score assigned to whether the factual and counterfactual values of the consequent differ as a value in the log prob space. We used `consequent_scale= 1e-8` which in the binary case results in `log_prob = 0` for cases in which there is a difference and in `-inf` for cases where there isn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-inf, 0., -inf, 0., 0., -inf, 0., 0., 0., -inf]]]]])\n"
     ]
    }
   ],
   "source": [
    "with mwc: \n",
    "    print(gather(nd['__consequent_forest_fire']['log_prob'], \n",
    "                IndexSet(**{'match_dropped': {1}})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with the but-for analysis of causality, however, is that it misdiagnoses causal factors in cases that involve over-determination. For example, if we ask the same question in the context in which both a match has been dropped and a lightning strike occurred, the answer will be negative, as strictly speaking preventing the match from being dropped wouldn't have prevented the forest fire. Similarly, the lightning would not have been taken to be a cause either. This is a misdiagnosis, as we still think that these factors played a causal role.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf]]]]])\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(99)\n",
    "\n",
    "observations = {\"match_dropped\": torch.tensor(1.),\n",
    "                \"lightning\": torch.tensor(1.),  # we changed this line \n",
    "                \"forest_fire\": torch.tensor(1.)}\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc:  \n",
    "    with SearchForExplanation(antecedents = antecedents, \n",
    "                              witnesses = witnesses, \n",
    "                              consequents = consequents,\n",
    "                              consequent_scale= 1e-8):\n",
    "        with condition(data = observations):\n",
    "            with pyro.plate(\"sample\", 10):\n",
    "                with pyro.poutine.trace() as tr:\n",
    "                    ff_disjunctive()\n",
    "\n",
    "tr.trace.compute_log_prob()\n",
    "nd = tr.trace.nodes\n",
    "with mwc: \n",
    "    print(gather(nd['__consequent_forest_fire']['log_prob'], \n",
    "                IndexSet(**{'match_dropped': {1}})))\n",
    "    \n",
    "# -inf indicates no change to the consequent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Witness nodes and context sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these intuitions in the forest fire example may be salvaged by considering a two-membered antecedent set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]]]])\n"
     ]
    }
   ],
   "source": [
    "antecedents = {\"match_dropped\": 0.0, 'lightning': 0.0}\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc:  \n",
    "    with SearchForExplanation(antecedents = antecedents,\n",
    "                              # we ca enforce the execution of the intervention\n",
    "                              # if we're not realy searching through\n",
    "                              # cause candidates \n",
    "                              # by shifting the probability of antecedent preemption\n",
    "                              # from .5 (default) to 0\n",
    "                              antecedent_bias= -.5, \n",
    "                              witnesses = witnesses, \n",
    "                              consequents = consequents,\n",
    "                              consequent_scale= 1e-8):\n",
    "        with condition(data = observations):\n",
    "            with pyro.plate(\"sample\", 10):\n",
    "                with pyro.poutine.trace() as tr:\n",
    "                    ff_disjunctive()\n",
    "\n",
    "tr.trace.compute_log_prob()\n",
    "nd = tr.trace.nodes\n",
    "with mwc: \n",
    "    print(gather(nd['__consequent_forest_fire']['log_prob'], \n",
    "                IndexSet(**{'match_dropped': {1}, \"lightning\": {1}})))  \n",
    "                # note we needed to add the index for lightning now\n",
    "    \n",
    "# 0s indicate change to the consequent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This already suggests a more complicated picture, as it turns out that we need to pay attention to membership in larger antecedent sets that would make a difference (that is one reason why we need stochasticity in antecedent candidate preemption: to search for such sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But even then, the but-for analysis does not pay sufficient attention to the granularity of a given problem and its causal structure. There are asymmetric cases where the efficiency of one cause prevents the efficiency of another, in which our causal attributions should also be asymmetric, but \"being a member of the same larger antecedent set\" isn't.\n",
    "\n",
    "A simple example is breaking a bottle. Suppose Sally and Bob throw a rock at a bottle, and Sally does so a little earlier than Bob. Suppose both are perfectly accurate, and the bottle shatters when hit. Sally hits, the bottle \n",
    "shatters, but Bob doesn't hit it because the bottle is no longer there.  \n",
    "\n",
    "Sally's throw does not satisfy the but-for condition: if she hadn't thrown the rock, the bottle would still have shattered. Of course, the combined event of Sally throwing a rock and Bob throwing a rock is a but-for cause of the bottle shattering. But that doesn't capture the clear asymmetry at work here. Intuitively, Sally's throw is the (actual) cause of the bottle breaking in a way that Bob's throw isn't.  Sally's throw actually caused the bottle to shatter and Bob's throw didn't, in part because Bob's stone didn't actually hit the bottle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An intuitive solution to the problem, inspired by the  Pearl-Halpern definition of actual causality (which we discuss in [another notebook](https://basisresearch.github.io/chirho/actual_causality.html)) is to say that **in answering actual causality queries, we need to consider what happens when part of the actual context is kept fixed.** For instance, in the bottle shattering example, given the observed fact that Bob’s stone didn’t hit, in the counterfactual world in which we keep this observed fact fixed, if Sally did not throw the stone, the bottle in fact would not have shattered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this reason, `SearchForCauses` allows not only stochastic preemption of interventions (to approximate the search through possible antecedent sets), but also stochastic witness preemption of those nodes that are considered part of the context (these needn't exclude each other). In a witness preemption, we ensure that the counterfactual value is identical to the factual one (and by applying it randomly to candidate witness nodes, we approximate a search through all possible context sets). Let's define the model and apply the handler before looking at what the trace now contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"960pt\" height=\"332pt\"\n",
       " viewBox=\"0.00 0.00 959.93 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-328 955.93,-328 955.93,4 -4,4\"/>\n",
       "<!-- prob_sally_throws -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>prob_sally_throws</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"527.44\" cy=\"-306\" rx=\"94.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"527.44\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">prob_sally_throws</text>\n",
       "</g>\n",
       "<!-- sally_throws -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>sally_throws</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"527.44\" cy=\"-234\" rx=\"68.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"527.44\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">sally_throws</text>\n",
       "</g>\n",
       "<!-- prob_sally_throws&#45;&gt;sally_throws -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>prob_sally_throws&#45;&gt;sally_throws</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M527.44,-287.7C527.44,-279.98 527.44,-270.71 527.44,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"530.94,-262.1 527.44,-252.1 523.94,-262.1 530.94,-262.1\"/>\n",
       "</g>\n",
       "<!-- prob_bill_throws -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>prob_bill_throws</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"174.44\" cy=\"-234\" rx=\"87.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.44\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">prob_bill_throws</text>\n",
       "</g>\n",
       "<!-- bill_throws -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>bill_throws</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"226.44\" cy=\"-162\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"226.44\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">bill_throws</text>\n",
       "</g>\n",
       "<!-- prob_bill_throws&#45;&gt;bill_throws -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>prob_bill_throws&#45;&gt;bill_throws</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M187.03,-216.05C193.29,-207.63 200.98,-197.28 207.9,-187.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"210.82,-189.9 213.97,-179.79 205.2,-185.73 210.82,-189.9\"/>\n",
       "</g>\n",
       "<!-- prob_sally_hits -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>prob_sally_hits</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"360.44\" cy=\"-234\" rx=\"79.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"360.44\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">prob_sally_hits</text>\n",
       "</g>\n",
       "<!-- sally_hits -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>sally_hits</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"360.44\" cy=\"-162\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"360.44\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">sally_hits</text>\n",
       "</g>\n",
       "<!-- prob_sally_hits&#45;&gt;sally_hits -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>prob_sally_hits&#45;&gt;sally_hits</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M360.44,-215.7C360.44,-207.98 360.44,-198.71 360.44,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"363.94,-190.1 360.44,-180.1 356.94,-190.1 363.94,-190.1\"/>\n",
       "</g>\n",
       "<!-- prob_bill_hits -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>prob_bill_hits</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"73.44\" cy=\"-162\" rx=\"73.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"73.44\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">prob_bill_hits</text>\n",
       "</g>\n",
       "<!-- bill_hits -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>bill_hits</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"255.44\" cy=\"-90\" rx=\"47.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"255.44\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">bill_hits</text>\n",
       "</g>\n",
       "<!-- prob_bill_hits&#45;&gt;bill_hits -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>prob_bill_hits&#45;&gt;bill_hits</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M111.15,-146.5C141.03,-135.01 182.74,-118.96 213.63,-107.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"215.18,-110.24 223.26,-103.38 212.67,-103.7 215.18,-110.24\"/>\n",
       "</g>\n",
       "<!-- prob_bottle_shatters_if_sally -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>prob_bottle_shatters_if_sally</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"517.44\" cy=\"-90\" rx=\"143.77\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"517.44\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">prob_bottle_shatters_if_sally</text>\n",
       "</g>\n",
       "<!-- bottle_shatters -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>bottle_shatters</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"431.44\" cy=\"-18\" rx=\"81.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"431.44\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">bottle_shatters</text>\n",
       "</g>\n",
       "<!-- prob_bottle_shatters_if_sally&#45;&gt;bottle_shatters -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>prob_bottle_shatters_if_sally&#45;&gt;bottle_shatters</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M496.63,-72.05C485.56,-63.05 471.79,-51.84 459.77,-42.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"461.74,-39.15 451.77,-35.55 457.32,-44.57 461.74,-39.15\"/>\n",
       "</g>\n",
       "<!-- prob_bottle_shatters_if_bill -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>prob_bottle_shatters_if_bill</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"815.44\" cy=\"-90\" rx=\"136.48\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"815.44\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">prob_bottle_shatters_if_bill</text>\n",
       "</g>\n",
       "<!-- prob_bottle_shatters_if_bill&#45;&gt;bottle_shatters -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>prob_bottle_shatters_if_bill&#45;&gt;bottle_shatters</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M738.66,-75C669.65,-62.42 569.12,-44.1 502.07,-31.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"502.48,-28.39 492.02,-30.04 501.23,-35.28 502.48,-28.39\"/>\n",
       "</g>\n",
       "<!-- sally_throws&#45;&gt;sally_hits -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>sally_throws&#45;&gt;sally_hits</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M492.43,-218.33C466.08,-207.28 429.87,-192.1 402.04,-180.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"403.15,-177.11 392.58,-176.47 400.45,-183.56 403.15,-177.11\"/>\n",
       "</g>\n",
       "<!-- bill_throws&#45;&gt;bill_hits -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>bill_throws&#45;&gt;bill_hits</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.46,-144.05C236.73,-136.18 240.69,-126.62 244.34,-117.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"247.69,-118.85 248.29,-108.28 241.23,-116.17 247.69,-118.85\"/>\n",
       "</g>\n",
       "<!-- sally_hits&#45;&gt;bill_hits -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>sally_hits&#45;&gt;bill_hits</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M337.4,-145.64C322.53,-135.72 302.99,-122.7 286.72,-111.85\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"288.33,-108.72 278.07,-106.09 284.45,-114.54 288.33,-108.72\"/>\n",
       "</g>\n",
       "<!-- sally_hits&#45;&gt;bottle_shatters -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>sally_hits&#45;&gt;bottle_shatters</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M357.19,-143.87C354.51,-125.12 352.81,-94.72 364.44,-72 370.85,-59.48 381.71,-48.96 392.83,-40.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"395.11,-43.37 401.33,-34.79 391.12,-37.62 395.11,-43.37\"/>\n",
       "</g>\n",
       "<!-- bill_hits&#45;&gt;bottle_shatters -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>bill_hits&#45;&gt;bottle_shatters</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M286.91,-76.49C313.94,-65.73 353.32,-50.07 384.15,-37.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"385.83,-40.91 393.83,-33.96 383.24,-34.4 385.83,-40.91\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f6c9186a320>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stones_model():        \n",
    "    prob_sally_throws = pyro.sample(\"prob_sally_throws\", dist.Beta(1, 1))\n",
    "    prob_bill_throws = pyro.sample(\"prob_bill_throws\", dist.Beta(1, 1))\n",
    "    prob_sally_hits = pyro.sample(\"prob_sally_hits\", dist.Beta(1, 1))\n",
    "    prob_bill_hits = pyro.sample(\"prob_bill_hits\", dist.Beta(1, 1))\n",
    "    prob_bottle_shatters_if_sally = pyro.sample(\"prob_bottle_shatters_if_sally\", dist.Beta(1, 1))\n",
    "    prob_bottle_shatters_if_bill = pyro.sample(\"prob_bottle_shatters_if_bill\", dist.Beta(1, 1))\n",
    "\n",
    "    sally_throws = pyro.sample(\"sally_throws\", dist.Bernoulli(prob_sally_throws))\n",
    "    bill_throws = pyro.sample(\"bill_throws\", dist.Bernoulli(prob_bill_throws))\n",
    "\n",
    "    # if Sally throws, she hits with probability prob_sally_hits\n",
    "    # hits with pr=0 otherwise\n",
    "    new_shp = torch.where(sally_throws == 1,prob_sally_hits, 0.0)\n",
    "\n",
    "    sally_hits = pyro.sample(\"sally_hits\",dist.Bernoulli(new_shp))\n",
    "\n",
    "    # if Bill throws, he hits with probability prob_bill_hits\n",
    "    # if sally doesn't hit sooner,\n",
    "    # misses otherwise\n",
    "    new_bhp = torch.where(\n",
    "        bill_throws.bool() & (~sally_hits.bool()),\n",
    "        prob_bill_hits,\n",
    "        torch.tensor(0.0),\n",
    "    )\n",
    "\n",
    "    bill_hits = pyro.sample(\"bill_hits\", dist.Bernoulli(new_bhp))\n",
    "\n",
    "    # you can use a analogous move to model the bottle shattering\n",
    "    # if being hit by a stone doesn't deterministically\n",
    "    # shatter the bottle\n",
    "    new_bsp = torch.where(bill_hits.bool(), prob_bottle_shatters_if_bill,\n",
    "            torch.where(sally_hits.bool(),prob_bottle_shatters_if_sally,torch.tensor(0.0),),)\n",
    "\n",
    "    bottle_shatters = pyro.sample(\"bottle_shatters\", dist.Bernoulli(new_bsp))\n",
    "\n",
    "    return {\"sally_throws\": sally_throws, \"bill_throws\": bill_throws,  \"sally_hits\": sally_hits,\n",
    "            \"bill_hits\": bill_hits,  \"bottle_shatters\": bottle_shatters,}\n",
    "\n",
    "stones_model.nodes = [\"sally_throws\",\"bill_throws\", \"sally_hits\", \"bill_hits\",\"bottle_shatters\",]\n",
    "\n",
    "def tensorize_observations(observations):\n",
    "    return {k: torch.as_tensor(v) for k, v in observations.items()}\n",
    "\n",
    "# for now, we assume the mechanisms are deterministic\n",
    "# and that both sally and bill throw stones\n",
    "observations = {\"prob_sally_throws\": 1.0, \n",
    "                \"prob_bill_throws\": 1.0,\n",
    "                \"prob_sally_hits\": 1.0,\n",
    "                \"prob_bill_hits\": 1.0,\n",
    "                \"prob_bottle_shatters_if_sally\": 1.0,\n",
    "                \"prob_bottle_shatters_if_bill\": 1.0,\n",
    "                \"sally_throws\": 1.0, \"bill_throws\": 1.0}\n",
    "\n",
    "observations_tensorized = tensorize_observations(observations)\n",
    "\n",
    "antecedents = {\"sally_hits\": torch.tensor(0.)}\n",
    "\n",
    "# this now specifies those nodes that are candidates for witnesses\n",
    "# i.e. those parts of context that are held fixed in a given run\n",
    "# in the counterfactual world\n",
    "witnesses = {\"bill_hits\": constraints.boolean,}\n",
    "\n",
    "\n",
    "consequents = {\"bottle_shatters\": constraints.boolean}\n",
    "\n",
    "pyro.set_rng_seed(100)\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc:\n",
    "    with SearchForExplanation(antecedents = antecedents, \n",
    "                       witnesses = witnesses, \n",
    "                       consequents = consequents,\n",
    "                       consequent_scale= 1e-8):\n",
    "        with condition(data = observations_tensorized):\n",
    "            with pyro.plate(\"sample\", 5000): \n",
    "                # increased sample size as we'll be estimating probabilities soon\n",
    "                with pyro.poutine.trace() as tr:\n",
    "                    stones_model()\n",
    "\n",
    "tr.trace.compute_log_prob()\n",
    "\n",
    "pyro.render_model(stones_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the original nodes and the auxiliary `__antecedent` and `__consequent` nodes, the trace now contains also:\n",
    "\n",
    "-  new auxiliary variables of the form `__witness_<node_name>`, which record whether in a particular model run the original node has been considered part of the context to be fixed. If so, its counterfactual value has been preempted to be the same as its factual value (witness preemption trumps antecedent intervention if the antecedent and witness sets overlap).\n",
    "- new auxiliary variables of the form `__antecedent__proposal_<node_name>`, which records the proposed alternative values of the antecedent has been used in particular model runs. This is because instead of specifying the alternative antecedent value for contrast, passing a `constraint` instead, telling `SearchForCauses` to sample alternatives from an appropriate distribution. In the binary case this is not very exciting, as there is only one alternative value (we also introduced some redundancy as now some of the proposed values are identical to the factual value), but keeping track of proposals is definitely much more useful in the continuous case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['__antecedent_match_dropped', 'match_dropped', 'lightning', 'forest_fire_factual', 'forest_fire_counterfactual', '__consequent_forest_fire', 'forest_fire'])\n"
     ]
    }
   ],
   "source": [
    "nd = tr.trace.nodes\n",
    "print(nd.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we use the resulting trace to answer causal queries that we were interested with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified actual causality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question you might be interested in is a simplified question in line with the original Halpern-Pearl definition (take a look at a separate notebook, if you're interested in the details of the original definition):\n",
    "\n",
    "**Is there some context such that if it is kept fixed at the factual values, if the antecedent were different, so would be the consequent?**\n",
    "\n",
    "In our case, we might want to know whether there are some nodes which kept fixed would make a context-restricted but-for clause true (intuitively: keeping the fact that bill failed fixed, if Sally didn't throw the stone, the bottle wouldn't have shattered). \n",
    "\n",
    "To answer this query using the trace we need to focus on cases in which the antecedent has been intervened and ask whether any of the resulting log prob scores is `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "mask = nd['__antecedent_sally_hits']['value'] == 0\n",
    "with mwc:\n",
    "    scores = gather(nd['__consequent_bottle_shatters']['log_prob'], \n",
    "                IndexSet(**{'sally_hits': 1})).squeeze()\n",
    "\n",
    "print(torch.any(scores[mask] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability that X is a cause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might be interested in more involved queries. For instance, in the probability of a context-sensitive but-for clause holding.\n",
    "\n",
    "**Assuming each witness candidate is equally likely to be considered part of a context and we observed such and such outcome, what's the probability that the antecedent having a different value would lead to a different outcome?**\n",
    "\n",
    "To answer this query, we need to also exclude cases in which the antecedent has been antecedent preempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4953)\n"
     ]
    }
   ],
   "source": [
    "mask_intervened = nd['__antecedent_sally_hits']['value'] == 0\n",
    "\n",
    "print(\n",
    "torch.mean((scores[mask_intervened] == 0).float())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular case, since Sally is sure to hit if she throws and sure to shatter the bottle if she hits, the only stochastic part is whether we keep the only relevant witness (`bill_hits`) fixed. If we set witness bias to .0 and so the witness preemption probability to .5, the bottle shatters if an only if this witness is preempted, the bottle shatters. This somewhat degenerate example illustrates that `witness_bias` is an important parameter. The parameter specifies the \"level of realism\" with which one wants to consider the context to be fixed. At one extreme, if witness bias is `-.5` no attention is paid to the context and we're back at the but-for clause and probability of causality being 0. On another, witness bias is `.5` and then all witnesses are always kept fixed, which results in the most local evaluation and the probability of causality equaling 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine we only have partial knowledge. We know the probabilities involved (let's make them less trivial in this example), we observed the consequent (the bottle shattered), but we don't know what the cause of this event was. In such a situation, we include all nodes of interest in the list of potential causes **and** in the list of potential witnesses (as they might be witnesses for other nodes). Moreover, since we don't know what values they have, we can't really set some particular values as the alternative antecedent values for contrast, and need to sample from appropriate proposal distributions instead. Let's say we focus on stones hitting the bottle and the bottle shattering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = {\"prob_sally_throws\": .6, \n",
    "                \"prob_bill_throws\": .4,\n",
    "                \"prob_sally_hits\": .9,\n",
    "                \"prob_bill_hits\": .8,\n",
    "                \"prob_bottle_shatters_if_sally\": .9,\n",
    "                \"prob_bottle_shatters_if_bill\": .8,\n",
    "                \"bottle_shatters\": 1.}\n",
    "\n",
    "observations_tensorized = tensorize_observations(observations)\n",
    "\n",
    "antecedents = {\"sally_hits\": constraints.boolean, \n",
    "               \"bill_hits\": constraints.boolean}\n",
    "\n",
    "witnesses = {\"sally_hits\": constraints.boolean, \n",
    "               \"bill_hits\": constraints.boolean}\n",
    "\n",
    "# witnesses and antecedents now overlap\n",
    "# if they both happen to be preempted,\n",
    "# witness preemption wins and the \n",
    "# counterfactual values are identical to the factual ones\n",
    "\n",
    "consequents = {\"bottle_shatters\": constraints.boolean}\n",
    "\n",
    "pyro.set_rng_seed(100)\n",
    "\n",
    "with MultiWorldCounterfactual() as mwc_prob:\n",
    "    with SearchForExplanation(antecedents = antecedents, \n",
    "                       witnesses = witnesses, \n",
    "                       consequents = consequents,\n",
    "                       consequent_scale= 1e-8):\n",
    "        with condition(data = observations_tensorized):\n",
    "            with pyro.plate(\"sample\", 5000): \n",
    "                with pyro.poutine.trace() as tr_prob:\n",
    "                    stones_model()\n",
    "\n",
    "tr_prob.trace.compute_log_prob()\n",
    "nd_prob = tr_prob.trace.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are at least two different queries that we might be interested in. We might want to focus on a particular variable and ask:\n",
    "\n",
    "**With what probability would making a change to X make a difference to the consequent (assuming all witness candidates are equally likely)?**\n",
    "\n",
    "which is analogous to the query we already covered (Probability that X is a cause), except now we do not assume we know what the factual value of X is. The use of trace, however, is pretty much the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexSet({'sally_hits': {0, 1}, 'bill_hits': {0, 1}})\n",
      "sally_hits: 0.42266401648521423\n",
      "bill_hits: 0.38750511407852173\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with mwc_prob:\n",
    "    print(indices_of(nd_prob['__consequent_bottle_shatters']['log_prob']))\n",
    "    scores = gather(nd_prob['__consequent_bottle_shatters']['log_prob'], \n",
    "               IndexSet(**{'sally_hits': 1, 'bill_hits': 1})).squeeze()\n",
    "\n",
    "# mind your head: index values equal to 1 \n",
    "# mean we're picking from the counterfactual scenario\n",
    "# but it's still possible we're dealing with preemption\n",
    "# and the counterfactual value mirrors the factual one    \n",
    "\n",
    "for ant in antecedents.keys():\n",
    "    mask_intervened = nd_prob[f'__antecedent_{ant}']['value'] == 0\n",
    "\n",
    "    # now we need to make sure it's not witness preempted either\n",
    "    mask_not_witness = nd_prob[f'__antecedent_{ant}']['value'] == 0\n",
    "\n",
    "    mask = torch.logical_and(mask_intervened, mask_not_witness)\n",
    "\n",
    "    print(f\"{ant}: {torch.mean((scores[mask] == 0).float())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we also can start with focusing on those scenarios where the counterfactual value of the consequent differs from the factual one and ask about the probability that a given variable is involved:\n",
    "\n",
    "**If a difference in outcomes results, what's the probability that a change in the value of $X$ was involved (assuming all the witness candidates...)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sally_hits: 0.5283300280570984\n",
      "bill_hits: 0.4716699719429016\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with mwc_prob:\n",
    "    scores = gather(nd_prob['__consequent_bottle_shatters']['log_prob'], \n",
    "               IndexSet(**{'sally_hits': 1, 'bill_hits': 1})).squeeze()\n",
    "\n",
    "# mind your head: index values equal to 1 \n",
    "# mean we're picking from the counterfactual scenario\n",
    "# but it's still possible we're dealing with preemption\n",
    "# and the counterfactual value mirrors the factual one    \n",
    "\n",
    "mask_outcome_diff = scores == 0 \n",
    "\n",
    "for ant in antecedents.keys():\n",
    "\n",
    "    mask_intervened = nd_prob[f'__antecedent_{ant}']['value'] == 0 \n",
    "    mask_not_witness = nd_prob[f'__antecedent_{ant}']['value'] == 0\n",
    "    mask = torch.logical_and(mask_intervened, mask_not_witness)\n",
    "    print(f\"{ant}: {torch.mean((mask[mask_outcome_diff]).float())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that the pairs of values differ might be initially surprising. The first pair seems intuitive: after all, Sally throws first, and her probabilies are higher, so you'd expect her hitting to have higher \"causal power\". The latter calculations, though, also track a different probability, that of involvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chirho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
