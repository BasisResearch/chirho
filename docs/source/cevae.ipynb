{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: the causal effect variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Optional, Tuple, Union, TypeVar\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "from pyro.infer.util import torch_item\n",
    "from pyro.nn import PyroModule, PyroSample, PyroParam\n",
    "from pyro.contrib.autoname import scope\n",
    "from pyro.poutine import condition, reparam\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.util import torch_isnan\n",
    "\n",
    "import causal_pyro\n",
    "from causal_pyro.query.do_messenger import do\n",
    "from causal_pyro.counterfactual.handlers import Factual, MultiWorldCounterfactual, TwinWorldCounterfactual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of what to do\n",
    "\n",
    "- [X] Look at Pyro intro tutorial, tensor shapes tutorial, variational inference background tutorials, \n",
    "    - the paper cited in the CEVAE example (which is somewhat unrealistic, assuming identifiablity)\n",
    "- [X] define a forward model\n",
    "- [X] fill in neural networks from https://github.com/pyro-ppl/pyro/blob/b7ba915b851d51c61d805da741bf7a74fcf9319d/pyro/contrib/cevae/__init__.py\n",
    "    - the NNs are functions with learnable params\n",
    "- [X] practice using SVI by fitting the original (non intervened) model\n",
    "    CEVAE_CATE takes the original model, and twins it, and makes interventions\n",
    "- [X] Make an intervened model, pyro.render_model to make graphical models http://pyro.ai/examples/model_rendering.html\n",
    "    - it renders, but haven't gotten SVI working yet\n",
    "- [ ] fit the model (Start with code in pyro cevae, with autoguide, and pyro.infer.traceELBO)\n",
    "    - likely modify to make treatment effect an output of the model\n",
    "- [ ] compare the ate that I get with the Pyro implementation below\n",
    "\n",
    "- https://github.com/BasisResearch/causal_pyro/issues/46\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Fully connected multi-layer network with ELU activations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes, final_activation=None):\n",
    "        layers = []\n",
    "        for in_size, out_size in zip(sizes, sizes[1:]):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            layers.append(nn.ELU())\n",
    "        layers.pop(-1)\n",
    "        if final_activation is not None:\n",
    "            layers.append(final_activation)\n",
    "        super().__init__(*layers)\n",
    "\n",
    "    def append(self, layer):\n",
    "        assert isinstance(layer, nn.Module)\n",
    "        self.add_module(str(len(self)), layer)\n",
    "\n",
    "\n",
    "class DistributionNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for distribution nets.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_class(dtype):\n",
    "        \"\"\"\n",
    "        Get a subclass by a prefix of its name, e.g.::\n",
    "            assert DistributionNet.get_class(\"bernoulli\") is BernoulliNet\n",
    "        \"\"\"\n",
    "        for cls in DistributionNet.__subclasses__():\n",
    "            if cls.__name__.lower() == dtype + \"net\":\n",
    "                return cls\n",
    "        raise ValueError(\"dtype not supported: {}\".format(dtype))\n",
    "\n",
    "\n",
    "class BernoulliNet(DistributionNet):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a single ``logits`` value.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    single Bernoulli random variable conditioned on a ``sizes[0]``-sized real\n",
    "    value, for example::\n",
    "        net = BernoulliNet([3, 4])\n",
    "        z = torch.randn(3)\n",
    "        logits, = net(z)\n",
    "        t = net.make_dist(logits).sample()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 1\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes + [1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.fc(x).squeeze(-1).clamp(min=-10, max=10)\n",
    "        return (logits,)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dist(logits):\n",
    "        return dist.Bernoulli(logits=logits)\n",
    "\n",
    "\n",
    "class ExponentialNet(DistributionNet):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a constrained ``rate``.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    single Normal random variable conditioned on a ``sizes[0]``-size real\n",
    "    value, for example::\n",
    "        net = ExponentialNet([3, 4])\n",
    "        x = torch.randn(3)\n",
    "        rate, = net(x)\n",
    "        y = net.make_dist(rate).sample()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 1\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes + [1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = nn.functional.softplus(self.fc(x).squeeze(-1)).clamp(min=1e-3, max=1e6)\n",
    "        rate = scale.reciprocal()\n",
    "        return (rate,)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dist(rate):\n",
    "        return dist.Exponential(rate)\n",
    "\n",
    "\n",
    "class LaplaceNet(DistributionNet):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a constrained ``loc,scale``\n",
    "    pair.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    single Laplace random variable conditioned on a ``sizes[0]``-size real\n",
    "    value, for example::\n",
    "        net = LaplaceNet([3, 4])\n",
    "        x = torch.randn(3)\n",
    "        loc, scale = net(x)\n",
    "        y = net.make_dist(loc, scale).sample()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 1\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes + [2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        loc_scale = self.fc(x)\n",
    "        loc = loc_scale[..., 0].clamp(min=-1e6, max=1e6)\n",
    "        scale = nn.functional.softplus(loc_scale[..., 1]).clamp(min=1e-3, max=1e6)\n",
    "        return loc, scale\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dist(loc, scale):\n",
    "        return dist.Laplace(loc, scale)\n",
    "\n",
    "\n",
    "class NormalNet(DistributionNet):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a constrained ``loc,scale``\n",
    "    pair.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    single Normal random variable conditioned on a ``sizes[0]``-size real\n",
    "    value, for example::\n",
    "        net = NormalNet([3, 4])\n",
    "        x = torch.randn(3)\n",
    "        loc, scale = net(x)\n",
    "        y = net.make_dist(loc, scale).sample()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 1\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes + [2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        loc_scale = self.fc(x)\n",
    "        loc = loc_scale[..., 0].clamp(min=-1e6, max=1e6)\n",
    "        scale = nn.functional.softplus(loc_scale[..., 1]).clamp(min=1e-3, max=1e6)\n",
    "        return loc, scale\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dist(loc, scale):\n",
    "        return dist.Normal(loc, scale)\n",
    "\n",
    "\n",
    "class StudentTNet(DistributionNet):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a constrained ``df,loc,scale``\n",
    "    triple, with shared ``df > 1``.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    single Student's t random variable conditioned on a ``sizes[0]``-size real\n",
    "    value, for example::\n",
    "        net = StudentTNet([3, 4])\n",
    "        x = torch.randn(3)\n",
    "        df, loc, scale = net(x)\n",
    "        y = net.make_dist(df, loc, scale).sample()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 1\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes + [2])\n",
    "        self.df_unconstrained = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        loc_scale = self.fc(x)\n",
    "        loc = loc_scale[..., 0].clamp(min=-1e6, max=1e6)\n",
    "        scale = nn.functional.softplus(loc_scale[..., 1]).clamp(min=1e-3, max=1e6)\n",
    "        df = nn.functional.softplus(self.df_unconstrained).add(1).expand_as(loc)\n",
    "        return df, loc, scale\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dist(df, loc, scale):\n",
    "        return dist.StudentT(df, loc, scale)\n",
    "\n",
    "\n",
    "class DiagNormalNet(nn.Module):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a constrained ``loc,scale``\n",
    "    pair.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    ``sizes[-1]``-sized diagonal Normal random variable conditioned on a\n",
    "    ``sizes[0]``-size real value, for example::\n",
    "        net = DiagNormalNet([3, 4, 5])\n",
    "        z = torch.randn(3)\n",
    "        loc, scale = net(z)\n",
    "        x = dist.Normal(loc, scale).sample()\n",
    "    This is intended for the latent ``z`` distribution and the prewhitened\n",
    "    ``x`` features, and conservatively clips ``loc`` and ``scale`` values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 2\n",
    "        self.dim = sizes[-1]\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes[:-1] + [self.dim * 2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        loc_scale = self.fc(x)\n",
    "        loc = loc_scale[..., : self.dim].clamp(min=-1e2, max=1e2)\n",
    "        scale = (\n",
    "            nn.functional.softplus(loc_scale[..., self.dim :]).add(1e-3).clamp(max=1e2)\n",
    "        )\n",
    "        return loc, scale\n",
    "\n",
    "\n",
    "class PreWhitener(nn.Module):\n",
    "    \"\"\"\n",
    "    Data pre-whitener.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        with torch.no_grad():\n",
    "            loc = data.mean(0)\n",
    "            scale = data.std(0)\n",
    "            scale[~(scale > 0)] = 1.0\n",
    "            self.register_buffer(\"loc\", loc)\n",
    "            self.register_buffer(\"inv_scale\", scale.reciprocal())\n",
    "\n",
    "    def forward(self, data):\n",
    "        return (data - self.loc) * self.inv_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Proxy variables and latent confounders\n",
    "\n",
    "The backdoor adjustment example assumed that it was always possible to measure all\n",
    "potential confounders $X$, but when this is not the case, additional\n",
    "assumptions are necessary to perform causal inference. This example,\n",
    "derived from @louizos2017causal, considers a setting where parametric\n",
    "assumptions are necessary for a causal model to be fully identifiable\n",
    "from observed data.\n",
    "\n",
    "Suppose we observe a population of individuals with features $X_i$\n",
    "undergo treatment $t_i \\in \\{0, 1\\}$ with outcome $y_i$. The treatment\n",
    "variable might represent a medication or an educational strategy, for\n",
    "example, for populations of patients or students, respectively.\n",
    "\n",
    "The task\n",
    "is to estimate the *conditional average treatment effect*: for a new\n",
    "individual with features $X_*$, what difference in outcome $y_*$ should\n",
    "we expect if we assign treatment $t_* = 1$ vs. $t_* = 0$? One cannot\n",
    "simply estimate the conditional probabilities\n",
    "$p(y_* \\mid X = X_*, t = 0)$ and $p(y_* \\mid X = X_*, t = 1)$, because\n",
    "there may be hidden confounders: latent factors $z$ that induce\n",
    "non-causal correlations between $t$ and $y$ even controlling for the\n",
    "observed covariates $X$. \n",
    "\n",
    "For example, a student's socio-economic status\n",
    "might influence both their outcome $y$ and the educational strategy $t$\n",
    "they are exposed to, and the observed covariates $X$ may not fully\n",
    "characterize the student's SES. As a result, conditioning on $t$ may\n",
    "alter the distribution over SES, changing the reported outcome.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: neural surrogate causal Bayesian network\n",
    "\n",
    "Our model captures the intuition that our three observed variables, $X$,\n",
    "$t$, and $y$, may be correlated, thanks to unobserved confounders $z$.\n",
    "Here, $f$, $g$, and $h$ are neural networks parameterized by different\n",
    "parts of the parameter set $\\theta$. The parameters of our model can be fit\n",
    "using standard techniques in Pyro (e.g., stochastic variational\n",
    "inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProxyConfounderModel(PyroModule):\n",
    "    \"\"\"\n",
    "    Generative model for a causal model with latent confounder ``z`` and binary\n",
    "    treatment ``t``::\n",
    "        z ~ p(z)      # latent confounder\n",
    "        x ~ p(x|z)    # partial noisy observation of z\n",
    "        t ~ p(t|z)    # treatment, whose application is biased by z\n",
    "        y ~ p(y|t,z)  # outcome\n",
    "    Each of these distributions is defined by a neural network.  The ``y``\n",
    "    distribution is defined by a disjoint pair of neural networks defining\n",
    "    ``p(y|t=0,z)`` and ``p(y|t=1,z)``; this allows highly imbalanced treatment.\n",
    "    :param dict config: A dict specifying ``feature_dim``, ``latent_dim``,\n",
    "        ``hidden_dim``, ``num_layers``, and ``outcome_dist``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.latent_dim = config[\"latent_dim\"]\n",
    "        super().__init__()\n",
    "        self.x_nn = DiagNormalNet(\n",
    "            [config[\"latent_dim\"]]\n",
    "            + [config[\"hidden_dim\"]] * config[\"num_layers\"]\n",
    "            + [config[\"feature_dim\"]]\n",
    "        )\n",
    "        OutcomeNet = DistributionNet.get_class(config[\"outcome_dist\"])\n",
    "        # The y network is split between the two t values.\n",
    "        self.y0_nn = OutcomeNet(\n",
    "            [config[\"latent_dim\"]] + [config[\"hidden_dim\"]] * config[\"num_layers\"]\n",
    "        )\n",
    "        self.y1_nn = OutcomeNet(\n",
    "            [config[\"latent_dim\"]] + [config[\"hidden_dim\"]] * config[\"num_layers\"]\n",
    "        )\n",
    "        self.t_nn = BernoulliNet([config[\"latent_dim\"]])\n",
    "\n",
    "    def forward(self, x, t=None, y=None):\n",
    "        z = pyro.sample(\"z\", self.z_dist())\n",
    "        x = pyro.sample(\"x\", self.x_dist(z), obs=x)\n",
    "        t = pyro.sample(\"t\", self.t_dist(z), obs=t)\n",
    "        y = pyro.sample(\"y\", self.y_dist(t, z), obs=y)\n",
    "        return y\n",
    "\n",
    "    def y_mean(self, x, t=None):\n",
    "        z = pyro.sample(\"z\", self.z_dist())\n",
    "        x = pyro.sample(\"x\", self.x_dist(z), obs=x)\n",
    "        t = pyro.sample(\"t\", self.t_dist(z), obs=t)\n",
    "        return self.y_dist(t, z).mean\n",
    "\n",
    "    def z_dist(self):\n",
    "        return dist.Normal(0, 1).expand([self.latent_dim]).to_event(1)\n",
    "\n",
    "    def x_dist(self, z):\n",
    "        loc, scale = self.x_nn(z)\n",
    "        return dist.Normal(loc, scale).to_event(1)\n",
    "\n",
    "    def y_dist(self, t, z):\n",
    "        # Parameters are not shared among t values.\n",
    "        params0 = self.y0_nn(z)\n",
    "        params1 = self.y1_nn(z)\n",
    "        t = t.bool()\n",
    "        params = [torch.where(t, p1, p0) for p0, p1 in zip(params0, params1)]\n",
    "        return self.y0_nn.make_dist(*params)\n",
    "\n",
    "    def t_dist(self, z):\n",
    "        (logits,) = self.t_nn(z)\n",
    "        return dist.Bernoulli(logits=logits)\n",
    "    \n",
    "# ProxyConfounderModel(config).x_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = 1000\n",
    "feature_dim = 5\n",
    "num_layers = 3 \n",
    "num_epochs = 50 \n",
    "batch_size = 100 \n",
    "learning_rate = 1e-3 \n",
    "learning_rate_decay = 0.1 \n",
    "weight_decay = 1e-4\n",
    "seed = 1234567890\n",
    "jit = False \n",
    "cuda = False\n",
    "latent_dim = 20 \n",
    "hidden_dim = 200\n",
    "outcome_dist = \"bernoulli\"\n",
    "num_layers=3\n",
    "num_samples=100\n",
    "\n",
    "def generate_data(num_data,\n",
    "    feature_dim):\n",
    "\n",
    "    z = dist.Bernoulli(0.5).sample([num_data])\n",
    "    x = dist.Normal(z, 5 * z + 3 * (1 - z)).sample([feature_dim]).t()\n",
    "    t = dist.Bernoulli(0.75 * z + 0.25 * (1 - z)).sample()\n",
    "    y = dist.Bernoulli(logits=3 * (z + 2 * (2 * t - 2))).sample()\n",
    "\n",
    "    # Compute true ite for evaluation (via Monte Carlo approximation).\n",
    "    t0_t1 = torch.tensor([[0.0], [1.0]])\n",
    "    y_t0, y_t1 = dist.Bernoulli(logits=3 * (z + 2 * (2 * t0_t1 - 2))).mean\n",
    "    true_ite = y_t1 - y_t0\n",
    "    return x, t, y, true_ite\n",
    "\n",
    "\n",
    "x, t, y, true_ite = generate_data(num_data, feature_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.0 (20221023.0053)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"330pt\" height=\"610pt\"\n",
       " viewBox=\"0.00 0.00 329.50 610.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 606)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-606 325.5,-606 325.5,4 -4,4\"/>\n",
       "<!-- z -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"99\" cy=\"-373\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-369.3\" font-family=\"Times,serif\" font-size=\"14.00\">z</text>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;x -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>z&#45;&gt;x</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M94.6,-354.85C82.55,-307.8 48.89,-176.43 34.11,-118.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"37.59,-118.21 31.71,-109.4 30.81,-119.95 37.59,-118.21\"/>\n",
       "</g>\n",
       "<!-- t -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>t</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">t</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;t -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>z&#45;&gt;t</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99,-354.85C99,-308.01 99,-177.6 99,-119.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-119.8 99,-109.8 95.5,-119.8 102.5,-119.8\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"126\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>z&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.17,-354.79C109.73,-312.8 128.64,-201.69 135,-108 136.08,-92.04 136.34,-87.94 135,-72 134.32,-63.97 133.08,-55.33 131.73,-47.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.17,-46.79 129.93,-37.58 128.29,-48.05 135.17,-46.79\"/>\n",
       "</g>\n",
       "<!-- t&#45;&gt;y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>t&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M105.54,-72.05C108.52,-64.32 112.13,-54.96 115.48,-46.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.65,-47.79 118.98,-37.2 112.12,-45.27 118.65,-47.79\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-586.8\" font-family=\"Times,serif\" font-size=\"14.00\">z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-571.8\" font-family=\"Times,serif\" font-size=\"14.00\">x ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-556.8\" font-family=\"Times,serif\" font-size=\"14.00\">t ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-541.8\" font-family=\"Times,serif\" font-size=\"14.00\">y ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-526.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-511.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-496.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-481.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-466.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-451.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-436.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-421.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-406.8\" font-family=\"Times,serif\" font-size=\"14.00\">t_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-391.8\" font-family=\"Times,serif\" font-size=\"14.00\">t_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-376.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-361.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-346.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-331.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-316.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-286.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-256.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-241.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-226.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-211.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-196.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-181.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-166.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.6.bias : Real()</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fc88810a670>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "        feature_dim=feature_dim,\n",
    "        latent_dim=latent_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_samples=num_samples,\n",
    "        outcome_dist=outcome_dist\n",
    "    )\n",
    "\n",
    "pyro.render_model(ProxyConfounderModel(config), model_args=(x,t,y), render_distributions=True, render_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit with SVI (to practice SVI syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 134.6248\n",
      "[iteration 0101] loss: 36.2104\n",
      "[iteration 0201] loss: 35.4132\n",
      "[iteration 0301] loss: 35.2210\n",
      "[iteration 0401] loss: 35.1679\n"
     ]
    }
   ],
   "source": [
    "def observational_model(individual_model: ProxyConfounderModel) -> Callable:\n",
    "    def _wrapper(x_obs, t_obs, y_obs):\n",
    "        size = x_obs.shape[0]\n",
    "        with pyro.plate(\"observations\", size=size, dim=-1):\n",
    "            return individual_model(x_obs, t_obs, y_obs)\n",
    "    return _wrapper\n",
    "\n",
    "model_to_fit = observational_model(ProxyConfounderModel(config))\n",
    "guide = pyro.infer.autoguide.AutoNormal(model_to_fit)\n",
    "\n",
    "\n",
    "# Define loss and optimize\n",
    "# loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "adam = pyro.optim.Adam({\"lr\": 0.03})\n",
    "svi = SVI(model_to_fit, guide, adam, loss=Trace_ELBO())\n",
    "\n",
    "\n",
    "num_iterations = 500 \n",
    "x_data = x.clone().detach().requires_grad_(True)\n",
    "t_data = t.clone().detach().requires_grad_(True)\n",
    "y_data = y.clone().detach().requires_grad_(True)\n",
    "\n",
    "\n",
    "pyro.clear_param_store()\n",
    "for j in range(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_data, t_data, y_data)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_data)))\n",
    "\n",
    "\n",
    "# # Inspect learned parameters\n",
    "# print(\"Learned parameters:\")\n",
    "# for name, param in model_to_fit.named_parameters():\n",
    "#     print(name, param.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: conditional average treatment effect (CATE)\n",
    "\n",
    "We can now set up a larger model in which the *conditional average\n",
    "treatment effect* (CATE) we want to estimate is a random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.0 (20221023.0053)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1062pt\" height=\"755pt\"\n",
       " viewBox=\"0.00 0.00 1062.00 755.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 751)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-751 1058,-751 1058,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_observations</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"604,-39 604,-506.5 766,-506.5 766,-39 604,-39\"/>\n",
       "<text text-anchor=\"middle\" x=\"723.5\" y=\"-46.8\" font-family=\"Times,serif\" font-size=\"14.00\">observations</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_intervention_2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-122 596,-122 596,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"548.5\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervention_2</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_intervention_3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"16,-39 16,-114 588,-114 588,-39 16,-39\"/>\n",
       "<text text-anchor=\"middle\" x=\"540.5\" y=\"-46.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervention_3</text>\n",
       "</g>\n",
       "<!-- intervened/z -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>intervened/z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"307\" cy=\"-480.5\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"307\" y=\"-476.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/z</text>\n",
       "</g>\n",
       "<!-- intervened/x -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>intervened/x</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"245\" cy=\"-160\" rx=\"54.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-156.3\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/x</text>\n",
       "</g>\n",
       "<!-- intervened/z&#45;&gt;intervened/x -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>intervened/z&#45;&gt;intervened/x</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M303.67,-462.38C293.53,-410.31 263.02,-253.55 250.47,-189.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"253.99,-188.84 248.64,-179.69 247.11,-190.18 253.99,-188.84\"/>\n",
       "</g>\n",
       "<!-- intervened/t -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>intervened/t</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"370\" cy=\"-160\" rx=\"52.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"370\" y=\"-156.3\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/t</text>\n",
       "</g>\n",
       "<!-- intervened/z&#45;&gt;intervened/t -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>intervened/z&#45;&gt;intervened/t</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M310.39,-462.38C320.69,-410.31 351.69,-253.55 364.44,-189.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"367.8,-190.18 366.3,-179.69 360.93,-188.82 367.8,-190.18\"/>\n",
       "</g>\n",
       "<!-- intervened/intervened/y_observed -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>intervened/intervened/y_observed</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"450\" cy=\"-88\" rx=\"129.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"450\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/intervened/y_observed</text>\n",
       "</g>\n",
       "<!-- intervened/z&#45;&gt;intervened/intervened/y_observed -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>intervened/z&#45;&gt;intervened/intervened/y_observed</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M315.54,-462.27C337.75,-416.84 397.92,-289.64 432,-178 438.06,-158.15 442.65,-135.19 445.67,-117.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"449.11,-118.24 447.27,-107.8 442.2,-117.1 449.11,-118.24\"/>\n",
       "</g>\n",
       "<!-- intervened/intervened/y_unobserved -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>intervened/intervened/y_unobserved</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"163\" cy=\"-88\" rx=\"139.18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"163\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/intervened/y_unobserved</text>\n",
       "</g>\n",
       "<!-- intervened/z&#45;&gt;intervened/intervened/y_unobserved -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>intervened/z&#45;&gt;intervened/intervened/y_unobserved</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M298.38,-462.27C275.98,-416.87 215.28,-289.72 181,-178 174.91,-158.16 170.33,-135.2 167.31,-117.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.78,-117.11 165.71,-107.8 163.87,-118.24 170.78,-117.11\"/>\n",
       "</g>\n",
       "<!-- intervened/t&#45;&gt;intervened/intervened/y_observed -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>intervened/t&#45;&gt;intervened/intervened/y_observed</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M388.55,-142.76C398.46,-134.1 410.86,-123.25 421.92,-113.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"424.07,-116.34 429.29,-107.12 419.46,-111.07 424.07,-116.34\"/>\n",
       "</g>\n",
       "<!-- intervened/t&#45;&gt;intervened/intervened/y_unobserved -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>intervened/t&#45;&gt;intervened/intervened/y_unobserved</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M333.47,-146.65C302.65,-136.22 257.95,-121.11 222.05,-108.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.25,-105.68 212.65,-105.79 221,-112.31 223.25,-105.68\"/>\n",
       "</g>\n",
       "<!-- z -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"685\" cy=\"-480.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"685\" y=\"-476.8\" font-family=\"Times,serif\" font-size=\"14.00\">z</text>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"731\" cy=\"-160\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"731\" y=\"-156.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;x -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>z&#45;&gt;x</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M687.47,-462.38C694.98,-410.42 717.54,-254.2 726.88,-189.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"730.33,-190.1 728.3,-179.71 723.4,-189.1 730.33,-190.1\"/>\n",
       "</g>\n",
       "<!-- t -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>t</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"639\" cy=\"-160\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"639\" y=\"-156.3\" font-family=\"Times,serif\" font-size=\"14.00\">t</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;t -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>z&#45;&gt;t</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M682.53,-462.38C675.02,-410.42 652.46,-254.2 643.12,-189.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"646.6,-189.1 641.7,-179.71 639.67,-190.1 646.6,-189.1\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"662\" cy=\"-88\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"662\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>z&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M685.77,-462.18C687.71,-412.24 691.54,-263.69 675,-142 673.89,-133.8 672.02,-125.03 670.04,-117.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"673.46,-116.25 667.53,-107.47 666.69,-118.03 673.46,-116.25\"/>\n",
       "</g>\n",
       "<!-- t&#45;&gt;y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>t&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M644.57,-142.05C647.08,-134.4 650.12,-125.16 652.95,-116.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"656.21,-117.82 656.01,-107.23 649.56,-115.63 656.21,-117.82\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-731.8\" font-family=\"Times,serif\" font-size=\"14.00\">z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-716.8\" font-family=\"Times,serif\" font-size=\"14.00\">x ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-701.8\" font-family=\"Times,serif\" font-size=\"14.00\">t ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-686.8\" font-family=\"Times,serif\" font-size=\"14.00\">y ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-671.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-656.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/x ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-641.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/t ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-626.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/intervened/y_observed ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-611.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/intervened/y_unobserved ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-596.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-581.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-566.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-551.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-536.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-521.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-506.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-491.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-476.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.t_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-461.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.t_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-446.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-431.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-416.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-401.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-386.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-371.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-356.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-341.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-326.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-311.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-296.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-281.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-266.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-251.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-236.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"782\" y=\"-221.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.6.bias : Real()</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fc888111250>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#                 scope(prefix=\"intervened\"), \\\n",
    "\n",
    "class CEVAE_CATE(PyroModule):\n",
    "    def __init__(self, individual_model: ProxyConfounderModel):\n",
    "        super().__init__()\n",
    "        self.individual_model = individual_model\n",
    "\n",
    "    def forward(self, x_obs, t_obs, y_obs, x_pred):\n",
    "\n",
    "        with condition(data={\"x\": x_obs, \"t\": t_obs, \"y\": y_obs}), \\\n",
    "                pyro.plate(\"observations\", size=x_obs.shape[0], dim=-1):\n",
    "\n",
    "            Y_obs = self.individual_model(x_obs)\n",
    "\n",
    "        with MultiWorldCounterfactual(-2), \\\n",
    "                scope(prefix=\"intervened\"), \\\n",
    "                do(actions={\"intervened/t\": 1. }), \\\n",
    "                do(actions={\"intervened/t\": 0. }), \\\n",
    "                condition(data={\"x\": x_pred}):\n",
    "            Ys_pred = self.individual_model(x_pred)\n",
    "#         CATE = Ys_pred[...,0,1,:] - Ys_pred[...,1,0,:]\n",
    "#         CATE = pyro.deterministic(\"CATE\", CATE) # see intro tutorial, makes it show up in traces\n",
    "        return Ys_pred\n",
    "    \n",
    "pyro.render_model(CEVAE_CATE(ProxyConfounderModel(config)), model_args=(x,t,y,x), render_distributions=True, render_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.0 (20221023.0053)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"590pt\" height=\"726pt\"\n",
       " viewBox=\"0.00 0.00 589.50 726.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 722)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-722 585.5,-722 585.5,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_data</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-507.5 296,-507.5 296,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"276.5\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_intervention_2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"16,-39 16,-153 288,-153 288,-39 16,-39\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.5\" y=\"-46.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervention_2</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_intervention_3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24,-70 24,-145 280,-145 280,-70 24,-70\"/>\n",
       "<text text-anchor=\"middle\" x=\"232.5\" y=\"-77.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervention_3</text>\n",
       "</g>\n",
       "<!-- z -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"127\" cy=\"-481.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-477.8\" font-family=\"Times,serif\" font-size=\"14.00\">z</text>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"58\" cy=\"-191\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-187.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;x -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>z&#45;&gt;x</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.89,-463.32C111.41,-415.31 78.91,-279.43 64.74,-220.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.17,-219.48 62.44,-210.56 61.36,-221.1 68.17,-219.48\"/>\n",
       "</g>\n",
       "<!-- t -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>t</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"150\" cy=\"-191\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"150\" y=\"-187.3\" font-family=\"Times,serif\" font-size=\"14.00\">t</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;t -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>z&#45;&gt;t</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.37,-463.32C132.19,-415.43 142.98,-280.07 147.72,-220.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"151.18,-221.21 148.49,-210.97 144.2,-220.66 151.18,-221.21\"/>\n",
       "</g>\n",
       "<!-- y_observed -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>y_observed</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"83\" cy=\"-119\" rx=\"51.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-115.3\" font-family=\"Times,serif\" font-size=\"14.00\">y_observed</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;y_observed -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>z&#45;&gt;y_observed</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125.73,-463.08C122.18,-416.08 111.24,-282.8 94,-173 92.73,-164.89 91.04,-156.15 89.37,-148.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.84,-147.62 87.31,-138.59 86,-149.1 92.84,-147.62\"/>\n",
       "</g>\n",
       "<!-- y_unobserved -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>y_unobserved</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"212\" cy=\"-119\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"212\" y=\"-115.3\" font-family=\"Times,serif\" font-size=\"14.00\">y_unobserved</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;y_unobserved -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>z&#45;&gt;y_unobserved</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.99,-463.6C144.48,-406.37 188.54,-219.51 205.37,-148.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"208.69,-149.3 207.58,-138.76 201.88,-147.69 208.69,-149.3\"/>\n",
       "</g>\n",
       "<!-- t&#45;&gt;y_observed -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>t&#45;&gt;y_observed</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M136.12,-175.5C127.61,-166.61 116.5,-155 106.65,-144.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.23,-142.35 99.79,-137.54 104.18,-147.19 109.23,-142.35\"/>\n",
       "</g>\n",
       "<!-- t&#45;&gt;y_unobserved -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>t&#45;&gt;y_unobserved</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.15,-175.15C170.85,-166.46 180.77,-155.26 189.66,-145.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"192.12,-147.73 196.13,-137.92 186.88,-143.09 192.12,-147.73\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-702.8\" font-family=\"Times,serif\" font-size=\"14.00\">z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-687.8\" font-family=\"Times,serif\" font-size=\"14.00\">x ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-672.8\" font-family=\"Times,serif\" font-size=\"14.00\">t ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-657.8\" font-family=\"Times,serif\" font-size=\"14.00\">y_observed ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-642.8\" font-family=\"Times,serif\" font-size=\"14.00\">y_unobserved ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-627.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-612.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-597.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-582.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-567.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-552.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-537.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-522.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-507.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.t_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.t_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-477.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-462.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-447.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-432.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-417.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-402.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-387.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-372.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-342.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-327.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-312.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-297.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-282.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-267.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-252.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.6.bias : Real()</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fc899aaa8e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Structure trying to match Sam's model:\n",
    "class CEVAE_CATE_sam_style(PyroModule):\n",
    "    def __init__(self, individual_model: ProxyConfounderModel):\n",
    "        super().__init__()\n",
    "        self.individual_model = individual_model\n",
    "\n",
    "    def forward(self, x_obs, t_obs, y_obs, x_pred):\n",
    "        extended_model = do(actions = {\"t\": 0})(\n",
    "                            do(actions = {\"t\": 1})(\n",
    "                                pyro.plate(\"data\", size=x_obs.shape[0], dim=-1)(\n",
    "                                    condition(data={\"x\": x_pred})(self.individual_model))))\n",
    "        with MultiWorldCounterfactual(-2):\n",
    "            Ys_pred = extended_model(x_obs, t_obs, y_obs)\n",
    "        return Ys_pred\n",
    "    \n",
    "pyro.render_model(CEVAE_CATE_sam_style(ProxyConfounderModel(config)), model_args=(x,t,y,x), render_distributions=True, render_params=True)\n",
    "\n",
    "# code from Sam: \n",
    "# def forward(self, covariates_obs, training_obs, earnings_obs, n=None):\n",
    "#         if not covariates_obs is None:\n",
    "#             # Little hack to allow sampling without observations\n",
    "#             n = covariates_obs.shape[0]\n",
    "#         elif not training_obs is None:\n",
    "#             n = training_obs.shape[0]\n",
    "#         elif not earnings_obs is None:\n",
    "#             n = earnings_obs.shape[0]\n",
    "#         extended_model = do(actions={\"training\": 0})(\n",
    "#                             do(actions={\"training\": 1})(\n",
    "#                                 pyro.plate(\"data\", n, dim=-1)(\n",
    "#                                         condition(data={\"covariates\": covariates_obs, \"training\": training_obs, \"earnings\": earnings_obs})(\n",
    "#                                                 backdoor_cbn))))\n",
    "#         with MultiWorldCounterfactual(-2):\n",
    "#             model_args = (self.loc_covariates, self.variances_covariates, self.lower_cholesky_covariates, self.weights_training, self.bias_training, self.weights_earnings, self.bias_earnings, self.variance_earnings)\n",
    "#             _, _, earnings = extended_model(*model_args)\n",
    "#         earnings_treatment = earnings[..., 1, 0, :]\n",
    "#         earnings_control = earnings[..., 0, 1, :]\n",
    "#         return pyro.deterministic(\"SATE\", torch.sum(earnings_treatment - earnings_control, dim=-1) / n)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CEVAE_CATE(ProxyConfounderModel(config))(x,y,t,x)\n",
    "model_tr = pyro.poutine.trace(model_to_fit).get_trace(x,y,t,x)\n",
    "model_tr.nodes\n",
    "\n",
    "# getting a sample, after SVI\n",
    "# guide_tr = trace(guide).get_trace(covariates_obs, training_obs, earnings_obs, n=n)\n",
    "# model_tr = trace(replay(model, trace=guide_tr)).get_trace(covariates_obs, training_obs, earnings_obs, n=n)\n",
    "# Use predictive to sample: https://docs.pyro.ai/en/stable/inference_algos.html?highlight=Predictive#pyro.infer.predictive.Predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward(self, covariates_obs, training_obs, earnings_obs, n=None):\n",
    "\n",
    "#         if not covariates_obs is None:\n",
    "#             # Little hack to allow sampling without observations\n",
    "#             n = covariates_obs.shape[0]\n",
    "#         elif not training_obs is None:\n",
    "#             n = training_obs.shape[0]\n",
    "#         elif not earnings_obs is None:\n",
    "#             n = earnings_obs.shape[0]\n",
    "\n",
    "#         extended_model = do(actions={\"training\": 0})(\n",
    "#                             do(actions={\"training\": 1})(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_fit = CEVAE_CATE(ProxyConfounderModel(config))\n",
    "guide = pyro.infer.autoguide.AutoNormal(pyro.poutine.block(model_to_fit, hide=['intervened/t', 'intervened/intervened/y_observed', 'intervened/intervened/y_unobserved']))\n",
    "\n",
    "\n",
    "# Define loss and optimize\n",
    "# loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "adam = pyro.optim.Adam({\"lr\": 0.03})\n",
    "elbo = TraceEnum_ELBO()\n",
    "elbo.loss(model_to_fit, config_enumerate(guide, \"parallel\"), x,t,y,x);\n",
    "svi = SVI(model_to_fit, guide, adam, loss=elbo)\n",
    "\n",
    "\n",
    "num_iterations = 500 \n",
    "x_data = x.clone().detach().requires_grad_(True)\n",
    "t_data = t.clone().detach().requires_grad_(True)\n",
    "y_data = y.clone().detach().requires_grad_(True)\n",
    "x_pred_data = x.clone().detach().requires_grad_(True)\n",
    "\n",
    "\n",
    "pyro.clear_param_store()\n",
    "for j in range(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_data, t_data, y_data, x_pred_data)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_data)))\n",
    "        \n",
    "        \n",
    "# # fit the model\n",
    "# num_epochs=100\n",
    "# batch_size=100\n",
    "# learning_rate=1e-3\n",
    "# learning_rate_decay=0.1\n",
    "# weight_decay=1e-4\n",
    "# log_every=100\n",
    "\n",
    "\n",
    "# dataset = TensorDataset(x, t, y)\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "# num_steps = num_epochs * len(dataloader)\n",
    "# optim = ClippedAdam(\n",
    "#             {\n",
    "#                 \"lr\": learning_rate,\n",
    "#                 \"weight_decay\": weight_decay,\n",
    "#                 \"lrd\": learning_rate_decay ** (1 / num_steps),\n",
    "#             }\n",
    "#         )\n",
    "# model = CEVAE_CATE(ProxyConfounderModel(config))\n",
    "# guide = pyro.infer.autoguide.guides.AutoMultivariateNormal(model)\n",
    "\n",
    "# svi = SVI(model_to_fit, guide, adam, loss=Trace_ELBO())\n",
    "\n",
    "# num_iterations = 500 \n",
    "# x_data = x.clone().detach().requires_grad_(True)\n",
    "# t_data = t.clone().detach().requires_grad_(True)\n",
    "# y_data = y.clone().detach().requires_grad_(True)\n",
    "\n",
    "\n",
    "# pyro.clear_param_store()\n",
    "# for j in range(num_iterations):\n",
    "#     # calculate the loss and take a gradient step\n",
    "#     loss = svi.step(x_data, t_data, y_data, x_data)\n",
    "#     if j % 100 == 0:\n",
    "#         print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_data)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, value in pyro.get_param_store().items():\n",
    "#     print(name, pyro.param(name).data.cpu().numpy())\n",
    "# guide(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CATE is the expected return value of this new model, conditioning on\n",
    "the observed covariates $X$. Any inference method available in Pyro\n",
    "could be used to estimate it, including amortized variational inference\n",
    "[@kingma2013auto] as in the original paper [@louizos2017causal]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below, copied from http://pyro.ai/examples/cevae.html, \n",
    "More docs here: https://docs.pyro.ai/en/latest/contrib.cevae.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2017-2019 Uber Technologies, Inc.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "\"\"\"\n",
    "This example demonstrates how to use the Causal Effect Variational Autoencoder\n",
    "[1] implemented in pyro.contrib.cevae.CEVAE, documented at\n",
    "http://docs.pyro.ai/en/latest/contrib.cevae.html\n",
    "\n",
    "**References**\n",
    "\n",
    "[1] C. Louizos, U. Shalit, J. Mooij, D. Sontag, R. Zemel, M. Welling (2017).\n",
    "    Causal Effect Inference with Deep Latent-Variable Models.\n",
    "    http://papers.nips.cc/paper/7223-causal-effect-inference-with-deep-latent-variable-models.pdf\n",
    "    https://github.com/AMLab-Amsterdam/CEVAE\n",
    "\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.cevae import CEVAE\n",
    "\n",
    "# logging.getLogger(\"pyro\").setLevel(logging.DEBUG)\n",
    "# logging.getLogger(\"pyro\").handlers[0].setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def generate_data(num_data = 1000,\n",
    "    feature_dim = 5):\n",
    "    \"\"\"\n",
    "    This implements the generative process of [1], but using larger feature and\n",
    "    latent spaces ([1] assumes ``feature_dim=1`` and ``latent_dim=5``).\n",
    "    \"\"\"\n",
    "    z = dist.Bernoulli(0.5).sample([num_data])\n",
    "    x = dist.Normal(z, 5 * z + 3 * (1 - z)).sample([feature_dim]).t()\n",
    "    t = dist.Bernoulli(0.75 * z + 0.25 * (1 - z)).sample()\n",
    "    y = dist.Bernoulli(logits=3 * (z + 2 * (2 * t - 2))).sample()\n",
    "\n",
    "    # Compute true ite for evaluation (via Monte Carlo approximation).\n",
    "    t0_t1 = torch.tensor([[0.0], [1.0]])\n",
    "    y_t0, y_t1 = dist.Bernoulli(logits=3 * (z + 2 * (2 * t0_t1 - 2))).mean\n",
    "    true_ite = y_t1 - y_t0\n",
    "    return x, t, y, true_ite\n",
    "\n",
    "\n",
    "def main(num_data = 1000,\n",
    "    feature_dim = 5,\n",
    "    num_layers = 3, \n",
    "    num_epochs = 50, \n",
    "    batch_size = 100, \n",
    "    learning_rate = 1e-3, \n",
    "    learning_rate_decay = 0.1, \n",
    "    weight_decay = 1e-4, \n",
    "    seed = 1234567890, \n",
    "    jit = False, \n",
    "    cuda = False,\n",
    "    latent_dim = 20, \n",
    "    hidden_dim = 200):\n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "\n",
    "    # Generate synthetic data.\n",
    "    pyro.set_rng_seed(seed)\n",
    "    x_train, t_train, y_train, _ = generate_data(num_data, feature_dim)\n",
    "\n",
    "    # Train.\n",
    "    pyro.set_rng_seed(seed)\n",
    "    pyro.clear_param_store()\n",
    "    cevae = CEVAE(\n",
    "        feature_dim=feature_dim,\n",
    "        latent_dim=latent_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_samples=10,\n",
    "    )\n",
    "    cevae.fit(\n",
    "        x_train,\n",
    "        t_train,\n",
    "        y_train,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        learning_rate_decay=learning_rate_decay,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    # Evaluate.\n",
    "    x_test, t_test, y_test, true_ite = generate_data(num_data, feature_dim)\n",
    "    true_ate = true_ite.mean()\n",
    "    print(\"true ATE = {:0.3g}\".format(true_ate.item()))\n",
    "    naive_ate = y_test[t_test == 1].mean() - y_test[t_test == 0].mean()\n",
    "    print(\"naive ATE = {:0.3g}\".format(naive_ate))\n",
    "    if jit:\n",
    "        cevae = cevae.to_script_module()\n",
    "    est_ite = cevae.ite(x_test)\n",
    "    est_ate = est_ite.mean()\n",
    "    print(\"estimated ATE = {:0.3g}\".format(est_ate.item()))\n",
    "    return cevae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavae = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
