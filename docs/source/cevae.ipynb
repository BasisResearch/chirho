{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: the causal effect variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Optional, Tuple, Union, TypeVar\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "from pyro.infer.util import torch_item\n",
    "from pyro.nn import PyroModule, PyroSample, PyroParam\n",
    "from pyro.contrib.autoname import scope\n",
    "from pyro.poutine import condition, reparam\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.util import torch_isnan\n",
    "\n",
    "import causal_pyro\n",
    "from causal_pyro.query.do_messenger import do\n",
    "from causal_pyro.counterfactual.handlers import Factual, MultiWorldCounterfactual, TwinWorldCounterfactual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of what to do\n",
    "\n",
    "- [X] Look at Pyro intro tutorial, tensor shapes tutorial, variational inference background tutorials, \n",
    "    - the paper cited in the CEVAE example (which is somewhat unrealistic, assuming identifiablity)\n",
    "- [X] define a forward model\n",
    "- [X] fill in neural networks from https://github.com/pyro-ppl/pyro/blob/b7ba915b851d51c61d805da741bf7a74fcf9319d/pyro/contrib/cevae/__init__.py\n",
    "    - the NNs are functions with learnable params\n",
    "- [X] practice using SVI by fitting the original (non intervened) model\n",
    "    CEVAE_CATE takes the original model, and twins it, and makes interventions\n",
    "- [X] Make an intervened model, pyro.render_model to make graphical models http://pyro.ai/examples/model_rendering.html\n",
    "    - it renders, but haven't gotten SVI working yet\n",
    "- [ ] fit the model (Start with code in pyro cevae, with autoguide, and pyro.infer.traceELBO)\n",
    "    - likely modify to make treatment effect an output of the model\n",
    "- [ ] compare the ate that I get with the Pyro implementation below\n",
    "\n",
    "- https://github.com/BasisResearch/causal_pyro/issues/46\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Fully connected multi-layer network with ELU activations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes, final_activation=None):\n",
    "        layers = []\n",
    "        for in_size, out_size in zip(sizes, sizes[1:]):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            layers.append(nn.ELU())\n",
    "        layers.pop(-1)\n",
    "        if final_activation is not None:\n",
    "            layers.append(final_activation)\n",
    "        super().__init__(*layers)\n",
    "\n",
    "    def append(self, layer):\n",
    "        assert isinstance(layer, nn.Module)\n",
    "        self.add_module(str(len(self)), layer)\n",
    "\n",
    "\n",
    "class DistributionNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for distribution nets.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_class(dtype):\n",
    "        \"\"\"\n",
    "        Get a subclass by a prefix of its name, e.g.::\n",
    "            assert DistributionNet.get_class(\"bernoulli\") is BernoulliNet\n",
    "        \"\"\"\n",
    "        for cls in DistributionNet.__subclasses__():\n",
    "            if cls.__name__.lower() == dtype + \"net\":\n",
    "                return cls\n",
    "        raise ValueError(\"dtype not supported: {}\".format(dtype))\n",
    "\n",
    "\n",
    "class BernoulliNet(DistributionNet):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a single ``logits`` value.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    single Bernoulli random variable conditioned on a ``sizes[0]``-sized real\n",
    "    value, for example::\n",
    "        net = BernoulliNet([3, 4])\n",
    "        z = torch.randn(3)\n",
    "        logits, = net(z)\n",
    "        t = net.make_dist(logits).sample()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 1\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes + [1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.fc(x).squeeze(-1).clamp(min=-10, max=10)\n",
    "        return (logits,)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dist(logits):\n",
    "        return dist.Bernoulli(logits=logits)\n",
    "\n",
    "\n",
    "class ExponentialNet(DistributionNet):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a constrained ``rate``.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    single Normal random variable conditioned on a ``sizes[0]``-size real\n",
    "    value, for example::\n",
    "        net = ExponentialNet([3, 4])\n",
    "        x = torch.randn(3)\n",
    "        rate, = net(x)\n",
    "        y = net.make_dist(rate).sample()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 1\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes + [1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = nn.functional.softplus(self.fc(x).squeeze(-1)).clamp(min=1e-3, max=1e6)\n",
    "        rate = scale.reciprocal()\n",
    "        return (rate,)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dist(rate):\n",
    "        return dist.Exponential(rate)\n",
    "\n",
    "\n",
    "class LaplaceNet(DistributionNet):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a constrained ``loc,scale``\n",
    "    pair.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    single Laplace random variable conditioned on a ``sizes[0]``-size real\n",
    "    value, for example::\n",
    "        net = LaplaceNet([3, 4])\n",
    "        x = torch.randn(3)\n",
    "        loc, scale = net(x)\n",
    "        y = net.make_dist(loc, scale).sample()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 1\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes + [2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        loc_scale = self.fc(x)\n",
    "        loc = loc_scale[..., 0].clamp(min=-1e6, max=1e6)\n",
    "        scale = nn.functional.softplus(loc_scale[..., 1]).clamp(min=1e-3, max=1e6)\n",
    "        return loc, scale\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dist(loc, scale):\n",
    "        return dist.Laplace(loc, scale)\n",
    "\n",
    "\n",
    "class NormalNet(DistributionNet):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a constrained ``loc,scale``\n",
    "    pair.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    single Normal random variable conditioned on a ``sizes[0]``-size real\n",
    "    value, for example::\n",
    "        net = NormalNet([3, 4])\n",
    "        x = torch.randn(3)\n",
    "        loc, scale = net(x)\n",
    "        y = net.make_dist(loc, scale).sample()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 1\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes + [2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        loc_scale = self.fc(x)\n",
    "        loc = loc_scale[..., 0].clamp(min=-1e6, max=1e6)\n",
    "        scale = nn.functional.softplus(loc_scale[..., 1]).clamp(min=1e-3, max=1e6)\n",
    "        return loc, scale\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dist(loc, scale):\n",
    "        return dist.Normal(loc, scale)\n",
    "\n",
    "\n",
    "class StudentTNet(DistributionNet):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a constrained ``df,loc,scale``\n",
    "    triple, with shared ``df > 1``.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    single Student's t random variable conditioned on a ``sizes[0]``-size real\n",
    "    value, for example::\n",
    "        net = StudentTNet([3, 4])\n",
    "        x = torch.randn(3)\n",
    "        df, loc, scale = net(x)\n",
    "        y = net.make_dist(df, loc, scale).sample()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 1\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes + [2])\n",
    "        self.df_unconstrained = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        loc_scale = self.fc(x)\n",
    "        loc = loc_scale[..., 0].clamp(min=-1e6, max=1e6)\n",
    "        scale = nn.functional.softplus(loc_scale[..., 1]).clamp(min=1e-3, max=1e6)\n",
    "        df = nn.functional.softplus(self.df_unconstrained).add(1).expand_as(loc)\n",
    "        return df, loc, scale\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dist(df, loc, scale):\n",
    "        return dist.StudentT(df, loc, scale)\n",
    "\n",
    "\n",
    "class DiagNormalNet(nn.Module):\n",
    "    \"\"\"\n",
    "    :class:`FullyConnected` network outputting a constrained ``loc,scale``\n",
    "    pair.\n",
    "    This is used to represent a conditional probability distribution of a\n",
    "    ``sizes[-1]``-sized diagonal Normal random variable conditioned on a\n",
    "    ``sizes[0]``-size real value, for example::\n",
    "        net = DiagNormalNet([3, 4, 5])\n",
    "        z = torch.randn(3)\n",
    "        loc, scale = net(z)\n",
    "        x = dist.Normal(loc, scale).sample()\n",
    "    This is intended for the latent ``z`` distribution and the prewhitened\n",
    "    ``x`` features, and conservatively clips ``loc`` and ``scale`` values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 2\n",
    "        self.dim = sizes[-1]\n",
    "        super().__init__()\n",
    "        self.fc = FullyConnected(sizes[:-1] + [self.dim * 2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        loc_scale = self.fc(x)\n",
    "        loc = loc_scale[..., : self.dim].clamp(min=-1e2, max=1e2)\n",
    "        scale = (\n",
    "            nn.functional.softplus(loc_scale[..., self.dim :]).add(1e-3).clamp(max=1e2)\n",
    "        )\n",
    "        return loc, scale\n",
    "\n",
    "\n",
    "class PreWhitener(nn.Module):\n",
    "    \"\"\"\n",
    "    Data pre-whitener.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        with torch.no_grad():\n",
    "            loc = data.mean(0)\n",
    "            scale = data.std(0)\n",
    "            scale[~(scale > 0)] = 1.0\n",
    "            self.register_buffer(\"loc\", loc)\n",
    "            self.register_buffer(\"inv_scale\", scale.reciprocal())\n",
    "\n",
    "    def forward(self, data):\n",
    "        return (data - self.loc) * self.inv_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: Proxy variables and latent confounders\n",
    "\n",
    "The backdoor adjustment example assumed that it was always possible to measure all\n",
    "potential confounders $X$, but when this is not the case, additional\n",
    "assumptions are necessary to perform causal inference. This example,\n",
    "derived from @louizos2017causal, considers a setting where parametric\n",
    "assumptions are necessary for a causal model to be fully identifiable\n",
    "from observed data.\n",
    "\n",
    "Suppose we observe a population of individuals with features $X_i$\n",
    "undergo treatment $t_i \\in \\{0, 1\\}$ with outcome $y_i$. The treatment\n",
    "variable might represent a medication or an educational strategy, for\n",
    "example, for populations of patients or students, respectively.\n",
    "\n",
    "The task\n",
    "is to estimate the *conditional average treatment effect*: for a new\n",
    "individual with features $X_*$, what difference in outcome $y_*$ should\n",
    "we expect if we assign treatment $t_* = 1$ vs. $t_* = 0$? One cannot\n",
    "simply estimate the conditional probabilities\n",
    "$p(y_* \\mid X = X_*, t = 0)$ and $p(y_* \\mid X = X_*, t = 1)$, because\n",
    "there may be hidden confounders: latent factors $z$ that induce\n",
    "non-causal correlations between $t$ and $y$ even controlling for the\n",
    "observed covariates $X$. \n",
    "\n",
    "For example, a student's socio-economic status\n",
    "might influence both their outcome $y$ and the educational strategy $t$\n",
    "they are exposed to, and the observed covariates $X$ may not fully\n",
    "characterize the student's SES. As a result, conditioning on $t$ may\n",
    "alter the distribution over SES, changing the reported outcome.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: neural surrogate causal Bayesian network\n",
    "\n",
    "Our model captures the intuition that our three observed variables, $X$,\n",
    "$t$, and $y$, may be correlated, thanks to unobserved confounders $z$.\n",
    "Here, $f$, $g$, and $h$ are neural networks parameterized by different\n",
    "parts of the parameter set $\\theta$. The parameters of our model can be fit\n",
    "using standard techniques in Pyro (e.g., stochastic variational\n",
    "inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProxyConfounderModel(PyroModule):\n",
    "    \"\"\"\n",
    "    Generative model for a causal model with latent confounder ``z`` and binary\n",
    "    treatment ``t``::\n",
    "        z ~ p(z)      # latent confounder\n",
    "        x ~ p(x|z)    # partial noisy observation of z\n",
    "        t ~ p(t|z)    # treatment, whose application is biased by z\n",
    "        y ~ p(y|t,z)  # outcome\n",
    "    Each of these distributions is defined by a neural network.  The ``y``\n",
    "    distribution is defined by a disjoint pair of neural networks defining\n",
    "    ``p(y|t=0,z)`` and ``p(y|t=1,z)``; this allows highly imbalanced treatment.\n",
    "    :param dict config: A dict specifying ``feature_dim``, ``latent_dim``,\n",
    "        ``hidden_dim``, ``num_layers``, and ``outcome_dist``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.latent_dim = config[\"latent_dim\"]\n",
    "        super().__init__()\n",
    "        self.x_nn = DiagNormalNet(\n",
    "            [config[\"latent_dim\"]]\n",
    "            + [config[\"hidden_dim\"]] * config[\"num_layers\"]\n",
    "            + [config[\"feature_dim\"]]\n",
    "        )\n",
    "        OutcomeNet = DistributionNet.get_class(config[\"outcome_dist\"])\n",
    "        # The y network is split between the two t values.\n",
    "        self.y0_nn = OutcomeNet(\n",
    "            [config[\"latent_dim\"]] + [config[\"hidden_dim\"]] * config[\"num_layers\"]\n",
    "        )\n",
    "        self.y1_nn = OutcomeNet(\n",
    "            [config[\"latent_dim\"]] + [config[\"hidden_dim\"]] * config[\"num_layers\"]\n",
    "        )\n",
    "        self.t_nn = BernoulliNet([config[\"latent_dim\"]])\n",
    "\n",
    "    def forward(self, x, t=None, y=None):\n",
    "        z = pyro.sample(\"z\", self.z_dist())\n",
    "        x = pyro.sample(\"x\", self.x_dist(z), obs=x)\n",
    "        t = pyro.sample(\"t\", self.t_dist(z), obs=t)\n",
    "        y = pyro.sample(\"y\", self.y_dist(t, z), obs=y)\n",
    "        return y\n",
    "\n",
    "    def y_mean(self, x, t=None):\n",
    "        z = pyro.sample(\"z\", self.z_dist())\n",
    "        x = pyro.sample(\"x\", self.x_dist(z), obs=x)\n",
    "        t = pyro.sample(\"t\", self.t_dist(z), obs=t)\n",
    "        return self.y_dist(t, z).mean\n",
    "\n",
    "    def z_dist(self):\n",
    "        return dist.Normal(0, 1).expand([self.latent_dim]).to_event(1)\n",
    "\n",
    "    def x_dist(self, z):\n",
    "        loc, scale = self.x_nn(z)\n",
    "        return dist.Normal(loc, scale).to_event(1)\n",
    "\n",
    "    def y_dist(self, t, z):\n",
    "        # Parameters are not shared among t values.\n",
    "        params0 = self.y0_nn(z)\n",
    "        params1 = self.y1_nn(z)\n",
    "        t = t.bool()\n",
    "        params = [torch.where(t, p1, p0) for p0, p1 in zip(params0, params1)]\n",
    "        return self.y0_nn.make_dist(*params)\n",
    "\n",
    "    def t_dist(self, z):\n",
    "        (logits,) = self.t_nn(z)\n",
    "        return dist.Bernoulli(logits=logits)\n",
    "    \n",
    "# ProxyConfounderModel(config).x_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000\n",
    "feature_dim = 5\n",
    "num_layers = 3 \n",
    "num_epochs = 50 \n",
    "batch_size = 100 \n",
    "learning_rate = 1e-3 \n",
    "learning_rate_decay = 0.1 \n",
    "weight_decay = 1e-4\n",
    "seed = 1234567890\n",
    "jit = False \n",
    "cuda = False\n",
    "latent_dim = 20 \n",
    "hidden_dim = 200\n",
    "outcome_dist = \"bernoulli\"\n",
    "num_layers=3\n",
    "num_samples=100\n",
    "\n",
    "def generate_data(num_data,\n",
    "    feature_dim):\n",
    "\n",
    "    z = dist.Bernoulli(0.5).sample([num_data])\n",
    "    x = dist.Normal(z, 5 * z + 3 * (1 - z)).sample([feature_dim]).t()\n",
    "    t = dist.Bernoulli(0.75 * z + 0.25 * (1 - z)).sample()\n",
    "    y = dist.Bernoulli(logits=3 * (z + 2 * (2 * t - 2))).sample()\n",
    "\n",
    "    # Compute true ite for evaluation (via Monte Carlo approximation).\n",
    "    t0_t1 = torch.tensor([[0.0], [1.0]])\n",
    "    y_t0, y_t1 = dist.Bernoulli(logits=3 * (z + 2 * (2 * t0_t1 - 2))).mean\n",
    "    true_ite = y_t1 - y_t0\n",
    "    return x, t, y, true_ite\n",
    "\n",
    "\n",
    "x, t, y, true_ite = generate_data(num_data, feature_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.0 (20221023.0053)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"330pt\" height=\"610pt\"\n",
       " viewBox=\"0.00 0.00 329.50 610.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 606)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-606 325.5,-606 325.5,4 -4,4\"/>\n",
       "<!-- z -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"99\" cy=\"-373\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-369.3\" font-family=\"Times,serif\" font-size=\"14.00\">z</text>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;x -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>z&#45;&gt;x</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M94.6,-354.85C82.55,-307.8 48.89,-176.43 34.11,-118.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"37.59,-118.21 31.71,-109.4 30.81,-119.95 37.59,-118.21\"/>\n",
       "</g>\n",
       "<!-- t -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>t</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">t</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;t -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>z&#45;&gt;t</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99,-354.85C99,-308.01 99,-177.6 99,-119.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-119.8 99,-109.8 95.5,-119.8 102.5,-119.8\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"126\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"126\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>z&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.17,-354.79C109.73,-312.8 128.64,-201.69 135,-108 136.08,-92.04 136.34,-87.94 135,-72 134.32,-63.97 133.08,-55.33 131.73,-47.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.17,-46.79 129.93,-37.58 128.29,-48.05 135.17,-46.79\"/>\n",
       "</g>\n",
       "<!-- t&#45;&gt;y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>t&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M105.54,-72.05C108.52,-64.32 112.13,-54.96 115.48,-46.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.65,-47.79 118.98,-37.2 112.12,-45.27 118.65,-47.79\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-586.8\" font-family=\"Times,serif\" font-size=\"14.00\">z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-571.8\" font-family=\"Times,serif\" font-size=\"14.00\">x ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-556.8\" font-family=\"Times,serif\" font-size=\"14.00\">t ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-541.8\" font-family=\"Times,serif\" font-size=\"14.00\">y ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-526.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-511.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-496.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-481.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-466.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-451.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-436.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-421.8\" font-family=\"Times,serif\" font-size=\"14.00\">x_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-406.8\" font-family=\"Times,serif\" font-size=\"14.00\">t_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-391.8\" font-family=\"Times,serif\" font-size=\"14.00\">t_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-376.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-361.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-346.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-331.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-316.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-286.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\">y0_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-256.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-241.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-226.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-211.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-196.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-181.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-166.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">y1_nn$$$fc.6.bias : Real()</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f7c32ee54f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "        feature_dim=feature_dim,\n",
    "        latent_dim=latent_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_samples=num_samples,\n",
    "        outcome_dist=outcome_dist\n",
    "    )\n",
    "\n",
    "pyro.render_model(ProxyConfounderModel(config), model_args=(x,t,y), render_distributions=True, render_params=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit with SVI (to practice SVI syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 131.1831\n",
      "[iteration 0101] loss: 35.2102\n",
      "[iteration 0201] loss: 34.7706\n",
      "[iteration 0301] loss: 34.5351\n",
      "[iteration 0401] loss: 34.4959\n",
      "[iteration 0501] loss: 34.4688\n",
      "[iteration 0601] loss: 34.4181\n",
      "[iteration 0701] loss: 34.4520\n",
      "[iteration 0801] loss: 34.3009\n",
      "[iteration 0901] loss: 34.4012\n",
      "[iteration 1001] loss: 34.4739\n",
      "[iteration 1101] loss: 34.3391\n",
      "[iteration 1201] loss: 34.3781\n",
      "[iteration 1301] loss: 34.3533\n",
      "[iteration 1401] loss: 34.2725\n"
     ]
    }
   ],
   "source": [
    "def observational_model(individual_model: ProxyConfounderModel) -> Callable:\n",
    "    def _wrapper(x_obs, t_obs, y_obs):\n",
    "        size = x_obs.shape[0]\n",
    "        with pyro.plate(\"observations\", size=size, dim=-1):\n",
    "            return individual_model(x_obs, t_obs, y_obs)\n",
    "    return _wrapper\n",
    "\n",
    "model_to_fit = observational_model(ProxyConfounderModel(config))\n",
    "guide = pyro.infer.autoguide.AutoNormal(model_to_fit)\n",
    "\n",
    "\n",
    "# Define loss and optimize\n",
    "# loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "adam = pyro.optim.Adam({\"lr\": 0.03})\n",
    "svi = SVI(model_to_fit, guide, adam, loss=Trace_ELBO())\n",
    "\n",
    "\n",
    "num_iterations = 1500 \n",
    "x_data = x.clone().detach().requires_grad_(True)\n",
    "t_data = t.clone().detach().requires_grad_(True)\n",
    "y_data = y.clone().detach().requires_grad_(True)\n",
    "\n",
    "\n",
    "pyro.clear_param_store()\n",
    "for j in range(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_data, t_data, y_data)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_data)))\n",
    "\n",
    "\n",
    "# # Inspect learned parameters\n",
    "# print(\"Learned parameters:\")\n",
    "# for name, param in model_to_fit.named_parameters():\n",
    "#     print(name, param.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query: conditional average treatment effect (CATE)\n",
    "\n",
    "We can now set up a larger model in which the *conditional average\n",
    "treatment effect* (CATE) we want to estimate is a random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.0 (20221023.0053)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1142pt\" height=\"801pt\"\n",
       " viewBox=\"0.00 0.00 1142.50 801.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 797)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-797 1138.5,-797 1138.5,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_observations</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"72.5,-70 72.5,-545 234.5,-545 234.5,-70 72.5,-70\"/>\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-77.8\" font-family=\"Times,serif\" font-size=\"14.00\">observations</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_predictions</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"242.5,-8 242.5,-545 846.5,-545 846.5,-8 242.5,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"808\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">predictions</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_intervention_2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"250.5,-39 250.5,-153 838.5,-153 838.5,-39 250.5,-39\"/>\n",
       "<text text-anchor=\"middle\" x=\"791\" y=\"-46.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervention_2</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster_intervention_3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"258.5,-70 258.5,-145 830.5,-145 830.5,-70 258.5,-70\"/>\n",
       "<text text-anchor=\"middle\" x=\"783\" y=\"-77.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervention_3</text>\n",
       "</g>\n",
       "<!-- CATE -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>CATE</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"32.5\" cy=\"-519\" rx=\"32.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"32.5\" y=\"-515.3\" font-family=\"Times,serif\" font-size=\"14.00\">CATE</text>\n",
       "</g>\n",
       "<!-- z -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"153.5\" cy=\"-519\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.5\" y=\"-515.3\" font-family=\"Times,serif\" font-size=\"14.00\">z</text>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"199.5\" cy=\"-191\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"199.5\" y=\"-187.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;x -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>z&#45;&gt;x</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M155.91,-500.93C163.37,-448.02 186.18,-286.37 195.48,-220.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"198.91,-221.18 196.85,-210.79 191.98,-220.2 198.91,-221.18\"/>\n",
       "</g>\n",
       "<!-- t -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>t</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"107.5\" cy=\"-191\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.5\" y=\"-187.3\" font-family=\"Times,serif\" font-size=\"14.00\">t</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;t -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>z&#45;&gt;t</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.09,-500.93C143.62,-448.02 120.81,-286.37 111.51,-220.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.01,-220.2 110.15,-210.79 108.08,-221.18 115.01,-220.2\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"130.5\" cy=\"-119\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-115.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>z&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.28,-500.66C156.3,-449.97 160.4,-297.69 143.5,-173 142.39,-164.8 140.52,-156.03 138.54,-148.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"141.96,-147.25 136.03,-138.47 135.19,-149.03 141.96,-147.25\"/>\n",
       "</g>\n",
       "<!-- t&#45;&gt;y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>t&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.06,-173.05C115.58,-165.4 118.61,-156.16 121.44,-147.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.71,-148.82 124.51,-138.23 118.06,-146.63 124.71,-148.82\"/>\n",
       "</g>\n",
       "<!-- intervened/z -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>intervened/z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"551.5\" cy=\"-519\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"551.5\" y=\"-515.3\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/z</text>\n",
       "</g>\n",
       "<!-- intervened/x -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>intervened/x</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"489.5\" cy=\"-191\" rx=\"54.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"489.5\" y=\"-187.3\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/x</text>\n",
       "</g>\n",
       "<!-- intervened/z&#45;&gt;intervened/x -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>intervened/z&#45;&gt;intervened/x</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M548.25,-500.93C538.19,-448.02 507.44,-286.37 494.91,-220.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"498.38,-219.95 493.07,-210.78 491.5,-221.26 498.38,-219.95\"/>\n",
       "</g>\n",
       "<!-- intervened/t -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>intervened/t</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"614.5\" cy=\"-191\" rx=\"52.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"614.5\" y=\"-187.3\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/t</text>\n",
       "</g>\n",
       "<!-- intervened/z&#45;&gt;intervened/t -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>intervened/z&#45;&gt;intervened/t</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M554.8,-500.93C565.02,-448.02 596.26,-286.37 609,-220.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"612.41,-221.26 610.87,-210.78 605.53,-219.93 612.41,-221.26\"/>\n",
       "</g>\n",
       "<!-- intervened/intervened/y_observed -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>intervened/intervened/y_observed</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"692.5\" cy=\"-119\" rx=\"129.98\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"692.5\" y=\"-115.3\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/intervened/y_observed</text>\n",
       "</g>\n",
       "<!-- intervened/z&#45;&gt;intervened/intervened/y_observed -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>intervened/z&#45;&gt;intervened/intervened/y_observed</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M559.83,-501.02C582.05,-455.09 643.26,-324.09 676.5,-209 682.23,-189.15 686.3,-166.18 688.9,-148.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"692.34,-149.19 690.25,-138.8 685.41,-148.22 692.34,-149.19\"/>\n",
       "</g>\n",
       "<!-- intervened/intervened/y_unobserved -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>intervened/intervened/y_unobserved</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"405.5\" cy=\"-119\" rx=\"139.18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"405.5\" y=\"-115.3\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/intervened/y_unobserved</text>\n",
       "</g>\n",
       "<!-- intervened/z&#45;&gt;intervened/intervened/y_unobserved -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>intervened/z&#45;&gt;intervened/intervened/y_unobserved</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M543.36,-500.95C521.63,-454.83 461.41,-323.42 425.5,-209 419.26,-189.11 414.14,-166.15 410.65,-148.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"414.1,-147.94 408.78,-138.77 407.23,-149.25 414.1,-147.94\"/>\n",
       "</g>\n",
       "<!-- intervened/t&#45;&gt;intervened/intervened/y_observed -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>intervened/t&#45;&gt;intervened/intervened/y_observed</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M632.59,-173.76C642.25,-165.1 654.34,-154.25 665.12,-144.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"667.18,-147.42 672.29,-138.13 662.51,-142.21 667.18,-147.42\"/>\n",
       "</g>\n",
       "<!-- intervened/t&#45;&gt;intervened/intervened/y_unobserved -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>intervened/t&#45;&gt;intervened/intervened/y_unobserved</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M578.09,-177.81C546.8,-167.33 501.07,-152.01 464.55,-139.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"466.05,-136.59 455.46,-136.73 463.83,-143.23 466.05,-136.59\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-777.8\" font-family=\"Times,serif\" font-size=\"14.00\">z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-762.8\" font-family=\"Times,serif\" font-size=\"14.00\">x ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-747.8\" font-family=\"Times,serif\" font-size=\"14.00\">t ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-732.8\" font-family=\"Times,serif\" font-size=\"14.00\">y ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-717.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-702.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/x ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-687.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/t ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-672.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/intervened/y_observed ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-657.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervened/intervened/y_unobserved ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-642.8\" font-family=\"Times,serif\" font-size=\"14.00\">CATE ~ Delta</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-627.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-612.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-597.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-582.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-567.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-552.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-537.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-522.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-507.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.t_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.t_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-477.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-462.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-447.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-432.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-417.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-402.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-387.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-372.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-342.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-327.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-312.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-297.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-282.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-267.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"862.5\" y=\"-252.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.6.bias : Real()</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f7c32ee3670>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CEVAE_CATE(PyroModule):\n",
    "    def __init__(self, individual_model: ProxyConfounderModel):\n",
    "        super().__init__()\n",
    "        self.individual_model = individual_model\n",
    "\n",
    "    def forward(self, x_obs, t_obs, y_obs, x_pred):\n",
    "\n",
    "        with condition(data={\"x\": x_obs, \"t\": t_obs, \"y\": y_obs}), \\\n",
    "                pyro.plate(\"observations\", size=x_obs.shape[0], dim=-1):\n",
    "\n",
    "            Y_obs = self.individual_model(x_obs)\n",
    "\n",
    "        with MultiWorldCounterfactual(-2), \\\n",
    "                scope(prefix=\"intervened\"), \\\n",
    "                do(actions={\"intervened/t\": 1. }), \\\n",
    "                do(actions={\"intervened/t\": 0. }), \\\n",
    "                condition(data={\"x\": x_pred}), \\\n",
    "                pyro.plate(\"predictions\", size=x_pred.shape[0], dim=-1):\n",
    "            Ys_pred = self.individual_model(x_pred)\n",
    "        CATE = Ys_pred[...,0,1,:] - Ys_pred[...,1,0,:]\n",
    "        CATE = pyro.deterministic(\"CATE\", CATE) # see intro tutorial, makes it show up in traces\n",
    "        return Ys_pred, CATE\n",
    "    \n",
    "pyro.render_model(CEVAE_CATE(ProxyConfounderModel(config)), model_args=(x,t,y,x), render_distributions=True, render_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.0 (20221023.0053)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"590pt\" height=\"726pt\"\n",
       " viewBox=\"0.00 0.00 589.50 726.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 722)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-722 585.5,-722 585.5,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_data</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-507.5 296,-507.5 296,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"276.5\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_intervention_2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"16,-39 16,-153 288,-153 288,-39 16,-39\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.5\" y=\"-46.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervention_2</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_intervention_3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"24,-70 24,-145 280,-145 280,-70 24,-70\"/>\n",
       "<text text-anchor=\"middle\" x=\"232.5\" y=\"-77.8\" font-family=\"Times,serif\" font-size=\"14.00\">intervention_3</text>\n",
       "</g>\n",
       "<!-- z -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>z</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"127\" cy=\"-481.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-477.8\" font-family=\"Times,serif\" font-size=\"14.00\">z</text>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"58\" cy=\"-191\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-187.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;x -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>z&#45;&gt;x</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.89,-463.32C111.41,-415.31 78.91,-279.43 64.74,-220.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.17,-219.48 62.44,-210.56 61.36,-221.1 68.17,-219.48\"/>\n",
       "</g>\n",
       "<!-- t -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>t</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"150\" cy=\"-191\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"150\" y=\"-187.3\" font-family=\"Times,serif\" font-size=\"14.00\">t</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;t -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>z&#45;&gt;t</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.37,-463.32C132.19,-415.43 142.98,-280.07 147.72,-220.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"151.18,-221.21 148.49,-210.97 144.2,-220.66 151.18,-221.21\"/>\n",
       "</g>\n",
       "<!-- y_observed -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>y_observed</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"83\" cy=\"-119\" rx=\"51.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-115.3\" font-family=\"Times,serif\" font-size=\"14.00\">y_observed</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;y_observed -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>z&#45;&gt;y_observed</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125.73,-463.08C122.18,-416.08 111.24,-282.8 94,-173 92.73,-164.89 91.04,-156.15 89.37,-148.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.84,-147.62 87.31,-138.59 86,-149.1 92.84,-147.62\"/>\n",
       "</g>\n",
       "<!-- y_unobserved -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>y_unobserved</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"212\" cy=\"-119\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"212\" y=\"-115.3\" font-family=\"Times,serif\" font-size=\"14.00\">y_unobserved</text>\n",
       "</g>\n",
       "<!-- z&#45;&gt;y_unobserved -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>z&#45;&gt;y_unobserved</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.99,-463.6C144.48,-406.37 188.54,-219.51 205.37,-148.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"208.69,-149.3 207.58,-138.76 201.88,-147.69 208.69,-149.3\"/>\n",
       "</g>\n",
       "<!-- t&#45;&gt;y_observed -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>t&#45;&gt;y_observed</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M136.12,-175.5C127.61,-166.61 116.5,-155 106.65,-144.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.23,-142.35 99.79,-137.54 104.18,-147.19 109.23,-142.35\"/>\n",
       "</g>\n",
       "<!-- t&#45;&gt;y_unobserved -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>t&#45;&gt;y_unobserved</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.15,-175.15C170.85,-166.46 180.77,-155.26 189.66,-145.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"192.12,-147.73 196.13,-137.92 186.88,-143.09 192.12,-147.73\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-702.8\" font-family=\"Times,serif\" font-size=\"14.00\">z ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-687.8\" font-family=\"Times,serif\" font-size=\"14.00\">x ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-672.8\" font-family=\"Times,serif\" font-size=\"14.00\">t ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-657.8\" font-family=\"Times,serif\" font-size=\"14.00\">y_observed ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-642.8\" font-family=\"Times,serif\" font-size=\"14.00\">y_unobserved ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-627.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-612.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-597.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-582.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-567.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-552.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-537.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-522.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.x_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-507.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.t_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-492.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.t_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-477.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-462.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-447.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-432.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-417.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-402.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-387.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-372.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y0_nn$$$fc.6.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.0.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-342.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.0.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-327.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.2.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-312.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.2.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-297.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.4.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-282.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.4.bias : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-267.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.6.weight : Real()</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-252.8\" font-family=\"Times,serif\" font-size=\"14.00\">individual_model.y1_nn$$$fc.6.bias : Real()</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f7c318dad90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Structure trying to match Sam's model:\n",
    "class CEVAE_CATE_sam_style(PyroModule):\n",
    "    def __init__(self, individual_model: ProxyConfounderModel):\n",
    "        super().__init__()\n",
    "        self.individual_model = individual_model\n",
    "\n",
    "    def forward(self, x_obs, t_obs, y_obs, x_pred):\n",
    "        extended_model = do(actions = {\"t\": 0})(\n",
    "                            do(actions = {\"t\": 1})(\n",
    "                                pyro.plate(\"data\", size=x_obs.shape[0], dim=-1)(\n",
    "                                    condition(data={\"x\": x_pred})(self.individual_model))))\n",
    "        with MultiWorldCounterfactual(-2):\n",
    "            Ys_pred = extended_model(x_obs, t_obs, y_obs)\n",
    "        return Ys_pred\n",
    "    \n",
    "pyro.render_model(CEVAE_CATE_sam_style(ProxyConfounderModel(config)), model_args=(x,t,y,x), render_distributions=True, render_params=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_wrapper() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# From Sam, to inspect model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m CEVAE_CATE(ProxyConfounderModel(config))(x,y,t,x)\n\u001b[0;32m----> 3\u001b[0m model_tr \u001b[38;5;241m=\u001b[39m \u001b[43mpyro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoutine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_fit\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m model_tr\u001b[38;5;241m.\u001b[39mnodes\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# getting a sample, after SVI\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# guide_tr = trace(guide).get_trace(covariates_obs, training_obs, earnings_obs, n=n)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# model_tr = trace(replay(model, trace=guide_tr)).get_trace(covariates_obs, training_obs, earnings_obs, n=n)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Use predictive to sample: https://docs.pyro.ai/en/stable/inference_algos.html?highlight=Predictive#pyro.infer.predictive.Predictive\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "\u001b[0;31mTypeError\u001b[0m: _wrapper() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# From Sam, to inspect model\n",
    "CEVAE_CATE(ProxyConfounderModel(config))(x,y,t,x)\n",
    "model_tr = pyro.poutine.trace(model_to_fit).get_trace(x,y,t,x)\n",
    "model_tr.nodes\n",
    "\n",
    "# getting a sample, after SVI\n",
    "# guide_tr = trace(guide).get_trace(covariates_obs, training_obs, earnings_obs, n=n)\n",
    "# model_tr = trace(replay(model, trace=guide_tr)).get_trace(covariates_obs, training_obs, earnings_obs, n=n)\n",
    "# Use predictive to sample: https://docs.pyro.ai/en/stable/inference_algos.html?highlight=Predictive#pyro.infer.predictive.Predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward(self, covariates_obs, training_obs, earnings_obs, n=None):\n",
    "\n",
    "#         if not covariates_obs is None:\n",
    "#             # Little hack to allow sampling without observations\n",
    "#             n = covariates_obs.shape[0]\n",
    "#         elif not training_obs is None:\n",
    "#             n = training_obs.shape[0]\n",
    "#         elif not earnings_obs is None:\n",
    "#             n = earnings_obs.shape[0]\n",
    "\n",
    "#         extended_model = do(actions={\"training\": 0})(\n",
    "#                             do(actions={\"training\": 1})(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0180)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre training\n",
    "Y_pred, CATE = CEVAE_CATE(ProxyConfounderModel(config))(x,t,y,x) # model_to_fit(x,t,y,x)\n",
    "CATE.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 133.5979\n",
      "[iteration 0101] loss: 90.1264\n",
      "[iteration 0201] loss: 89.9963\n",
      "[iteration 0301] loss: 90.1961\n",
      "[iteration 0401] loss: 89.9411\n"
     ]
    }
   ],
   "source": [
    "model_to_fit = CEVAE_CATE(ProxyConfounderModel(config))\n",
    "guide = pyro.infer.autoguide.AutoNormal(pyro.poutine.block(model_to_fit, hide=['intervened/t', 'intervened/intervened/y_observed', 'intervened/intervened/y_unobserved']))\n",
    "\n",
    "\n",
    "# Define loss and optimize\n",
    "# loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "adam = pyro.optim.Adam({\"lr\": 0.03})\n",
    "elbo = TraceEnum_ELBO()\n",
    "elbo.loss(config_enumerate(model_to_fit, \"parallel\"), guide, x,t,y,x);\n",
    "svi = SVI(config_enumerate(model_to_fit, \"parallel\"), guide, adam, loss=elbo)\n",
    "\n",
    "\n",
    "num_iterations = 3500 \n",
    "x_data = x.clone().detach().requires_grad_(True)\n",
    "t_data = t.clone().detach().requires_grad_(True)\n",
    "y_data = y.clone().detach().requires_grad_(True)\n",
    "x_pred_data = x.clone().detach().requires_grad_(True)\n",
    "whiten = PreWhitener(x_data)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "for j in range(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    x_data = whiten(x_data)\n",
    "    loss = svi.step(x_data, t_data, y_data, x_pred_data)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_data)))\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 1.,  ..., 0., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred, CATE = model_to_fit(x,t,y,x) # model_to_fit(x,t,y,x)\n",
    "CATE.mean()\n",
    "Y_pred(..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CATE is the expected return value of this new model, conditioning on\n",
    "the observed covariates $X$. Any inference method available in Pyro\n",
    "could be used to estimate it, including amortized variational inference\n",
    "[@kingma2013auto] as in the original paper [@louizos2017causal]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below, copied from http://pyro.ai/examples/cevae.html, \n",
    "More docs here: https://docs.pyro.ai/en/latest/contrib.cevae.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2017-2019 Uber Technologies, Inc.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "\"\"\"\n",
    "This example demonstrates how to use the Causal Effect Variational Autoencoder\n",
    "[1] implemented in pyro.contrib.cevae.CEVAE, documented at\n",
    "http://docs.pyro.ai/en/latest/contrib.cevae.html\n",
    "\n",
    "**References**\n",
    "\n",
    "[1] C. Louizos, U. Shalit, J. Mooij, D. Sontag, R. Zemel, M. Welling (2017).\n",
    "    Causal Effect Inference with Deep Latent-Variable Models.\n",
    "    http://papers.nips.cc/paper/7223-causal-effect-inference-with-deep-latent-variable-models.pdf\n",
    "    https://github.com/AMLab-Amsterdam/CEVAE\n",
    "\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.cevae import CEVAE\n",
    "\n",
    "# logging.getLogger(\"pyro\").setLevel(logging.DEBUG)\n",
    "# logging.getLogger(\"pyro\").handlers[0].setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def generate_data(num_data = 1000,\n",
    "    feature_dim = 5):\n",
    "    \"\"\"\n",
    "    This implements the generative process of [1], but using larger feature and\n",
    "    latent spaces ([1] assumes ``feature_dim=1`` and ``latent_dim=5``).\n",
    "    \"\"\"\n",
    "    z = dist.Bernoulli(0.5).sample([num_data])\n",
    "    x = dist.Normal(z, 5 * z + 3 * (1 - z)).sample([feature_dim]).t()\n",
    "    t = dist.Bernoulli(0.75 * z + 0.25 * (1 - z)).sample()\n",
    "    y = dist.Bernoulli(logits=3 * (z + 2 * (2 * t - 2))).sample()\n",
    "\n",
    "    # Compute true ite for evaluation (via Monte Carlo approximation).\n",
    "    t0_t1 = torch.tensor([[0.0], [1.0]])\n",
    "    y_t0, y_t1 = dist.Bernoulli(logits=3 * (z + 2 * (2 * t0_t1 - 2))).mean\n",
    "    true_ite = y_t1 - y_t0\n",
    "    return x, t, y, true_ite\n",
    "\n",
    "\n",
    "def main(num_data = 1000,\n",
    "    feature_dim = 5,\n",
    "    num_layers = 3, \n",
    "    num_epochs = 50, \n",
    "    batch_size = 100, \n",
    "    learning_rate = 1e-3, \n",
    "    learning_rate_decay = 0.1, \n",
    "    weight_decay = 1e-4, \n",
    "    seed = 1234567890, \n",
    "    jit = False, \n",
    "    cuda = False,\n",
    "    latent_dim = 20, \n",
    "    hidden_dim = 200):\n",
    "    if cuda:\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "\n",
    "    # Generate synthetic data.\n",
    "    pyro.set_rng_seed(seed)\n",
    "    x_train, t_train, y_train, _ = generate_data(num_data, feature_dim)\n",
    "\n",
    "    # Train.\n",
    "    pyro.set_rng_seed(seed)\n",
    "    pyro.clear_param_store()\n",
    "    cevae = CEVAE(\n",
    "        feature_dim=feature_dim,\n",
    "        latent_dim=latent_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        num_samples=10,\n",
    "    )\n",
    "    cevae.fit(\n",
    "        x_train,\n",
    "        t_train,\n",
    "        y_train,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        learning_rate_decay=learning_rate_decay,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "    # Evaluate.\n",
    "    x_test, t_test, y_test, true_ite = generate_data(num_data, feature_dim)\n",
    "    true_ate = true_ite.mean()\n",
    "    print(\"true ATE = {:0.3g}\".format(true_ate.item()))\n",
    "    naive_ate = y_test[t_test == 1].mean() - y_test[t_test == 0].mean()\n",
    "    print(\"naive ATE = {:0.3g}\".format(naive_ate))\n",
    "    if jit:\n",
    "        cevae = cevae.to_script_module()\n",
    "    est_ite = cevae.ite(x_test)\n",
    "    est_ate = est_ite.mean()\n",
    "    print(\"estimated ATE = {:0.3g}\".format(est_ate.item()))\n",
    "    return cevae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavae = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
