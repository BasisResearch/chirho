{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Effect Variational Autoencoder Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "[Setup](#setup)\n",
    "\n",
    "[Overview: Systematically adjusting for observed confounding](#overview-systematically-adjusting-for-observed-confounding)\n",
    "- [Task: Treatment effect estimation with observational data](#task-treatment-effect-estimation-with-observational-data)\n",
    "- [Challenge: Confounding](#challenge-confounding)\n",
    "- [Assumptions: All latent confounders influence at least one \"proxy\" covariate](#assumptions-all-latent-confounders-influence-at-least-one-proxy-covariate)\n",
    "- [Intuition: Adjusting for confounding via proxies](#intuition-adjusting-for-confounding-via-proxies)\n",
    "\n",
    "[Example: Synthetic data](#example-synthetic-data)\n",
    "\n",
    "[Causal Probabilistic Program](#causal-probabilistic-program)\n",
    "- [Model Description](#model-description)\n",
    "- [Prior Description](#prior-description)\n",
    "\n",
    "[Causal Query: conditional average treatment effect](#causal-query-average-treatment-effect-ate)\n",
    "- [Fit parameter via maximum likelihood](#fit-parameters-via-maximum-likelihood)\n",
    "\n",
    "[Causal Inference as Probabilistic Inference](#causal-inference-as-probabilistic-inference)\n",
    "- [Maximum Likelihood Inference](#maximum-likelihood-inference)\n",
    "- [Maximum a Posteriori Inference](#maximum-a-posteriori-inference)\n",
    "\n",
    "[Results](#results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we install the necessary Pytorch, Pyro, and Causal Pyro dependencies for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO trim this down to just the CEVAE example.\n",
    "\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Union, TypeVar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "from pyro.infer.util import torch_item\n",
    "from pyro.nn import PyroModule, PyroSample, PyroParam\n",
    "from pyro.contrib.autoname import scope\n",
    "from pyro.poutine import condition, reparam\n",
    "from pyro.optim import ClippedAdam\n",
    "from pyro.util import torch_isnan\n",
    "\n",
    "import causal_pyro\n",
    "from causal_pyro.query.do_messenger import do\n",
    "from causal_pyro.counterfactual.handlers import Factual, MultiWorldCounterfactual, TwinWorldCounterfactual\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview: Proxy variables and latent confounders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task:** Treatment effect estimation with observational data\n",
    "\n",
    "Just as in the [backdoor](backdoor.ipynb) and [slc](slc.ipynb) examples, in this example we are interested in estimating how changes (or interventions) to a particular treatment variable $T$ influence a particular outcome variable $Y$. We wish to estimate this causal effect using *observational* (non-randomized) data from $T$, $Y$, and some collection of covariates $X =\\{X_1, ..., X_d\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Challenge:** Confounding\n",
    "\n",
    "As the task here is exactly identical to the [backdoor](backdoor.ipynb) and [slc](slc.ipynb) examples, so too are the challenges. From the [backdoor](backdoor.ipynb) example: \n",
    "\n",
    "\"Unfortunately, naively estimating the effect of an intervention by simply approximating $P(Y|T)$ alone may produce poor estimates of $T$'s effect on $Y$.\"\n",
    "\n",
    "Note: While the challenges remain the same between these examples, the assumptions we make will differ substantially."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assumptions:** All latent confounders influence at least one \"proxy\" covariate\n",
    "\n",
    "In the [backdoor](backdoor.ipynb) example we saw how to estimate causal effects from observational data when all confounders were observed. In the [slc](slc.ipynb) example we softened this assumption, instead allowing some latent confounders to be shared between instances (e.g. students) belonging to the same object (e.g. school). In this example we again soften the restrictive assumptions made in the [backdoor](backdoor.ipynb) example, however using a different assumption about the relationship between potential latent confounders $Z$ and data $T$, $Y$, and $X$.\n",
    "\n",
    "Specifically, in this example we assume that every latent confounder $Z_i \\in Z$ is a cause of at least one \"proxy\" covariate $X_j \\in X$. See Figure 1 in Louizos et al. [louizos2017causal] for a graphical description of these assumptions.\n",
    "\n",
    "Importantly, in this work we do not wish to make strong parameteric assumptions (e.g. linear structural functions) relating latent confounders, proxy covariates, treatment, and outcome. As we'll see later, we can instead approximate these local causal dependencies using probabilistic models with neural network components.\n",
    "\n",
    "**Note:** In the original paper introducing the CEVAE model [louizos2017causal], the authors prove a theorem (Theorem 1) stating that the conditional average treatment effect is identifiable if the model is correctly specified, including a strong assumption about the marginal distribution over latent confounders $Z$. Recent work [rissanen2021critical] has investigated the consequences of misspecifying components of the CEVAE model, concluding that its derived causal estimate are in fact sensitive to these detailed assumptions about the generative model. While some more restrictive settings may yield more robust identification results or bounds on causal effects (e.g. binary variables [kuroki2014measurement]), to the best of our knowledge little more is known about the nonparametric or semiparametric settings.\n",
    "\n",
    "Rissanen, Severi, and Pekka Marttinen. \"A critical look at the consistency of causal estimation with deep latent variable models.\" Advances in Neural Information Processing Systems 34 (2021): 4207-4217.\n",
    "\n",
    "Kuroki, Manabu, and Judea Pearl. \"Measurement bias and effect restoration in causal inference.\" Biometrika 101.2 (2014): 423-437."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Intuition:** Adjusting for confounding via proxies\n",
    "\n",
    "In the [backdoor](backdoor.ipynb) tutorial we discussed how to estiamte causal effects with observational data by partitioning individual units into nonoverlapping subgroups such that each subgroup had similar or identical values of observed covariates $X$. When all confounders are observed, \"adjusting for\" confounders in this way produces unbiased estimates of the population-level causal effects we are interested in. However, this is not the case when some confounders are latent.\n",
    "\n",
    "In this example we have made an additional assumption that all latent confounders causally influence at least one observed covariate, which we call \"proxy confounders\". Imagine for moment a scenario where this causal relationship is deterministic, bijective, and smooth. In this idealized scenario partitioning groups of individuals based on observed covariates $X$ produces groups that are equivalent to those we would have produced if the latent confounders $Z$ were in fact observed. This is true even though we don't know the true assignments of $Z$ for our observed data; as every subgroup will have similar values by construction. \n",
    "\n",
    "In practice, the relationship between latent confounders and observed covariates never satisfies this idealized deterministic property. Instead, the CEVAE model includes an explicitly probabilistic relationship between latent confounders and observed covariates, using neural network components as function approximators. With the previous caveat about identifiability and robustness of the CEVAE model aside, we can intuit that conditioning on these proxy confounders will update our posterior beliefs about which latent confounders are similar to each other, albiet without absolute certainty."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Synthetic Data\n",
    "\n",
    "In this example we'll use synthetic data to demonstrate the CEVAE model. Here we generate observed and counterfactual data, which can then be used to compute a \"ground truth\" treatment effect for us to compare against when we use Causal Pyro for causal inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, num_test = 10000, 2000\n",
    "feature_dim = 10\n",
    "z_gap = 1.\n",
    "y_gap = 3.\n",
    "\n",
    "def generate_data(num_data, feature_dim, z_gap, y_gap):\n",
    "\n",
    "    # Latent confounder z is binary.\n",
    "    z = dist.Bernoulli(0.5).sample([num_data])\n",
    "\n",
    "    # Covariates x are normally distributed, with higher variance for z=1.\n",
    "    x = dist.Normal(z * z_gap, 5 * z + 3 * (1 - z)).sample([feature_dim]).t()\n",
    "\n",
    "    # Treatment t is binary, with higher probability for z=1.\n",
    "    t = dist.Bernoulli(0.75 * z + 0.25 * (1 - z)).sample()\n",
    "\n",
    "    # Outcome y is binary, with higher probability for z=1 and t=1.\n",
    "    y = dist.Bernoulli(logits=y_gap * (z + 2 * (2 * t - 1))).sample()\n",
    "\n",
    "    # Compute true c-specific CATE for evaluation (via Monte Carlo approximation).\n",
    "    t0_t1 = torch.tensor([[0.0], [1.0]])\n",
    "    y_t0, y_t1 = dist.Bernoulli(logits=y_gap * (z + 2 * (2 * t0_t1 - 1))).mean\n",
    "    true_cates = y_t1 - y_t0\n",
    "    return x, t, y, true_cates\n",
    "\n",
    "# Note: In the CEVAE paper they refer to c-specific causal effects as individual treatment effects.\n",
    "# We use the term c-specific causal effects to be consistent with the terminology in the broader causal inference literature.\n",
    "\n",
    "x, t, y, _ = generate_data(num_train, feature_dim, z_gap, y_gap)\n",
    "x_test, _, _, true_cates = generate_data(num_test, feature_dim, z_gap, y_gap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Probabilistic Program\n",
    "\n",
    "Our causal assumptions can be encoded as a probabilistic program in Pyro. Here, unlike the [backdoor](backdoor.ipynb) and [slc](slc.ipynb) tutorials, we'll perform maximum likelihood inference over neural network parameters, and then only later use variational approximations for the latent proxy confounders $Z$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description\n",
    "\n",
    "Our model captures the intuition that our three observed variables, $X$, $t$, and $y$, may be correlated, thanks to unobserved confounders $z$. Here, $f$, $g$, and $h$ are neural networks parameterized by different parts of the parameter set $\\theta$, which are implicitly defined when the neural network modules are instantiated. As you can see in the automatically constructed rendering below, our probabilistically program model is faithful to the assumed causal structure in the CEVAE paper [louizos2017causal].\n",
    "\n",
    "**Note:** In the CEVAE paper the authors propose a more sophisticated inference scheme using both a probabilsitic encoder and decoder network. Here, we simply show maximum likelihood estimation for brevity, but one could straightforwardly extend this example to include the full VAE training infrastructure using Pyro."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Description\n",
    "\n",
    "As we only apply maximum likelihood inference in this example, we do not place priors on any of the latent parameters in the CEVAE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Sequential):\n",
    "    # Fully connected neural network with ELU activations.\n",
    "    def __init__(self, sizes):\n",
    "        layers = []\n",
    "        for in_size, out_size in zip(sizes, sizes[1:]):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            layers.append(nn.ELU())\n",
    "        layers.pop(-1)\n",
    "        super().__init__(*layers)\n",
    "\n",
    "\n",
    "class DiagNormalNet(FullyConnected):\n",
    "    # Fully connected neural network with ELU activations, followed by a diagonal Gaussian.\n",
    "    def __init__(self, sizes):\n",
    "        assert len(sizes) >= 2\n",
    "        sizes = sizes[:-1] + [sizes[-1] * 2]\n",
    "        super().__init__(sizes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        loc, scale = super().forward(x).chunk(2, dim=-1)\n",
    "        return loc, nn.functional.softplus(scale)\n",
    "\n",
    "\n",
    "class BernoulliNet(FullyConnected):\n",
    "    # Fully connected neural network with ELU activations, followed by a Bernoulli.\n",
    "    def __init__(self, sizes):\n",
    "        super().__init__(sizes + [1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return super().forward(x).squeeze(-1).clamp(min=-10, max=10)\n",
    "\n",
    "\n",
    "class PreWhitener(nn.Module):\n",
    "    \"\"\"\n",
    "    Data pre-whitener.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        with torch.no_grad():\n",
    "            loc = data.mean(0)\n",
    "            scale = data.std(0)\n",
    "            scale[~(scale > 0)] = 1.0\n",
    "            self.register_buffer(\"loc\", loc)\n",
    "            self.register_buffer(\"inv_scale\", scale.reciprocal())\n",
    "\n",
    "    def forward(self, data):\n",
    "        return (data - self.loc) * self.inv_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 6.0.2 (20221011.1828)\n -->\n<!-- Pages: 1 -->\n<svg width=\"242pt\" height=\"220pt\"\n viewBox=\"0.00 0.00 241.50 220.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 216)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-216 237.5,-216 237.5,4 -4,4\"/>\n<!-- z -->\n<g id=\"node1\" class=\"node\">\n<title>z</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"99\" cy=\"-178\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">z</text>\n</g>\n<!-- x -->\n<g id=\"node2\" class=\"node\">\n<title>x</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n</g>\n<!-- z&#45;&gt;x -->\n<g id=\"edge1\" class=\"edge\">\n<title>z&#45;&gt;x</title>\n<path fill=\"none\" stroke=\"black\" d=\"M86.46,-162.02C75.38,-148.78 59.04,-129.27 46.29,-114.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"48.74,-111.52 39.64,-106.1 43.38,-116.01 48.74,-111.52\"/>\n</g>\n<!-- t -->\n<g id=\"node3\" class=\"node\">\n<title>t</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">t</text>\n</g>\n<!-- z&#45;&gt;t -->\n<g id=\"edge2\" class=\"edge\">\n<title>z&#45;&gt;t</title>\n<path fill=\"none\" stroke=\"black\" d=\"M99,-159.6C99,-147.75 99,-131.82 99,-118.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-118.08 99,-108.08 95.5,-118.08 102.5,-118.08\"/>\n</g>\n<!-- y -->\n<g id=\"node4\" class=\"node\">\n<title>y</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"126\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"126\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n</g>\n<!-- z&#45;&gt;y -->\n<g id=\"edge4\" class=\"edge\">\n<title>z&#45;&gt;y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M109.92,-161.43C118.64,-147.99 130.17,-127.68 135,-108 140.04,-87.45 137.16,-63.56 133.37,-45.71\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"136.78,-44.9 131.09,-35.97 129.96,-46.5 136.78,-44.9\"/>\n</g>\n<!-- t&#45;&gt;y -->\n<g id=\"edge3\" class=\"edge\">\n<title>t&#45;&gt;y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M105.4,-72.41C108.51,-64.34 112.33,-54.43 115.83,-45.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.13,-46.55 119.46,-35.96 112.6,-44.03 119.13,-46.55\"/>\n</g>\n<!-- distribution_description_node -->\n<g id=\"node5\" class=\"node\">\n<title>distribution_description_node</title>\n<text text-anchor=\"start\" x=\"152.5\" y=\"-196.8\" font-family=\"Times,serif\" font-size=\"14.00\">z ~ Normal</text>\n<text text-anchor=\"start\" x=\"152.5\" y=\"-181.8\" font-family=\"Times,serif\" font-size=\"14.00\">x ~ Normal</text>\n<text text-anchor=\"start\" x=\"152.5\" y=\"-166.8\" font-family=\"Times,serif\" font-size=\"14.00\">t ~ Bernoulli</text>\n<text text-anchor=\"start\" x=\"152.5\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">y ~ Bernoulli</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7ff07a86aeb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ProxyConfounderModel(PyroModule):\n",
    "    \"\"\"\n",
    "    :param dict config: A dict specifying ``feature_dim``, ``latent_dim``,\n",
    "        ``hidden_dim``, ``num_layers``, and ``outcome_dist``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_dim: int, latent_dim: int, hidden_dim: int, num_layers: int):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.feature_dim = feature_dim\n",
    "        self.x_nn = DiagNormalNet([latent_dim] + [hidden_dim] * num_layers + [feature_dim])\n",
    "        self.t_nn = BernoulliNet([latent_dim])\n",
    "        # The y network is split between the two t values.\n",
    "        self.y0_nn = BernoulliNet([latent_dim] + [hidden_dim] * num_layers)\n",
    "        self.y1_nn = BernoulliNet([latent_dim] + [hidden_dim] * num_layers)\n",
    "\n",
    "    def forward(self):\n",
    "        # Proxy confounder\n",
    "        z = pyro.sample(\"z\", dist.Normal(0, 1).expand([self.latent_dim]).to_event(1))\n",
    "        # Observed covariates\n",
    "        x = pyro.sample(\"x\", dist.Normal(*self.x_nn(z)).to_event(1))\n",
    "        # Treatment\n",
    "        t = pyro.sample(\"t\", dist.Bernoulli(logits=self.t_nn(z)))\n",
    "        # parameters are not shared among values of t\n",
    "        y_logits = torch.where(t == 1, self.y1_nn(z), self.y0_nn(z))\n",
    "        # Outcome\n",
    "        y = pyro.sample(\"y\", dist.Bernoulli(logits=y_logits))\n",
    "        return y\n",
    "\n",
    "\n",
    "individual_model = ProxyConfounderModel(\n",
    "    feature_dim=x.shape[-1],\n",
    "    latent_dim=5,\n",
    "    hidden_dim=200,\n",
    "    num_layers=3,\n",
    ")\n",
    "pyro.render_model(individual_model, model_args=(), render_distributions=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Query: conditional average treatment effect (CATE)\n",
    "\n",
    "In this setting we wish to compute the *conditional average treatment effect*, $CATE = \\mathbb{E}[Y=1|do(T=1), X=x] - \\mathbb{E}[Y=1|do(T=0), X=x]$. The `do` notation indicates that the expectations are taken according to *intervened* versions of the model, with $T$ set to a particular value. Note from our [tutorial](tutorial_i.ipynb) that this is different from conditioning on $T$ in the original `causal_model`, which assumes $Z$ and $T$, and thus $X$ and $Y$ are dependent.\n",
    "\n",
    "In words, in this setting the CATE tells us how much greater the outcome would be across all individuals with the same set of covariates if we forced those individuals to receive treatment relative to if we forced them to not receive treatment. Here, we are interested in the average only over that subpopulation of individuals with the same value of the covariates. \n",
    "\n",
    "As we're using maximum likelihood inference here, we'll first condition our model to update neural network parameters, and then afterwards transform the model with learned parameters according to the desired intervention. This two-stage procedure separates the computation for convenience, but could instead be implemented in a single inference run in an extended model like the [backdoor](backdoor.ipynb) and [slc](slc.ipynb) models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit parameters via maximum likelihood\n",
    "\n",
    "Before estimating the query, we fit deterministic neural network parameters in the model to the observed data via maximum likelihood.\n",
    "\n",
    "First, we must extend the model over individual instances to be a model over the entire population using Pyro's `plate` effect handler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 6.0.2 (20221011.1828)\n -->\n<!-- Pages: 1 -->\n<svg width=\"276pt\" height=\"259pt\"\n viewBox=\"0.00 0.00 275.50 259.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 255)\">\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-255 271.5,-255 271.5,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_observations</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-243 170,-243 170,-8 8,-8\"/>\n<text text-anchor=\"middle\" x=\"127.5\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">observations</text>\n</g>\n<!-- z -->\n<g id=\"node1\" class=\"node\">\n<title>z</title>\n<ellipse fill=\"white\" stroke=\"black\" cx=\"115\" cy=\"-217\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"115\" y=\"-213.3\" font-family=\"Times,serif\" font-size=\"14.00\">z</text>\n</g>\n<!-- x -->\n<g id=\"node2\" class=\"node\">\n<title>x</title>\n<ellipse fill=\"gray\" stroke=\"black\" cx=\"43\" cy=\"-129\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"43\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">x</text>\n</g>\n<!-- z&#45;&gt;x -->\n<g id=\"edge1\" class=\"edge\">\n<title>z&#45;&gt;x</title>\n<path fill=\"none\" stroke=\"black\" d=\"M102.46,-201.02C91.38,-187.78 75.04,-168.27 62.29,-153.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"64.74,-150.52 55.64,-145.1 59.38,-155.01 64.74,-150.52\"/>\n</g>\n<!-- t -->\n<g id=\"node3\" class=\"node\">\n<title>t</title>\n<ellipse fill=\"gray\" stroke=\"black\" cx=\"115\" cy=\"-129\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"115\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">t</text>\n</g>\n<!-- z&#45;&gt;t -->\n<g id=\"edge2\" class=\"edge\">\n<title>z&#45;&gt;t</title>\n<path fill=\"none\" stroke=\"black\" d=\"M115,-198.6C115,-186.75 115,-170.82 115,-157.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"118.5,-157.08 115,-147.08 111.5,-157.08 118.5,-157.08\"/>\n</g>\n<!-- y -->\n<g id=\"node4\" class=\"node\">\n<title>y</title>\n<ellipse fill=\"gray\" stroke=\"black\" cx=\"125\" cy=\"-57\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"125\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n</g>\n<!-- z&#45;&gt;y -->\n<g id=\"edge4\" class=\"edge\">\n<title>z&#45;&gt;y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M125.92,-200.43C134.64,-186.99 146.17,-166.68 151,-147 154.81,-131.46 154.62,-126.59 151,-111 148.78,-101.43 144.57,-91.59 140.18,-83.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"143.11,-81.08 135.24,-73.98 136.96,-84.44 143.11,-81.08\"/>\n</g>\n<!-- t&#45;&gt;y -->\n<g id=\"edge3\" class=\"edge\">\n<title>t&#45;&gt;y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M117.42,-111.05C118.52,-103.35 119.85,-94.03 121.09,-85.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"124.58,-85.67 122.53,-75.28 117.65,-84.68 124.58,-85.67\"/>\n</g>\n<!-- distribution_description_node -->\n<g id=\"node5\" class=\"node\">\n<title>distribution_description_node</title>\n<text text-anchor=\"start\" x=\"186.5\" y=\"-235.8\" font-family=\"Times,serif\" font-size=\"14.00\">z ~ Normal</text>\n<text text-anchor=\"start\" x=\"186.5\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">x ~ Normal</text>\n<text text-anchor=\"start\" x=\"186.5\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\">t ~ Bernoulli</text>\n<text text-anchor=\"start\" x=\"186.5\" y=\"-190.8\" font-family=\"Times,serif\" font-size=\"14.00\">y ~ Bernoulli</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7ff078ab4d60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CEVAE_Population(PyroModule):\n",
    "    def __init__(self, individual_model: ProxyConfounderModel):\n",
    "        super().__init__()\n",
    "        self.individual_model = individual_model\n",
    "\n",
    "    def forward(self, x_obs, t_obs, y_obs):\n",
    "        # Condition on observed x, t, y\n",
    "        # Use a plate to indicate that the following observations are conditionally independent given NN parameters.\n",
    "        with pyro.condition(data=dict(x=x_obs, t=t_obs, y=y_obs)), \\\n",
    "                pyro.plate(\"observations\", size=x_obs.shape[0], dim=-1):\n",
    "            return self.individual_model()\n",
    "\n",
    "\n",
    "mle_model = CEVAE_Population(individual_model)\n",
    "pyro.render_model(mle_model, model_args=(x, t ,y), render_distributions=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we condition the model on data and run maximum likelihood estimation for neural network parameters using Pyro's `SVI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 198.2783\n"
     ]
    }
   ],
   "source": [
    "# Opimization parameters\n",
    "pyro.clear_param_store()\n",
    "num_iterations = 25\n",
    "batch_size = 100 \n",
    "learning_rate = 1e-3 \n",
    "learning_rate_decay = 0.1 \n",
    "weight_decay = 1e-4\n",
    "jit = False \n",
    "\n",
    "x_data = x.clone().detach()\n",
    "t_data = t.clone().detach()\n",
    "y_data = y.clone().detach()\n",
    "\n",
    "# Create the variational approximation and optimizer\n",
    "mle_guide = pyro.infer.autoguide.AutoNormal(mle_model)\n",
    "adam = pyro.optim.Adam({\"lr\": learning_rate, \"weight_decay\": weight_decay})\n",
    "elbo = pyro.infer.Trace_ELBO()\n",
    "svi = pyro.infer.SVI(mle_model, mle_guide, adam, elbo)\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_data, t_data, y_data)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_data)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've learned neural network parameters, we can construct a transformed model using causal_pyro's `do` effect handler to represent interventions and its `MultiWorldCounterfactual` handler to automatically instantiate multiple counterfactual worlds. In the next section we discuss why we condition on `x_pred` in this new transformed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "\n                   Trace Shapes:             \n                    Param Sites:             \nindividual_model.x_nn$$$0.weight   200   5   \n  individual_model.x_nn$$$0.bias       200   \nindividual_model.x_nn$$$2.weight   200 200   \n  individual_model.x_nn$$$2.bias       200   \nindividual_model.x_nn$$$4.weight   200 200   \n  individual_model.x_nn$$$4.bias       200   \nindividual_model.x_nn$$$6.weight    20 200   \n  individual_model.x_nn$$$6.bias        20   \nindividual_model.t_nn$$$0.weight     1   5   \n  individual_model.t_nn$$$0.bias         1   \n                   Sample Sites:             \n                  test_data dist         |   \n                           value 10000   |   \n                          z dist 10000   |  5\n                           value 10000   |  5\n                          x dist 10000   | 10\n                           value 10000   | 10\n                          t dist 10000   |   \n                           value 10000   |   ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/nn/module.py:448\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 448\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    450\u001b[0m     pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    451\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    452\u001b[0m     \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    453\u001b[0m ):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mCEVAE_CATE.forward\u001b[0;34m(self, x_pred)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mwith\u001b[39;00m MultiWorldCounterfactual(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     Ys_pred \u001b[39m=\u001b[39m extended_model()\n\u001b[1;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m Ys_pred\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _context_wrap at line 12 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/nn/module.py:448\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 448\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    450\u001b[0m     pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    451\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    452\u001b[0m     \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    453\u001b[0m ):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m, in \u001b[0;36mProxyConfounderModel.forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m# parameters are not shared among values of t\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m y_logits \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(t \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my1_nn(z), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my0_nn(z))\n\u001b[1;32m     28\u001b[0m \u001b[39m# Outcome\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/nn/module.py:547\u001b[0m, in \u001b[0;36mPyroModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive:\n\u001b[0;32m--> 547\u001b[0m             pyro\u001b[39m.\u001b[39;49mmodule(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pyro_get_fullname(name), result)\n\u001b[1;32m    549\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/primitives.py:438\u001b[0m, in \u001b[0;36mmodule\u001b[0;34m(name, nn_module, update_module_params)\u001b[0m\n\u001b[1;32m    437\u001b[0m full_param_name \u001b[39m=\u001b[39m param_with_module_name(name, param_name)\n\u001b[0;32m--> 438\u001b[0m returned_param \u001b[39m=\u001b[39m param(full_param_name, param_value)\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m param_value\u001b[39m.\u001b[39m_cdata \u001b[39m!=\u001b[39m returned_param\u001b[39m.\u001b[39m_cdata:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/primitives.py:78\u001b[0m, in \u001b[0;36mparam\u001b[0;34m(name, init_tensor, constraint, event_dim)\u001b[0m\n\u001b[1;32m     77\u001b[0m args \u001b[39m=\u001b[39m (name,) \u001b[39mif\u001b[39;00m init_tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (name, init_tensor)\n\u001b[0;32m---> 78\u001b[0m \u001b[39mreturn\u001b[39;00m _param(\u001b[39m*\u001b[39;49margs, constraint\u001b[39m=\u001b[39;49mconstraint, event_dim\u001b[39m=\u001b[39;49mevent_dim, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/runtime.py:283\u001b[0m, in \u001b[0;36meffectful.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39m# apply the stack and return its return value\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m apply_stack(msg)\n\u001b[1;32m    284\u001b[0m \u001b[39mreturn\u001b[39;00m msg[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/runtime.py:213\u001b[0m, in \u001b[0;36mapply_stack\u001b[0;34m(initial_msg)\u001b[0m\n\u001b[1;32m    211\u001b[0m pointer \u001b[39m=\u001b[39m pointer \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 213\u001b[0m frame\u001b[39m.\u001b[39;49m_process_message(msg)\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m msg[\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Desktop/Research/causal_pyro/causal_pyro/counterfactual/internals.py:233\u001b[0m, in \u001b[0;36m_LazyPlateMessenger._process_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m union(indices_of(msg[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]), indices_of(msg[\u001b[39m\"\u001b[39;49m\u001b[39mfn\u001b[39;49m\u001b[39m\"\u001b[39;49m])):\n\u001b[1;32m    234\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_process_message(msg)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/Desktop/Research/causal_pyro/causal_pyro/primitives.py:225\u001b[0m, in \u001b[0;36mindices_of\u001b[0;34m(value, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39mGet a :class:`IndexSet` of indices on which an indexed value is supported.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m:return: A :class:`IndexSet` containing the indices on which the value is supported.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[39mreturn\u001b[39;00m Ys_pred\n\u001b[1;32m     19\u001b[0m cate_model \u001b[39m=\u001b[39m CEVAE_CATE(individual_model)\n\u001b[0;32m---> 20\u001b[0m pyro\u001b[39m.\u001b[39;49mrender_model(cate_model, model_args\u001b[39m=\u001b[39;49m(x,), render_distributions\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/infer/inspect.py:584\u001b[0m, in \u001b[0;36mrender_model\u001b[0;34m(model, model_args, model_kwargs, filename, render_distributions, render_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[39m# Get model relations.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model_args, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model_kwargs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m--> 584\u001b[0m     relations \u001b[39m=\u001b[39m [get_model_relations(model, model_args, model_kwargs)]\n\u001b[1;32m    585\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# semisupervised\u001b[39;00m\n\u001b[1;32m    586\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model_args, \u001b[39mlist\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/infer/inspect.py:284\u001b[0m, in \u001b[0;36mget_model_relations\u001b[0;34m(model, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mfork_rng(), torch\u001b[39m.\u001b[39mno_grad(), pyro\u001b[39m.\u001b[39mvalidation_enabled(\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    283\u001b[0m     \u001b[39mwith\u001b[39;00m TrackProvenance():\n\u001b[0;32m--> 284\u001b[0m         trace \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39;49mtrace(model)\u001b[39m.\u001b[39;49mget_trace(\u001b[39m*\u001b[39;49mmodel_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m    286\u001b[0m sample_sample \u001b[39m=\u001b[39m {}\n\u001b[1;32m    287\u001b[0m sample_param \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_trace\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py:180\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         exc \u001b[39m=\u001b[39m exc_type(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(exc_value, shapes))\n\u001b[1;32m    179\u001b[0m         exc \u001b[39m=\u001b[39m exc\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39mret\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/nn/module.py:448\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    447\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 448\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    449\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    450\u001b[0m         pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    451\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    453\u001b[0m     ):\n\u001b[1;32m    454\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mCEVAE_CATE.forward\u001b[0;34m(self, x_pred)\u001b[0m\n\u001b[1;32m      8\u001b[0m extended_model \u001b[39m=\u001b[39m do(actions \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.0\u001b[39m})(\n\u001b[1;32m      9\u001b[0m                     do(actions \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1.0\u001b[39m})(\n\u001b[1;32m     10\u001b[0m                         pyro\u001b[39m.\u001b[39mplate(\u001b[39m\"\u001b[39m\u001b[39mtest_data\u001b[39m\u001b[39m\"\u001b[39m, size\u001b[39m=\u001b[39mx_pred\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)(\n\u001b[1;32m     11\u001b[0m                             condition(data\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(x\u001b[39m=\u001b[39mx_pred))(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindividual_model))))\n\u001b[1;32m     13\u001b[0m \u001b[39mwith\u001b[39;00m MultiWorldCounterfactual(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     Ys_pred \u001b[39m=\u001b[39m extended_model()\n\u001b[1;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m Ys_pred\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: _context_wrap at line 12 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/nn/module.py:448\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    447\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 448\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    449\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    450\u001b[0m         pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    451\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    453\u001b[0m     ):\n\u001b[1;32m    454\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m, in \u001b[0;36mProxyConfounderModel.forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m t \u001b[39m=\u001b[39m pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39mBernoulli(logits\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_nn(z)))\n\u001b[1;32m     26\u001b[0m \u001b[39m# parameters are not shared among values of t\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m y_logits \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(t \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my1_nn(z), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my0_nn(z))\n\u001b[1;32m     28\u001b[0m \u001b[39m# Outcome\u001b[39;00m\n\u001b[1;32m     29\u001b[0m y \u001b[39m=\u001b[39m pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39mBernoulli(logits\u001b[39m=\u001b[39my_logits))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/nn/module.py:547\u001b[0m, in \u001b[0;36mPyroModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    545\u001b[0m         \u001b[39m# Regular nn.Modules trigger pyro.module statements.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive:\n\u001b[0;32m--> 547\u001b[0m             pyro\u001b[39m.\u001b[39;49mmodule(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pyro_get_fullname(name), result)\n\u001b[1;32m    549\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/primitives.py:438\u001b[0m, in \u001b[0;36mmodule\u001b[0;34m(name, nn_module, update_module_params)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39mif\u001b[39;00m param_value\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m    435\u001b[0m     \u001b[39m# register the parameter in the module with pyro\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     \u001b[39m# this only does something substantive if the parameter hasn't been seen before\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     full_param_name \u001b[39m=\u001b[39m param_with_module_name(name, param_name)\n\u001b[0;32m--> 438\u001b[0m     returned_param \u001b[39m=\u001b[39m param(full_param_name, param_value)\n\u001b[1;32m    440\u001b[0m     \u001b[39mif\u001b[39;00m param_value\u001b[39m.\u001b[39m_cdata \u001b[39m!=\u001b[39m returned_param\u001b[39m.\u001b[39m_cdata:\n\u001b[1;32m    441\u001b[0m         target_state_dict[param_name] \u001b[39m=\u001b[39m returned_param\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/primitives.py:78\u001b[0m, in \u001b[0;36mparam\u001b[0;34m(name, init_tensor, constraint, event_dim)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m# Note effectful(-) requires the double passing of name below.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m args \u001b[39m=\u001b[39m (name,) \u001b[39mif\u001b[39;00m init_tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (name, init_tensor)\n\u001b[0;32m---> 78\u001b[0m \u001b[39mreturn\u001b[39;00m _param(\u001b[39m*\u001b[39;49margs, constraint\u001b[39m=\u001b[39;49mconstraint, event_dim\u001b[39m=\u001b[39;49mevent_dim, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/runtime.py:283\u001b[0m, in \u001b[0;36meffectful.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m msg \u001b[39m=\u001b[39m {\n\u001b[1;32m    267\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minfer\u001b[39m\u001b[39m\"\u001b[39m: infer,\n\u001b[1;32m    281\u001b[0m }\n\u001b[1;32m    282\u001b[0m \u001b[39m# apply the stack and return its return value\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m apply_stack(msg)\n\u001b[1;32m    284\u001b[0m \u001b[39mreturn\u001b[39;00m msg[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/site-packages/pyro/poutine/runtime.py:213\u001b[0m, in \u001b[0;36mapply_stack\u001b[0;34m(initial_msg)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mfor\u001b[39;00m frame \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(stack):\n\u001b[1;32m    211\u001b[0m     pointer \u001b[39m=\u001b[39m pointer \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 213\u001b[0m     frame\u001b[39m.\u001b[39;49m_process_message(msg)\n\u001b[1;32m    215\u001b[0m     \u001b[39mif\u001b[39;00m msg[\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    216\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Research/causal_pyro/causal_pyro/counterfactual/internals.py:233\u001b[0m, in \u001b[0;36m_LazyPlateMessenger._process_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m msg[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\n\u001b[1;32m    229\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msample\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    230\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mparam\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m ) \u001b[39mor\u001b[39;00m pyro\u001b[39m.\u001b[39mpoutine\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39msite_is_subsample(msg):\n\u001b[1;32m    232\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m union(indices_of(msg[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]), indices_of(msg[\u001b[39m\"\u001b[39;49m\u001b[39mfn\u001b[39;49m\u001b[39m\"\u001b[39;49m])):\n\u001b[1;32m    234\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_process_message(msg)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/causal_pyro/lib/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/Desktop/Research/causal_pyro/causal_pyro/primitives.py:225\u001b[0m, in \u001b[0;36mindices_of\u001b[0;34m(value, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39msingledispatch\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mindices_of\u001b[39m(value, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m IndexSet:\n\u001b[1;32m    169\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m    Get a :class:`IndexSet` of indices on which an indexed value is supported.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m    :return: A :class:`IndexSet` containing the indices on which the value is supported.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: \n                   Trace Shapes:             \n                    Param Sites:             \nindividual_model.x_nn$$$0.weight   200   5   \n  individual_model.x_nn$$$0.bias       200   \nindividual_model.x_nn$$$2.weight   200 200   \n  individual_model.x_nn$$$2.bias       200   \nindividual_model.x_nn$$$4.weight   200 200   \n  individual_model.x_nn$$$4.bias       200   \nindividual_model.x_nn$$$6.weight    20 200   \n  individual_model.x_nn$$$6.bias        20   \nindividual_model.t_nn$$$0.weight     1   5   \n  individual_model.t_nn$$$0.bias         1   \n                   Sample Sites:             \n                  test_data dist         |   \n                           value 10000   |   \n                          z dist 10000   |  5\n                           value 10000   |  5\n                          x dist 10000   | 10\n                           value 10000   | 10\n                          t dist 10000   |   \n                           value 10000   |   "
     ]
    }
   ],
   "source": [
    "class CEVAE_CATE(PyroModule):\n",
    "    def __init__(self, individual_model: ProxyConfounderModel):\n",
    "        super().__init__()\n",
    "        self.individual_model = individual_model\n",
    "\n",
    "    def forward(self, x_pred):\n",
    "        # As we're evaluating the CATE, we need to condition on the observed data at test time.\n",
    "        extended_model = do(actions = {\"t\": 0.0})(\n",
    "                            do(actions = {\"t\": 1.0})(\n",
    "                                pyro.plate(\"test_data\", size=x_pred.shape[0], dim=-1)(\n",
    "                                    condition(data=dict(x=x_pred))(self.individual_model))))\n",
    "        \n",
    "        with MultiWorldCounterfactual(-2):\n",
    "            Ys_pred = extended_model()\n",
    "\n",
    "        return Ys_pred\n",
    "\n",
    "\n",
    "cate_model = CEVAE_CATE(individual_model)\n",
    "pyro.render_model(cate_model, model_args=(x,), render_distributions=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Inference as Probabilistic Inference\n",
    "\n",
    "In the [backdoor](backdoor.ipynb) and [slc](slc.ipynb) examples we only used Pyro's approximate inference utilities to estimate posterior distributions over model parameters, and then used those inferred (distributions over) parameters to estimate causal effects using Causal Pyro's interventions. Here the story is somewhat more complicated by the fact that we are estimating the conditional average treatment effect for yet unseen test data. Therefore, not only do we need to estimate model parameters as we've done above, we also must estimate posterior distributions over latent $Z$ conditional on observed covariates $X$. Similar to previous example, any inference method available in Pyro could be used to estimate the CATE, including amortized variational inference [@kingma2013auto] as in the original paper [@louizos2017causal].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize the model and guide\n",
    "pyro.clear_param_store()\n",
    "num_iterations = 2500 \n",
    "x_pred_data = x_test.clone().detach()\n",
    "whiten = PreWhitener(x_pred_data)\n",
    "\n",
    "cate_model_fit = pyro.poutine.block(hide_types=[\"param\",])(\n",
    "    pyro.infer.config_enumerate(cate_model))\n",
    "cate_guide = pyro.infer.autoguide.AutoNormal(pyro.poutine.block(cate_model_fit, hide=['t', 'y_observed', 'y_unobserved']))\n",
    "elbo = pyro.infer.TraceEnum_ELBO()\n",
    "\n",
    "adam = pyro.optim.Adam({\"lr\": learning_rate, \"weight_decay\": weight_decay})\n",
    "svi = pyro.infer.SVI(cate_model_fit, cate_guide, adam, elbo)\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    x_data = whiten(x_pred_data)\n",
    "    loss = svi.step(x_pred_data)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_pred_data)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from the posterior predictive distribution\n",
    "predictive = pyro.infer.Predictive(cate_model, guide=cate_guide, num_samples=100, return_sites=(\"t\", \"x\", \"z\", \"y_unobserved\",))\n",
    "preds = predictive(x_pred_data)\n",
    "ys_pred, t_pred, zs_pred = preds[\"y_unobserved\"], preds[\"t\"], preds[\"z\"]\n",
    "\n",
    "# Evaluate the c-specific causal effects for each individual and for each posterior sample\n",
    "est_cates = ys_pred[..., 1, 0, :] - ys_pred[..., 0, 1, :]\n",
    "\n",
    "# Evaluate the average causal effect by taking the mean over the individual-specific effects\n",
    "# ate = est_cates.mean(0)\n",
    "true_ate = true_cates.mean()\n",
    "est_ate = est_cates.mean(-1)\n",
    "\n",
    "mae_ate = torch.abs(true_cates - est_cates).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cates[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_pred[..., 1, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Average Treatment Effect -> X = 0\n",
    "import seaborn as sns\n",
    "\n",
    "est_cates_0 = est_cates[:, x_test[:, 0] == 0]\n",
    "\n",
    "est_cates_0.shape\n",
    "# ax = sns.kdeplot(est_cates_0[:, 0], label=\"Estimated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = 0.9 * true_cates.min().item(), 1.1 * true_cates.max().item()\n",
    "ymin, ymax = 0.9 * est_cates.min().item(), 1.1 * est_cates.max().item()\n",
    "diag = torch.linspace(min(xmin, ymin), max(xmax, ymax), 1000)\n",
    "plt.scatter(diag.detach().cpu().numpy(), diag.detach().cpu().numpy(), color='red', marker='.', label='perfect fit (true = est)')\n",
    "plt.scatter(true_cates.detach().cpu().numpy(), est_cates.detach().cpu().numpy(), color='blue', label='Individual CATE estimates')\n",
    "plt.scatter(true_ate.expand(est_ate.shape).detach().cpu().numpy(), est_ate.detach().cpu().numpy(), color='green', marker='+', label=f'ATE estimates (MAE = {mae_ate}')\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.xlabel('True Treatment Effect')\n",
    "plt.ylabel('Estimated Treatment Effect')\n",
    "plt.title('True vs. estimated treatment effects')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(est_ate.detach().cpu().numpy(), bins=50)\n",
    "plt.title(f'Individual ATE estimates (mean = {est_ate.mean().item()})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b21c0b9d110a5a3043a375d760ca16faf426bffca7e8cbf746b0d228ab037b0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
