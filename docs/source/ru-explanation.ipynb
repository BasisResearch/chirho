{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from typing import Dict, List, Optional,  Union, Callable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "from causal_pyro.indexed.ops import IndexSet, gather, indices_of, scatter\n",
    "from causal_pyro.interventional.handlers import do\n",
    "from causal_pyro.counterfactual.handlers import MultiWorldCounterfactual, Preemptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HalpernPearlModifiedApproximate:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: Callable,\n",
    "        antecedents: Union[Dict[str, torch.Tensor], List[str]],\n",
    "        outcome: str,\n",
    "        witness_candidates: List[str],\n",
    "        observations: Optional[Dict[str, torch.Tensor]],\n",
    "        sample_size: int = 100,\n",
    "        event_dim: int = 0\n",
    "        ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.antecedents = antecedents\n",
    "        self.outcome = outcome\n",
    "        self.witness_candidates = witness_candidates\n",
    "        self.observations = observations\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        self.antecedents_dict = (\n",
    "            self.antecedents if isinstance(self.antecedents, dict)\n",
    "            else self.revert_antecedents(self.antecedents)\n",
    "        )\n",
    "    \n",
    "        self.preemptions = {candidate: functools.partial(self.preempt_with_factual,\n",
    "                                             antecedents = self.antecedents) for \n",
    "                                             candidate in self.witness_candidates}\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def revert_antecedents(antecedents: List[str]) -> Dict[str, Callable[[torch.Tensor], torch.Tensor]]:\n",
    "        return {antecedent: (lambda v: 1 - v) for antecedent in antecedents}\n",
    "\n",
    "    @staticmethod   \n",
    "    def preempt_with_factual(value: torch.Tensor, *,\n",
    "                          antecedents: List[str] = None, event_dim: int = 0):\n",
    "    \n",
    "        if antecedents is None:\n",
    "            antecedents = []\n",
    "\n",
    "        antecedents = [a for a in antecedents if a in indices_of(value, event_dim=event_dim)]\n",
    "\n",
    "        factual_value = gather(value, IndexSet(**{antecedent: {0} for antecedent in antecedents}),\n",
    "                                event_dim=event_dim)\n",
    "            \n",
    "        return scatter({\n",
    "            IndexSet(**{antecedent: {0} for antecedent in antecedents}): factual_value,\n",
    "            IndexSet(**{antecedent: {1} for antecedent in antecedents}): factual_value,\n",
    "        }, event_dim=event_dim)\n",
    "        \n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with pyro.poutine.trace() as trace:\n",
    "            with MultiWorldCounterfactual():\n",
    "                with do(actions=self.antecedents_dict):\n",
    "                    with Preemptions(actions = self.preemptions):\n",
    "                        with pyro.condition(data={k: torch.as_tensor(v) for k, v in self.observations.items()}):\n",
    "                            with pyro.plate(\"plate\", self.sample_size):\n",
    "                                self.consequent = self.model()[self.outcome]\n",
    "                                self.intervened_consequent = gather(self.consequent, IndexSet(**{ant: {1} for ant in self.antecedents}))\n",
    "                                self.observed_consequent = gather(self.consequent, IndexSet(**{ant: {0} for ant in self.antecedents}))\n",
    "                                self.consequent_differs = self.intervened_consequent != self.observed_consequent   \n",
    "                                pyro.factor(\"consequent_differs\", torch.where(self.consequent_differs, torch.tensor(0.0), torch.tensor(-1e8)))\n",
    "                            \n",
    "        self.trace = trace.trace\n",
    "\n",
    "        # slightly hacky solution for odd witness candidate sets\n",
    "        if  isinstance(self.consequent_differs.squeeze().tolist(), bool):\n",
    "            self.existential_but_for = self.consequent_differs.squeeze()\n",
    "        else:\n",
    "            #if (len(self.consequent_differs.squeeze().tolist() )>1):\n",
    "            self.existential_but_for = any(self.consequent_differs.squeeze().tolist()                )  \n",
    "\n",
    "            \n",
    "\n",
    "        witness_dict = dict()\n",
    "        if self.witness_candidates:\n",
    "            witness_keys = [\"__split_\" + candidate for candidate in self.witness_candidates]\n",
    "            witness_dict = {key: self.trace.nodes[key]['value']  for key in witness_keys}\n",
    "            \n",
    "        witness_dict['observed'] = self.observed_consequent.squeeze()\n",
    "        witness_dict['intervened'] = self.intervened_consequent.squeeze()\n",
    "        witness_dict['consequent_differs'] = self.consequent_differs.squeeze()\n",
    "\n",
    "        # slightly hacky as above\n",
    "        self.witness_df = pd.DataFrame(witness_dict) if self.witness_candidates else witness_dict\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_conjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                       u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", torch.logical_and(match_dropped, lightning), event_dim=0).float()\n",
    "\n",
    "    return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n",
    "\n",
    "def ff_disjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                       u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", torch.logical_or(match_dropped, lightning), event_dim=0).float()\n",
    "\n",
    "    return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def factivity_check(model, antecedents_dict, outcome_dict, observations):\n",
    "    \n",
    "    with pyro.condition(data={k: torch.as_tensor(v) for k, v in observations.items()}):\n",
    "        output = model()\n",
    "        factivity_tensors = {k: torch.as_tensor(v) for k, v in list(antecedents_dict.items()) + list(outcome_dict.items())}\n",
    "        return all([factivity_tensors[key] == output[key] for key in factivity_tensors.keys()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_of_minimal_cause(model, antecedents, outcome, nodes, observations, runs_n):\n",
    "\n",
    "    cache = []\n",
    "    minimal_antecedents = []\n",
    "\n",
    "    for step in range(1,runs_n):\n",
    "        if outcome in nodes:\n",
    "            nodes.remove(outcome)\n",
    "\n",
    "        companion_size = random.randint(0,len(nodes))\n",
    "        companion_candidates = random.sample(nodes, companion_size)\n",
    "\n",
    "        if set(companion_candidates) in cache:\n",
    "            continue\n",
    "        \n",
    "        cache.append(set(companion_candidates))\n",
    "\n",
    "        witness_candidates = [node for node in nodes if \n",
    "                                node not in antecedents and \n",
    "                                node != outcome and \n",
    "                                    node not in companion_candidates]\n",
    "        \n",
    "        HPM = HalpernPearlModifiedApproximate(\n",
    "        model = model,\n",
    "        antecedents = companion_candidates,\n",
    "        outcome =  outcome,\n",
    "        witness_candidates = witness_candidates,\n",
    "        observations = observations,\n",
    "        sample_size = 1000)\n",
    "    \n",
    "        HPM()\n",
    "\n",
    "        if  not HPM.existential_but_for:\n",
    "            continue\n",
    "        \n",
    "        subset_is_a_minimal_cause = any([s.issubset(set(HPM.antecedents)) for s in minimal_antecedents])\n",
    "             \n",
    "        if subset_is_a_minimal_cause:\n",
    "            continue\n",
    "        minimal_antecedents.append(set(HPM.antecedents))\n",
    "\n",
    "        \n",
    "        for s in minimal_antecedents:\n",
    "            if set(HPM.antecedents).issubset(s) and s != set(HPM.antecedents):\n",
    "                minimal_antecedents.remove(s)  \n",
    "\n",
    "\n",
    "    return {\"sufficient_cause\": any([set(antecedents).issubset(s) for s in minimal_antecedents]),\n",
    "            \"actual_cause\": set(antecedents) in minimal_antecedents,\n",
    "                \"minimal_antecedents\" : minimal_antecedents, \"cache\": cache}\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sufficient_cause': True,\n",
       " 'actual_cause': False,\n",
       " 'minimal_antecedents': [{'lightning', 'match_dropped'}],\n",
       " 'cache': [{'lightning', 'match_dropped'},\n",
       "  set(),\n",
       "  {'lightning'},\n",
       "  {'match_dropped'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_of_minimal_cause(model = ff_conjunctive, \n",
    "                        antecedents = ['lightning'],\n",
    "                        outcome =  'forest_fire',\n",
    "                        nodes =  ['match_dropped', 'lightning'],\n",
    "                        observations = {\"u_match_dropped\": 1., \"u_lightning\": 1.},\n",
    "                        runs_n = 20)\n",
    "\n",
    "part_of_minimal_cause(model = ff_disjunctive, \n",
    "                        antecedents = ['lightning'],\n",
    "                        outcome =  'forest_fire',\n",
    "                        nodes =  ['match_dropped', 'lightning'],\n",
    "                        observations = {\"u_match_dropped\": 1., \"u_lightning\": 1.},\n",
    "                        runs_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overlap': True, 'overlaps': [{'lightning'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def overlap_with_cause(model, antecedents, outcome, nodes, observations, runs_n = 20):\n",
    "    \n",
    "    minimal_ante = part_of_minimal_cause(model, antecedents, outcome, nodes, observations, runs_n)['minimal_antecedents']\n",
    "    antecedents_set = set(antecedents)\n",
    "    \n",
    "    overlaps = [antecedents_set.intersection(s) for s in minimal_ante if antecedents_set.intersection(s)]\n",
    "    overlap = any(overlaps)\n",
    "    return {\"overlap\": overlap, \"overlaps\": overlaps    }\n",
    "    \n",
    "\n",
    "overlap_with_cause(model = ff_disjunctive, \n",
    "                        antecedents = ['lightning', 'blah'],\n",
    "                        outcome =  'forest_fire',\n",
    "                        nodes =  ['match_dropped', 'lightning'],\n",
    "                        observations = {\"u_match_dropped\": 1., \"u_lightning\": 1.},\n",
    "                        runs_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ensurer': True,\n",
       " 'settings_cache': [[0.0, 1.0], [0.0, 0.0], [1.0, 0.0]],\n",
       " 'intervened_consequent': [1.0, 1.0, 1.0]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ensurer(model, exogenous_variables, antecedents_dict, outcome_dict, runs_n):\n",
    "\n",
    "    settings_cache = []\n",
    "    intervened_consequent = []\n",
    "\n",
    "    outcome = list(outcome_dict.keys())[0]\n",
    "    antecedents = [key for key in antecedents_dict.keys()]\n",
    "\n",
    "    for step in range(1,runs_n):\n",
    "        \n",
    "        random_setting = [random.choice([0., 1.]) for _ in range(len(exogenous_variables))]\n",
    "        if random_setting in settings_cache:\n",
    "            continue\n",
    "        \n",
    "        settings_cache.append(random_setting)\n",
    "\n",
    "        observations = {var: val for var, val in zip(exogenous_variables, random_setting)}\n",
    "\n",
    "        with pyro.condition(data={k: torch.as_tensor(v) for k, v in observations.items()}):\n",
    "                with MultiWorldCounterfactual():\n",
    "                    with do(actions=antecedents_dict):\n",
    "                        intervened_consequent.append(\n",
    "                             gather(model()[outcome], \n",
    "                                    IndexSet(**{ant: {1} for ant in antecedents})).squeeze().item())\n",
    "                        \n",
    "    return {\"ensurer\": all(intervened_consequent),\n",
    "            \"settings_cache\": settings_cache, \n",
    "            \"intervened_consequent\": intervened_consequent}\n",
    "\n",
    "    print(settings_cache)\n",
    "    print(observations)     \n",
    "    print(intervened_consequent)   \n",
    "    print(all(intervened_consequent))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ensurer(model = ff_conjunctive,\n",
    "        exogenous_variables = [\"u_match_dropped\", \"u_lightning\"],\n",
    "        antecedents_dict = {\"match_dropped\": 1., \"lightning\": 1.},\n",
    "        outcome_dict = {\"forest_fire\": 1.},\n",
    "                        runs_n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sufficient_cause(model, exogenous_variables, antecedents_dict, outcome_dict, nodes, observations, runs_n):\n",
    "\n",
    "    factivity = factivity_check(model = model,\n",
    "                antecedents_dict = antecedents_dict,\n",
    "                outcome_dict = outcome_dict, \n",
    "                observations = observations)\n",
    "    \n",
    "    if not factivity:\n",
    "        return {\"sufficient_cause\": False, \"failure_reason\": {\"factivity\": False}}   \n",
    "\n",
    "    \n",
    "    ensure = ensurer(model = model,\n",
    "        exogenous_variables = exogenous_variables,\n",
    "        antecedents_dict = antecedents_dict,\n",
    "        outcome_dict = outcome_dict,\n",
    "        runs_n = runs_n)['ensurer']\n",
    "    \n",
    "    if not ensure:\n",
    "        return {\"sufficient_cause\": False, \"failure_reason\": {\"ensure\": False}}\n",
    "    \n",
    "    overlap = overlap_with_cause(model = model,\n",
    "                        antecedents = [key for key in antecedents_dict.keys()],\n",
    "                        outcome =  list(outcome_dict.keys())[0],\n",
    "                        nodes =  nodes,\n",
    "                        observations = observations,\n",
    "                        runs_n= runs_n)\n",
    "    \n",
    "    if not overlap['overlap']:\n",
    "        return {\"sufficient_cause\": False, \"failure_reason\": {\"overlap\": False}}\n",
    "\n",
    "\n",
    "    # minimality check starts here\n",
    "    antecedents = [key for key in antecedents_dict.keys()]\n",
    "    subsets = [[]]\n",
    "    for node in antecedents:\n",
    "        subsets.extend([subset + [node] for subset in subsets])\n",
    "    subsets.pop()\n",
    "\n",
    "    \n",
    "    for subset in subsets:\n",
    "    \n",
    "        subset_ensure = ensurer(model = model,\n",
    "            exogenous_variables = exogenous_variables,\n",
    "            antecedents_dict = {key: antecedents_dict[key] for key in subset},\n",
    "            outcome_dict = outcome_dict,\n",
    "            runs_n = runs_n)['ensurer']    \n",
    "    \n",
    "        if not subset_ensure:\n",
    "            continue\n",
    "\n",
    "        subset_overlap = overlap_with_cause(model = model,\n",
    "                    antecedents = subset,\n",
    "                    outcome =  list(outcome_dict.keys())[0],\n",
    "                    nodes =  nodes,\n",
    "                    observations = observations,\n",
    "                    runs_n= runs_n)['overlap']\n",
    "\n",
    "        if subset_ensure and subset_overlap:\n",
    "            \n",
    "            return {\"sufficient_cause\": False, \"failure_reason\": {\"minimality\": False, \"subset\": subset}}\n",
    "      # minimality check ends here \n",
    "\n",
    "    return {\"sufficient_cause\": True, \"failure_reason\": None}\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sufficient_cause': False,\n",
       " 'failure_reason': {'minimality': False, 'subset': ['match_dropped']}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        \n",
    "sufficient_cause(model = ff_disjunctive,\n",
    "                 exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "                    antecedents_dict = {\"match_dropped\": 1., \"lightning\": 1.},\n",
    "                    outcome_dict = {\"forest_fire\": 1.},\n",
    "                    nodes = [\"match_dropped\", \"lightning\"],\n",
    "                    observations= {\"u_match_dropped\": 1., \"u_lightning\": 1.},\n",
    "                    runs_n = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sufficient_cause': True, 'failure_reason': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sufficient_cause(model = ff_conjunctive,\n",
    "                 exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "                    antecedents_dict = {\"match_dropped\": 1., \"lightning\": 1.},\n",
    "                    outcome_dict = {\"forest_fire\": 1.},\n",
    "                    nodes = [\"match_dropped\", \"lightning\"],\n",
    "                    observations= {\"u_match_dropped\": 1., \"u_lightning\": 1.},\n",
    "                    runs_n = 20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(0)\n",
    "\n",
    "def explanation(model, exogenous_variables, antecedents_dict, outcome_dict, nodes, excluded_settings, runs_n):\n",
    "\n",
    "    settings_cache = []\n",
    "    factive_settings = []\n",
    "    sufficient_causality_status = []\n",
    "    failure_reasons = []\n",
    "    possibility = False\n",
    "    nontriviality = False\n",
    "\n",
    "    outcome = list(outcome_dict.keys())[0]\n",
    "    if outcome in nodes:\n",
    "        nodes.remove(outcome)\n",
    "\n",
    "    for step in range(1,runs_n):\n",
    "        random_setting = [random.choice([0., 1.]) for _ in range(len(exogenous_variables))]\n",
    "\n",
    "        if random_setting in settings_cache or random_setting in excluded_settings:\n",
    "            continue\n",
    "\n",
    "        settings_cache.append(random_setting)\n",
    "        observations = {var: val for var, val in zip(exogenous_variables, random_setting)}\n",
    "\n",
    "         \n",
    "        consequent_satisfied = factivity_check(model, {}, outcome_dict, observations)\n",
    "\n",
    "        if not consequent_satisfied:\n",
    "            continue\n",
    "        \n",
    "        antecedent_satisfied = factivity_check(model, antecedents_dict, {}, observations)\n",
    "            \n",
    "        if not antecedent_satisfied:\n",
    "            nontriviality = True\n",
    "\n",
    "        else:\n",
    "            \n",
    "            possibility = True\n",
    "            factive_settings.append(random_setting)\n",
    "\n",
    "            sc = sufficient_cause(model = model,\n",
    "                                  exogenous_variables= exogenous_variables,\n",
    "                                    antecedents_dict = antecedents_dict,\n",
    "                                    outcome_dict = outcome_dict,\n",
    "                                    nodes = nodes,\n",
    "                                    observations= observations,\n",
    "                                    runs_n = 20)\n",
    "            \n",
    "            sufficient_causality_status.append(sc['sufficient_cause'])\n",
    "            failure_reasons.append(sc['failure_reason'])\n",
    "\n",
    "    if factive_settings:\n",
    "        explanation =  all(sufficient_causality_status)\n",
    "    else:\n",
    "        explanation = False\n",
    "\n",
    "    return {\"explanation\": explanation,\n",
    "            \"factive_settings\": factive_settings,\n",
    "            \"sufficient_causality_status\": sufficient_causality_status,\n",
    "            \"failure_reasons\": failure_reasons,\n",
    "            \"possibility\": possibility,\n",
    "            \"nontriviality\": nontriviality,\n",
    "            \"settings_cache\": settings_cache}        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': True,\n",
       " 'factive_settings': [[1.0, 1.0]],\n",
       " 'sufficient_causality_status': [True],\n",
       " 'failure_reasons': [None],\n",
       " 'possibility': True,\n",
       " 'nontriviality': False,\n",
       " 'settings_cache': [[1.0, 1.0], [0.0, 1.0], [1.0, 0.0]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation(model = ff_conjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"match_dropped\": 1., \"lightning\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\", \"lightning\"],\n",
    "            excluded_settings= [[0., 0.]],\n",
    "            runs_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': True,\n",
       " 'factive_settings': [[1.0, 1.0], [1.0, 0.0]],\n",
       " 'sufficient_causality_status': [True, True],\n",
       " 'failure_reasons': [None, None],\n",
       " 'possibility': True,\n",
       " 'nontriviality': True,\n",
       " 'settings_cache': [[1.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 0.0]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 7.1.2.\n",
    "# - ff\n",
    "# - all context available\n",
    "#in the disjunctive model, both lightning and match dropped are explanations\n",
    "\n",
    "explanation(model = ff_disjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"lightning\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\", \"lightning\"],\n",
    "            excluded_settings= [],\n",
    "            runs_n = 20)\n",
    "\n",
    "explanation(model = ff_disjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"match_dropped\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\", \"lightning\"],\n",
    "            excluded_settings= [],\n",
    "            runs_n = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': False,\n",
       " 'factive_settings': [[0.0, 1.0], [1.0, 1.0]],\n",
       " 'sufficient_causality_status': [False, False],\n",
       " 'failure_reasons': [{'overlap': False}, {'overlap': False}],\n",
       " 'possibility': True,\n",
       " 'nontriviality': False,\n",
       " 'settings_cache': [[0.0, 1.0], [0.0, 0.0], [1.0, 1.0]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in a setting where we exclude no lightning and match\n",
    "# the explanation is trivial\n",
    "\n",
    "explanation(model = ff_disjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"lightning\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\"],\n",
    "            excluded_settings= [[1.0, 0.0]],\n",
    "            runs_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': False,\n",
       " 'factive_settings': [[1.0, 1.0]],\n",
       " 'sufficient_causality_status': [False],\n",
       " 'failure_reasons': [{'ensure': False}],\n",
       " 'possibility': True,\n",
       " 'nontriviality': False,\n",
       " 'settings_cache': [[0.0, 1.0], [1.0, 0.0], [1.0, 1.0]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the conjunctive model no node on its own is an explanation\n",
    "\n",
    "explanation(model = ff_conjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"match_dropped\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\", \"lightning\"],\n",
    "            excluded_settings= [[0., 0.]],\n",
    "            runs_n = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': False,\n",
       " 'factive_settings': [[1.0, 1.0]],\n",
       " 'sufficient_causality_status': [False],\n",
       " 'failure_reasons': [{'ensure': False}],\n",
       " 'possibility': True,\n",
       " 'nontriviality': False,\n",
       " 'settings_cache': [[1.0, 1.0], [1.0, 0.0], [0.0, 1.0]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "explanation(model = ff_conjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"lightning\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\", \"lightning\"],\n",
    "            excluded_settings= [[0., 0.]],\n",
    "            runs_n = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u_ar': tensor(0.),\n",
       " 'u_esm': tensor(1.),\n",
       " 'u_esj': tensor(1.),\n",
       " 'ar': tensor(0.),\n",
       " 'esm': tensor(1.),\n",
       " 'esj': tensor(1.),\n",
       " 'ffm': tensor(1.),\n",
       " 'ffj': tensor(0.),\n",
       " 'ff': tensor(1.)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ff_extended():\n",
    "    u_ar = pyro.sample(\"u_ar\", dist.Bernoulli(0.5))\n",
    "    u_esm = pyro.sample(\"u_esm\", dist.Bernoulli(0.5))\n",
    "    u_esj = pyro.sample(\"u_esj\", dist.Bernoulli(0.5))\n",
    "\n",
    "    ar = pyro.deterministic(\"ar\", u_ar, event_dim=0)\n",
    "    esm = pyro.deterministic(\"esm\", u_esm, event_dim=0)\n",
    "    esj = pyro.deterministic(\"esj\", u_esj, event_dim=0)\n",
    "\n",
    "    ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
    "    ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
    "\n",
    "    ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
    "\n",
    "    return {\"u_ar\": u_ar, \"u_esm\": u_esm, \"u_esj\": u_esj, \n",
    "            \"ar\": ar, \"esm\": esm, \"esj\": esj, \"ffm\": ffm, \"ffj\": ffj, \"ff\": ff}\n",
    "\n",
    "ff_extended()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': True,\n",
       " 'factive_settings': [[0.0, 0.0, 1.0], [1.0, 1.0, 1.0], [0.0, 1.0, 1.0]],\n",
       " 'sufficient_causality_status': [True, True, True],\n",
       " 'failure_reasons': [None, None, None],\n",
       " 'possibility': True,\n",
       " 'nontriviality': True,\n",
       " 'settings_cache': [[1.0, 1.0, 0.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [1.0, 1.0, 1.0],\n",
       "  [0.0, 0.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 1.0]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with no excluded settings\n",
    "# one explanation for ff is esj\n",
    "\n",
    "explanation(model = ff_extended,\n",
    "            exogenous_variables= [\"u_ar\", \"u_esm\", \"u_esj\"],\n",
    "            antecedents_dict = {\"esj\": 1.},\n",
    "            outcome_dict = {\"ff\": 1.},\n",
    "            nodes= [\"ar\", \"esm\", \"esj\"],\n",
    "            excluded_settings= [],\n",
    "            runs_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': True,\n",
       " 'factive_settings': [[0.0, 1.0, 0.0], [0.0, 1.0, 1.0]],\n",
       " 'sufficient_causality_status': [True, True],\n",
       " 'failure_reasons': [None, None],\n",
       " 'possibility': True,\n",
       " 'nontriviality': True,\n",
       " 'settings_cache': [[0.0, 0.0, 0.0],\n",
       "  [1.0, 1.0, 1.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 0.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 1.0]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another involves esm =1 and ar = 0\n",
    "\n",
    "explanation(model = ff_extended,\n",
    "            exogenous_variables= [\"u_ar\", \"u_esm\", \"u_esj\"],\n",
    "            antecedents_dict = {\"esm\": 1., \"ar\": 0.},\n",
    "            outcome_dict = {\"ff\": 1.},\n",
    "            nodes= [\"ar\", \"esm\", \"esj\"],\n",
    "            excluded_settings= [],\n",
    "            runs_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': False,\n",
       " 'factive_settings': [],\n",
       " 'sufficient_causality_status': [],\n",
       " 'failure_reasons': [],\n",
       " 'possibility': False,\n",
       " 'nontriviality': True,\n",
       " 'settings_cache': [[0.0, 0.0, 0.0],\n",
       "  [1.0, 0.0, 1.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [1.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 1.0]]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation(model = ff_extended,\n",
    "            exogenous_variables= [\"u_ar\", \"u_esm\", \"u_esj\"],\n",
    "            antecedents_dict = {'esm': 0.0, 'esj': 0.0} ,\n",
    "            outcome_dict = {\"ff\": 1.},\n",
    "            nodes= [\"ar\", \"esm\", \"esj\"],\n",
    "            excluded_settings= [],\n",
    "            runs_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             candidates  explanatory_status\n",
      "0                                    {}               False\n",
      "1                           {'ar': 0.0}               False\n",
      "2                           {'ar': 1.0}               False\n",
      "3                          {'esm': 1.0}               False\n",
      "4                          {'esm': 0.0}               False\n",
      "5               {'ar': 1.0, 'esm': 0.0}               False\n",
      "6               {'ar': 0.0, 'esm': 0.0}               False\n",
      "7               {'ar': 1.0, 'esm': 1.0}               False\n",
      "8               {'ar': 0.0, 'esm': 1.0}                True\n",
      "9                          {'esj': 0.0}               False\n",
      "10                         {'esj': 1.0}                True\n",
      "11              {'ar': 0.0, 'esj': 1.0}               False\n",
      "12              {'ar': 1.0, 'esj': 1.0}               False\n",
      "13              {'ar': 1.0, 'esj': 0.0}               False\n",
      "14              {'ar': 0.0, 'esj': 0.0}               False\n",
      "15             {'esm': 1.0, 'esj': 0.0}               False\n",
      "16             {'esm': 0.0, 'esj': 0.0}               False\n",
      "17             {'esm': 1.0, 'esj': 1.0}               False\n",
      "18             {'esm': 0.0, 'esj': 1.0}               False\n",
      "19  {'ar': 0.0, 'esm': 0.0, 'esj': 0.0}               False\n",
      "20  {'ar': 0.0, 'esm': 1.0, 'esj': 0.0}               False\n",
      "21  {'ar': 1.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "22  {'ar': 1.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "23  {'ar': 1.0, 'esm': 0.0, 'esj': 0.0}               False\n",
      "24  {'ar': 0.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "25  {'ar': 1.0, 'esm': 1.0, 'esj': 0.0}               False\n",
      "26  {'ar': 0.0, 'esm': 0.0, 'esj': 1.0}               False\n"
     ]
    }
   ],
   "source": [
    "#  explore all 27 possible explanations\n",
    "\n",
    "explanatory_status = []\n",
    "candidates = []\n",
    "\n",
    "nodes = [\"ar\", \"esm\", \"esj\"]\n",
    "subsets = [[]]\n",
    "for node in nodes:\n",
    "        subsets.extend([subset + [node] for subset in subsets])\n",
    "\n",
    "# if you want to remove the explanations\n",
    "# subsets.remove([\"ar\", \"esm\"] )\n",
    "# subsets.remove([\"esj\"])\n",
    "\n",
    "\n",
    "for subset in subsets:\n",
    "        for _ in range(50):\n",
    "                random_setting = [random.choice([0., 1.]) \n",
    "                          for _ in range(len(subset))]\n",
    "                candidate = {var: val for var, val in zip(subset, random_setting)}\n",
    "\n",
    "                if candidate in candidates:\n",
    "                        continue\n",
    "\n",
    "                candidates.append(candidate)\n",
    "                explanatory_status.append(explanation(model = ff_extended,\n",
    "                        exogenous_variables= [\"u_ar\", \"u_esm\", \"u_esj\"],\n",
    "                        antecedents_dict = candidate,\n",
    "                        outcome_dict = {\"ff\": 1.},\n",
    "                        nodes= [\"ar\", \"esm\", \"esj\"],\n",
    "                        excluded_settings= [],\n",
    "                        runs_n = 600)['explanation'])\n",
    "        \n",
    "\n",
    "explanation_search = pd.DataFrame({\"candidates\": candidates,\n",
    "                                   \"explanatory_status\": explanatory_status})\n",
    "\n",
    "print(explanation_search)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_pyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
