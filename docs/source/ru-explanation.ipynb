{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from typing import Dict, List, Optional,  Union, Callable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "from causal_pyro.indexed.ops import IndexSet, gather, indices_of, scatter\n",
    "from causal_pyro.interventional.handlers import do\n",
    "from causal_pyro.counterfactual.handlers import MultiWorldCounterfactual, Preemptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HalpernPearlModifiedApproximate:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: Callable,\n",
    "        antecedents: Union[Dict[str, torch.Tensor], List[str]],\n",
    "        outcome: str,\n",
    "        witness_candidates: List[str],\n",
    "        observations: Optional[Dict[str, torch.Tensor]],\n",
    "        sample_size: int = 100,\n",
    "        event_dim: int = 0\n",
    "        ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.antecedents = antecedents\n",
    "        self.outcome = outcome\n",
    "        self.witness_candidates = witness_candidates\n",
    "        self.observations = observations\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        self.antecedents_dict = (\n",
    "            self.antecedents if isinstance(self.antecedents, dict)\n",
    "            else self.revert_antecedents(self.antecedents)\n",
    "        )\n",
    "    \n",
    "        self.preemptions = {candidate: functools.partial(self.preempt_with_factual,\n",
    "                                             antecedents = self.antecedents) for \n",
    "                                             candidate in self.witness_candidates}\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def revert_antecedents(antecedents: List[str]) -> Dict[str, Callable[[torch.Tensor], torch.Tensor]]:\n",
    "        return {antecedent: (lambda v: 1 - v) for antecedent in antecedents}\n",
    "\n",
    "    @staticmethod   \n",
    "    def preempt_with_factual(value: torch.Tensor, *,\n",
    "                          antecedents: List[str] = None, event_dim: int = 0):\n",
    "    \n",
    "        if antecedents is None:\n",
    "            antecedents = []\n",
    "\n",
    "        antecedents = [a for a in antecedents if a in indices_of(value, event_dim=event_dim)]\n",
    "\n",
    "        factual_value = gather(value, IndexSet(**{antecedent: {0} for antecedent in antecedents}),\n",
    "                                event_dim=event_dim)\n",
    "            \n",
    "        return scatter({\n",
    "            IndexSet(**{antecedent: {0} for antecedent in antecedents}): factual_value,\n",
    "            IndexSet(**{antecedent: {1} for antecedent in antecedents}): factual_value,\n",
    "        }, event_dim=event_dim)\n",
    "        \n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with pyro.poutine.trace() as trace:\n",
    "            with MultiWorldCounterfactual():\n",
    "                with do(actions=self.antecedents_dict):\n",
    "                    with Preemptions(actions = self.preemptions):\n",
    "                        with pyro.condition(data={k: torch.as_tensor(v) for k, v in self.observations.items()}):\n",
    "                            with pyro.plate(\"plate\", self.sample_size):\n",
    "                                self.consequent = self.model()[self.outcome]\n",
    "                                self.intervened_consequent = gather(self.consequent, IndexSet(**{ant: {1} for ant in self.antecedents}))\n",
    "                                self.observed_consequent = gather(self.consequent, IndexSet(**{ant: {0} for ant in self.antecedents}))\n",
    "                                self.consequent_differs = self.intervened_consequent != self.observed_consequent   \n",
    "                                pyro.factor(\"consequent_differs\", torch.where(self.consequent_differs, torch.tensor(0.0), torch.tensor(-1e8)))\n",
    "                            \n",
    "        self.trace = trace.trace\n",
    "\n",
    "        # slightly hacky solution for odd witness candidate sets\n",
    "        if  isinstance(self.consequent_differs.squeeze().tolist(), bool):\n",
    "            self.existential_but_for = self.consequent_differs.squeeze()\n",
    "        else:\n",
    "            #if (len(self.consequent_differs.squeeze().tolist() )>1):\n",
    "            self.existential_but_for = any(self.consequent_differs.squeeze().tolist()                )  \n",
    "\n",
    "            \n",
    "\n",
    "        witness_dict = dict()\n",
    "        if self.witness_candidates:\n",
    "            witness_keys = [\"__split_\" + candidate for candidate in self.witness_candidates]\n",
    "            witness_dict = {key: self.trace.nodes[key]['value']  for key in witness_keys}\n",
    "            \n",
    "        witness_dict['observed'] = self.observed_consequent.squeeze()\n",
    "        witness_dict['intervened'] = self.intervened_consequent.squeeze()\n",
    "        witness_dict['consequent_differs'] = self.consequent_differs.squeeze()\n",
    "\n",
    "        # slightly hacky as above\n",
    "        self.witness_df = pd.DataFrame(witness_dict) if self.witness_candidates else witness_dict\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_conjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                       u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", torch.logical_and(match_dropped, lightning), event_dim=0).float()\n",
    "\n",
    "    return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n",
    "\n",
    "def ff_disjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                       u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", torch.logical_or(match_dropped, lightning), event_dim=0).float()\n",
    "\n",
    "    return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def factivity_check(model, antecedents_dict, outcome_dict, observations):\n",
    "    \n",
    "    with pyro.condition(data={k: torch.as_tensor(v) for k, v in observations.items()}):\n",
    "        output = model()\n",
    "        factivity_tensors = {k: torch.as_tensor(v) for k, v in list(antecedents_dict.items()) + list(outcome_dict.items())}\n",
    "        return all([factivity_tensors[key] == output[key] for key in factivity_tensors.keys()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_of_minimal_cause(model, antecedents, outcome, nodes, observations, runs_n):\n",
    "\n",
    "    cache = []\n",
    "    minimal_antecedents = []\n",
    "\n",
    "    for step in range(1,runs_n):\n",
    "        if outcome in nodes:\n",
    "            nodes.remove(outcome)\n",
    "\n",
    "        companion_size = random.randint(0,len(nodes))\n",
    "        companion_candidates = random.sample(nodes, companion_size)\n",
    "\n",
    "        if set(companion_candidates) in cache:\n",
    "            continue\n",
    "        \n",
    "        cache.append(set(companion_candidates))\n",
    "\n",
    "        witness_candidates = [node for node in nodes if \n",
    "                                node not in antecedents and \n",
    "                                node != outcome and \n",
    "                                    node not in companion_candidates]\n",
    "        \n",
    "        HPM = HalpernPearlModifiedApproximate(\n",
    "        model = model,\n",
    "        antecedents = companion_candidates,\n",
    "        outcome =  outcome,\n",
    "        witness_candidates = witness_candidates,\n",
    "        observations = observations,\n",
    "        sample_size = 1000)\n",
    "    \n",
    "        HPM()\n",
    "\n",
    "        if  not HPM.existential_but_for:\n",
    "            continue\n",
    "        \n",
    "        subset_is_a_minimal_cause = any([s.issubset(set(HPM.antecedents)) for s in minimal_antecedents])\n",
    "             \n",
    "        if subset_is_a_minimal_cause:\n",
    "            continue\n",
    "        minimal_antecedents.append(set(HPM.antecedents))\n",
    "\n",
    "        \n",
    "        for s in minimal_antecedents:\n",
    "            if set(HPM.antecedents).issubset(s) and s != set(HPM.antecedents):\n",
    "                minimal_antecedents.remove(s)  \n",
    "\n",
    "\n",
    "    return {\"sufficient_cause\": any([set(antecedents).issubset(s) for s in minimal_antecedents]),\n",
    "            \"actual_cause\": set(antecedents) in minimal_antecedents,\n",
    "                \"minimal_antecedents\" : minimal_antecedents, \"cache\": cache}\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sufficient_cause': True,\n",
       " 'actual_cause': False,\n",
       " 'minimal_antecedents': [{'lightning', 'match_dropped'}],\n",
       " 'cache': [set(),\n",
       "  {'lightning', 'match_dropped'},\n",
       "  {'match_dropped'},\n",
       "  {'lightning'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_of_minimal_cause(model = ff_conjunctive, \n",
    "                        antecedents = ['lightning'],\n",
    "                        outcome =  'forest_fire',\n",
    "                        nodes =  ['match_dropped', 'lightning'],\n",
    "                        observations = {\"u_match_dropped\": 1., \"u_lightning\": 1.},\n",
    "                        runs_n = 20)\n",
    "\n",
    "part_of_minimal_cause(model = ff_disjunctive, \n",
    "                        antecedents = ['lightning'],\n",
    "                        outcome =  'forest_fire',\n",
    "                        nodes =  ['match_dropped', 'lightning'],\n",
    "                        observations = {\"u_match_dropped\": 1., \"u_lightning\": 1.},\n",
    "                        runs_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overlap': True, 'overlaps': [{'lightning'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def overlap_with_cause(model, antecedents, outcome, nodes, observations, runs_n = 20):\n",
    "    \n",
    "    minimal_ante = part_of_minimal_cause(model, antecedents, outcome, nodes, observations, runs_n)['minimal_antecedents']\n",
    "    antecedents_set = set(antecedents)\n",
    "    \n",
    "    overlaps = [antecedents_set.intersection(s) for s in minimal_ante if antecedents_set.intersection(s)]\n",
    "    overlap = any(overlaps)\n",
    "    return {\"overlap\": overlap, \"overlaps\": overlaps    }\n",
    "    \n",
    "\n",
    "overlap_with_cause(model = ff_disjunctive, \n",
    "                        antecedents = ['lightning', 'blah'],\n",
    "                        outcome =  'forest_fire',\n",
    "                        nodes =  ['match_dropped', 'lightning'],\n",
    "                        observations = {\"u_match_dropped\": 1., \"u_lightning\": 1.},\n",
    "                        runs_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ensurer': True,\n",
       " 'settings_cache': [[0.0, 1.0], [1.0, 0.0]],\n",
       " 'intervened_consequent': [1.0, 1.0]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ensurer(model, exogenous_variables, antecedents_dict, outcome_dict, runs_n):\n",
    "\n",
    "    settings_cache = []\n",
    "    intervened_consequent = []\n",
    "\n",
    "    outcome = list(outcome_dict.keys())[0]\n",
    "    antecedents = [key for key in antecedents_dict.keys()]\n",
    "\n",
    "    for step in range(1,runs_n):\n",
    "        \n",
    "        random_setting = [random.choice([0., 1.]) for _ in range(len(exogenous_variables))]\n",
    "        if random_setting in settings_cache:\n",
    "            continue\n",
    "        \n",
    "        settings_cache.append(random_setting)\n",
    "\n",
    "        observations = {var: val for var, val in zip(exogenous_variables, random_setting)}\n",
    "\n",
    "        with pyro.condition(data={k: torch.as_tensor(v) for k, v in observations.items()}):\n",
    "                with MultiWorldCounterfactual():\n",
    "                    with do(actions=antecedents_dict):\n",
    "                        intervened_consequent.append(\n",
    "                             gather(model()[outcome], \n",
    "                                    IndexSet(**{ant: {1} for ant in antecedents})).squeeze().item())\n",
    "                        \n",
    "    return {\"ensurer\": all(intervened_consequent),\n",
    "            \"settings_cache\": settings_cache, \n",
    "            \"intervened_consequent\": intervened_consequent}\n",
    "\n",
    "    print(settings_cache)\n",
    "    print(observations)     \n",
    "    print(intervened_consequent)   \n",
    "    print(all(intervened_consequent))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ensurer(model = ff_conjunctive,\n",
    "        exogenous_variables = [\"u_match_dropped\", \"u_lightning\"],\n",
    "        antecedents_dict = {\"match_dropped\": 1., \"lightning\": 1.},\n",
    "        outcome_dict = {\"forest_fire\": 1.},\n",
    "                        runs_n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sufficient_cause(model, exogenous_variables, antecedents_dict, outcome_dict, nodes, observations, runs_n):\n",
    "\n",
    "    factivity = factivity_check(model = model,\n",
    "                antecedents_dict = antecedents_dict,\n",
    "                outcome_dict = outcome_dict, \n",
    "                observations = observations)\n",
    "    \n",
    "    if not factivity:\n",
    "        return {\"sufficient_cause\": False, \"failure_reason\": {\"factivity\": False}}   \n",
    "\n",
    "    \n",
    "    ensure = ensurer(model = model,\n",
    "        exogenous_variables = exogenous_variables,\n",
    "        antecedents_dict = antecedents_dict,\n",
    "        outcome_dict = outcome_dict,\n",
    "        runs_n = runs_n)['ensurer']\n",
    "    \n",
    "    if not ensure:\n",
    "        return {\"sufficient_cause\": False, \"failure_reason\": {\"ensure\": False}}\n",
    "    \n",
    "    overlap = overlap_with_cause(model = model,\n",
    "                        antecedents = [key for key in antecedents_dict.keys()],\n",
    "                        outcome =  list(outcome_dict.keys())[0],\n",
    "                        nodes =  nodes,\n",
    "                        observations = observations,\n",
    "                        runs_n= runs_n)\n",
    "    \n",
    "    if not overlap['overlap']:\n",
    "        return {\"sufficient_cause\": False, \"failure_reason\": {\"overlap\": False}}\n",
    "\n",
    "\n",
    "    # minimality check starts here\n",
    "    antecedents = [key for key in antecedents_dict.keys()]\n",
    "    subsets = [[]]\n",
    "    for node in antecedents:\n",
    "        subsets.extend([subset + [node] for subset in subsets])\n",
    "    subsets.pop()\n",
    "\n",
    "    \n",
    "    for subset in subsets:\n",
    "    \n",
    "        subset_ensure = ensurer(model = model,\n",
    "            exogenous_variables = exogenous_variables,\n",
    "            antecedents_dict = {key: antecedents_dict[key] for key in subset},\n",
    "            outcome_dict = outcome_dict,\n",
    "            runs_n = runs_n)['ensurer']    \n",
    "    \n",
    "        if not subset_ensure:\n",
    "            continue\n",
    "\n",
    "        subset_overlap = overlap_with_cause(model = model,\n",
    "                    antecedents = subset,\n",
    "                    outcome =  list(outcome_dict.keys())[0],\n",
    "                    nodes =  nodes,\n",
    "                    observations = observations,\n",
    "                    runs_n= runs_n)['overlap']\n",
    "\n",
    "        if subset_ensure and subset_overlap:\n",
    "            \n",
    "            return {\"sufficient_cause\": False, \"failure_reason\": {\"minimality\": False, \"subset\": subset}}\n",
    "      # minimality check ends here \n",
    "\n",
    "    return {\"sufficient_cause\": True, \"failure_reason\": None}\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sufficient_cause': False,\n",
       " 'failure_reason': {'minimality': False, 'subset': ['match_dropped']}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        \n",
    "sufficient_cause(model = ff_disjunctive,\n",
    "                 exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "                    antecedents_dict = {\"match_dropped\": 1., \"lightning\": 1.},\n",
    "                    outcome_dict = {\"forest_fire\": 1.},\n",
    "                    nodes = [\"match_dropped\", \"lightning\"],\n",
    "                    observations= {\"u_match_dropped\": 1., \"u_lightning\": 1.},\n",
    "                    runs_n = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sufficient_cause': True, 'failure_reason': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sufficient_cause(model = ff_conjunctive,\n",
    "                 exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "                    antecedents_dict = {\"match_dropped\": 1., \"lightning\": 1.},\n",
    "                    outcome_dict = {\"forest_fire\": 1.},\n",
    "                    nodes = [\"match_dropped\", \"lightning\"],\n",
    "                    observations= {\"u_match_dropped\": 1., \"u_lightning\": 1.},\n",
    "                    runs_n = 20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'factive_settings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb Cell 12\u001b[0m in \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m             failure_reasons\u001b[39m.\u001b[39mappend(sc[\u001b[39m'\u001b[39m\u001b[39mfailure_reason\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mfactive_settings\u001b[39m\u001b[39m\"\u001b[39m: settings_cache, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39msufficient_causality_status\u001b[39m\u001b[39m\"\u001b[39m: sufficient_causality_status,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfailure_reasons\u001b[39m\u001b[39m\"\u001b[39m: failure_reasons,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39msettings_cache\u001b[39m\u001b[39m\"\u001b[39m: settings_cache}        \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m explanation(model \u001b[39m=\u001b[39;49m ff_conjunctive,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m             exogenous_variables\u001b[39m=\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39mu_match_dropped\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mu_lightning\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m             antecedents_dict \u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39mmatch_dropped\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1.\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mlightning\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1.\u001b[39;49m},\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m             outcome_dict \u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39mforest_fire\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m1.\u001b[39;49m},\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m             nodes\u001b[39m=\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39mmatch_dropped\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mlightning\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m             excluded_settings\u001b[39m=\u001b[39;49m [[\u001b[39m0.\u001b[39;49m, \u001b[39m0.\u001b[39;49m]],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m             runs_n \u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m)\n",
      "\u001b[1;32m/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb Cell 12\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m             \u001b[39mprint\u001b[39m(realized)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m             possibility \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m             factive_settings\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mblah\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m             sc \u001b[39m=\u001b[39m sufficient_cause(model \u001b[39m=\u001b[39m model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m                                   exogenous_variables\u001b[39m=\u001b[39m exogenous_variables,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m                                     antecedents_dict \u001b[39m=\u001b[39m antecedents_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m                                     observations\u001b[39m=\u001b[39m observations,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m                                     runs_n \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m#            print(observations)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rafal/UGPOP/projectsUGPOP/causal_pyro/docs/source/ru-explanation.ipynb#X24sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m  \u001b[39m#           print(sc)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'factive_settings' is not defined"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(0)\n",
    "\n",
    "def explanation(model, exogenous_variables, antecedents_dict, outcome_dict, nodes, excluded_settings, runs_n):\n",
    "\n",
    "    settings_cache = []\n",
    "    \n",
    "    sufficient_causality_status = []\n",
    "    failure_reasons = []\n",
    "\n",
    "    possibility = False\n",
    "    nontriviality = False\n",
    "\n",
    "    outcome = list(outcome_dict.keys())[0]\n",
    "    if outcome in nodes:\n",
    "        nodes.remove(outcome)\n",
    "\n",
    "\n",
    "    for step in range(1,runs_n):\n",
    "        random_setting = [random.choice([0., 1.]) for _ in range(len(exogenous_variables))]\n",
    "\n",
    "\n",
    "        if random_setting in settings_cache or random_setting in excluded_settings:\n",
    "            continue\n",
    "\n",
    "        settings_cache.append(random_setting)\n",
    "\n",
    "        observations = {var: val for var, val in zip(exogenous_variables, random_setting)}\n",
    "\n",
    "         \n",
    "        realized = factivity_check(model, antecedents_dict, outcome_dict, observations)\n",
    "\n",
    "        if not factivity_check(model, antecedents_dict, {}, observations):\n",
    "            nontriviality = True\n",
    "\n",
    "        if realized:\n",
    "            print(realized)\n",
    "            possibility = True\n",
    "\n",
    "            factive_settings.append(\"blah\")\n",
    "\n",
    "\n",
    "            sc = sufficient_cause(model = model,\n",
    "                                  exogenous_variables= exogenous_variables,\n",
    "                                    antecedents_dict = antecedents_dict,\n",
    "                                    outcome_dict = outcome_dict,\n",
    "                                    nodes = nodes,\n",
    "                                    observations= observations,\n",
    "                                    runs_n = 20)\n",
    "            \n",
    "#            print(observations)\n",
    " #           print(sc)\n",
    "\n",
    "            sufficient_causality_status.append(sc['sufficient_cause'])\n",
    "            failure_reasons.append(sc['failure_reason'])\n",
    "\n",
    "\n",
    "    return {\"factive_settings\": settings_cache, \n",
    "            \"sufficient_causality_status\": sufficient_causality_status,\n",
    "            \"failure_reasons\": failure_reasons,\n",
    "            \"settings_cache\": settings_cache}        \n",
    "        \n",
    "\n",
    "\n",
    "explanation(model = ff_conjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"match_dropped\": 1., \"lightning\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\", \"lightning\"],\n",
    "            excluded_settings= [[0., 0.]],\n",
    "            runs_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u_match_dropped': 1.0, 'u_lightning': 1.0}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "settings_cache = []\n",
    "HPMs = []\n",
    "minimal_antecedents_cache = []\n",
    "\n",
    "model = ff_disjunctive\n",
    "exogenous_variables = [\"u_match_dropped\", \"u_lightning\"]\n",
    "antecedents_dict = {\"match_dropped\": 1., \"lightning\": 1.}\n",
    "outcome_dict = {\"forest_fire\": 1.}\n",
    "nodes = [\"match_dropped\", \"lightning\"]\n",
    "witness_candidates = []\n",
    "\n",
    "\n",
    "\n",
    "antecedents = [key for key in antecedents_dict.keys()]\n",
    "outcome = list(outcome_dict.keys())[0]\n",
    "if outcome in nodes:\n",
    "    nodes.remove(outcome)\n",
    "\n",
    "\n",
    "pyro.set_rng_seed(0)\n",
    "random_setting = [random.choice([0., 1.]) for _ in range(len(exogenous_variables))]\n",
    "\n",
    "#if random_setting in settings_cache:\n",
    "#    continue\n",
    "\n",
    "settings_cache.append(random_setting)\n",
    "\n",
    "observations = {var: val for var, val in zip(exogenous_variables, random_setting)}\n",
    "\n",
    "print(observations)\n",
    "\n",
    "factivity = factivity_check(model = model,\n",
    "                antecedents_dict = antecedents_dict,\n",
    "                outcome_dict = outcome_dict, \n",
    "                observations = observations)\n",
    "\n",
    "\n",
    "print(factivity)\n",
    "#if not factivity:\n",
    "#    continue\n",
    "\n",
    "part_of_minimal = part_of_minimal_cause(model = model,\n",
    "                        antecedents = antecedents,\n",
    "                        outcome =  outcome,\n",
    "                        nodes = nodes,\n",
    "                        observations = observations,\n",
    "                        runs_n = 20)['sufficient_cause']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#factivity check to avoid needles computation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_pyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
