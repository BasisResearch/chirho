{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation and actual causality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preceding notebooks**\n",
    "\n",
    "- [Actual Causality: the modified Halpern-Pearl definition]() TODO add link\n",
    "\n",
    "- [Responsibility and actual causality]() TODO add link\n",
    "\n",
    "- [Blame and actual causality]() TODO add link\n",
    "\n",
    "**Summary**\n",
    "\n",
    "Following *Actual Causality* (J. Halpern, MIT Press, 2016), we use the Halpern-Pearl modified definition of actual causality to explicate the notion of an explanation (discussed in ch. 7 of the book).\n",
    "We will re-use our implementation of actual causality, discussed in a previous notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "[Intuitions](##intuitions)\n",
    "    \n",
    "[Formalization](#formalization)\n",
    "\n",
    "[Implementation](#implementation)\n",
    "\n",
    "[Examples](#examples)\n",
    "\n",
    "- [Comments on example selection](#comments-on-example-selection)\n",
    "  \n",
    "- [Forest fire](#forest-fire)\n",
    "\n",
    "- [Extended forest fire](#extended-forest-fire)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuitions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this approach, an explanation is a fact that, if found to be true, would constitute, roughly speaking, an actual cause of the fact to be explained. Moreover, as agents may have different epistemic states, explanations are agent-relative, telling the agents something that they don't already know."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent starts with some uncertainty, represented as a set $K$ of causal settings not excluded by what they know (for the sake of simplicity, we consider only causal settings differing in the values of the exogenous variables in the examples).  Relative to $K$, $\\vec{X} = \\vec{x}$ is an explanation of $\\varphi$ iff the following hold:\n",
    "\n",
    "1. $\\vec{X} = \\vec{x}$ is a sufficient cause of $\\varphi$ in all contexts in $K$ that satisfy $\\vec{X} = \\vec{x} \\wedge \\varphi$. That is:\n",
    "\n",
    "    A. For any $\\langle M, \\vec{u}\\rangle \\in K$, if $\\langle M, \\vec{u}\\rangle \\models \\vec{X} = \\vec{x} \\wedge \\varphi$, then there exists a conjunct $X=x$ of $\\vec{X} = \\vec{x}$ and a possibly empty conjunction $\\vec{Y}= \\vec{y}$ such that $X=x \\wedge \\vec{Y} = \\vec{y}$ is a cause of $\\varphi$ in $\\langle M, \\vec{u}\\rangle$.\n",
    "\n",
    "    B. $\\langle M, \\vec{u}\\rangle\\models[\\vec{X} = \\vec{x}]\\varphi$ for any $\\langle M, \\vec{u}\\rangle \\in K$.\n",
    "\n",
    "2. $\\vec{X}$ is a minimal set satisfying 1. \n",
    "\n",
    "3. $\\vec{X} = \\vec{x} \\wedge \\varphi$ hold in at least one member of $K$.\n",
    "\n",
    "Moreover, an explanation is **non-trivial** just in case $\\vec{X} = \\vec{x}$ fails in at least one member of $K$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we re-use the actual causality implementation discussed in another notebook. TODO add link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from typing import Dict, List, Optional,  Union, Callable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "from causal_pyro.indexed.ops import IndexSet, gather, indices_of, scatter\n",
    "from causal_pyro.interventional.handlers import do\n",
    "from causal_pyro.counterfactual.handlers import MultiWorldCounterfactual, Preemptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HalpernPearlModifiedApproximate:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: Callable,\n",
    "        antecedents: Union[Dict[str, torch.Tensor], List[str]],\n",
    "        outcome: str,\n",
    "        witness_candidates: List[str],\n",
    "        observations: Optional[Dict[str, torch.Tensor]],\n",
    "        sample_size: int = 100,\n",
    "        event_dim: int = 0\n",
    "        ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.antecedents = antecedents\n",
    "        self.outcome = outcome\n",
    "        self.witness_candidates = witness_candidates\n",
    "        self.observations = observations\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "        self.antecedents_dict = (\n",
    "            self.antecedents if isinstance(self.antecedents, dict)\n",
    "            else self.revert_antecedents(self.antecedents)\n",
    "        )\n",
    "    \n",
    "        self.preemptions = {candidate: functools.partial(self.preempt_with_factual,\n",
    "                                             antecedents = self.antecedents) for \n",
    "                                             candidate in self.witness_candidates}\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def revert_antecedents(antecedents: List[str]) -> Dict[str, Callable[[torch.Tensor], torch.Tensor]]:\n",
    "        return {antecedent: (lambda v: 1 - v) for antecedent in antecedents}\n",
    "\n",
    "    @staticmethod   \n",
    "    def preempt_with_factual(value: torch.Tensor, *,\n",
    "                          antecedents: List[str] = None, event_dim: int = 0):\n",
    "    \n",
    "        if antecedents is None:\n",
    "            antecedents = []\n",
    "\n",
    "        antecedents = [a for a in antecedents if a in indices_of(value, event_dim=event_dim)]\n",
    "\n",
    "        factual_value = gather(value, IndexSet(**{antecedent: {0} for antecedent in antecedents}),\n",
    "                                event_dim=event_dim)\n",
    "            \n",
    "        return scatter({\n",
    "            IndexSet(**{antecedent: {0} for antecedent in antecedents}): factual_value,\n",
    "            IndexSet(**{antecedent: {1} for antecedent in antecedents}): factual_value,\n",
    "        }, event_dim=event_dim)\n",
    "        \n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with pyro.poutine.trace() as trace:\n",
    "            with MultiWorldCounterfactual():\n",
    "                with do(actions=self.antecedents_dict):\n",
    "                    with Preemptions(actions = self.preemptions):\n",
    "                        with pyro.condition(data={k: torch.as_tensor(v) for k, v in self.observations.items()}):\n",
    "                            with pyro.plate(\"plate\", self.sample_size):\n",
    "                                self.consequent = self.model()[self.outcome]\n",
    "                                self.intervened_consequent = gather(self.consequent, IndexSet(**{ant: {1} for ant in self.antecedents}))\n",
    "                                self.observed_consequent = gather(self.consequent, IndexSet(**{ant: {0} for ant in self.antecedents}))\n",
    "                                self.consequent_differs = self.intervened_consequent != self.observed_consequent   \n",
    "                                pyro.factor(\"consequent_differs\", torch.where(self.consequent_differs, torch.tensor(0.0), torch.tensor(-1e8)))\n",
    "                            \n",
    "        self.trace = trace.trace\n",
    "\n",
    "        # slightly hacky solution for odd witness candidate sets\n",
    "        if  isinstance(self.consequent_differs.squeeze().tolist(), bool):\n",
    "            self.existential_but_for = self.consequent_differs.squeeze()\n",
    "        else:\n",
    "            #if (len(self.consequent_differs.squeeze().tolist() )>1):\n",
    "            self.existential_but_for = any(self.consequent_differs.squeeze().tolist()                )  \n",
    "\n",
    "            \n",
    "\n",
    "        witness_dict = dict()\n",
    "        if self.witness_candidates:\n",
    "            witness_keys = [\"__split_\" + candidate for candidate in self.witness_candidates]\n",
    "            witness_dict = {key: self.trace.nodes[key]['value']  for key in witness_keys}\n",
    "            \n",
    "        witness_dict['observed'] = self.observed_consequent.squeeze()\n",
    "        witness_dict['intervened'] = self.intervened_consequent.squeeze()\n",
    "        witness_dict['consequent_differs'] = self.consequent_differs.squeeze()\n",
    "\n",
    "        # slightly hacky as above\n",
    "        self.witness_df = pd.DataFrame(witness_dict) if self.witness_candidates else witness_dict\n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for explanation. All the existential conditions present in the definition get us involved in sampling-based approximate searches for witnesses for existential claims. As there are a few clauses, we divide the labor.`factivity_check` will be used to test if a formula holds in a model. `part_of_minimal_cause` checks if a dictionary represents a conjunct in a minimal actual cause. `overlap_with_cause` deals with the conjunction business present in the definition. `ensurer` will test for condition 1B from the definition. `sufficient_cause` puts this together to test condition 1 of the definition. `explanation_check` puts these together paying attention to minimality requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HalpernPearlExplanationApproximate:\n",
    "\n",
    "        def __init__(\n",
    "            self,\n",
    "            model: Callable,\n",
    "            exogenous_variables: List[str],\n",
    "            antecedents_dict: Dict[str, torch.Tensor],\n",
    "            outcome_dict: Dict[str, torch.Tensor],\n",
    "            nodes: List[str],\n",
    "            excluded_settings: List[List[int]],\n",
    "            runs_n: int = 100,\n",
    "        ):\n",
    "\n",
    "                self.model = model\n",
    "                self.exogenous_variables = exogenous_variables\n",
    "                self.antecedents_dict = antecedents_dict\n",
    "                self.outcome_dict = outcome_dict\n",
    "                self.nodes = nodes\n",
    "                self.excluded_settings = excluded_settings\n",
    "                self.runs_n = runs_n\n",
    "\n",
    "        def factivity_check(self, model: Callable,\n",
    "                             antecedents_dict: Dict[str, torch.Tensor],\n",
    "                             outcome_dict: Dict[str, torch.Tensor],\n",
    "                             observations: Dict[str, torch.Tensor]):\n",
    "\n",
    "                with pyro.condition(data={k: torch.as_tensor(v) for k, v in observations.items()}):\n",
    "                        output = model()\n",
    "                        factivity_tensors = {k: torch.as_tensor(v) for k, v in list(antecedents_dict.items()) + list(outcome_dict.items())}\n",
    "                        return all([factivity_tensors[key] == output[key] for key in factivity_tensors.keys()])\n",
    "\n",
    "\n",
    "        def part_of_minimal_cause(self,\n",
    "                                model: Callable,\n",
    "                                antecedents: List[str],\n",
    "                                outcome: str, \n",
    "                                nodes: List[str],\n",
    "                                observations: Dict[str, torch.Tensor],\n",
    "                                runs_n: int):\n",
    "\n",
    "                cache = []\n",
    "                minimal_antecedents = []\n",
    "\n",
    "                for _ in range(1,runs_n):\n",
    "                        if outcome in nodes:\n",
    "                                nodes.remove(outcome)\n",
    "\n",
    "                        companion_size = random.randint(0,len(nodes))\n",
    "                        companion_candidates = random.sample(nodes, companion_size)\n",
    "\n",
    "                        if set(companion_candidates) in cache:\n",
    "                                continue\n",
    "                \n",
    "                        cache.append(set(companion_candidates))\n",
    "\n",
    "                        witness_candidates = [node for node in nodes if \n",
    "                                        node not in antecedents and \n",
    "                                        node != outcome and \n",
    "                                        node not in companion_candidates]\n",
    "                \n",
    "                        HPM = HalpernPearlModifiedApproximate(\n",
    "                                model = model,\n",
    "                                antecedents = companion_candidates,\n",
    "                                outcome =  outcome,\n",
    "                                witness_candidates = witness_candidates,\n",
    "                                observations = observations,\n",
    "                                sample_size = 1000)\n",
    "                        \n",
    "                        HPM()\n",
    "\n",
    "                        if  not HPM.existential_but_for:\n",
    "                                continue\n",
    "                \n",
    "                        subset_is_a_minimal_cause = any([s.issubset(set(HPM.antecedents)) for s in minimal_antecedents])\n",
    "                \n",
    "                        if subset_is_a_minimal_cause:\n",
    "                                continue\n",
    "                        minimal_antecedents.append(set(HPM.antecedents))\n",
    "\n",
    "                        for s in minimal_antecedents:\n",
    "                                if set(HPM.antecedents).issubset(s) and s != set(HPM.antecedents):\n",
    "                                        minimal_antecedents.remove(s)  \n",
    "\n",
    "\n",
    "                return {\"sufficient_cause\": any([set(antecedents).issubset(s) for s in minimal_antecedents]),\n",
    "                        \"actual_cause\": set(antecedents) in minimal_antecedents,\n",
    "                        \"minimal_antecedents\" : minimal_antecedents, \"cache\": cache}\n",
    "\n",
    "        \n",
    "        def overlap_with_cause(self, model: Callable,\n",
    "                                antecedents: List[str],\n",
    "                                outcome: List[str],\n",
    "                                nodes: List[str],\n",
    "                                observations: Dict[str, torch.Tensor],\n",
    "                                runs_n: int = 20):\n",
    "    \n",
    "                minimal_ante = self.part_of_minimal_cause(model, antecedents, outcome, nodes, \n",
    "                                                                  observations, runs_n)['minimal_antecedents']\n",
    "                antecedents_set = set(antecedents)\n",
    "    \n",
    "                overlaps = [antecedents_set.intersection(s) for s in minimal_ante if antecedents_set.intersection(s)]\n",
    "                overlap = any(overlaps)\n",
    "                return {\"overlap\": overlap, \"overlaps\": overlaps    }\n",
    "\n",
    "\n",
    "        def ensurer(self, model: Callable,\n",
    "                exogenous_variables: List[str],\n",
    "                antecedents_dict: Dict[str, torch.Tensor],\n",
    "                outcome_dict: Dict[str, torch.Tensor], \n",
    "                runs_n: int):\n",
    "\n",
    "                settings_cache = []\n",
    "                intervened_consequent = []\n",
    "\n",
    "                outcome = list(outcome_dict.keys())[0]\n",
    "                antecedents = [key for key in antecedents_dict.keys()]\n",
    "\n",
    "                for step in range(1,runs_n):\n",
    "                        \n",
    "                        random_setting = [random.choice([0., 1.]) for _ in range(len(exogenous_variables))]\n",
    "                        \n",
    "                        if random_setting in settings_cache:\n",
    "                                continue\n",
    "                        \n",
    "                        settings_cache.append(random_setting)\n",
    "\n",
    "                        observations = {var: val for var, val in zip(exogenous_variables, random_setting)}\n",
    "\n",
    "                        with pyro.condition(data={k: torch.as_tensor(v) for k, v in observations.items()}):\n",
    "                                with MultiWorldCounterfactual():\n",
    "                                        with do(actions=antecedents_dict):\n",
    "                                                intervened_consequent.append(\n",
    "                                                gather(model()[outcome], \n",
    "                                                        IndexSet(**{ant: {1} for ant in antecedents})).squeeze().item())\n",
    "                                        \n",
    "                return {\"ensurer\": all(intervened_consequent),\n",
    "                        \"settings_cache\": settings_cache, \n",
    "                        \"intervened_consequent\": intervened_consequent}\n",
    "        \n",
    "\n",
    "        \n",
    "        def sufficient_cause(self, model, exogenous_variables, antecedents_dict, outcome_dict, nodes, observations, runs_n):\n",
    "\n",
    "                factivity = self.factivity_check(model = model,\n",
    "                                antecedents_dict = antecedents_dict,\n",
    "                                outcome_dict = outcome_dict, \n",
    "                                observations = observations)\n",
    "                \n",
    "                if not factivity:\n",
    "                        return {\"sufficient_cause\": False, \"failure_reason\": {\"factivity\": False}}   \n",
    "\n",
    "                \n",
    "                ensure = self.ensurer(model = model,\n",
    "                        exogenous_variables = exogenous_variables,\n",
    "                        antecedents_dict = antecedents_dict,\n",
    "                        outcome_dict = outcome_dict,\n",
    "                        runs_n = runs_n)['ensurer']\n",
    "                \n",
    "                if not ensure:\n",
    "                        return {\"sufficient_cause\": False, \"failure_reason\": {\"ensure\": False}}\n",
    "                \n",
    "                overlap = self.overlap_with_cause(model = model,\n",
    "                                        antecedents = [key for key in antecedents_dict.keys()],\n",
    "                                        outcome =  list(outcome_dict.keys())[0],\n",
    "                                        nodes =  nodes,\n",
    "                                        observations = observations,\n",
    "                                        runs_n= runs_n)\n",
    "                \n",
    "                if not overlap['overlap']:\n",
    "                        return {\"sufficient_cause\": False, \"failure_reason\": {\"overlap\": False}}\n",
    "\n",
    "\n",
    "                # minimality check starts here\n",
    "                antecedents = [key for key in antecedents_dict.keys()]\n",
    "                subsets = [[]]\n",
    "                for node in antecedents:\n",
    "                        subsets.extend([subset + [node] for subset in subsets])\n",
    "                subsets.pop()\n",
    "\n",
    "                \n",
    "                for subset in subsets:\n",
    "                \n",
    "                        subset_ensure = self.ensurer(model = model,\n",
    "                        exogenous_variables = exogenous_variables,\n",
    "                        antecedents_dict = {key: antecedents_dict[key] for key in subset},\n",
    "                        outcome_dict = outcome_dict,\n",
    "                        runs_n = runs_n)['ensurer']    \n",
    "                \n",
    "                        if not subset_ensure:\n",
    "                                continue\n",
    "\n",
    "                        subset_overlap = self.overlap_with_cause(model = model,\n",
    "                                antecedents = subset,\n",
    "                                outcome =  list(outcome_dict.keys())[0],\n",
    "                                nodes =  nodes,\n",
    "                                observations = observations,\n",
    "                                runs_n= runs_n)['overlap']\n",
    "\n",
    "                        if subset_ensure and subset_overlap:\n",
    "                        \n",
    "                                return {\"sufficient_cause\": False, \"failure_reason\": {\"minimality\": False, \"subset\": subset}}\n",
    "                # minimality check ends here \n",
    "\n",
    "                return {\"sufficient_cause\": True, \"failure_reason\": None}\n",
    "\n",
    "        def explanation_check(self, model, exogenous_variables, antecedents_dict, outcome_dict, nodes, excluded_settings, runs_n):\n",
    "\n",
    "                settings_cache = []\n",
    "                factive_settings = []\n",
    "                sufficient_causality_status = []\n",
    "                failure_reasons = []\n",
    "                possibility = False\n",
    "                nontriviality = False\n",
    "\n",
    "                outcome = list(outcome_dict.keys())[0]\n",
    "                if outcome in nodes:\n",
    "                        nodes.remove(outcome)\n",
    "\n",
    "                for step in range(1,runs_n):\n",
    "                        random_setting = [random.choice([0., 1.]) for _ in range(len(exogenous_variables))]\n",
    "\n",
    "                        if random_setting in settings_cache or random_setting in excluded_settings:\n",
    "                                continue\n",
    "\n",
    "                        settings_cache.append(random_setting)\n",
    "                        observations = {var: val for var, val in zip(exogenous_variables, random_setting)}\n",
    "\n",
    "         \n",
    "                        consequent_satisfied = self.factivity_check(model, {}, outcome_dict, observations)\n",
    "\n",
    "                        if not consequent_satisfied:\n",
    "                                continue\n",
    "                \n",
    "                        antecedent_satisfied = self.factivity_check(model, antecedents_dict, {}, observations)\n",
    "            \n",
    "                        if not antecedent_satisfied:\n",
    "                                nontriviality = True\n",
    "\n",
    "                        else:\n",
    "            \n",
    "                                possibility = True\n",
    "                                factive_settings.append(random_setting)\n",
    "\n",
    "                                sc = self.sufficient_cause(model = model,\n",
    "                                                        exogenous_variables= exogenous_variables,\n",
    "                                                        antecedents_dict = antecedents_dict,\n",
    "                                                        outcome_dict = outcome_dict,\n",
    "                                                        nodes = nodes,\n",
    "                                                        observations= observations,\n",
    "                                                        runs_n = 20)\n",
    "                                \n",
    "                                sufficient_causality_status.append(sc['sufficient_cause'])\n",
    "                                failure_reasons.append(sc['failure_reason'])\n",
    "\n",
    "                        if factive_settings:\n",
    "                                explanation =  all(sufficient_causality_status)\n",
    "                        else:\n",
    "                                explanation = False\n",
    "\n",
    "                return {\"explanation\": explanation,\n",
    "                        \"factive_settings\": factive_settings,\n",
    "                        \"sufficient_causality_status\": sufficient_causality_status,\n",
    "                        \"failure_reasons\": failure_reasons,\n",
    "                        \"possibility\": possibility,\n",
    "                        \"nontriviality\": nontriviality,\n",
    "                        \"settings_cache\": settings_cache}   \n",
    "\n",
    "\n",
    "        def __call__(self, *args, **kwargs):\n",
    "\n",
    "                self.explanation = self.explanation_check(\n",
    "                        model = self.model,\n",
    "                        exogenous_variables = self.exogenous_variables,\n",
    "                        antecedents_dict = self.antecedents_dict,\n",
    "                        outcome_dict = self.outcome_dict,\n",
    "                        nodes = self.nodes,\n",
    "                        excluded_settings= self.excluded_settings,\n",
    "                        runs_n = self.runs_n)\n",
    "                \n",
    "                return self.model(*args, **kwargs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on example selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **forest fire:** one of the running examples in the book: we choose it, as it is the simplest model rich enough to illustrate a few interesting properties of explanation\n",
    "\n",
    "- **extended forest fire:** the most complicated example discussed in the book, we use it to illustrate how the implementation handles the list and evaluation of potential explanations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest fire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been using this example in previous notebooks. In this simplified model, a forest fire was caused by lightning or an arsonist, so we use three endogenous variables, and two exogenous variables corresponding to the two factors. In the conjunctive model, both factors have to be present for the fire to start. In the disjunctive model, each of them alone is sufficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_conjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                       u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", torch.logical_and(match_dropped, lightning), event_dim=0).float()\n",
    "\n",
    "    return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n",
    "\n",
    "def ff_disjunctive():\n",
    "    u_match_dropped = pyro.sample(\"u_match_dropped\", dist.Bernoulli(0.5))\n",
    "    u_lightning = pyro.sample(\"u_lightning\", dist.Bernoulli(0.5))\n",
    "\n",
    "    match_dropped = pyro.deterministic(\"match_dropped\",\n",
    "                                       u_match_dropped, event_dim=0)\n",
    "    lightning = pyro.deterministic(\"lightning\", u_lightning, event_dim=0)\n",
    "    forest_fire = pyro.deterministic(\"forest_fire\", torch.logical_or(match_dropped, lightning), event_dim=0).float()\n",
    "\n",
    "    return {\"match_dropped\": match_dropped, \"lightning\": lightning,\n",
    "            \"forest_fire\": forest_fire}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': True,\n",
       " 'factive_settings': [[1.0, 1.0]],\n",
       " 'sufficient_causality_status': [True],\n",
       " 'failure_reasons': [None],\n",
       " 'possibility': True,\n",
       " 'nontriviality': False,\n",
       " 'settings_cache': [[0.0, 1.0], [1.0, 1.0], [0.0, 0.0], [1.0, 0.0]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 7.1.2. from the book\n",
    "\n",
    "# all contexts available, no settings excluded by what \n",
    "# the agent knows about the world\n",
    "# in the conjunctive model, the joint nodes are an explanation of forest fire\n",
    "\n",
    "conjunctiveHPE = HalpernPearlExplanationApproximate(model = ff_conjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"match_dropped\": 1., \"lightning\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\", \"lightning\"],\n",
    "            excluded_settings= [],\n",
    "            runs_n = 20)\n",
    "\n",
    "conjunctiveHPE()\n",
    "\n",
    "conjunctiveHPE.explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': False,\n",
       " 'factive_settings': [[1.0, 1.0]],\n",
       " 'sufficient_causality_status': [False],\n",
       " 'failure_reasons': [{'ensure': False}],\n",
       " 'possibility': True,\n",
       " 'nontriviality': False,\n",
       " 'settings_cache': [[0.0, 1.0], [1.0, 0.0], [0.0, 0.0], [1.0, 1.0]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But none individually is (see e.g. match_dropped)\n",
    "\n",
    "conjunctive_split_HPE = HalpernPearlExplanationApproximate(model = ff_conjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"match_dropped\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\", \"lightning\"],\n",
    "            excluded_settings= [],\n",
    "            runs_n = 20)\n",
    "\n",
    "conjunctive_split_HPE()\n",
    "\n",
    "conjunctive_split_HPE.explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': False,\n",
       " 'factive_settings': [[1.0, 1.0]],\n",
       " 'sufficient_causality_status': [False],\n",
       " 'failure_reasons': [{'minimality': False, 'subset': ['match_dropped']}],\n",
       " 'possibility': True,\n",
       " 'nontriviality': True,\n",
       " 'settings_cache': [[0.0, 1.0], [1.0, 0.0], [1.0, 1.0], [0.0, 0.0]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The situation is the opposite for the disjunctive model\n",
    "# the joint nodes are not an explanation of ff\n",
    "# each of the invidual nodes is an explanation of ff\n",
    "\n",
    "disjunctiveHPE = HalpernPearlExplanationApproximate(model = ff_disjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"match_dropped\": 1., \"lightning\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\", \"lightning\"],\n",
    "            excluded_settings= [],\n",
    "            runs_n = 20)\n",
    "\n",
    "disjunctiveHPE()\n",
    "\n",
    "disjunctiveHPE.explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': True,\n",
       " 'factive_settings': [[1.0, 0.0], [1.0, 1.0]],\n",
       " 'sufficient_causality_status': [True, True],\n",
       " 'failure_reasons': [None, None],\n",
       " 'possibility': True,\n",
       " 'nontriviality': True,\n",
       " 'settings_cache': [[0.0, 1.0], [1.0, 0.0], [0.0, 0.0], [1.0, 1.0]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disjunctive_split_HPE = HalpernPearlExplanationApproximate(model = ff_disjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"match_dropped\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\", \"lightning\"],\n",
    "            excluded_settings= [],\n",
    "            runs_n = 20)\n",
    "\n",
    "disjunctive_split_HPE()\n",
    "\n",
    "disjunctive_split_HPE.explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': False,\n",
       " 'factive_settings': [[0.0, 1.0], [1.0, 1.0]],\n",
       " 'sufficient_causality_status': [False, False],\n",
       " 'failure_reasons': [{'overlap': False}, {'overlap': False}],\n",
       " 'possibility': True,\n",
       " 'nontriviality': False,\n",
       " 'settings_cache': [[0.0, 1.0], [1.0, 1.0], [0.0, 0.0]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in a setting where we exclude  match and no lightning\n",
    "# triviality ensues, as expected\n",
    "\n",
    "disjunctive_excluded_HPE = HalpernPearlExplanationApproximate(model = ff_disjunctive,\n",
    "            exogenous_variables= [\"u_match_dropped\", \"u_lightning\"],\n",
    "            antecedents_dict = {\"lightning\": 1.},\n",
    "            outcome_dict = {\"forest_fire\": 1.},\n",
    "            nodes= [\"match_dropped\"],\n",
    "            excluded_settings= [[1.0, 0.0]],\n",
    "            runs_n = 20)\n",
    "\n",
    "disjunctive_excluded_HPE()\n",
    "\n",
    "disjunctive_excluded_HPE.explanation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended forest fire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In April, given the electrical storm in May, the forest would have caught fire in May (and not in June). However, given the storm, if there had been an electrical storm only in May, the forest\n",
    "would not have caught fire at all; if there had been an electrical storm only in June, it would have caught fire in June. The model has five endogenous variables: `ar` for *April rains*, \n",
    "`esm` for *electric storms in May*, `esj` for *electric storms in June*, `ffm` for *forest fire in May*, `ffj` for *forest fire in June* and `ff` for *forest fire either in May or in June (or both)*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff_extended():\n",
    "    u_ar = pyro.sample(\"u_ar\", dist.Bernoulli(0.5))\n",
    "    u_esm = pyro.sample(\"u_esm\", dist.Bernoulli(0.5))\n",
    "    u_esj = pyro.sample(\"u_esj\", dist.Bernoulli(0.5))\n",
    "\n",
    "    ar = pyro.deterministic(\"ar\", u_ar, event_dim=0)\n",
    "    esm = pyro.deterministic(\"esm\", u_esm, event_dim=0)\n",
    "    esj = pyro.deterministic(\"esj\", u_esj, event_dim=0)\n",
    "\n",
    "    ffm = pyro.deterministic(\"ffm\", torch.logical_and(esm, ~ ar.bool()), event_dim=0).float()\n",
    "    ffj = pyro.deterministic(\"ffj\", torch.logical_and(esj, (ar.bool() | ~ esm.bool())), event_dim=0).float()\n",
    "\n",
    "    ff = pyro.deterministic(\"ff\", torch.logical_or(ffm, ffj), event_dim=0).float()\n",
    "\n",
    "    return {\"u_ar\": u_ar, \"u_esm\": u_esm, \"u_esj\": u_esj, \n",
    "            \"ar\": ar, \"esm\": esm, \"esj\": esj, \"ffm\": ffm, \"ffj\": ffj, \"ff\": ff}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': True,\n",
       " 'factive_settings': [[1.0, 0.0, 1.0],\n",
       "  [0.0, 1.0, 1.0],\n",
       "  [1.0, 1.0, 1.0],\n",
       "  [0.0, 0.0, 1.0]],\n",
       " 'sufficient_causality_status': [True, True, True, True],\n",
       " 'failure_reasons': [None, None, None, None],\n",
       " 'possibility': True,\n",
       " 'nontriviality': True,\n",
       " 'settings_cache': [[0.0, 1.0, 0.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [1.0, 0.0, 1.0],\n",
       "  [0.0, 1.0, 1.0],\n",
       "  [0.0, 0.0, 0.0],\n",
       "  [1.0, 1.0, 1.0],\n",
       "  [0.0, 0.0, 1.0]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with no excluded settings\n",
    "# one explanation for ff is esj\n",
    "\n",
    "ff_extended_esj_HPE = HalpernPearlExplanationApproximate(model = ff_extended,\n",
    "            exogenous_variables= [\"u_ar\", \"u_esm\", \"u_esj\"],\n",
    "            antecedents_dict = {\"esj\": 1.},\n",
    "            outcome_dict = {\"ff\": 1.},\n",
    "            nodes= [\"ar\", \"esm\", \"esj\"],\n",
    "            excluded_settings= [],\n",
    "            runs_n = 20)\n",
    "\n",
    "ff_extended_esj_HPE()\n",
    "ff_extended_esj_HPE.explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explanation': True,\n",
       " 'factive_settings': [[0.0, 1.0, 1.0], [0.0, 1.0, 0.0]],\n",
       " 'sufficient_causality_status': [True, True],\n",
       " 'failure_reasons': [None, None],\n",
       " 'possibility': True,\n",
       " 'nontriviality': True,\n",
       " 'settings_cache': [[0.0, 0.0, 0.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [0.0, 1.0, 1.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [1.0, 1.0, 0.0],\n",
       "  [1.0, 0.0, 1.0]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another involves esm = 1 and ar = 0 \n",
    "ff_extended_esmar_HPE = HalpernPearlExplanationApproximate(model = ff_extended,\n",
    "            exogenous_variables= [\"u_ar\", \"u_esm\", \"u_esj\"],\n",
    "            antecedents_dict = {\"esm\": 1., \"ar\": 0.},\n",
    "            outcome_dict = {\"ff\": 1.},\n",
    "            nodes= [\"ar\", \"esm\", \"esj\"],\n",
    "            excluded_settings= [],\n",
    "            runs_n = 20)\n",
    "\n",
    "ff_extended_esmar_HPE()\n",
    "ff_extended_esmar_HPE.explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             candidates  explanatory_status\n",
      "0                                    {}               False\n",
      "1                           {'ar': 1.0}               False\n",
      "2                           {'ar': 0.0}               False\n",
      "3                          {'esm': 0.0}               False\n",
      "4                          {'esm': 1.0}               False\n",
      "5               {'ar': 0.0, 'esm': 1.0}                True\n",
      "6               {'ar': 1.0, 'esm': 0.0}               False\n",
      "7               {'ar': 1.0, 'esm': 1.0}               False\n",
      "8               {'ar': 0.0, 'esm': 0.0}               False\n",
      "9                          {'esj': 1.0}                True\n",
      "10                         {'esj': 0.0}               False\n",
      "11              {'ar': 0.0, 'esj': 0.0}               False\n",
      "12              {'ar': 0.0, 'esj': 1.0}               False\n",
      "13              {'ar': 1.0, 'esj': 1.0}               False\n",
      "14              {'ar': 1.0, 'esj': 0.0}               False\n",
      "15             {'esm': 1.0, 'esj': 1.0}               False\n",
      "16             {'esm': 0.0, 'esj': 1.0}               False\n",
      "17             {'esm': 1.0, 'esj': 0.0}               False\n",
      "18             {'esm': 0.0, 'esj': 0.0}               False\n",
      "19  {'ar': 1.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "20  {'ar': 0.0, 'esm': 0.0, 'esj': 0.0}               False\n",
      "21  {'ar': 0.0, 'esm': 1.0, 'esj': 1.0}               False\n",
      "22  {'ar': 1.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "23  {'ar': 1.0, 'esm': 1.0, 'esj': 0.0}               False\n",
      "24  {'ar': 0.0, 'esm': 1.0, 'esj': 0.0}               False\n",
      "25  {'ar': 0.0, 'esm': 0.0, 'esj': 1.0}               False\n",
      "26  {'ar': 1.0, 'esm': 0.0, 'esj': 0.0}               False\n"
     ]
    }
   ],
   "source": [
    "# explore all 27 possible explanations\n",
    "# to confirm that these are the only \n",
    "# possible explanations\n",
    "\n",
    "explanatory_status = []\n",
    "candidates = []\n",
    "\n",
    "nodes = [\"ar\", \"esm\", \"esj\"]\n",
    "subsets = [[]]\n",
    "for node in nodes:\n",
    "        subsets.extend([subset + [node] for subset in subsets])\n",
    "\n",
    "\n",
    "for subset in subsets:\n",
    "        for _ in range(50):\n",
    "                random_setting = [random.choice([0., 1.]) \n",
    "                          for _ in range(len(subset))]\n",
    "                candidate = {var: val for var, val in zip(subset, random_setting)}\n",
    "\n",
    "                if candidate in candidates:\n",
    "                        continue\n",
    "\n",
    "                candidates.append(candidate)\n",
    "\n",
    "                ffHPE = HalpernPearlExplanationApproximate(model = ff_extended,\n",
    "                        exogenous_variables= [\"u_ar\", \"u_esm\", \"u_esj\"],\n",
    "                        antecedents_dict = candidate,\n",
    "                        outcome_dict = {\"ff\": 1.},\n",
    "                        nodes= [\"ar\", \"esm\", \"esj\"],\n",
    "                        excluded_settings= [],\n",
    "                        runs_n = 20)\n",
    "\n",
    "                ffHPE()\n",
    "                explanatory_status.append(ffHPE.explanation['explanation'])\n",
    "        \n",
    "\n",
    "explanation_search = pd.DataFrame({\"candidates\": candidates,\n",
    "                                   \"explanatory_status\": explanatory_status})\n",
    "\n",
    "print(explanation_search)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_pyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
