{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import chirho.contrib.experiments.closed_form as cfe\n",
    "from torch import tensor as tnsr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_grad_error(problem: cfe.CostRiskProblem, traj, grads):\n",
    "    true_grads = torch.stack([problem.ana_loss_grad(tnsr(theta).double()) for theta in traj]).detach().numpy()\n",
    "    # We don't need to account for this explicitly if its the same for both.\n",
    "    # cost_grads = torch.stack([problem.cost_grad(tnsr(theta).double().requires_grad_()) for theta in traj]).detach().numpy()\n",
    "\n",
    "    grad_error = true_grads - grads\n",
    "    mag_error = np.linalg.norm(grad_error, axis=1)\n",
    "\n",
    "    # print(true_grads.shape, grads.shape, mag_error.shape)\n",
    "\n",
    "    return grad_error, mag_error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_ellipse_from_std_and_cov(std, cov):\n",
    "    t = np.linspace(0, 2 * np.pi)\n",
    "    circle = np.array([np.cos(t), np.sin(t)])\n",
    "    ellipse = std * np.linalg.cholesky(cov) @ circle\n",
    "    return ellipse\n",
    "\n",
    "\n",
    "def visualize_problem(problem: cfe.CostRiskProblem, ax: plt.Axes, err_axs: Tuple[plt.Axes, ...]):\n",
    "    assert problem.n == 2, \"Visualization only supported for 2D problems.\"\n",
    "\n",
    "    xl = yl = 9\n",
    "\n",
    "    # Set lims.\n",
    "    ax.set_xlim(-xl, xl)\n",
    "    ax.set_ylim(-yl, yl)\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.1)\n",
    "    ax.axvline(0, color='black', linewidth=0.1)\n",
    "\n",
    "    # Define a grid for plotting\n",
    "    x, y = np.mgrid[-xl:yl:.01, -xl:yl:.01]\n",
    "    pos = np.dstack((x, y))\n",
    "\n",
    "    prob_of_z = multivariate_normal(mean=[0, 0], cov=problem.Sigma).pdf(pos)\n",
    "\n",
    "    risk_curve = cfe.risk_curve(\n",
    "        theta=problem.theta0[None, None, :],\n",
    "        Q=problem.Q[None, None, :, :],\n",
    "        z=tnsr(pos).double()[:, :, None]).numpy().squeeze()\n",
    "\n",
    "    # Plot the non-filled contours of the risk_curve.\n",
    "    ax.contour(x, y, risk_curve, cmap='Reds', linewidths=0.5)\n",
    "    ax.plot([], [], 'r-', label='risk')\n",
    "\n",
    "    # Plot the rescaled covariance matrix\n",
    "    ax.contourf(x, y, prob_of_z, cmap='Blues', alpha=0.9)\n",
    "    ax.plot([], [], 'b-', label='p(z)')\n",
    "\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    # ax.set_title(f'Problem')\n",
    "\n",
    "    # Plot ellipse by making a unit circle with radius rstar and then transforming it by Sigma.\n",
    "    ax.plot(*get_ellipse_from_std_and_cov(std=problem.rstar, cov=problem.Sigma), '--', color='darkorange',\n",
    "            linewidth=0.5, label='~r*')\n",
    "\n",
    "    # And also plot the ellipse of the initial theta contour.\n",
    "    ax.plot(*get_ellipse_from_std_and_cov(std=problem.theta0_init_dist, cov=problem.Sigma), '--', color='black',\n",
    "            linewidth=0.3, label='r0')\n",
    "\n",
    "    # Plot the gradient vector field of the analytical loss.\n",
    "    xl = yl = 5\n",
    "    x, y = np.mgrid[-xl:yl:.5, -xl:yl:.5]\n",
    "    pos = np.dstack((x, y))\n",
    "    grad_field = np.array([-problem.ana_loss_grad(tnsr(p).double()).numpy() for p in pos.reshape(-1, 2)]).reshape(\n",
    "        pos.shape)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):  # Ignore div by zero warning.\n",
    "        normed_grad_field = grad_field / np.linalg.norm(grad_field, axis=-1, keepdims=True)\n",
    "\n",
    "    # Now, color the arrows according to the analytic objective (the negative of the loss).\n",
    "    objvals = np.array([-problem.ana_loss(tnsr(p).double()).numpy() for p in pos.reshape(-1, 2)]).reshape(\n",
    "        pos.shape[:-1])\n",
    "\n",
    "    # Thin arrows.\n",
    "    ax.quiver(x, y, normed_grad_field[:, :, 0], normed_grad_field[:, :, 1], objvals, cmap='cool',\n",
    "              alpha=1., scale=100, width=0.0010, headwidth=3, headlength=4, pivot='mid')\n",
    "\n",
    "    # Remove axis ticks.\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # TODO pull these out into a grouped solve function.\n",
    "    # <Solve>\n",
    "    hparams = cfe.Hyperparams(\n",
    "        lr=1e-3,\n",
    "        clip=0.1,\n",
    "        num_steps=5000,\n",
    "        tabi_num_samples=1,\n",
    "        decay_at_max_steps=0.5,\n",
    "        burnin=1000,\n",
    "        ray=False,\n",
    "        n=problem.n,\n",
    "        unnorm_const=0.1,\n",
    "        svi_lr=3e-3\n",
    "    )\n",
    "    \n",
    "    # <Exact>\n",
    "    # # Solve the problem with TABI, but with optimal guides (should be equivalent to exact).\n",
    "    # traj_opt_tabi = cfe.opt_opt_tabi_with_scipy(problem)\n",
    "    # ax.plot(traj_opt_tabi[:, 0], traj_opt_tabi[:, 1], 'g-', linewidth=0.2, label='opt tabi')\n",
    "    # # Plot an x at the final solution.\n",
    "    # ax.plot(traj_opt_tabi[-1, 0], traj_opt_tabi[-1, 1], 'gx', markersize=4, alpha=0.5)\n",
    "\n",
    "    # Solve the analytic problem with scipy, and plot the trajectory.\n",
    "    traj_ana = cfe.opt_ana_with_scipy(problem)\n",
    "    # ax.plot(traj_ana[:, 0], traj_ana[:, 1], 'k--', linewidth=0.2, label='ana bfgs')\n",
    "    # Plot an x at the final solution.\n",
    "    ax.plot(traj_ana[-1, 0], traj_ana[-1, 1], 'kx', markersize=5, alpha=0.5)\n",
    "    # </Exact>\n",
    "    \n",
    "    \n",
    "    # <NoGrad TABI>\n",
    "    nograd_tabi_res = cfe.opt_with_nograd_tabi_sgd(\n",
    "        problem=problem,\n",
    "        hparams=hparams\n",
    "    )\n",
    "    ax.plot(nograd_tabi_res.traj[:, 0], nograd_tabi_res.traj[:, 1], 'c--', linewidth=0.4, label='sgd nograd tabi', alpha=0.5)\n",
    "    # Mark an x at the mean of the last bit of the trajectory.\n",
    "    ax.plot(nograd_tabi_res.traj[-500:, 0].mean(), nograd_tabi_res.traj[-500:, 1].mean(), 'cx', markersize=5, alpha=0.5)\n",
    "    \n",
    "    _, err_sgd_nograd_tabi = compute_grad_error(problem=problem, traj=nograd_tabi_res.traj, grads=nograd_tabi_res.grad_ests)\n",
    "    err_axs[4].plot(err_sgd_nograd_tabi)\n",
    "    err_axs[4].set_title(\"NoGrad TABI\")\n",
    "    # </NoGrad TABI>\n",
    "    \n",
    "    # <ZeroVar>\n",
    "    # Solve the problem with SGD but zero variance.\n",
    "    zero_var_res = cfe.opt_with_zerovar_sgd(\n",
    "        problem=problem,\n",
    "        hparams=hparams\n",
    "    )\n",
    "    \n",
    "    ax.plot(zero_var_res.traj[:, 0], zero_var_res.traj[:, 1], 'k--', linewidth=0.4, label='sgd zero var', alpha=0.5)\n",
    "    # Mark an x at the mean of the last bit of the trajectory.\n",
    "    ax.plot(zero_var_res.traj[-500:, 0].mean(), zero_var_res.traj[-500:, 1].mean(), 'kx', markersize=6, alpha=0.5)\n",
    "    \n",
    "    # This has no gradient error, so don't bother plotting.\n",
    "    # </ZeroVar>\n",
    "    \n",
    "    # <Posterior Approximating IS>\n",
    "    # Solve the problem with PAIS single stage estimator.\n",
    "    pais_res = cfe.opt_with_pais_sgd(\n",
    "        problem=problem,\n",
    "        hparams=hparams\n",
    "    )\n",
    "    ax.plot(pais_res.traj[:, 0], pais_res.traj[:, 1], 'm--', linewidth=0.4, label='sgd pais', alpha=0.5)\n",
    "    # Mark an x at the mean of the last bit of the trajectory.\n",
    "    ax.plot(pais_res.traj[-500:, 0].mean(), pais_res.traj[-500:, 1].mean(), 'mx', markersize=5, alpha=0.5)\n",
    "    \n",
    "    _, err_sgd_pais = compute_grad_error(problem=problem, traj=pais_res.traj, grads=pais_res.grad_ests)\n",
    "    err_axs[3].plot(err_sgd_pais)\n",
    "    err_axs[3].set_title(\"PAIS\")\n",
    "    # </Posterior Approximating IS>\n",
    "\n",
    "    # <SNIS>\n",
    "    # Solve the problem with SNIS single stage estimator.\n",
    "    snis_res = cfe.opt_with_snis_sgd(\n",
    "        problem=problem,\n",
    "        hparams=hparams\n",
    "    )\n",
    "    ax.plot(snis_res.traj[:, 0], snis_res.traj[:, 1], 'g--', linewidth=0.4, label='sgd snis', alpha=0.5)\n",
    "    # Mark an x at the mean of the last bit of the trajectory.\n",
    "    ax.plot(snis_res.traj[-500:, 0].mean(), snis_res.traj[-500:, 1].mean(), 'gx', markersize=5, alpha=0.5)\n",
    "\n",
    "    _, err_sgd_snis = compute_grad_error(problem=problem, traj=snis_res.traj, grads=snis_res.grad_ests)\n",
    "    err_axs[2].plot(err_sgd_snis)\n",
    "    err_axs[2].set_title(\"SNIS\")\n",
    "    # </SNIS>\n",
    "\n",
    "    # <TABI>\n",
    "    # Solve problem with TABI single stage estimator.\n",
    "    tabi_res = cfe.opt_with_ss_tabi_sgd(\n",
    "        problem=problem,\n",
    "        hparams=hparams\n",
    "    )\n",
    "    ax.plot(tabi_res.traj[:, 0], tabi_res.traj[:, 1], 'r--', linewidth=0.4, label='sgd tabi', alpha=0.5)\n",
    "    # Mark an x at the mean of the last 100 of the trajectory.\n",
    "    ax.plot(tabi_res.traj[-500:, 0].mean(), tabi_res.traj[-500:, 1].mean(), 'rx', markersize=5, alpha=0.5)\n",
    "\n",
    "    _, err_sgd_tabi = compute_grad_error(problem=problem, traj=tabi_res.traj, grads=tabi_res.grad_ests)\n",
    "    err_axs[1].plot(err_sgd_tabi)\n",
    "    err_axs[1].set_title(\"TABI\")\n",
    "    # </TABI>\n",
    "\n",
    "    # <MC>\n",
    "    # Solve the approximate problem with mc SGD, and plot the trajectory.\n",
    "    mc_res = cfe.opt_with_mc_sgd(\n",
    "        problem=problem,\n",
    "        hparams=hparams,\n",
    "    )\n",
    "    ax.plot(mc_res.traj[:, 0], mc_res.traj[:, 1], 'b--', linewidth=0.4, label='sgd mc', alpha=0.5)\n",
    "    # Mark an x at the mean of the last 100 of the trajectory.\n",
    "    ax.plot(mc_res.traj[-500:, 0].mean(), mc_res.traj[-500:, 1].mean(), 'bx', markersize=6, alpha=0.5)\n",
    "\n",
    "    _, err_sgd_mc = compute_grad_error(problem=problem, traj=mc_res.traj, grads=mc_res.grad_ests)\n",
    "    err_axs[0].plot(err_sgd_mc)\n",
    "    err_axs[0].set_title(\"MC\")\n",
    "    # </MC>\n",
    "\n",
    "    # Plot the losses.\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(tabi_res.losses, label='tabi')\n",
    "    plt.plot(mc_res.losses, label='mc')\n",
    "    plt.plot(snis_res.losses, label='snis')\n",
    "    plt.plot(zero_var_res.losses, label='zero var')\n",
    "    # plt.plot(pais_res.losses, label='pais')\n",
    "    plt.plot(nograd_tabi_res.losses, label='nograd tabi')\n",
    "    # Plot a horizontal line on the loss plot for the final scipy solution.\n",
    "    plt.axhline(problem.ana_loss(tnsr(traj_ana[-1]).double()).numpy(), color='black', linewidth=0.5, linestyle='--')\n",
    "    plt.legend()\n",
    "\n",
    "    # DEBUG LR\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(tabi_res.lrs)\n",
    "    plt.plot(mc_res.lrs)\n",
    "    plt.plot(snis_res.lrs)\n",
    "    plt.plot(zero_var_res.lrs)\n",
    "    plt.plot(pais_res.lrs)\n",
    "    plt.plot(nograd_tabi_res.lrs)\n",
    "    # </Solve>\n",
    "\n",
    "    ax.legend(fontsize=6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyro.util import set_rng_seed\n",
    "def example_problems():\n",
    "    set_rng_seed(561)  # problem generation seed.\n",
    "    problem = cfe.CostRiskProblem(q=0.3, n=2, rstar=5., theta0_rstar_delta=0.0)\n",
    "    _, err_axs = plt.subplots(5, 1, figsize=(12, 9), sharey=True)\n",
    "    _, ax = plt.subplots(1, 1, dpi=600)\n",
    "    for err_ax in err_axs:\n",
    "        err_ax.set_yscale('log')\n",
    "    set_rng_seed(201)  # optimization seed.\n",
    "    visualize_problem(problem, ax, err_axs)\n",
    "    # plt.tight_layout()\n",
    "    plt.show()\n",
    "example_problems()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
