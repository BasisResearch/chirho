{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-11T01:21:47.747234Z",
     "start_time": "2023-11-11T01:21:47.727060Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import chirho.contrib.experiments.closed_form as cfe\n",
    "from chirho.contrib.experiments.decision_optimizer import DecisionOptimizer\n",
    "import pyro.distributions as dist\n",
    "from torch import tensor as tnsr\n",
    "from torch import Tensor as Tnsr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import chirho.contrib.compexp as ep\n",
    "import pyro\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class CostRiskProblem:\n",
    "    Sigma: Tnsr\n",
    "    Q: Tnsr\n",
    "    theta0: Tnsr\n",
    "    c: Tnsr\n",
    "    rstar: Tnsr\n",
    "    theta0_init_dist: Tnsr\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        return self.Sigma.shape[0]\n",
    "\n",
    "    def ana_loss(self, theta):\n",
    "        return -cfe.full_ana_obj(theta=theta, Sigma=self.Sigma, Q=self.Q, c=self.c)\n",
    "\n",
    "    def ana_loss_grad(self, theta):\n",
    "        theta = theta.detach().requires_grad_(True)\n",
    "        loss = self.ana_loss(theta)\n",
    "        grad = torch.autograd.grad(loss, theta)[0]\n",
    "        return grad\n",
    "\n",
    "    @staticmethod\n",
    "    def cost(theta):\n",
    "        return theta @ theta\n",
    "\n",
    "    def scaled_risk(self, theta, z):\n",
    "        return self.c * cfe.risk_curve(theta=theta, Q=self.Q, z=z)\n",
    "\n",
    "    def model(self):\n",
    "        return pyro.sample('z', dist.MultivariateNormal(loc=torch.zeros(self.n).double(), covariance_matrix=self.Sigma))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T01:21:47.747396Z",
     "start_time": "2023-11-11T01:21:47.730275Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def generate_problem(q: float, n: int, rstar: float, theta0_rstar_delta: float) -> CostRiskProblem:\n",
    "    \"\"\"\n",
    "    Generate a cost/risk minimization problem. Cost, in this case is simply ||theta||**2, while the risk\n",
    "     is the expecation of the risk curve with respect to the distribution p(z) = N(0, Sigma).\n",
    "    The risk curve is an unnormalized Gaussian with mean theta and covariance Q, which will have a covariance\n",
    "     inducing a similar-sized curve to one with an I*q covariance.\n",
    "\n",
    "    :param q: The stdev of the risk curve.\n",
    "    :param n: The dimensionality of the problem.\n",
    "    :param rstar: The distance to which theta should converge to solve the problem. This allows for precise experimental\n",
    "     control over how far into the tails of p(z) the optimization should position the risk curve.\n",
    "    :param theta0_rstar_delta: The delta from rstar that theta should be (randomly) initialized to. This will initialize\n",
    "     theta to sit on a hypersphere of radius rstar + theta0_rstar_delta.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    q, rstar, theta0_rstar_delta = map(lambda x: tnsr(x) if not isinstance(x, Tnsr) else x, [q, rstar, theta0_rstar_delta])\n",
    "\n",
    "    Sigma = dist.Wishart(covariance_matrix=torch.eye(n), df=tnsr(n+3)).sample()\n",
    "    if torch.linalg.det(Sigma) <= 0.7:  # If too singular, try again recursively.\n",
    "        return generate_problem(q, n, rstar, theta0_rstar_delta)\n",
    "    Sigma = cfe.rescale_cov_to_unit_mass(Sigma)\n",
    "\n",
    "    Q = dist.Wishart(covariance_matrix=torch.eye(n), df=tnsr(n+3)).sample()\n",
    "    if torch.linalg.det(Q) <= 0.5:\n",
    "        return generate_problem(q, n, rstar, theta0_rstar_delta)\n",
    "    Q = cfe.rescale_cov_to_unit_mass(Q) * q\n",
    "\n",
    "    c = cfe.compute_ana_c(q, rstar, n)\n",
    "\n",
    "    # Generate a uniformly random direction on the unit hypersphere.\n",
    "    theta0 = dist.Normal(torch.zeros(n), torch.ones(n)).sample()\n",
    "    # Rescale to the desired radius.\n",
    "    theta0 = theta0 / theta0.norm() * (rstar + theta0_rstar_delta)\n",
    "    # And transform according to Sigma. This ensures that the initial theta does indeed sit on the rstar + theta0_rstar_delta\n",
    "    #  contour of p(z), as opposed to just the unit normal.\n",
    "    theta0 = torch.linalg.cholesky(Sigma) @ theta0\n",
    "\n",
    "    problem = CostRiskProblem()\n",
    "    problem.Sigma = Sigma.double()\n",
    "    problem.Q = Q.double()\n",
    "    problem.theta0 = theta0.double()\n",
    "    problem.c = c.double()\n",
    "    problem.rstar = rstar.double()\n",
    "    problem.theta0_init_dist = (theta0_rstar_delta + rstar).double()\n",
    "\n",
    "    # Gradcheck the problem's analytical loss.\n",
    "    theta0 = problem.theta0.detach().requires_grad_(True)\n",
    "    torch.autograd.gradcheck(problem.ana_loss, theta0)\n",
    "\n",
    "    return problem"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T01:21:47.747525Z",
     "start_time": "2023-11-11T01:21:47.742919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def opt_ana_with_scipy(problem: CostRiskProblem):\n",
    "    traj = [problem.theta0.detach().numpy()]\n",
    "\n",
    "    def callback(xk):\n",
    "        traj.append(xk)\n",
    "\n",
    "    def numpy_loss(theta: np.ndarray):\n",
    "        return problem.ana_loss(tnsr(theta).double()).numpy()\n",
    "\n",
    "    def numpy_grad(theta: np.ndarray):\n",
    "        return problem.ana_loss_grad(tnsr(theta).double()).numpy()\n",
    "\n",
    "    theta0 = problem.theta0.numpy()\n",
    "    res = minimize(numpy_loss, theta0, method='BFGS', callback=callback, jac=numpy_grad, tol=1e-6)\n",
    "\n",
    "    assert np.allclose(traj[-1], res.x)\n",
    "\n",
    "    return np.array(traj)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T01:21:47.752530Z",
     "start_time": "2023-11-11T01:21:47.746707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def opt_with_mc_sgd(problem: CostRiskProblem, num_samples: int, num_steps: int, adjust_grads_: Callable):\n",
    "\n",
    "    theta = torch.nn.Parameter(problem.theta0.detach().clone().requires_grad_(True))\n",
    "\n",
    "    # TODO include an MC that estimates one grad from one z? This will implicitly split it up.\n",
    "    cost = ep.E(\n",
    "        f=lambda z: (problem.cost(theta) + problem.scaled_risk(theta, z)).squeeze(),\n",
    "        name=\"cost\"\n",
    "    )\n",
    "\n",
    "    do = DecisionOptimizer(\n",
    "        flat_dparams=theta,\n",
    "        model=problem.model,\n",
    "        cost=cost,\n",
    "        expectation_handler=ep.MonteCarloExpectationHandler(num_samples),\n",
    "        lr=1.\n",
    "    )\n",
    "\n",
    "    traj = [theta.detach().clone().numpy()]\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        grad_est = do.estimate_grad()\n",
    "        adjust_grads_(grad_est)\n",
    "        do.step_grad(grad_est)\n",
    "        traj.append(theta.detach().clone().numpy())\n",
    "        theta.grad.zero_()\n",
    "        print(f\"{i:05d}\", end=\"\\r\")\n",
    "\n",
    "        if i > 1000:\n",
    "            last_1000 = np.array(traj[-1000:])\n",
    "            last_500 = np.array(traj[-500:])\n",
    "            if np.allclose(last_500.mean(axis=0), last_1000.mean(axis=0), atol=1e-2):\n",
    "                break\n",
    "    print()\n",
    "\n",
    "    return np.array(traj)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T01:21:47.755342Z",
     "start_time": "2023-11-11T01:21:47.752070Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def default_adjust_grads_(grad_est: Tnsr):\n",
    "    # Clip to norm 1.\n",
    "    grad_est /= torch.max(tnsr(1.).double(), grad_est.norm())\n",
    "    # Then rescale.\n",
    "    grad_est *= 5e-3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T01:21:47.756252Z",
     "start_time": "2023-11-11T01:21:47.754656Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def get_ellipse_from_std_and_cov(std, cov):\n",
    "    t = np.linspace(0, 2 * np.pi)\n",
    "    circle = np.array([np.cos(t), np.sin(t)])\n",
    "    ellipse = std * np.linalg.cholesky(cov) @ circle\n",
    "    return ellipse\n",
    "\n",
    "\n",
    "def visualize_problem(problem: CostRiskProblem, ax: plt.Axes):\n",
    "\n",
    "    assert problem.n == 2, \"Visualization only supported for 2D problems.\"\n",
    "\n",
    "    xl = yl = 9\n",
    "\n",
    "    # Set lims.\n",
    "    ax.set_xlim(-xl, xl)\n",
    "    ax.set_ylim(-yl, yl)\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.1)\n",
    "    ax.axvline(0, color='black', linewidth=0.1)\n",
    "\n",
    "    # Define a grid for plotting\n",
    "    x, y = np.mgrid[-xl:yl:.01, -xl:yl:.01]\n",
    "    pos = np.dstack((x, y))\n",
    "\n",
    "    prob_of_z = multivariate_normal(mean=[0, 0], cov=problem.Sigma).pdf(pos)\n",
    "\n",
    "    risk_curve = cfe.risk_curve(\n",
    "        theta=problem.theta0[None, None, :],\n",
    "        Q=problem.Q[None, None, :, :],\n",
    "        z=tnsr(pos).double()[:, :, None]).numpy().squeeze()\n",
    "\n",
    "    # Plot the non-filled contours of the risk_curve.\n",
    "    ax.contour(x, y, risk_curve, cmap='Reds', linewidths=0.5)\n",
    "    ax.plot([], [], 'r-', label='risk')\n",
    "\n",
    "    # Plot the rescaled covariance matrix\n",
    "    ax.contourf(x, y, prob_of_z, cmap='Blues', alpha=0.9)\n",
    "    ax.plot([], [], 'b-', label='p(z)')\n",
    "\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    # ax.set_title(f'Problem')\n",
    "\n",
    "    # Plot ellipse by making a unit circle with radius rstar and then transforming it by Sigma.\n",
    "    ax.plot(*get_ellipse_from_std_and_cov(std=problem.rstar, cov=problem.Sigma), '--', color='darkorange', linewidth=0.5, label='~r*')\n",
    "\n",
    "    # And also plot the ellipse of the initial theta contour.\n",
    "    ax.plot(*get_ellipse_from_std_and_cov(std=problem.theta0_init_dist, cov=problem.Sigma), '--', color='black', linewidth=0.3, label='r0')\n",
    "\n",
    "    # Plot the gradient vector field of the analytical loss.\n",
    "    xl = yl = 5\n",
    "    x, y = np.mgrid[-xl:yl:.5, -xl:yl:.5]\n",
    "    pos = np.dstack((x, y))\n",
    "    grad_field = np.array([-problem.ana_loss_grad(tnsr(p).double()).numpy() for p in pos.reshape(-1, 2)]).reshape(pos.shape)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):  # Ignore div by zero warning.\n",
    "        normed_grad_field = grad_field / np.linalg.norm(grad_field, axis=-1, keepdims=True)\n",
    "\n",
    "    # Now, color the arrows according to the analytic objective (the negative of the loss).\n",
    "    objvals = np.array([-problem.ana_loss(tnsr(p).double()).numpy() for p in pos.reshape(-1, 2)]).reshape(pos.shape[:-1])\n",
    "\n",
    "    # Thin arrows.\n",
    "    ax.quiver(x, y, normed_grad_field[:, :, 0], normed_grad_field[:, :, 1], objvals, cmap='cool',\n",
    "              alpha=1., scale=100, width=0.0010, headwidth=3, headlength=4, pivot='mid')\n",
    "\n",
    "    # Remove axis ticks.\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # TODO pull these out into a grouped solve function.\n",
    "    # <Solve>\n",
    "    # Solve the approximate problem with mc SGD, and plot the trajectory.\n",
    "    traj = opt_with_mc_sgd(\n",
    "        problem=problem,\n",
    "        num_samples=50,\n",
    "        num_steps=10000,\n",
    "        adjust_grads_=default_adjust_grads_\n",
    "    )\n",
    "    ax.plot(traj[:, 0], traj[:, 1], 'b--', linewidth=0.4, label='sgd mc', alpha=0.5)\n",
    "    # Mark an x at the mean of the last 100 of the trajectory.\n",
    "    ax.plot(traj[-500:, 0].mean(), traj[-500:, 1].mean(), 'bx', markersize=3, alpha=0.5)\n",
    "\n",
    "    # Solve the analytic problem with scipy, and plot the trajectory.\n",
    "    traj = opt_ana_with_scipy(problem)\n",
    "    ax.plot(traj[:, 0], traj[:, 1], 'k-', linewidth=0.4, label='ana bfgs')\n",
    "    # Plot an x at the final solution.\n",
    "    ax.plot(traj[-1, 0], traj[-1, 1], 'kx', markersize=2, alpha=0.5)\n",
    "    # </Solve>\n",
    "\n",
    "    ax.legend(fontsize=6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T01:21:47.766722Z",
     "start_time": "2023-11-11T01:21:47.765739Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00218\r"
     ]
    }
   ],
   "source": [
    "def example_problems():\n",
    "    problem = generate_problem(q=0.3, n=2, rstar=2.5, theta0_rstar_delta=-.5)\n",
    "    fig, ax = plt.subplots(1, 1, dpi=400)\n",
    "    visualize_problem(problem, ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "example_problems()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-11T01:21:47.768274Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
