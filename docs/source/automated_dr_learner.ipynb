{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated doubly robust estimation with ChiRho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [Setup](#setup)\n",
    "\n",
    "- [Overview: Systematically adjusting for observed confounding](#overview:-systematically-adjusting-for-observed-confounding)\n",
    "    - [Task: Treatment effect estimation with observational data](#task:-treatment-effect-estimation-with-observational-data)\n",
    "    - [Challenge: Confounding](#challenge:-confounding)\n",
    "    - [Assumptions: All confounders observed](#assumptions:-all-confounders-observed)\n",
    "    - [Intuition: Statistically adjusting for confounding](#intuition:-statistically-adjusting-for-confounding)\n",
    "\n",
    "- [Causal Probabilistic Program](#causal-probabilistic-program)\n",
    "    - [Model description](#model-description)\n",
    "    - [Generating data](#generating-data)\n",
    "    - [Fit parameters via maximum likelihood](#fit-parameters-via-maximum-likelihood)\n",
    "\n",
    "- [Causal Query: average treatment effect (ATE)](#causal-query:-average-treatment-effect-\\(ATE\\))\n",
    "    - [Defining the target functional](#defining-the-target-functional)\n",
    "    - [Closed form doubly robust correction](#closed-form-doubly-robust-correction)\n",
    "    - [Computing automated doubly robust correction via Monte Carlo](#computing-automated-doubly-robust-correction-via-monte-carlo)\n",
    "    - [Results](#results)\n",
    "\n",
    "- [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we install the necessary Pytorch, Pyro, and ChiRho dependencies for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Tuple\n",
    "\n",
    "import functools\n",
    "import torch\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import Predictive\n",
    "import pyro.contrib.gp as gp\n",
    "\n",
    "from chirho.counterfactual.handlers import MultiWorldCounterfactual\n",
    "from chirho.indexed.ops import IndexSet, gather\n",
    "from chirho.interventional.handlers import do\n",
    "from chirho.robust.internals.utils import ParamDict\n",
    "from chirho.robust.handlers.estimators import one_step_correction \n",
    "from chirho.robust.handlers.predictive import PredictiveModel \n",
    "\n",
    "pyro.settings.set(module_local_params=True)\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "pyro.set_rng_seed(321) # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial, we will use ChiRho to estimate the average treatment effect (ATE) from observational data. We will use a simple example to illustrate the basic concepts of doubly robust estimation and how ChiRho can be used to automate the process for more general summaries of interest. \n",
    "\n",
    "There are five main steps to our doubly robust estimation procedure but only the last step is different from a standard probabilistic programming workflow:\n",
    "1. Write model of interest\n",
    "    - Define probabilistic model of interest using Pyro\n",
    "2. Feed in data\n",
    "    - Observed data used to train the model\n",
    "3. Run inference\n",
    "    - Use Pyro's rich inference library to fit the model to the data\n",
    "4. Define target functional\n",
    "    - This is the model summary of interest (e.g. average treatment effect)\n",
    "5. Compute robust estimate\n",
    "    - Use ChiRho to compute the doubly robust estimate of the target functional\n",
    "    - Importantly, this step is automated and does not require refitting the model for each new functional\n",
    "\n",
    "\n",
    "Our proposed automated robust inference pipeline is summarized in the figure below.\n",
    "\n",
    "![fig1](figures/robust_pipeline.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Probabilistic Program\n",
    "\n",
    "### Model Description\n",
    "In this example, we will focus on a cannonical model `CausalGLM` consisting of three types of variables: binary treatment (`A`), confounders (`X`), and response (`Y`). For simplicitly, we assume that the response is generated from a generalized linear model with link function $g$. The model is described by the following generative process:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "X &\\sim \\text{Normal}(0, I_p) \\\\\n",
    "A &\\sim \\text{Bernoulli}(\\pi(X)) \\\\\n",
    "\\mu &= \\beta_0 + \\beta_1^T X + \\tau A \\\\\n",
    "Y &\\sim \\text{ExponentialFamily}(\\text{mean} = g^{-1}(\\mu))\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $p$ denotes the number of confounders, $\\pi(X)$ is the probability of treatment conditional on confounders $X$, $\\beta_0$ is the intercept, $\\beta_1$ is the confounder effect, and $\\tau$ is the treatment effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalGLM(pyro.nn.PyroModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        p: int,\n",
    "        link_fn: Callable[..., dist.Distribution] = lambda mu: dist.Normal(mu, 1.0),\n",
    "        prior_scale: Optional[float] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.link_fn = link_fn\n",
    "        if prior_scale is None:\n",
    "            self.prior_scale = 1 / math.sqrt(self.p)\n",
    "        else:\n",
    "            self.prior_scale = prior_scale\n",
    "\n",
    "    def sample_outcome_weights(self):\n",
    "        return pyro.sample(\n",
    "            \"outcome_weights\",\n",
    "            dist.Normal(0.0, self.prior_scale).expand((self.p,)).to_event(1),\n",
    "        )\n",
    "\n",
    "    def sample_intercept(self):\n",
    "        return pyro.sample(\"intercept\", dist.Normal(0.0, 1.0))\n",
    "\n",
    "    def sample_propensity_weights(self):\n",
    "        return pyro.sample(\n",
    "            \"propensity_weights\",\n",
    "            dist.Normal(0.0, self.prior_scale).expand((self.p,)).to_event(1),\n",
    "        )\n",
    "\n",
    "    def sample_treatment_weight(self):\n",
    "        return pyro.sample(\"treatment_weight\", dist.Normal(0.0, 1.0))\n",
    "\n",
    "    def sample_covariate_loc_scale(self):\n",
    "        return torch.zeros(self.p), torch.ones(self.p)\n",
    "\n",
    "    def forward(self):\n",
    "        intercept = self.sample_intercept()\n",
    "        outcome_weights = self.sample_outcome_weights()\n",
    "        propensity_weights = self.sample_propensity_weights()\n",
    "        tau = self.sample_treatment_weight()\n",
    "        x_loc, x_scale = self.sample_covariate_loc_scale()\n",
    "        X = pyro.sample(\"X\", dist.Normal(x_loc, x_scale).to_event(1))\n",
    "        A = pyro.sample(\n",
    "            \"A\",\n",
    "            dist.Bernoulli(\n",
    "                logits=torch.einsum(\"...i,...i->...\", X, propensity_weights)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return pyro.sample(\n",
    "            \"Y\",\n",
    "            self.link_fn(\n",
    "                torch.einsum(\"...i,...i->...\", X, outcome_weights) + A * tau + intercept\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will condition on both treatment and confounders to estimate the causal effect of treatment on the outcome. We will use the following causal probabilistic program to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionedCausalGLM(CausalGLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: torch.Tensor,\n",
    "        A: torch.Tensor,\n",
    "        Y: torch.Tensor,\n",
    "        link_fn: Callable[..., dist.Distribution] = lambda mu: dist.Normal(mu, 1.0),\n",
    "        prior_scale: Optional[float] = None,\n",
    "    ):\n",
    "        p = X.shape[1]\n",
    "        super().__init__(p, link_fn, prior_scale)\n",
    "        self.X = X\n",
    "        self.A = A\n",
    "        self.Y = Y\n",
    "\n",
    "    def forward(self):\n",
    "        intercept = self.sample_intercept()\n",
    "        outcome_weights = self.sample_outcome_weights()\n",
    "        propensity_weights = self.sample_propensity_weights()\n",
    "        tau = self.sample_treatment_weight()\n",
    "        x_loc, x_scale = self.sample_covariate_loc_scale()\n",
    "        with pyro.plate(\"__train__\", size=self.X.shape[0], dim=-1):\n",
    "            X = pyro.sample(\"X\", dist.Normal(x_loc, x_scale).to_event(1), obs=self.X)\n",
    "            A = pyro.sample(\n",
    "                \"A\",\n",
    "                dist.Bernoulli(\n",
    "                    logits=torch.einsum(\"ni,i->n\", self.X, propensity_weights)\n",
    "                ),\n",
    "                obs=self.A,\n",
    "            )\n",
    "            pyro.sample(\n",
    "                \"Y\",\n",
    "                self.link_fn(\n",
    "                    torch.einsum(\"ni,i->n\", X, outcome_weights)\n",
    "                    + A * tau\n",
    "                    + intercept\n",
    "                ),\n",
    "                obs=self.Y,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"563pt\" height=\"304pt\"\n",
       " viewBox=\"0.00 0.00 563.39 304.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-300 559.39,-300 559.39,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster___train__</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"93.6,-8 93.6,-155 235.6,-155 235.6,-8 93.6,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"201.6\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">__train__</text>\n",
       "</g>\n",
       "<!-- intercept -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>intercept</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"41.6\" cy=\"-129\" rx=\"41.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"41.6\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">intercept</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"200.6\" cy=\"-57\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.6\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- intercept&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>intercept&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.66,-115.65C97.53,-103.38 140.19,-84.59 169.18,-71.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.71,-74.98 178.45,-67.75 167.89,-68.58 170.71,-74.98\"/>\n",
       "</g>\n",
       "<!-- outcome_weights -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>outcome_weights</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"318.6\" cy=\"-129\" rx=\"73.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.6\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">outcome_weights</text>\n",
       "</g>\n",
       "<!-- outcome_weights&#45;&gt;Y -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>outcome_weights&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M291.82,-112.12C273.12,-101.02 248.19,-86.23 229.12,-74.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"230.67,-71.77 220.28,-69.68 227.1,-77.79 230.67,-71.77\"/>\n",
       "</g>\n",
       "<!-- propensity_weights -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>propensity_weights</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"128.6\" cy=\"-239.5\" rx=\"79.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"128.6\" y=\"-235.8\" font-family=\"Times,serif\" font-size=\"14.00\">propensity_weights</text>\n",
       "</g>\n",
       "<!-- A -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"128.6\" cy=\"-129\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"128.6\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n",
       "</g>\n",
       "<!-- propensity_weights&#45;&gt;A -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>propensity_weights&#45;&gt;A</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.6,-221.07C128.6,-203.8 128.6,-177.12 128.6,-157.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.1,-157.03 128.6,-147.03 125.1,-157.03 132.1,-157.03\"/>\n",
       "</g>\n",
       "<!-- treatment_weight -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>treatment_weight</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"482.6\" cy=\"-129\" rx=\"72.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"482.6\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">treatment_weight</text>\n",
       "</g>\n",
       "<!-- treatment_weight&#45;&gt;Y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>treatment_weight&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M433.15,-115.73C376.52,-101.67 285.18,-79 235.5,-66.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"236.11,-63.21 225.56,-64.2 234.42,-70 236.11,-63.21\"/>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"gray\" stroke=\"black\" cx=\"200.6\" cy=\"-129\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.6\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M200.6,-110.7C200.6,-102.98 200.6,-93.71 200.6,-85.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.1,-85.1 200.6,-75.1 197.1,-85.1 204.1,-85.1\"/>\n",
       "</g>\n",
       "<!-- A&#45;&gt;Y -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>A&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M143.17,-113.83C153.35,-103.94 167.12,-90.55 178.63,-79.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.07,-81.87 185.8,-72.38 176.19,-76.85 181.07,-81.87\"/>\n",
       "</g>\n",
       "<!-- distribution_description_node -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>distribution_description_node</title>\n",
       "<text text-anchor=\"start\" x=\"234.1\" y=\"-280.8\" font-family=\"Times,serif\" font-size=\"14.00\">intercept ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"234.1\" y=\"-265.8\" font-family=\"Times,serif\" font-size=\"14.00\">outcome_weights ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"234.1\" y=\"-250.8\" font-family=\"Times,serif\" font-size=\"14.00\">propensity_weights ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"234.1\" y=\"-235.8\" font-family=\"Times,serif\" font-size=\"14.00\">treatment_weight ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"234.1\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">X ~ Normal</text>\n",
       "<text text-anchor=\"start\" x=\"234.1\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\">A ~ Bernoulli</text>\n",
       "<text text-anchor=\"start\" x=\"234.1\" y=\"-190.8\" font-family=\"Times,serif\" font-size=\"14.00\">Y ~ Normal</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x29d067eb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the model\n",
    "pyro.render_model(\n",
    "    ConditionedCausalGLM(torch.zeros(1, 1), torch.zeros(1), torch.zeros(1)),\n",
    "    render_params=True, \n",
    "    render_distributions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data\n",
    "\n",
    "For evaluation, we generate `N_datasets` datasets, each with `N` samples. We compare vanilla estimates of the target functional with the double robust estimates of the target functional across the `N_sims` datasets. We use a similar data generating process as in Kennedy (2022)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroundTruthModel(CausalGLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        p: int,\n",
    "        alpha: int,\n",
    "        beta: int,\n",
    "        link_fn: Callable[..., dist.Distribution] = lambda mu: dist.Normal(mu, 1.0),\n",
    "        treatment_weight: float = 0.0,\n",
    "    ):\n",
    "        super().__init__(p, link_fn)\n",
    "        self.alpha = alpha  # sparsity of propensity weights\n",
    "        self.beta = beta  # sparisty of outcome weights\n",
    "        self.treatment_weight = treatment_weight\n",
    "\n",
    "    def sample_outcome_weights(self):\n",
    "        outcome_weights = 1 / math.sqrt(self.beta) * torch.ones(self.p)\n",
    "        outcome_weights[self.beta :] = 0.0\n",
    "        return outcome_weights\n",
    "\n",
    "    def sample_propensity_weights(self):\n",
    "        propensity_weights = 1 / math.sqrt(self.alpha) * torch.ones(self.p)\n",
    "        propensity_weights[self.alpha :] = 0.0\n",
    "        return propensity_weights\n",
    "\n",
    "    def sample_treatment_weight(self):\n",
    "        return torch.tensor(self.treatment_weight)\n",
    "\n",
    "    def sample_intercept(self):\n",
    "        return torch.tensor(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_datasets = 1\n",
    "simulated_datasets = []\n",
    "\n",
    "# Data configuration\n",
    "p = 200\n",
    "alpha = 50\n",
    "beta = 50\n",
    "N_train = 500\n",
    "N_test = 500\n",
    "\n",
    "true_model = GroundTruthModel(p, alpha, beta)\n",
    "\n",
    "for _ in range(N_datasets):\n",
    "    # Generate data\n",
    "    D_train = Predictive(\n",
    "        true_model, num_samples=N_train, return_sites=[\"X\", \"A\", \"Y\"]\n",
    "    )()\n",
    "    D_test = Predictive(\n",
    "        true_model, num_samples=N_test, return_sites=[\"X\", \"A\", \"Y\"]\n",
    "    )()\n",
    "    simulated_datasets.append((D_train, D_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit parameters via maximum likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_params = []\n",
    "for i in range(N_datasets):\n",
    "    # Generate data\n",
    "    D_train = simulated_datasets[i][0]\n",
    "\n",
    "    # Fit model using maximum likelihood\n",
    "    conditioned_model = ConditionedCausalGLM(\n",
    "        X=D_train[\"X\"], A=D_train[\"A\"], Y=D_train[\"Y\"]\n",
    "    )\n",
    "    \n",
    "    guide_train = pyro.infer.autoguide.AutoDelta(conditioned_model)\n",
    "    elbo = pyro.infer.Trace_ELBO()(conditioned_model, guide_train)\n",
    "\n",
    "    # initialize parameters\n",
    "    elbo()\n",
    "    adam = torch.optim.Adam(elbo.parameters(), lr=0.03)\n",
    "\n",
    "    # Do gradient steps\n",
    "    for _ in range(2000):\n",
    "        adam.zero_grad()\n",
    "        loss = elbo()\n",
    "        loss.backward()\n",
    "        adam.step()\n",
    "\n",
    "    theta_hat = {\n",
    "        k: v.clone().detach().requires_grad_(True) for k, v in guide_train().items()\n",
    "    }\n",
    "    fitted_params.append(theta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Query: Average treatment effect (ATE)\n",
    "\n",
    "The average treatment effect summarizes, on average, how much the treatment changes the response, $ATE = \\mathbb{E}[Y|do(A=1)] - \\mathbb{E}[Y|do(A=0)]$. The `do` notation indicates that the expectations are taken according to *intervened* versions of the model, with $A$ set to a particular value. Note from our [tutorial](tutorial_i.ipynb) that this is different from conditioning on $A$ in the original `causal_model`, which assumes $X$ and $T$ are dependent.\n",
    "\n",
    "\n",
    "To implement this query in ChiRho, we define the `ATEFunctional` class which take in a `model` and `guide` and returns the average treatment effect by simulating from the posterior predictive distribution of the model and guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the target functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATEFunctional(torch.nn.Module):\n",
    "    def __init__(self, model: Callable, *, num_monte_carlo: int = 100):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.num_monte_carlo = num_monte_carlo\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        with MultiWorldCounterfactual():\n",
    "            with pyro.plate(\"monte_carlo_functional\", size=self.num_monte_carlo, dim=-2):\n",
    "                with do(actions=dict(A=(torch.tensor(0.0), torch.tensor(1.0)))):\n",
    "                    Ys = self.model(*args, **kwargs)\n",
    "                Y0 = gather(Ys, IndexSet(A={1}), event_dim=0)\n",
    "                Y1 = gather(Ys, IndexSet(A={2}), event_dim=0)\n",
    "        ate = (Y1 - Y0).mean(dim=-2, keepdim=True).mean(dim=-1, keepdim=True).squeeze()\n",
    "        return pyro.deterministic(\"ATE\", ate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed form doubly robust correction\n",
    "\n",
    "For the average treatment effect functional, there exists a closed-form analytical formula for the doubly robust correction. This formula is derived in Kennedy (2022) and is implemented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closed form expression\n",
    "def closed_form_doubly_robust_ate_correction(X_test, theta) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    X = X_test[\"X\"]\n",
    "    A = X_test[\"A\"]\n",
    "    Y = X_test[\"Y\"]\n",
    "    pi_X = torch.sigmoid(X.mv(theta[\"propensity_weights\"]))\n",
    "    mu_X = (\n",
    "        X.mv(theta[\"outcome_weights\"])\n",
    "        + A * theta[\"treatment_weight\"]\n",
    "        + theta[\"intercept\"]\n",
    "    )\n",
    "    analytic_eif_at_test_pts = (A / pi_X - (1 - A) / (1 - pi_X)) * (Y - mu_X)\n",
    "    analytic_correction = analytic_eif_at_test_pts.mean()\n",
    "    return analytic_correction, analytic_eif_at_test_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing automated doubly robust correction via Monte Carlo\n",
    "\n",
    "While the doubly robust correction term is known in closed-form for the average treatment effect functional, our `one_step_correction` function in `ChiRho` works for a wide class of other functionals. We focus on the average treatment effect functional here so that we have a ground truth to compare `one_step_correction` against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class to create a trivial guide that returns the maximum likelihood estimate\n",
    "class MLEGuide(torch.nn.Module):\n",
    "    def __init__(self, mle_est: ParamDict):\n",
    "        super().__init__()\n",
    "        self.names = list(mle_est.keys())\n",
    "        for name, value in mle_est.items():\n",
    "            setattr(self, name + \"_param\", torch.nn.Parameter(value))\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        for name in self.names:\n",
    "            value = getattr(self, name + \"_param\")\n",
    "            pyro.sample(\n",
    "                name, pyro.distributions.Delta(value, event_dim=len(value.shape))\n",
    "            )\n",
    "\n",
    "# Compute doubly robust ATE estimates using both the automated and closed form expressions\n",
    "plug_in_ates = []\n",
    "analytic_corrections = []\n",
    "automated_monte_carlo_corrections = []\n",
    "for i in range(N_datasets):\n",
    "    theta_hat = fitted_params[i]\n",
    "    D_test = simulated_datasets[i][1]\n",
    "    mle_guide = MLEGuide(theta_hat)\n",
    "    functional = functools.partial(ATEFunctional, num_monte_carlo=10000)\n",
    "    ate_plug_in = functional(\n",
    "        PredictiveModel(CausalGLM(p), mle_guide)\n",
    "    )()\n",
    "    analytic_correction, analytic_eif_at_test_pts = closed_form_doubly_robust_ate_correction(D_test, theta_hat)\n",
    "    automated_monte_carlo_correction = one_step_correction(\n",
    "        PredictiveModel(CausalGLM(p), mle_guide),\n",
    "        functional, \n",
    "        num_samples_outer=max(10000, 100 * p), \n",
    "        num_samples_inner=1\n",
    "    )(D_test)\n",
    "\n",
    "    plug_in_ates.append(ate_plug_in.detach().item())\n",
    "    analytic_corrections.append(analytic_correction.detach().item())\n",
    "    automated_monte_carlo_corrections.append(automated_monte_carlo_correction.detach().item())\n",
    "\n",
    "plug_in_ates = np.array(plug_in_ates)\n",
    "analytic_corrections = np.array(analytic_corrections)\n",
    "automated_monte_carlo_corrections = np.array(automated_monte_carlo_corrections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"plug_in_ate\": plug_in_ates,\n",
    "        \"analytic_correction\": plug_in_ates + analytic_corrections,\n",
    "        \"automated_monte_carlo_correction\": plug_in_ates + automated_monte_carlo_corrections,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plug_in_ate</th>\n",
       "      <th>analytic_correction</th>\n",
       "      <th>automated_monte_carlo_correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       plug_in_ate  analytic_correction  automated_monte_carlo_correction\n",
       "count         1.00                 1.00                              1.00\n",
       "mean          0.34                 0.29                              0.31\n",
       "std            NaN                  NaN                               NaN\n",
       "min           0.34                 0.29                              0.31\n",
       "25%           0.34                 0.29                              0.31\n",
       "50%           0.34                 0.29                              0.31\n",
       "75%           0.34                 0.29                              0.31\n",
       "max           0.34                 0.29                              0.31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The true treatment effect is 0, so a mean estimate closer to zero is better\n",
    "results.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1n/rv21b_n10gx0tp5_zz33z7qc0000gn/T/ipykernel_35884/1648148626.py:4: UserWarning: Dataset has 0 variance; skipping density estimate. Pass `warn_singular=False` to disable this warning.\n",
      "  sns.kdeplot(\n",
      "/var/folders/1n/rv21b_n10gx0tp5_zz33z7qc0000gn/T/ipykernel_35884/1648148626.py:9: UserWarning: Dataset has 0 variance; skipping density estimate. Pass `warn_singular=False` to disable this warning.\n",
      "  sns.kdeplot(\n",
      "/var/folders/1n/rv21b_n10gx0tp5_zz33z7qc0000gn/T/ipykernel_35884/1648148626.py:14: UserWarning: Dataset has 0 variance; skipping density estimate. Pass `warn_singular=False` to disable this warning.\n",
      "  sns.kdeplot(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'ATE Estimate')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.kdeplot(\n",
    "    results['plug_in_ate'], \n",
    "    label=\"Plug-in\", ax=ax\n",
    ")\n",
    "\n",
    "sns.kdeplot(\n",
    "    results['automated_monte_carlo_correction'], \n",
    "    label=\"DR-Monte Carlo\", ax=ax\n",
    ")\n",
    "\n",
    "sns.kdeplot(\n",
    "    results['analytic_correction'], \n",
    "    label=\"DR-Analytic\", ax=ax\n",
    ")\n",
    "\n",
    "ax.axvline(0, color=\"black\", label=\"True ATE\", linestyle=\"--\")\n",
    "ax.set_yticks([])\n",
    "sns.despine()\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlabel(\"ATE Estimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(\n",
    "    results['automated_monte_carlo_correction'],\n",
    "    results['analytic_correction'],\n",
    ")\n",
    "plt.plot(np.linspace(-.1, .5), np.linspace(-.1, .5), color=\"black\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"DR-Monte Carlo\")\n",
    "plt.ylabel(\"DR-Analytic\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _square_scaled_dist(self, X, Z=None, lengthscale=1.0):\n",
    "#     r\"\"\"\n",
    "#     Returns :math:`\\|\\frac{X-Z}{l}\\|^2`.\n",
    "#     \"\"\"\n",
    "#     if Z is None:\n",
    "#         Z = X\n",
    "\n",
    "#     if X.size(-1) != Z.size(-1):\n",
    "#         raise ValueError(\"Inputs must have the same number of features.\")\n",
    "\n",
    "#     X2 = X.unsqueeze(-2)  # Shape: (..., N, 1, P)\n",
    "#     Z2 = Z.unsqueeze(-3)  # Shape: (..., 1, M, P)\n",
    "#     squared_diff = (X2 - Z2) ** 2\n",
    "#     squared_distances = torch.sum(squared_diff, dim=-1)\n",
    "#     # scaled_X = X / lengthscale\n",
    "#     # scaled_Z = Z / lengthscale\n",
    "#     # X2 = torch.einsum(\"...np,...mp->...nm\", scaled_X, scaled_X)\n",
    "#     # Z2 = torch.einsum(\"...np,...mp->...nm\", scaled_Z, scaled_Z)\n",
    "#     # XZ = torch.einsum(\"...np,...mp->...nm\", scaled_X, scaled_Z)\n",
    "#     # r2 = X2 - 2 * XZ + Z2.t()\n",
    "#     return r2.clamp(min=0)\n",
    "\n",
    "\n",
    "# def rbf_kernel(X, Z=None, lengthscale=1.0):\n",
    "#     return torch.exp(-0.5 * _square_scaled_dist(X, Z, lengthscale=lengthscale))\n",
    "\n",
    "def linear_kernel(X, Z=None):\n",
    "    if Z == None:\n",
    "        Z = X\n",
    "    return torch.einsum(\"...np,...mp->...nm\", X, Z)\n",
    "\n",
    "class CausalGP(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X_train: torch.Tensor,\n",
    "        A_train: torch.Tensor,\n",
    "        Y_train: torch.Tensor,\n",
    "        kernel,\n",
    "        noise: float = 1.0,\n",
    "        prior_scale: Optional[float] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.XA_train = torch.concatenate([X_train, A_train.unsqueeze(-1)], dim=-1)\n",
    "        self.p = X_train.shape[1]\n",
    "        self.kernel = kernel\n",
    "        self.noise = noise\n",
    "        alpha, Lff = self._gp_mean_cholesky(self.XA_train, Y_train)\n",
    "        self.alpha = torch.nn.Parameter(alpha)\n",
    "        self.Lff = Lff\n",
    "        if prior_scale is None:\n",
    "            self.prior_scale = 1 / math.sqrt(self.p)\n",
    "        else:\n",
    "            self.prior_scale = prior_scale\n",
    "\n",
    "    def _gp_mean_cholesky(self, X: torch.Tensor, Y: torch.Tensor):\n",
    "        N = X.size(0)\n",
    "        Kff = self.kernel(X)\n",
    "        Kff.view(-1)[:: N + 1] += self.noise  # add noise to diagonal\n",
    "        Lff = torch.linalg.cholesky(Kff)\n",
    "        alpha = torch.cholesky_solve(Y.unsqueeze(-1), Lff).squeeze()\n",
    "        return alpha, Lff\n",
    "\n",
    "    def sample_covariate_loc_scale(self):\n",
    "        return torch.zeros(self.p), torch.ones(self.p)\n",
    "\n",
    "    def sample_propensity_weights(self):\n",
    "        return pyro.sample(\n",
    "            \"propensity_weights\",\n",
    "            dist.Normal(0.0, self.prior_scale).expand((self.p,)).to_event(1),\n",
    "        )\n",
    "\n",
    "    def forward(self):\n",
    "        x_loc, x_scale = self.sample_covariate_loc_scale()\n",
    "        X = pyro.sample(\"X\", dist.Normal(x_loc, x_scale).to_event(1))\n",
    "        propensity_weights = self.sample_propensity_weights()\n",
    "        A = pyro.sample(\n",
    "            \"A\",\n",
    "            dist.Bernoulli(\n",
    "                logits=torch.einsum(\"...i,...i->...\", X, propensity_weights)\n",
    "            ),\n",
    "        )\n",
    "        # Sample Y from GP\n",
    "        # print(X.shape, A.shape, A.unsqueeze(-1).shape)\n",
    "        X = X.expand(A.shape + X.shape[-1:])\n",
    "        XA = torch.concatenate([X, A.unsqueeze(-1)], dim=-1)\n",
    "        XA = XA.unsqueeze(0)\n",
    "        f_loc = torch.einsum(\n",
    "            \"...mn,...n->...m\", self.kernel(XA, self.XA_train), self.alpha\n",
    "        )\n",
    "        cov_train_x = torch.cholesky_solve(self.kernel(self.XA_train, XA), self.Lff)\n",
    "        f_cov = self.kernel(XA) - torch.einsum(\n",
    "            \"...mn,...nk->...mk\", self.kernel(XA, self.XA_train), cov_train_x\n",
    "        )\n",
    "        return pyro.sample(\"Y\", dist.MultivariateNormal(f_loc, f_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected parameter covariance_matrix (Tensor of shape (1, 10000, 10000)) of distribution MultivariateNormal(loc: torch.Size([1, 10000]), covariance_matrix: torch.Size([1, 10000, 10000])) to satisfy the constraint PositiveDefinite(), but found invalid values:\ntensor([[[ 0.1183,  0.0485,  0.0142,  ...,  0.0028,  0.0578,  0.0505],\n         [ 0.0485,  0.0644,  0.0488,  ..., -0.0104,  0.0055,  0.0235],\n         [ 0.0142,  0.0488,  0.0575,  ..., -0.0048, -0.0220, -0.0127],\n         ...,\n         [ 0.0028, -0.0104, -0.0048,  ...,  0.0055,  0.0013, -0.0084],\n         [ 0.0578,  0.0055, -0.0220,  ...,  0.0013,  0.0448,  0.0406],\n         [ 0.0505,  0.0235, -0.0127,  ..., -0.0084,  0.0406,  0.0536]]])\n          Trace Shapes:          \n           Param Sites:          \n          Sample Sites:          \n                 X dist 10000 | 2\n                  value 10000 | 2\npropensity_weights dist 10000 | 2\n                  value 10000 | 2\n                 A dist 10000 |  \n                  value 10000 |  ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb Cell 30\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m f_cov \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel(XA) \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39meinsum(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m...mn,...nk->...mk\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel(XA, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mXA_train), cov_train_x\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39mY\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39;49mMultivariateNormal(f_loc, f_cov))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/distributions/distribution.py:24\u001b[0m, in \u001b[0;36mDistributionMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 24\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/distributions/multivariate_normal.py:177\u001b[0m, in \u001b[0;36mMultivariateNormal.__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    176\u001b[0m event_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 177\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(batch_shape, event_shape, validate_args\u001b[39m=\u001b[39;49mvalidate_args)\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m scale_tril \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/distributions/distribution.py:68\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid\u001b[39m.\u001b[39mall():\n\u001b[0;32m---> 68\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected parameter \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof distribution \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mto satisfy the constraint \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(constraint)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut found invalid values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             )\n\u001b[1;32m     75\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter covariance_matrix (Tensor of shape (1, 10000, 10000)) of distribution MultivariateNormal(loc: torch.Size([1, 10000]), covariance_matrix: torch.Size([1, 10000, 10000])) to satisfy the constraint PositiveDefinite(), but found invalid values:\ntensor([[[ 0.1183,  0.0485,  0.0142,  ...,  0.0028,  0.0578,  0.0505],\n         [ 0.0485,  0.0644,  0.0488,  ..., -0.0104,  0.0055,  0.0235],\n         [ 0.0142,  0.0488,  0.0575,  ..., -0.0048, -0.0220, -0.0127],\n         ...,\n         [ 0.0028, -0.0104, -0.0048,  ...,  0.0055,  0.0013, -0.0084],\n         [ 0.0578,  0.0055, -0.0220,  ...,  0.0013,  0.0448,  0.0406],\n         [ 0.0505,  0.0235, -0.0127,  ..., -0.0084,  0.0406,  0.0536]]])",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb Cell 30\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m ate_plug_in \u001b[39m=\u001b[39m functional(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     fitted_gp_model\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m )()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m analytic_correction, analytic_eif_at_test_pts \u001b[39m=\u001b[39m closed_form_doubly_robust_ate_correction(D_test, theta_hat)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m automated_monte_carlo_correction \u001b[39m=\u001b[39m one_step_correction(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     fitted_gp_model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     functional, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     num_samples_outer\u001b[39m=\u001b[39;49m\u001b[39mmax\u001b[39;49m(\u001b[39m10000\u001b[39;49m, \u001b[39m100\u001b[39;49m \u001b[39m*\u001b[39;49m p), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     num_samples_inner\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m )(D_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m plug_in_ates\u001b[39m.\u001b[39mappend(ate_plug_in\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m analytic_corrections\u001b[39m.\u001b[39mappend(analytic_correction\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Desktop/causal_pyro/chirho/robust/handlers/estimators.py:39\u001b[0m, in \u001b[0;36mone_step_correction.<locals>._one_step\u001b[0;34m(test_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_one_step\u001b[39m(test_data: Point[T], \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m S:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m eif_fn(test_data, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/causal_pyro/chirho/robust/ops.py:132\u001b[0m, in \u001b[0;36minfluence_fn.<locals>._fn\u001b[0;34m(points, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(target)\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fn\u001b[39m(points: Point[T], \u001b[39m*\u001b[39margs: P\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: P\u001b[39m.\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m S:\n\u001b[1;32m    123\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m    Evaluates the efficient influence function for ``functional`` at each\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m    point in ``points``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m    :rtype: S\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     param_eif \u001b[39m=\u001b[39m linearized(points, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    133\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mvmap(\n\u001b[1;32m    134\u001b[0m         \u001b[39mlambda\u001b[39;00m d: torch\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39mjvp(\n\u001b[1;32m    135\u001b[0m             \u001b[39mlambda\u001b[39;00m p: func_target(p, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs), (target_params,), (d,)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         randomness\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdifferent\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    139\u001b[0m     )(param_eif)\n",
      "File \u001b[0;32m~/Desktop/causal_pyro/chirho/robust/internals/linearize.py:360\u001b[0m, in \u001b[0;36mlinearize.<locals>._fn\u001b[0;34m(points, *args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fn\u001b[39m(\n\u001b[1;32m    355\u001b[0m     points: Point[T],\n\u001b[1;32m    356\u001b[0m     \u001b[39m*\u001b[39margs: P\u001b[39m.\u001b[39margs,\n\u001b[1;32m    357\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: P\u001b[39m.\u001b[39mkwargs,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ParamDict:\n\u001b[1;32m    359\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 360\u001b[0m         data: Point[T] \u001b[39m=\u001b[39m predictive(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    361\u001b[0m         data \u001b[39m=\u001b[39m {k: data[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m points\u001b[39m.\u001b[39mkeys()}\n\u001b[1;32m    362\u001b[0m     fvp \u001b[39m=\u001b[39m make_empirical_fisher_vp(\n\u001b[1;32m    363\u001b[0m         batched_func_log_prob, log_prob_params, data, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    364\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/infer/predictive.py:273\u001b[0m, in \u001b[0;36mPredictive.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     return_sites \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_sites \u001b[39melse\u001b[39;00m return_sites\n\u001b[1;32m    264\u001b[0m     posterior_samples \u001b[39m=\u001b[39m _predictive(\n\u001b[1;32m    265\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mguide,\n\u001b[1;32m    266\u001b[0m         posterior_samples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m         model_kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m    272\u001b[0m     )\n\u001b[0;32m--> 273\u001b[0m \u001b[39mreturn\u001b[39;00m _predictive(\n\u001b[1;32m    274\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    275\u001b[0m     posterior_samples,\n\u001b[1;32m    276\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_samples,\n\u001b[1;32m    277\u001b[0m     return_sites\u001b[39m=\u001b[39;49mreturn_sites,\n\u001b[1;32m    278\u001b[0m     parallel\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel,\n\u001b[1;32m    279\u001b[0m     model_args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    280\u001b[0m     model_kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m    281\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/infer/predictive.py:137\u001b[0m, in \u001b[0;36m_predictive\u001b[0;34m(model, posterior_samples, num_samples, return_sites, return_trace, parallel, model_args, model_kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parallel:\n\u001b[1;32m    127\u001b[0m     \u001b[39mreturn\u001b[39;00m _predictive_sequential(\n\u001b[1;32m    128\u001b[0m         model,\n\u001b[1;32m    129\u001b[0m         posterior_samples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m         return_trace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    135\u001b[0m     )\n\u001b[0;32m--> 137\u001b[0m trace \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39;49mtrace(\n\u001b[1;32m    138\u001b[0m     poutine\u001b[39m.\u001b[39;49mcondition(vectorize(model), reshaped_samples)\n\u001b[1;32m    139\u001b[0m )\u001b[39m.\u001b[39;49mget_trace(\u001b[39m*\u001b[39;49mmodel_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m    140\u001b[0m predictions \u001b[39m=\u001b[39m {}\n\u001b[1;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m site, shape \u001b[39min\u001b[39;00m return_site_shapes\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_trace\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:180\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         exc \u001b[39m=\u001b[39m exc_type(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(exc_value, shapes))\n\u001b[1;32m    179\u001b[0m         exc \u001b[39m=\u001b[39m exc\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39mret\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb Cell 30\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m cov_train_x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcholesky_solve(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mXA_train, XA), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLff)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m f_cov \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel(XA) \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39meinsum(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m...mn,...nk->...mk\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel(XA, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mXA_train), cov_train_x\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/raj/Desktop/causal_pyro/docs/source/automated_dr_learner.ipynb#Y110sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39mY\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39;49mMultivariateNormal(f_loc, f_cov))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/pyro/distributions/distribution.py:24\u001b[0m, in \u001b[0;36mDistributionMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 24\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/distributions/multivariate_normal.py:177\u001b[0m, in \u001b[0;36mMultivariateNormal.__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc \u001b[39m=\u001b[39m loc\u001b[39m.\u001b[39mexpand(batch_shape \u001b[39m+\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,))\n\u001b[1;32m    176\u001b[0m event_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 177\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(batch_shape, event_shape, validate_args\u001b[39m=\u001b[39;49mvalidate_args)\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m scale_tril \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbroadcasted_scale_tril \u001b[39m=\u001b[39m scale_tril\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/basis/lib/python3.10/site-packages/torch/distributions/distribution.py:68\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         valid \u001b[39m=\u001b[39m constraint\u001b[39m.\u001b[39mcheck(value)\n\u001b[1;32m     67\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid\u001b[39m.\u001b[39mall():\n\u001b[0;32m---> 68\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected parameter \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of shape \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(value\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof distribution \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mto satisfy the constraint \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(constraint)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut found invalid values:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             )\n\u001b[1;32m     75\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter covariance_matrix (Tensor of shape (1, 10000, 10000)) of distribution MultivariateNormal(loc: torch.Size([1, 10000]), covariance_matrix: torch.Size([1, 10000, 10000])) to satisfy the constraint PositiveDefinite(), but found invalid values:\ntensor([[[ 0.1183,  0.0485,  0.0142,  ...,  0.0028,  0.0578,  0.0505],\n         [ 0.0485,  0.0644,  0.0488,  ..., -0.0104,  0.0055,  0.0235],\n         [ 0.0142,  0.0488,  0.0575,  ..., -0.0048, -0.0220, -0.0127],\n         ...,\n         [ 0.0028, -0.0104, -0.0048,  ...,  0.0055,  0.0013, -0.0084],\n         [ 0.0578,  0.0055, -0.0220,  ...,  0.0013,  0.0448,  0.0406],\n         [ 0.0505,  0.0235, -0.0127,  ..., -0.0084,  0.0406,  0.0536]]])\n          Trace Shapes:          \n           Param Sites:          \n          Sample Sites:          \n                 X dist 10000 | 2\n                  value 10000 | 2\npropensity_weights dist 10000 | 2\n                  value 10000 | 2\n                 A dist 10000 |  \n                  value 10000 |  "
     ]
    }
   ],
   "source": [
    "N_datasets = 1\n",
    "simulated_datasets = []\n",
    "\n",
    "# Data configuration\n",
    "p = 2\n",
    "alpha = 50\n",
    "beta = 50\n",
    "N_train = 51\n",
    "N_test = 6\n",
    "\n",
    "true_model = GroundTruthModel(p, alpha, beta)\n",
    "\n",
    "for _ in range(N_datasets):\n",
    "    # Generate data\n",
    "    D_train = Predictive(\n",
    "        true_model, num_samples=N_train, return_sites=[\"X\", \"A\", \"Y\"]\n",
    "    )()\n",
    "    D_test = Predictive(\n",
    "        true_model, num_samples=N_test, return_sites=[\"X\", \"A\", \"Y\"]\n",
    "    )()\n",
    "    simulated_datasets.append((D_train, D_test))\n",
    "\n",
    "\n",
    "fitted_params = []\n",
    "for i in range(N_datasets):\n",
    "    # Generate data\n",
    "    D_train = simulated_datasets[i][0]\n",
    "\n",
    "    # Fit model using maximum likelihood\n",
    "    conditioned_model = ConditionedCausalGLM(\n",
    "        X=D_train[\"X\"], A=D_train[\"A\"], Y=D_train[\"Y\"]\n",
    "    )\n",
    "    \n",
    "    guide_train = pyro.infer.autoguide.AutoDelta(conditioned_model)\n",
    "    elbo = pyro.infer.Trace_ELBO()(conditioned_model, guide_train)\n",
    "\n",
    "    # initialize parameters\n",
    "    elbo()\n",
    "    adam = torch.optim.Adam(elbo.parameters(), lr=0.03)\n",
    "\n",
    "    # Do gradient steps\n",
    "    for _ in range(2000):\n",
    "        adam.zero_grad()\n",
    "        loss = elbo()\n",
    "        loss.backward()\n",
    "        adam.step()\n",
    "\n",
    "    theta_hat = {\n",
    "        k: v.clone().detach().requires_grad_(True) for k, v in guide_train().items()\n",
    "    }\n",
    "    fitted_params.append(theta_hat)\n",
    "\n",
    "# Compute doubly robust ATE estimates using both the automated and closed form expressions\n",
    "plug_in_ates = []\n",
    "analytic_corrections = []\n",
    "automated_monte_carlo_corrections = []\n",
    "for i in range(N_datasets):\n",
    "    theta_hat = fitted_params[i]\n",
    "    D_train = simulated_datasets[i][0]\n",
    "    D_test = simulated_datasets[i][1]\n",
    "    functional = functools.partial(ATEFunctional, num_monte_carlo=500)\n",
    "    # gp_kernel = gp.kernels.RBF(input_dim=D_train['X'].shape[1] + 1)\n",
    "    gp_kernel = linear_kernel\n",
    "    fitted_gp_model = CausalGP(\n",
    "        X_train=D_train[\"X\"], A_train=D_train[\"A\"], Y_train=D_train[\"Y\"], kernel=gp_kernel\n",
    "    )\n",
    "    ate_plug_in = functional(\n",
    "        fitted_gp_model\n",
    "    )()\n",
    "    analytic_correction, analytic_eif_at_test_pts = closed_form_doubly_robust_ate_correction(D_test, theta_hat)\n",
    "    automated_monte_carlo_correction = one_step_correction(\n",
    "        fitted_gp_model,\n",
    "        functional, \n",
    "        num_samples_outer=max(10000, 100 * p), \n",
    "        num_samples_inner=1\n",
    "    )(D_test)\n",
    "\n",
    "    plug_in_ates.append(ate_plug_in.detach().item())\n",
    "    analytic_corrections.append(analytic_correction.detach().item())\n",
    "    automated_monte_carlo_corrections.append(automated_monte_carlo_correction.detach().item())\n",
    "\n",
    "plug_in_ates = np.array(plug_in_ates)\n",
    "analytic_corrections = np.array(analytic_corrections)\n",
    "automated_monte_carlo_corrections = np.array(automated_monte_carlo_corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATEFunctional2(torch.nn.Module):\n",
    "    def __init__(self, model: Callable, *, num_monte_carlo: int = 7):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.num_monte_carlo = num_monte_carlo\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        with MultiWorldCounterfactual():\n",
    "            with pyro.plate(\"monte_carlo_functional\", size=self.num_monte_carlo, dim=-2):\n",
    "                with do(actions=dict(A=(torch.tensor(0.0), torch.tensor(1.0)))):\n",
    "                    Ys = self.model(*args, **kwargs)\n",
    "                    print(Ys)\n",
    "        #         Y0 = gather(Ys, IndexSet(A={1}), event_dim=0)\n",
    "        #         Y1 = gather(Ys, IndexSet(A={2}), event_dim=0)\n",
    "        # ate = (Y1 - Y0).mean(dim=-2, keepdim=True).mean(dim=-1, keepdim=True).squeeze()\n",
    "        return Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[[ 0.1153],\n",
      "            [ 0.0033],\n",
      "            [-1.6923],\n",
      "            ...,\n",
      "            [ 0.3421],\n",
      "            [-0.9091],\n",
      "            [-0.7877]],\n",
      "\n",
      "           [[-0.5976],\n",
      "            [-0.4744],\n",
      "            [ 1.2695],\n",
      "            ...,\n",
      "            [ 1.1632],\n",
      "            [-1.0379],\n",
      "            [-0.7739]],\n",
      "\n",
      "           [[-0.0456],\n",
      "            [-1.1869],\n",
      "            [ 0.2358],\n",
      "            ...,\n",
      "            [-0.2167],\n",
      "            [-1.4200],\n",
      "            [ 0.4552]],\n",
      "\n",
      "           ...,\n",
      "\n",
      "           [[ 0.4207],\n",
      "            [ 0.0874],\n",
      "            [ 0.8749],\n",
      "            ...,\n",
      "            [ 0.5122],\n",
      "            [-0.7757],\n",
      "            [ 0.1773]],\n",
      "\n",
      "           [[ 0.0048],\n",
      "            [ 0.2891],\n",
      "            [ 1.0170],\n",
      "            ...,\n",
      "            [ 0.5254],\n",
      "            [-1.0860],\n",
      "            [-0.1508]],\n",
      "\n",
      "           [[-0.0552],\n",
      "            [-0.0671],\n",
      "            [ 0.4524],\n",
      "            ...,\n",
      "            [ 0.4744],\n",
      "            [-0.8206],\n",
      "            [ 0.0283]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[-0.5222],\n",
      "            [ 0.6568],\n",
      "            [ 0.3793],\n",
      "            ...,\n",
      "            [ 1.2790],\n",
      "            [-1.2353],\n",
      "            [-0.3167]],\n",
      "\n",
      "           [[-0.1027],\n",
      "            [ 0.2399],\n",
      "            [ 0.9468],\n",
      "            ...,\n",
      "            [ 0.5135],\n",
      "            [-0.1571],\n",
      "            [-0.2311]],\n",
      "\n",
      "           [[-0.1315],\n",
      "            [-0.7789],\n",
      "            [ 0.4469],\n",
      "            ...,\n",
      "            [ 0.8951],\n",
      "            [-1.5297],\n",
      "            [-0.0828]],\n",
      "\n",
      "           ...,\n",
      "\n",
      "           [[-0.3345],\n",
      "            [ 0.3389],\n",
      "            [ 0.3769],\n",
      "            ...,\n",
      "            [ 0.6804],\n",
      "            [-1.2738],\n",
      "            [ 0.3441]],\n",
      "\n",
      "           [[-0.0517],\n",
      "            [-0.4922],\n",
      "            [ 0.3698],\n",
      "            ...,\n",
      "            [ 0.7731],\n",
      "            [-2.3268],\n",
      "            [ 0.0900]],\n",
      "\n",
      "           [[-0.2767],\n",
      "            [ 0.1840],\n",
      "            [ 1.3493],\n",
      "            ...,\n",
      "            [ 1.4123],\n",
      "            [-0.4253],\n",
      "            [ 0.2742]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[ 0.5659],\n",
      "            [ 0.0702],\n",
      "            [ 0.8400],\n",
      "            ...,\n",
      "            [-0.5476],\n",
      "            [-0.6532],\n",
      "            [-0.6660]],\n",
      "\n",
      "           [[-0.0744],\n",
      "            [ 0.0523],\n",
      "            [ 0.4459],\n",
      "            ...,\n",
      "            [ 1.0829],\n",
      "            [-2.4500],\n",
      "            [-0.6062]],\n",
      "\n",
      "           [[-0.5200],\n",
      "            [ 0.2325],\n",
      "            [-0.7063],\n",
      "            ...,\n",
      "            [ 0.1345],\n",
      "            [-2.3139],\n",
      "            [-0.1517]],\n",
      "\n",
      "           ...,\n",
      "\n",
      "           [[-0.6800],\n",
      "            [-0.1905],\n",
      "            [ 0.7433],\n",
      "            ...,\n",
      "            [ 0.0958],\n",
      "            [-0.7223],\n",
      "            [ 0.1364]],\n",
      "\n",
      "           [[-0.5726],\n",
      "            [-0.8159],\n",
      "            [ 0.2054],\n",
      "            ...,\n",
      "            [-0.2757],\n",
      "            [-1.3368],\n",
      "            [-0.9896]],\n",
      "\n",
      "           [[-0.0875],\n",
      "            [-0.4222],\n",
      "            [ 0.6592],\n",
      "            ...,\n",
      "            [ 0.8006],\n",
      "            [-1.5176],\n",
      "            [-0.4557]]]]]], grad_fn=<ExpandBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[[[ 0.1153],\n",
       "            [ 0.0033],\n",
       "            [-1.6923],\n",
       "            ...,\n",
       "            [ 0.3421],\n",
       "            [-0.9091],\n",
       "            [-0.7877]],\n",
       "\n",
       "           [[-0.5976],\n",
       "            [-0.4744],\n",
       "            [ 1.2695],\n",
       "            ...,\n",
       "            [ 1.1632],\n",
       "            [-1.0379],\n",
       "            [-0.7739]],\n",
       "\n",
       "           [[-0.0456],\n",
       "            [-1.1869],\n",
       "            [ 0.2358],\n",
       "            ...,\n",
       "            [-0.2167],\n",
       "            [-1.4200],\n",
       "            [ 0.4552]],\n",
       "\n",
       "           ...,\n",
       "\n",
       "           [[ 0.4207],\n",
       "            [ 0.0874],\n",
       "            [ 0.8749],\n",
       "            ...,\n",
       "            [ 0.5122],\n",
       "            [-0.7757],\n",
       "            [ 0.1773]],\n",
       "\n",
       "           [[ 0.0048],\n",
       "            [ 0.2891],\n",
       "            [ 1.0170],\n",
       "            ...,\n",
       "            [ 0.5254],\n",
       "            [-1.0860],\n",
       "            [-0.1508]],\n",
       "\n",
       "           [[-0.0552],\n",
       "            [-0.0671],\n",
       "            [ 0.4524],\n",
       "            ...,\n",
       "            [ 0.4744],\n",
       "            [-0.8206],\n",
       "            [ 0.0283]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[-0.5222],\n",
       "            [ 0.6568],\n",
       "            [ 0.3793],\n",
       "            ...,\n",
       "            [ 1.2790],\n",
       "            [-1.2353],\n",
       "            [-0.3167]],\n",
       "\n",
       "           [[-0.1027],\n",
       "            [ 0.2399],\n",
       "            [ 0.9468],\n",
       "            ...,\n",
       "            [ 0.5135],\n",
       "            [-0.1571],\n",
       "            [-0.2311]],\n",
       "\n",
       "           [[-0.1315],\n",
       "            [-0.7789],\n",
       "            [ 0.4469],\n",
       "            ...,\n",
       "            [ 0.8951],\n",
       "            [-1.5297],\n",
       "            [-0.0828]],\n",
       "\n",
       "           ...,\n",
       "\n",
       "           [[-0.3345],\n",
       "            [ 0.3389],\n",
       "            [ 0.3769],\n",
       "            ...,\n",
       "            [ 0.6804],\n",
       "            [-1.2738],\n",
       "            [ 0.3441]],\n",
       "\n",
       "           [[-0.0517],\n",
       "            [-0.4922],\n",
       "            [ 0.3698],\n",
       "            ...,\n",
       "            [ 0.7731],\n",
       "            [-2.3268],\n",
       "            [ 0.0900]],\n",
       "\n",
       "           [[-0.2767],\n",
       "            [ 0.1840],\n",
       "            [ 1.3493],\n",
       "            ...,\n",
       "            [ 1.4123],\n",
       "            [-0.4253],\n",
       "            [ 0.2742]]]],\n",
       "\n",
       "\n",
       "\n",
       "         [[[[ 0.5659],\n",
       "            [ 0.0702],\n",
       "            [ 0.8400],\n",
       "            ...,\n",
       "            [-0.5476],\n",
       "            [-0.6532],\n",
       "            [-0.6660]],\n",
       "\n",
       "           [[-0.0744],\n",
       "            [ 0.0523],\n",
       "            [ 0.4459],\n",
       "            ...,\n",
       "            [ 1.0829],\n",
       "            [-2.4500],\n",
       "            [-0.6062]],\n",
       "\n",
       "           [[-0.5200],\n",
       "            [ 0.2325],\n",
       "            [-0.7063],\n",
       "            ...,\n",
       "            [ 0.1345],\n",
       "            [-2.3139],\n",
       "            [-0.1517]],\n",
       "\n",
       "           ...,\n",
       "\n",
       "           [[-0.6800],\n",
       "            [-0.1905],\n",
       "            [ 0.7433],\n",
       "            ...,\n",
       "            [ 0.0958],\n",
       "            [-0.7223],\n",
       "            [ 0.1364]],\n",
       "\n",
       "           [[-0.5726],\n",
       "            [-0.8159],\n",
       "            [ 0.2054],\n",
       "            ...,\n",
       "            [-0.2757],\n",
       "            [-1.3368],\n",
       "            [-0.9896]],\n",
       "\n",
       "           [[-0.0875],\n",
       "            [-0.4222],\n",
       "            [ 0.6592],\n",
       "            ...,\n",
       "            [ 0.8006],\n",
       "            [-1.5176],\n",
       "            [-0.4557]]]]]], grad_fn=<ExpandBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functools.partial(ATEFunctional2, num_monte_carlo=500)(fitted_gp_model)()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Kennedy, Edward. \"Towards optimal doubly robust estimation of heterogeneous causal effects\", 2022. https://arxiv.org/abs/2004.14497."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
